 State Dimensions :- 3
 Action Dimensions :- 1
 Action Max :- 200
EPISODE :- 0
Random Player utility: 41.612265
=================Random Agent Turn=================
Action taken: 7.543307
===============Feedback to learned agent round===============
Observation:
[0, 0, 7.543307117487913]
Reward: -1.000000, Currnt Bid: 7.543307
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 89.472816
Exploit action: 89.472816
Action taken: 89.472816
===============Feedback to random agent round===============
Currnt Bid: 89.472816
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([89.47282], dtype=float32), 7.543307117487913]
Reward: 10.527184, Currnt Bid: 89.472816
Is done? True
Episode End
Positive: 1, Negative: 0
Models saved successfully
EPISODE :- 1
Random Player utility: 36.132893
=================Random Agent Turn=================
Action taken: 25.850161
===============Feedback to learned agent round===============
Observation:
[0, 0, 25.85016120322916]
Reward: -1.000000, Currnt Bid: 25.850161
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([88.0612])
After exploration
[114.29938194]
Explore action: 114.299382
Action taken: 114.299382
===============Feedback to random agent round===============
Currnt Bid: 114.299382
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([114.29938194]), 25.85016120322916]
Reward: -14.299382, Currnt Bid: 114.299382
Is done? True
Episode End
Positive: 1, Negative: 1
EPISODE :- 2
Random Player utility: 194.390892
=================Random Agent Turn=================
Action taken: 121.727778
===============Feedback to learned agent round===============
Observation:
[0, 0, 121.72777844509865]
Reward: -1.000000, Currnt Bid: 121.727778
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([86.7810])
After exploration
[117.76773684]
Explore action: 117.767737
Action taken: 117.767737
===============Feedback to random agent round===============
Currnt Bid: 121.727778
=================Random Agent Turn=================
Action taken: 168.275916
===============Feedback to learned agent round===============
Observation:
[1, 0, 121.72777844509865]
Reward: -2.000000, Currnt Bid: 121.727778
Is done? True
Episode End
Positive: 1, Negative: 1
EPISODE :- 3
Random Player utility: 145.797352
=================Random Agent Turn=================
Action taken: 6.956517
===============Feedback to learned agent round===============
Observation:
[0, 0, 6.956517080759455]
Reward: -1.000000, Currnt Bid: 6.956517
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([85.0151])
After exploration
[111.7142015]
Explore action: 111.714202
Action taken: 111.714202
===============Feedback to random agent round===============
Currnt Bid: 111.714202
=================Random Agent Turn=================
Action taken: 136.962652
===============Feedback to learned agent round===============
Observation:
[0, array([111.7142015]), array([136.96265205])]
Reward: -1.000000, Currnt Bid: 136.962652
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([82.9509])
After exploration
[112.62576399]
Explore action: 112.625764
Action taken: 112.625764
===============Feedback to random agent round===============
Currnt Bid: 136.962652
=================Random Agent Turn=================
Action taken: 138.613098
===============Feedback to learned agent round===============
Observation:
[1, array([111.7142015]), array([136.96265205])]
Reward: -2.000000, Currnt Bid: 136.962652
Is done? True
Episode End
Positive: 1, Negative: 1
EPISODE :- 4
Random Player utility: 78.049285
=================Random Agent Turn=================
Action taken: 30.779867
===============Feedback to learned agent round===============
Observation:
[0, 0, 30.779867350512536]
Reward: -1.000000, Currnt Bid: 30.779867
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([80.6798])
After exploration
[116.58505701]
Explore action: 116.585057
Action taken: 116.585057
===============Feedback to random agent round===============
Currnt Bid: 116.585057
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([116.58505701]), 30.779867350512536]
Reward: -16.585057, Currnt Bid: 116.585057
Is done? True
Episode End
Positive: 1, Negative: 2
EPISODE :- 5
Random Player utility: 153.920330
=================Random Agent Turn=================
Action taken: 52.486289
===============Feedback to learned agent round===============
Observation:
[0, 0, 52.486289320800594]
Reward: -1.000000, Currnt Bid: 52.486289
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 89.445412
Exploit action: 89.445412
Action taken: 89.445412
===============Feedback to random agent round===============
Currnt Bid: 89.445412
=================Random Agent Turn=================
Action taken: 99.762154
===============Feedback to learned agent round===============
Observation:
[0, array([89.44541], dtype=float32), array([99.76215], dtype=float32)]
Reward: -1.000000, Currnt Bid: 99.762154
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 90.740372
Exploit action: 90.740372
Action taken: 90.740372
===============Feedback to random agent round===============
Currnt Bid: 99.762154
=================Random Agent Turn=================
Action taken: 123.024269
===============Feedback to learned agent round===============
Observation:
[1, array([89.44541], dtype=float32), array([99.76215], dtype=float32)]
Reward: -2.000000, Currnt Bid: 99.762154
Is done? True
Episode End
Positive: 1, Negative: 2
EPISODE :- 6
Random Player utility: 40.997268
=================Random Agent Turn=================
Action taken: 28.581859
===============Feedback to learned agent round===============
Observation:
[0, 0, 28.58185932309992]
Reward: -1.000000, Currnt Bid: 28.581859
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([64.8533])
After exploration
[110.17579194]
Explore action: 110.175792
Action taken: 110.175792
===============Feedback to random agent round===============
Currnt Bid: 110.175792
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([110.17579194]), 28.58185932309992]
Reward: -10.175792, Currnt Bid: 110.175792
Is done? True
Episode End
Positive: 1, Negative: 3
EPISODE :- 7
Random Player utility: 215.049702
=================Random Agent Turn=================
Action taken: 167.365791
===============Feedback to learned agent round===============
Observation:
[0, 0, 167.36579111324198]
Reward: -1.000000, Currnt Bid: 167.365791
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([54.5452])
After exploration
[111.51449839]
Explore action: 111.514498
Action taken: 111.514498
===============Feedback to random agent round===============
Currnt Bid: 167.365791
=================Random Agent Turn=================
Action taken: 192.127297
===============Feedback to learned agent round===============
Observation:
[1, 0, 167.36579111324198]
Reward: -2.000000, Currnt Bid: 167.365791
Is done? True
Episode End
Positive: 1, Negative: 3
EPISODE :- 8
Random Player utility: 115.405964
=================Random Agent Turn=================
Action taken: 14.172684
===============Feedback to learned agent round===============
Observation:
[0, 0, 14.172684334022678]
Reward: -1.000000, Currnt Bid: 14.172684
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([42.4143])
After exploration
[110.82557081]
Explore action: 110.825571
Action taken: 110.825571
===============Feedback to random agent round===============
Currnt Bid: 110.825571
=================Random Agent Turn=================
Action taken: 115.040111
===============Feedback to learned agent round===============
Observation:
[0, array([110.82557081]), array([115.04011075])]
Reward: -1.000000, Currnt Bid: 115.040111
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([8.9414])
After exploration
[87.33630434]
Explore action: 87.336304
Action taken: 87.336304
===============Feedback to random agent round===============
Currnt Bid: 115.040111
=================Random Agent Turn=================
Action taken: 115.184050
===============Feedback to learned agent round===============
Observation:
[1, array([110.82557081]), array([115.04011075])]
Reward: -2.000000, Currnt Bid: 115.040111
Is done? True
Episode End
Positive: 1, Negative: 3
EPISODE :- 9
Random Player utility: 159.350055
=================Random Agent Turn=================
Action taken: 62.236025
===============Feedback to learned agent round===============
Observation:
[0, 0, 62.23602538956057]
Reward: -1.000000, Currnt Bid: 62.236025
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([24.3466])
After exploration
[82.18366705]
Explore action: 82.183667
Action taken: 82.183667
===============Feedback to random agent round===============
Currnt Bid: 82.183667
=================Random Agent Turn=================
Action taken: 125.120279
===============Feedback to learned agent round===============
Observation:
[0, array([82.18366705]), array([125.12027886])]
Reward: -1.000000, Currnt Bid: 125.120279
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([5.9605e-06])
After exploration
[56.61295474]
Explore action: 56.612955
Action taken: 56.612955
===============Feedback to random agent round===============
Currnt Bid: 125.120279
=================Random Agent Turn=================
Action taken: 146.809161
===============Feedback to learned agent round===============
Observation:
[1, array([82.18366705]), array([125.12027886])]
Reward: -2.000000, Currnt Bid: 125.120279
Is done? True
Episode End
Positive: 1, Negative: 3
EPISODE :- 10
Random Player utility: 40.651522
=================Random Agent Turn=================
Action taken: 23.103772
===============Feedback to learned agent round===============
Observation:
[0, 0, 23.10377233115064]
Reward: -1.000000, Currnt Bid: 23.103772
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 89.357643
Exploit action: 89.357643
Action taken: 89.357643
===============Feedback to random agent round===============
Currnt Bid: 89.357643
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([89.35764], dtype=float32), 23.10377233115064]
Reward: 10.642357, Currnt Bid: 89.357643
Is done? True
Episode End
Positive: 2, Negative: 3
EPISODE :- 11
Random Player utility: 199.118444
=================Random Agent Turn=================
Action taken: 170.732211
===============Feedback to learned agent round===============
Observation:
[0, 0, 170.73221110685208]
Reward: -1.000000, Currnt Bid: 170.732211
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([7.0649])
After exploration
[56.95400546]
Explore action: 56.954005
Action taken: 56.954005
===============Feedback to random agent round===============
Currnt Bid: 170.732211
=================Random Agent Turn=================
Action taken: 178.690927
===============Feedback to learned agent round===============
Observation:
[1, 0, 170.73221110685208]
Reward: -2.000000, Currnt Bid: 170.732211
Is done? True
Episode End
Positive: 2, Negative: 3
EPISODE :- 12
Random Player utility: 64.927807
=================Random Agent Turn=================
Action taken: 7.241007
===============Feedback to learned agent round===============
Observation:
[0, 0, 7.2410071890098875]
Reward: -1.000000, Currnt Bid: 7.241007
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([4.3668])
After exploration
[61.54994959]
Explore action: 61.549950
Action taken: 61.549950
===============Feedback to random agent round===============
Currnt Bid: 61.549950
=================Random Agent Turn=================
Action taken: 63.590978
===============Feedback to learned agent round===============
Observation:
[0, array([61.54994959]), array([63.59097817])]
Reward: -1.000000, Currnt Bid: 63.590978
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.5025])
After exploration
[46.34471063]
Explore action: 46.344711
Action taken: 46.344711
===============Feedback to random agent round===============
Currnt Bid: 63.590978
=================Random Agent Turn=================
Action taken: 64.065328
===============Feedback to learned agent round===============
Observation:
[1, array([61.54994959]), array([63.59097817])]
Reward: -2.000000, Currnt Bid: 63.590978
Is done? True
Episode End
Positive: 2, Negative: 4
EPISODE :- 13
Random Player utility: 33.657258
=================Random Agent Turn=================
Action taken: 1.706876
===============Feedback to learned agent round===============
Observation:
[0, 0, 1.7068761852578147]
Reward: -1.000000, Currnt Bid: 1.706876
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([1.9728])
After exploration
[40.79182827]
Explore action: 40.791828
Action taken: 40.791828
===============Feedback to random agent round===============
Currnt Bid: 40.791828
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([40.79182827]), 1.7068761852578147]
Reward: 59.208172, Currnt Bid: 40.791828
Is done? True
Episode End
Positive: 3, Negative: 4
EPISODE :- 14
Random Player utility: 125.225993
=================Random Agent Turn=================
Action taken: 74.417791
===============Feedback to learned agent round===============
Observation:
[0, 0, 74.41779062163577]
Reward: -1.000000, Currnt Bid: 74.417791
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([1.1858])
After exploration
[27.80109221]
Explore action: 27.801092
Action taken: 27.801092
===============Feedback to random agent round===============
Currnt Bid: 74.417791
=================Random Agent Turn=================
Action taken: 108.691367
===============Feedback to learned agent round===============
Observation:
[1, 0, 74.41779062163577]
Reward: -2.000000, Currnt Bid: 74.417791
Is done? True
Episode End
Positive: 3, Negative: 4
EPISODE :- 15
Random Player utility: 42.685959
=================Random Agent Turn=================
Action taken: 5.782209
===============Feedback to learned agent round===============
Observation:
[0, 0, 5.782208696094891]
Reward: -1.000000, Currnt Bid: 5.782209
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 89.240273
Exploit action: 89.240273
Action taken: 89.240273
===============Feedback to random agent round===============
Currnt Bid: 89.240273
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([89.24027], dtype=float32), 5.782208696094891]
Reward: 10.759727, Currnt Bid: 89.240273
Is done? True
Episode End
Positive: 4, Negative: 4
EPISODE :- 16
Random Player utility: 17.557320
=================Random Agent Turn=================
Action taken: 6.643020
===============Feedback to learned agent round===============
Observation:
[0, 0, 6.6430203251408475]
Reward: -1.000000, Currnt Bid: 6.643020
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.5272])
After exploration
[19.32868099]
Explore action: 19.328681
Action taken: 19.328681
===============Feedback to random agent round===============
Currnt Bid: 19.328681
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([19.32868099]), 6.6430203251408475]
Reward: 80.671319, Currnt Bid: 19.328681
Is done? True
Episode End
Positive: 5, Negative: 4
EPISODE :- 17
Random Player utility: 151.328090
=================Random Agent Turn=================
Action taken: 136.309812
===============Feedback to learned agent round===============
Observation:
[0, 0, 136.30981193482182]
Reward: -1.000000, Currnt Bid: 136.309812
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.3911])
After exploration
[19.8390976]
Explore action: 19.839098
Action taken: 19.839098
===============Feedback to random agent round===============
Currnt Bid: 136.309812
=================Random Agent Turn=================
Action taken: 140.621310
===============Feedback to learned agent round===============
Observation:
[1, 0, 136.30981193482182]
Reward: -2.000000, Currnt Bid: 136.309812
Is done? True
Episode End
Positive: 5, Negative: 4
EPISODE :- 18
Random Player utility: 69.936053
=================Random Agent Turn=================
Action taken: 25.682851
===============Feedback to learned agent round===============
Observation:
[0, 0, 25.682851225043432]
Reward: -1.000000, Currnt Bid: 25.682851
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.3059])
After exploration
[4.83208618]
Explore action: 4.832086
Action taken: 4.832086
===============Feedback to random agent round===============
Currnt Bid: 25.682851
=================Random Agent Turn=================
Action taken: 47.660900
===============Feedback to learned agent round===============
Observation:
[1, 0, 25.682851225043432]
Reward: -2.000000, Currnt Bid: 25.682851
Is done? True
Episode End
Positive: 5, Negative: 5
EPISODE :- 19
Random Player utility: 57.498810
=================Random Agent Turn=================
Action taken: 40.879679
===============Feedback to learned agent round===============
Observation:
[0, 0, 40.87967863722247]
Reward: -1.000000, Currnt Bid: 40.879679
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.2448])
After exploration
[3.01821851]
Explore action: 3.018219
Action taken: 3.018219
===============Feedback to random agent round===============
Currnt Bid: 40.879679
=================Random Agent Turn=================
Action taken: 54.886862
===============Feedback to learned agent round===============
Observation:
[1, 0, 40.87967863722247]
Reward: -2.000000, Currnt Bid: 40.879679
Is done? True
Episode End
Positive: 5, Negative: 6
EPISODE :- 20
Random Player utility: 255.050388
=================Random Agent Turn=================
Action taken: 209.947070
===============Feedback to learned agent round===============
Observation:
[0, 0, 209.94706975169603]
Reward: -1.000000, Currnt Bid: 209.947070
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 89.109726
Exploit action: 89.109726
Action taken: 89.109726
===============Feedback to random agent round===============
Currnt Bid: 209.947070
=================Random Agent Turn=================
Action taken: 242.436618
===============Feedback to learned agent round===============
Observation:
[1, 0, 209.94706975169603]
Reward: -2.000000, Currnt Bid: 209.947070
Is done? True
Episode End
Positive: 5, Negative: 6
EPISODE :- 21
Random Player utility: 65.716694
=================Random Agent Turn=================
Action taken: 42.849133
===============Feedback to learned agent round===============
Observation:
[0, 0, 42.84913262407749]
Reward: -1.000000, Currnt Bid: 42.849133
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.1486])
After exploration
[20.17078091]
Explore action: 20.170781
Action taken: 20.170781
===============Feedback to random agent round===============
Currnt Bid: 42.849133
=================Random Agent Turn=================
Action taken: 55.011084
===============Feedback to learned agent round===============
Observation:
[1, 0, 42.84913262407749]
Reward: -2.000000, Currnt Bid: 42.849133
Is done? True
Episode End
Positive: 5, Negative: 7
EPISODE :- 22
Random Player utility: 225.509144
=================Random Agent Turn=================
Action taken: 65.854198
===============Feedback to learned agent round===============
Observation:
[0, 0, 65.85419769255326]
Reward: -1.000000, Currnt Bid: 65.854198
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.1096])
After exploration
[20.3559512]
Explore action: 20.355951
Action taken: 20.355951
===============Feedback to random agent round===============
Currnt Bid: 65.854198
=================Random Agent Turn=================
Action taken: 76.291042
===============Feedback to learned agent round===============
Observation:
[1, 0, 65.85419769255326]
Reward: -2.000000, Currnt Bid: 65.854198
Is done? True
Episode End
Positive: 5, Negative: 7
EPISODE :- 23
Random Player utility: 26.660061
=================Random Agent Turn=================
Action taken: 21.333112
===============Feedback to learned agent round===============
Observation:
[0, 0, 21.33311243449393]
Reward: -1.000000, Currnt Bid: 21.333112
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.0773])
After exploration
[38.34029326]
Explore action: 38.340293
Action taken: 38.340293
===============Feedback to random agent round===============
Currnt Bid: 38.340293
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([38.34029326]), 21.33311243449393]
Reward: 61.659707, Currnt Bid: 38.340293
Is done? True
Episode End
Positive: 6, Negative: 7
EPISODE :- 24
Random Player utility: 149.854012
=================Random Agent Turn=================
Action taken: 72.981038
===============Feedback to learned agent round===============
Observation:
[0, 0, 72.98103778540411]
Reward: -1.000000, Currnt Bid: 72.981038
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.0524])
After exploration
[48.62555687]
Explore action: 48.625557
Action taken: 48.625557
===============Feedback to random agent round===============
Currnt Bid: 72.981038
=================Random Agent Turn=================
Action taken: 122.539328
===============Feedback to learned agent round===============
Observation:
[1, 0, 72.98103778540411]
Reward: -2.000000, Currnt Bid: 72.981038
Is done? True
Episode End
Positive: 6, Negative: 7
EPISODE :- 25
Random Player utility: 93.506253
=================Random Agent Turn=================
Action taken: 74.696753
===============Feedback to learned agent round===============
Observation:
[0, 0, 74.69675287194116]
Reward: -1.000000, Currnt Bid: 74.696753
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 88.958252
Exploit action: 88.958252
Action taken: 88.958252
===============Feedback to random agent round===============
Currnt Bid: 88.958252
=================Random Agent Turn=================
Action taken: 91.601028
===============Feedback to learned agent round===============
Observation:
[0, array([88.95825], dtype=float32), array([91.60103], dtype=float32)]
Reward: -1.000000, Currnt Bid: 91.601028
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 87.620842
Exploit action: 87.620842
Action taken: 87.620842
===============Feedback to random agent round===============
Currnt Bid: 91.601028
=================Random Agent Turn=================
Action taken: 93.353775
===============Feedback to learned agent round===============
Observation:
[1, array([88.95825], dtype=float32), array([91.60103], dtype=float32)]
Reward: -2.000000, Currnt Bid: 91.601028
Is done? True
Episode End
Positive: 6, Negative: 8
EPISODE :- 26
Random Player utility: 58.636045
=================Random Agent Turn=================
Action taken: 17.240102
===============Feedback to learned agent round===============
Observation:
[0, 0, 17.240102415473967]
Reward: -1.000000, Currnt Bid: 17.240102
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.0169])
After exploration
[50.42945135]
Explore action: 50.429451
Action taken: 50.429451
===============Feedback to random agent round===============
Currnt Bid: 50.429451
=================Random Agent Turn=================
Action taken: 50.773562
===============Feedback to learned agent round===============
Observation:
[0, array([50.42945135]), array([50.7735618])]
Reward: -1.000000, Currnt Bid: 50.773562
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[54.39311907]
Explore action: 54.393119
Action taken: 54.393119
===============Feedback to random agent round===============
Currnt Bid: 54.393119
=================Random Agent Turn=================
Action taken: 56.332958
===============Feedback to learned agent round===============
Observation:
[0, array([54.39311907]), array([56.33295784])]
Reward: -1.000000, Currnt Bid: 56.332958
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[47.55891862]
Explore action: 47.558919
Action taken: 47.558919
===============Feedback to random agent round===============
Currnt Bid: 56.332958
=================Random Agent Turn=================
Action taken: 57.020105
===============Feedback to learned agent round===============
Observation:
[1, array([54.39311907]), array([56.33295784])]
Reward: -2.000000, Currnt Bid: 56.332958
Is done? True
Episode End
Positive: 6, Negative: 9
EPISODE :- 27
Random Player utility: 58.033878
=================Random Agent Turn=================
Action taken: 20.406930
===============Feedback to learned agent round===============
Observation:
[0, 0, 20.40693013276748]
Reward: -1.000000, Currnt Bid: 20.406930
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.0066])
After exploration
[48.58032052]
Explore action: 48.580321
Action taken: 48.580321
===============Feedback to random agent round===============
Currnt Bid: 48.580321
=================Random Agent Turn=================
Action taken: 48.923738
===============Feedback to learned agent round===============
Observation:
[0, array([48.58032052]), array([48.92373797])]
Reward: -1.000000, Currnt Bid: 48.923738
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[33.11207183]
Explore action: 33.112072
Action taken: 33.112072
===============Feedback to random agent round===============
Currnt Bid: 48.923738
=================Random Agent Turn=================
Action taken: 51.169953
===============Feedback to learned agent round===============
Observation:
[1, array([48.58032052]), array([48.92373797])]
Reward: -2.000000, Currnt Bid: 48.923738
Is done? True
Episode End
Positive: 6, Negative: 10
EPISODE :- 28
Random Player utility: 130.629424
=================Random Agent Turn=================
Action taken: 36.919155
===============Feedback to learned agent round===============
Observation:
[0, 0, 36.91915479640984]
Reward: -1.000000, Currnt Bid: 36.919155
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.0034])
After exploration
[45.04725006]
Explore action: 45.047250
Action taken: 45.047250
===============Feedback to random agent round===============
Currnt Bid: 45.047250
=================Random Agent Turn=================
Action taken: 61.655576
===============Feedback to learned agent round===============
Observation:
[0, array([45.04725006]), array([61.6555757])]
Reward: -1.000000, Currnt Bid: 61.655576
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[35.42562531]
Explore action: 35.425625
Action taken: 35.425625
===============Feedback to random agent round===============
Currnt Bid: 61.655576
=================Random Agent Turn=================
Action taken: 99.801459
===============Feedback to learned agent round===============
Observation:
[1, array([45.04725006]), array([61.6555757])]
Reward: -2.000000, Currnt Bid: 61.655576
Is done? True
Episode End
Positive: 6, Negative: 10
EPISODE :- 29
Random Player utility: 224.371056
=================Random Agent Turn=================
Action taken: 212.313109
===============Feedback to learned agent round===============
Observation:
[0, 0, 212.3131092383536]
Reward: -1.000000, Currnt Bid: 212.313109
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.0019])
After exploration
[28.14093561]
Explore action: 28.140936
Action taken: 28.140936
===============Feedback to random agent round===============
Currnt Bid: 212.313109
=================Random Agent Turn=================
Action taken: 214.096415
===============Feedback to learned agent round===============
Observation:
[1, 0, 212.3131092383536]
Reward: -2.000000, Currnt Bid: 212.313109
Is done? True
Episode End
Positive: 6, Negative: 10
EPISODE :- 30
Random Player utility: 83.023986
=================Random Agent Turn=================
Action taken: 23.917336
===============Feedback to learned agent round===============
Observation:
[0, 0, 23.917335573308822]
Reward: -1.000000, Currnt Bid: 23.917336
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 88.683754
Exploit action: 88.683754
Action taken: 88.683754
===============Feedback to random agent round===============
Currnt Bid: 88.683754
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([88.683754], dtype=float32), 23.917335573308822]
Reward: 11.316246, Currnt Bid: 88.683754
Is done? True
Episode End
Positive: 7, Negative: 10
EPISODE :- 31
Random Player utility: 101.795054
=================Random Agent Turn=================
Action taken: 16.486218
===============Feedback to learned agent round===============
Observation:
[0, 0, 16.486218292158522]
Reward: -1.000000, Currnt Bid: 16.486218
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.0010])
After exploration
[65.34548255]
Explore action: 65.345483
Action taken: 65.345483
===============Feedback to random agent round===============
Currnt Bid: 65.345483
=================Random Agent Turn=================
Action taken: 101.238407
===============Feedback to learned agent round===============
Observation:
[0, array([65.34548255]), array([101.23840719])]
Reward: -1.000000, Currnt Bid: 101.238407
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[58.87994612]
Explore action: 58.879946
Action taken: 58.879946
===============Feedback to random agent round===============
Currnt Bid: 101.238407
=================Random Agent Turn=================
Action taken: 101.401356
===============Feedback to learned agent round===============
Observation:
[1, array([65.34548255]), array([101.23840719])]
Reward: -2.000000, Currnt Bid: 101.238407
Is done? True
Episode End
Positive: 7, Negative: 10
EPISODE :- 32
Random Player utility: 24.018726
=================Random Agent Turn=================
Action taken: 9.923737
===============Feedback to learned agent round===============
Observation:
[0, 0, 9.923736623081073]
Reward: -1.000000, Currnt Bid: 9.923737
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.0006])
After exploration
[47.36212874]
Explore action: 47.362129
Action taken: 47.362129
===============Feedback to random agent round===============
Currnt Bid: 47.362129
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([47.36212874]), 9.923736623081073]
Reward: 52.637871, Currnt Bid: 47.362129
Is done? True
Episode End
Positive: 8, Negative: 10
EPISODE :- 33
Random Player utility: 167.654651
=================Random Agent Turn=================
Action taken: 148.781638
===============Feedback to learned agent round===============
Observation:
[0, 0, 148.78163802787185]
Reward: -1.000000, Currnt Bid: 148.781638
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.0005])
After exploration
[39.50095897]
Explore action: 39.500959
Action taken: 39.500959
===============Feedback to random agent round===============
Currnt Bid: 148.781638
=================Random Agent Turn=================
Action taken: 162.240787
===============Feedback to learned agent round===============
Observation:
[1, 0, 148.78163802787185]
Reward: -2.000000, Currnt Bid: 148.781638
Is done? True
Episode End
Positive: 8, Negative: 10
EPISODE :- 34
Random Player utility: 60.053146
=================Random Agent Turn=================
Action taken: 37.587372
===============Feedback to learned agent round===============
Observation:
[0, 0, 37.587372218453275]
Reward: -1.000000, Currnt Bid: 37.587372
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.0004])
After exploration
[20.59294777]
Explore action: 20.592948
Action taken: 20.592948
===============Feedback to random agent round===============
Currnt Bid: 37.587372
=================Random Agent Turn=================
Action taken: 53.559728
===============Feedback to learned agent round===============
Observation:
[1, 0, 37.587372218453275]
Reward: -2.000000, Currnt Bid: 37.587372
Is done? True
Episode End
Positive: 8, Negative: 11
EPISODE :- 35
Random Player utility: 46.673668
=================Random Agent Turn=================
Action taken: 25.669405
===============Feedback to learned agent round===============
Observation:
[0, 0, 25.669405081434277]
Reward: -1.000000, Currnt Bid: 25.669405
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 88.443535
Exploit action: 88.443535
Action taken: 88.443535
===============Feedback to random agent round===============
Currnt Bid: 88.443535
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([88.443535], dtype=float32), 25.669405081434277]
Reward: 11.556465, Currnt Bid: 88.443535
Is done? True
Episode End
Positive: 9, Negative: 11
EPISODE :- 36
Random Player utility: 197.224134
=================Random Agent Turn=================
Action taken: 56.368379
===============Feedback to learned agent round===============
Observation:
[0, 0, 56.36837921330106]
Reward: -1.000000, Currnt Bid: 56.368379
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.0003])
After exploration
[33.73782579]
Explore action: 33.737826
Action taken: 33.737826
===============Feedback to random agent round===============
Currnt Bid: 56.368379
=================Random Agent Turn=================
Action taken: 82.854601
===============Feedback to learned agent round===============
Observation:
[1, 0, 56.36837921330106]
Reward: -2.000000, Currnt Bid: 56.368379
Is done? True
Episode End
Positive: 9, Negative: 11
EPISODE :- 37
Random Player utility: 142.257430
=================Random Agent Turn=================
Action taken: 110.145570
===============Feedback to learned agent round===============
Observation:
[0, 0, 110.14557020693198]
Reward: -1.000000, Currnt Bid: 110.145570
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.0002])
After exploration
[27.79979411]
Explore action: 27.799794
Action taken: 27.799794
===============Feedback to random agent round===============
Currnt Bid: 110.145570
=================Random Agent Turn=================
Action taken: 112.244987
===============Feedback to learned agent round===============
Observation:
[1, 0, 110.14557020693198]
Reward: -2.000000, Currnt Bid: 110.145570
Is done? True
Episode End
Positive: 9, Negative: 11
EPISODE :- 38
Random Player utility: 31.219073
=================Random Agent Turn=================
Action taken: 20.786562
===============Feedback to learned agent round===============
Observation:
[0, 0, 20.786561652591004]
Reward: -1.000000, Currnt Bid: 20.786562
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.0002])
After exploration
[32.02810965]
Explore action: 32.028110
Action taken: 32.028110
===============Feedback to random agent round===============
Currnt Bid: 32.028110
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([32.02810965]), 20.786561652591004]
Reward: 67.971890, Currnt Bid: 32.028110
Is done? True
Episode End
Positive: 10, Negative: 11
EPISODE :- 39
Random Player utility: 218.075374
=================Random Agent Turn=================
Action taken: 125.409323
===============Feedback to learned agent round===============
Observation:
[0, 0, 125.40932293253964]
Reward: -1.000000, Currnt Bid: 125.409323
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.0002])
After exploration
[42.93152875]
Explore action: 42.931529
Action taken: 42.931529
===============Feedback to random agent round===============
Currnt Bid: 125.409323
=================Random Agent Turn=================
Action taken: 213.384990
===============Feedback to learned agent round===============
Observation:
[1, 0, 125.40932293253964]
Reward: -2.000000, Currnt Bid: 125.409323
Is done? True
Episode End
Positive: 10, Negative: 11
EPISODE :- 40
Random Player utility: 125.400061
=================Random Agent Turn=================
Action taken: 90.639582
===============Feedback to learned agent round===============
Observation:
[0, 0, 90.63958201094772]
Reward: -1.000000, Currnt Bid: 90.639582
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 88.197388
Exploit action: 88.197388
Action taken: 88.197388
===============Feedback to random agent round===============
Currnt Bid: 90.639582
=================Random Agent Turn=================
Action taken: 94.248431
===============Feedback to learned agent round===============
Observation:
[1, 0, 90.63958201094772]
Reward: -2.000000, Currnt Bid: 90.639582
Is done? True
Episode End
Positive: 10, Negative: 11
EPISODE :- 41
Random Player utility: 62.517407
=================Random Agent Turn=================
Action taken: 40.225629
===============Feedback to learned agent round===============
Observation:
[0, 0, 40.22562943518715]
Reward: -1.000000, Currnt Bid: 40.225629
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.0001])
After exploration
[53.23944246]
Explore action: 53.239442
Action taken: 53.239442
===============Feedback to random agent round===============
Currnt Bid: 53.239442
=================Random Agent Turn=================
Action taken: 54.529659
===============Feedback to learned agent round===============
Observation:
[0, array([53.23944246]), array([54.52965935])]
Reward: -1.000000, Currnt Bid: 54.529659
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[46.90337437]
Explore action: 46.903374
Action taken: 46.903374
===============Feedback to random agent round===============
Currnt Bid: 54.529659
=================Random Agent Turn=================
Action taken: 61.596978
===============Feedback to learned agent round===============
Observation:
[1, array([53.23944246]), array([54.52965935])]
Reward: -2.000000, Currnt Bid: 54.529659
Is done? True
Episode End
Positive: 10, Negative: 12
EPISODE :- 42
Random Player utility: 127.913468
=================Random Agent Turn=================
Action taken: 0.569127
===============Feedback to learned agent round===============
Observation:
[0, 0, 0.5691270418414117]
Reward: -1.000000, Currnt Bid: 0.569127
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([9.5367e-05])
After exploration
[42.99752128]
Explore action: 42.997521
Action taken: 42.997521
===============Feedback to random agent round===============
Currnt Bid: 42.997521
=================Random Agent Turn=================
Action taken: 96.450950
===============Feedback to learned agent round===============
Observation:
[0, array([42.99752128]), array([96.45095041])]
Reward: -1.000000, Currnt Bid: 96.450950
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([5.9605e-05])
After exploration
[37.89583617]
Explore action: 37.895836
Action taken: 37.895836
===============Feedback to random agent round===============
Currnt Bid: 96.450950
=================Random Agent Turn=================
Action taken: 127.238784
===============Feedback to learned agent round===============
Observation:
[1, array([42.99752128]), array([96.45095041])]
Reward: -2.000000, Currnt Bid: 96.450950
Is done? True
Episode End
Positive: 10, Negative: 12
EPISODE :- 43
Random Player utility: 118.224764
=================Random Agent Turn=================
Action taken: 104.967056
===============Feedback to learned agent round===============
Observation:
[0, 0, 104.96705553459306]
Reward: -1.000000, Currnt Bid: 104.967056
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([7.7486e-05])
After exploration
[36.18953841]
Explore action: 36.189538
Action taken: 36.189538
===============Feedback to random agent round===============
Currnt Bid: 104.967056
=================Random Agent Turn=================
Action taken: 115.029937
===============Feedback to learned agent round===============
Observation:
[1, 0, 104.96705553459306]
Reward: -2.000000, Currnt Bid: 104.967056
Is done? True
Episode End
Positive: 10, Negative: 12
EPISODE :- 44
Random Player utility: 182.883751
=================Random Agent Turn=================
Action taken: 154.543428
===============Feedback to learned agent round===============
Observation:
[0, 0, 154.54342830477017]
Reward: -1.000000, Currnt Bid: 154.543428
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([7.1526e-05])
After exploration
[41.80100151]
Explore action: 41.801002
Action taken: 41.801002
===============Feedback to random agent round===============
Currnt Bid: 154.543428
=================Random Agent Turn=================
Action taken: 173.566468
===============Feedback to learned agent round===============
Observation:
[1, 0, 154.54342830477017]
Reward: -2.000000, Currnt Bid: 154.543428
Is done? True
Episode End
Positive: 10, Negative: 12
EPISODE :- 45
Random Player utility: 114.320271
=================Random Agent Turn=================
Action taken: 86.109449
===============Feedback to learned agent round===============
Observation:
[0, 0, 86.10944948933877]
Reward: -1.000000, Currnt Bid: 86.109449
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 87.867012
Exploit action: 87.867012
Action taken: 87.867012
===============Feedback to random agent round===============
Currnt Bid: 87.867012
=================Random Agent Turn=================
Action taken: 109.937859
===============Feedback to learned agent round===============
Observation:
[0, array([87.86701], dtype=float32), array([109.93786], dtype=float32)]
Reward: -1.000000, Currnt Bid: 109.937859
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 77.204819
Exploit action: 77.204819
Action taken: 77.204819
===============Feedback to random agent round===============
Currnt Bid: 109.937859
=================Random Agent Turn=================
Action taken: 113.982483
===============Feedback to learned agent round===============
Observation:
[1, array([87.86701], dtype=float32), array([109.93786], dtype=float32)]
Reward: -2.000000, Currnt Bid: 109.937859
Is done? True
Episode End
Positive: 10, Negative: 12
EPISODE :- 46
Random Player utility: 55.718729
=================Random Agent Turn=================
Action taken: 20.582686
===============Feedback to learned agent round===============
Observation:
[0, 0, 20.582686432497905]
Reward: -1.000000, Currnt Bid: 20.582686
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([5.3644e-05])
After exploration
[35.20636499]
Explore action: 35.206365
Action taken: 35.206365
===============Feedback to random agent round===============
Currnt Bid: 35.206365
=================Random Agent Turn=================
Action taken: 49.170056
===============Feedback to learned agent round===============
Observation:
[0, array([35.20636499]), array([49.17005642])]
Reward: -1.000000, Currnt Bid: 49.170056
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[43.81975222]
Explore action: 43.819752
Action taken: 43.819752
===============Feedback to random agent round===============
Currnt Bid: 49.170056
=================Random Agent Turn=================
Action taken: 52.034854
===============Feedback to learned agent round===============
Observation:
[1, array([35.20636499]), array([49.17005642])]
Reward: -2.000000, Currnt Bid: 49.170056
Is done? True
Episode End
Positive: 10, Negative: 13
EPISODE :- 47
Random Player utility: 40.777614
=================Random Agent Turn=================
Action taken: 9.558282
===============Feedback to learned agent round===============
Observation:
[0, 0, 9.558282330443319]
Reward: -1.000000, Currnt Bid: 9.558282
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([4.1723e-05])
After exploration
[55.09628124]
Explore action: 55.096281
Action taken: 55.096281
===============Feedback to random agent round===============
Currnt Bid: 55.096281
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([55.09628124]), 9.558282330443319]
Reward: 44.903719, Currnt Bid: 55.096281
Is done? True
Episode End
Positive: 11, Negative: 13
EPISODE :- 48
Random Player utility: 68.455013
=================Random Agent Turn=================
Action taken: 68.053599
===============Feedback to learned agent round===============
Observation:
[0, 0, 68.05359875759858]
Reward: -1.000000, Currnt Bid: 68.053599
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([3.5763e-05])
After exploration
[51.71708005]
Explore action: 51.717080
Action taken: 51.717080
===============Feedback to random agent round===============
Currnt Bid: 68.053599
=================Random Agent Turn=================
Action taken: 68.239298
===============Feedback to learned agent round===============
Observation:
[1, 0, 68.05359875759858]
Reward: -2.000000, Currnt Bid: 68.053599
Is done? True
Episode End
Positive: 11, Negative: 14
EPISODE :- 49
Random Player utility: 11.057292
=================Random Agent Turn=================
Action taken: 10.914127
===============Feedback to learned agent round===============
Observation:
[0, 0, 10.914126778861114]
Reward: -1.000000, Currnt Bid: 10.914127
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([3.5763e-05])
After exploration
[26.77821694]
Explore action: 26.778217
Action taken: 26.778217
===============Feedback to random agent round===============
Currnt Bid: 26.778217
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([26.77821694]), 10.914126778861114]
Reward: 73.221783, Currnt Bid: 26.778217
Is done? True
Episode End
Positive: 12, Negative: 14
EPISODE :- 50
Random Player utility: 91.065640
=================Random Agent Turn=================
Action taken: 14.860353
===============Feedback to learned agent round===============
Observation:
[0, 0, 14.860352717152686]
Reward: -1.000000, Currnt Bid: 14.860353
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 87.495132
Exploit action: 87.495132
Action taken: 87.495132
===============Feedback to random agent round===============
Currnt Bid: 87.495132
=================Random Agent Turn=================
Action taken: 90.445892
===============Feedback to learned agent round===============
Observation:
[0, array([87.49513], dtype=float32), array([90.44589], dtype=float32)]
Reward: -1.000000, Currnt Bid: 90.445892
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 86.159424
Exploit action: 86.159424
Action taken: 86.159424
===============Feedback to random agent round===============
Currnt Bid: 90.445892
=================Random Agent Turn=================
Action taken: 90.949760
===============Feedback to learned agent round===============
Observation:
[1, array([87.49513], dtype=float32), array([90.44589], dtype=float32)]
Reward: -2.000000, Currnt Bid: 90.445892
Is done? True
Episode End
Positive: 12, Negative: 15
EPISODE :- 51
Random Player utility: 93.558498
=================Random Agent Turn=================
Action taken: 48.346770
===============Feedback to learned agent round===============
Observation:
[0, 0, 48.346770268572364]
Reward: -1.000000, Currnt Bid: 48.346770
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([2.3842e-05])
After exploration
[31.74336495]
Explore action: 31.743365
Action taken: 31.743365
===============Feedback to random agent round===============
Currnt Bid: 48.346770
=================Random Agent Turn=================
Action taken: 90.152523
===============Feedback to learned agent round===============
Observation:
[1, 0, 48.346770268572364]
Reward: -2.000000, Currnt Bid: 48.346770
Is done? True
Episode End
Positive: 12, Negative: 16
EPISODE :- 52
Random Player utility: 196.216074
=================Random Agent Turn=================
Action taken: 54.006089
===============Feedback to learned agent round===============
Observation:
[0, 0, 54.00608872039115]
Reward: -1.000000, Currnt Bid: 54.006089
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([2.3842e-05])
After exploration
[31.63710568]
Explore action: 31.637106
Action taken: 31.637106
===============Feedback to random agent round===============
Currnt Bid: 54.006089
=================Random Agent Turn=================
Action taken: 177.946012
===============Feedback to learned agent round===============
Observation:
[1, 0, 54.00608872039115]
Reward: -2.000000, Currnt Bid: 54.006089
Is done? True
Episode End
Positive: 12, Negative: 16
EPISODE :- 53
Random Player utility: 204.445096
=================Random Agent Turn=================
Action taken: 41.012679
===============Feedback to learned agent round===============
Observation:
[0, 0, 41.012679071857]
Reward: -1.000000, Currnt Bid: 41.012679
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([1.7881e-05])
After exploration
[12.30732712]
Explore action: 12.307327
Action taken: 12.307327
===============Feedback to random agent round===============
Currnt Bid: 41.012679
=================Random Agent Turn=================
Action taken: 143.191558
===============Feedback to learned agent round===============
Observation:
[1, 0, 41.012679071857]
Reward: -2.000000, Currnt Bid: 41.012679
Is done? True
Episode End
Positive: 12, Negative: 16
EPISODE :- 54
Random Player utility: 119.116338
=================Random Agent Turn=================
Action taken: 109.530319
===============Feedback to learned agent round===============
Observation:
[0, 0, 109.53031909335942]
Reward: -1.000000, Currnt Bid: 109.530319
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([1.7881e-05])
After exploration
[4.98776223]
Explore action: 4.987762
Action taken: 4.987762
===============Feedback to random agent round===============
Currnt Bid: 109.530319
=================Random Agent Turn=================
Action taken: 119.097555
===============Feedback to learned agent round===============
Observation:
[1, 0, 109.53031909335942]
Reward: -2.000000, Currnt Bid: 109.530319
Is done? True
Episode End
Positive: 12, Negative: 16
EPISODE :- 55
Random Player utility: 191.888471
=================Random Agent Turn=================
Action taken: 94.315469
===============Feedback to learned agent round===============
Observation:
[0, 0, 94.31546931317907]
Reward: -1.000000, Currnt Bid: 94.315469
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 87.110771
Exploit action: 87.110771
Action taken: 87.110771
===============Feedback to random agent round===============
Currnt Bid: 94.315469
=================Random Agent Turn=================
Action taken: 103.952606
===============Feedback to learned agent round===============
Observation:
[1, 0, 94.31546931317907]
Reward: -2.000000, Currnt Bid: 94.315469
Is done? True
Episode End
Positive: 12, Negative: 16
EPISODE :- 56
Random Player utility: 76.296430
=================Random Agent Turn=================
Action taken: 26.803197
===============Feedback to learned agent round===============
Observation:
[0, 0, 26.80319670535789]
Reward: -1.000000, Currnt Bid: 26.803197
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([1.1921e-05])
After exploration
[19.85227115]
Explore action: 19.852271
Action taken: 19.852271
===============Feedback to random agent round===============
Currnt Bid: 26.803197
=================Random Agent Turn=================
Action taken: 64.723159
===============Feedback to learned agent round===============
Observation:
[1, 0, 26.80319670535789]
Reward: -2.000000, Currnt Bid: 26.803197
Is done? True
Episode End
Positive: 12, Negative: 17
EPISODE :- 57
Random Player utility: 150.616872
=================Random Agent Turn=================
Action taken: 26.838930
===============Feedback to learned agent round===============
Observation:
[0, 0, 26.83892952792943]
Reward: -1.000000, Currnt Bid: 26.838930
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([1.1921e-05])
After exploration
[7.94116474]
Explore action: 7.941165
Action taken: 7.941165
===============Feedback to random agent round===============
Currnt Bid: 26.838930
=================Random Agent Turn=================
Action taken: 31.273108
===============Feedback to learned agent round===============
Observation:
[1, 0, 26.83892952792943]
Reward: -2.000000, Currnt Bid: 26.838930
Is done? True
Episode End
Positive: 12, Negative: 17
EPISODE :- 58
Random Player utility: 101.008912
=================Random Agent Turn=================
Action taken: 61.131755
===============Feedback to learned agent round===============
Observation:
[0, 0, 61.131755462767444]
Reward: -1.000000, Currnt Bid: 61.131755
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([1.1921e-05])
After exploration
[19.5934645]
Explore action: 19.593464
Action taken: 19.593464
===============Feedback to random agent round===============
Currnt Bid: 61.131755
=================Random Agent Turn=================
Action taken: 72.748892
===============Feedback to learned agent round===============
Observation:
[1, 0, 61.131755462767444]
Reward: -2.000000, Currnt Bid: 61.131755
Is done? True
Episode End
Positive: 12, Negative: 17
EPISODE :- 59
Random Player utility: 16.235008
=================Random Agent Turn=================
Action taken: 0.838181
===============Feedback to learned agent round===============
Observation:
[0, 0, 0.838181102279159]
Reward: -1.000000, Currnt Bid: 0.838181
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([1.1921e-05])
After exploration
[29.44128251]
Explore action: 29.441283
Action taken: 29.441283
===============Feedback to random agent round===============
Currnt Bid: 29.441283
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([29.44128251]), 0.838181102279159]
Reward: 70.558717, Currnt Bid: 29.441283
Is done? True
Episode End
Positive: 13, Negative: 17
EPISODE :- 60
Random Player utility: 69.232271
=================Random Agent Turn=================
Action taken: 35.660632
===============Feedback to learned agent round===============
Observation:
[0, 0, 35.66063212728482]
Reward: -1.000000, Currnt Bid: 35.660632
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 86.719353
Exploit action: 86.719353
Action taken: 86.719353
===============Feedback to random agent round===============
Currnt Bid: 86.719353
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([86.71935], dtype=float32), 35.66063212728482]
Reward: 13.280647, Currnt Bid: 86.719353
Is done? True
Episode End
Positive: 14, Negative: 17
EPISODE :- 61
Random Player utility: 15.303734
=================Random Agent Turn=================
Action taken: 2.395628
===============Feedback to learned agent round===============
Observation:
[0, 0, 2.395628133919094]
Reward: -1.000000, Currnt Bid: 2.395628
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([5.9605e-06])
After exploration
[7.69766315]
Explore action: 7.697663
Action taken: 7.697663
===============Feedback to random agent round===============
Currnt Bid: 7.697663
=================Random Agent Turn=================
Action taken: 8.896405
===============Feedback to learned agent round===============
Observation:
[0, array([7.69766315]), array([8.89640467])]
Reward: -1.000000, Currnt Bid: 8.896405
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[0.35023659]
Explore action: 0.350237
Action taken: 0.350237
===============Feedback to random agent round===============
Currnt Bid: 8.896405
=================Random Agent Turn=================
Action taken: 14.625011
===============Feedback to learned agent round===============
Observation:
[1, array([7.69766315]), array([8.89640467])]
Reward: -2.000000, Currnt Bid: 8.896405
Is done? True
Episode End
Positive: 14, Negative: 18
EPISODE :- 62
Random Player utility: 56.690314
=================Random Agent Turn=================
Action taken: 0.624503
===============Feedback to learned agent round===============
Observation:
[0, 0, 0.6245032415950919]
Reward: -1.000000, Currnt Bid: 0.624503
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([5.9605e-06])
After exploration
[3.36462521]
Explore action: 3.364625
Action taken: 3.364625
===============Feedback to random agent round===============
Currnt Bid: 3.364625
=================Random Agent Turn=================
Action taken: 8.653236
===============Feedback to learned agent round===============
Observation:
[0, array([3.36462521]), array([8.65323579])]
Reward: -1.000000, Currnt Bid: 8.653236
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[8.50505772]
Explore action: 8.505058
Action taken: 8.505058
===============Feedback to random agent round===============
Currnt Bid: 8.653236
=================Random Agent Turn=================
Action taken: 13.476895
===============Feedback to learned agent round===============
Observation:
[1, array([3.36462521]), array([8.65323579])]
Reward: -2.000000, Currnt Bid: 8.653236
Is done? True
Episode End
Positive: 14, Negative: 19
EPISODE :- 63
Random Player utility: 163.393097
=================Random Agent Turn=================
Action taken: 85.773968
===============Feedback to learned agent round===============
Observation:
[0, 0, 85.77396803973242]
Reward: -1.000000, Currnt Bid: 85.773968
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([5.9605e-06])
After exploration
[23.95671789]
Explore action: 23.956718
Action taken: 23.956718
===============Feedback to random agent round===============
Currnt Bid: 85.773968
=================Random Agent Turn=================
Action taken: 135.446001
===============Feedback to learned agent round===============
Observation:
[1, 0, 85.77396803973242]
Reward: -2.000000, Currnt Bid: 85.773968
Is done? True
Episode End
Positive: 14, Negative: 19
EPISODE :- 64
Random Player utility: 144.347147
=================Random Agent Turn=================
Action taken: 14.266764
===============Feedback to learned agent round===============
Observation:
[0, 0, 14.266764326600814]
Reward: -1.000000, Currnt Bid: 14.266764
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[38.04380678]
Explore action: 38.043807
Action taken: 38.043807
===============Feedback to random agent round===============
Currnt Bid: 38.043807
=================Random Agent Turn=================
Action taken: 117.626368
===============Feedback to learned agent round===============
Observation:
[0, array([38.04380678]), array([117.62636828])]
Reward: -1.000000, Currnt Bid: 117.626368
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[52.81884256]
Explore action: 52.818843
Action taken: 52.818843
===============Feedback to random agent round===============
Currnt Bid: 117.626368
=================Random Agent Turn=================
Action taken: 118.296506
===============Feedback to learned agent round===============
Observation:
[1, array([38.04380678]), array([117.62636828])]
Reward: -2.000000, Currnt Bid: 117.626368
Is done? True
Episode End
Positive: 14, Negative: 19
EPISODE :- 65
Random Player utility: 126.063441
=================Random Agent Turn=================
Action taken: 100.816174
===============Feedback to learned agent round===============
Observation:
[0, 0, 100.81617390546813]
Reward: -1.000000, Currnt Bid: 100.816174
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 86.155853
Exploit action: 86.155853
Action taken: 86.155853
===============Feedback to random agent round===============
Currnt Bid: 100.816174
=================Random Agent Turn=================
Action taken: 120.909934
===============Feedback to learned agent round===============
Observation:
[1, 0, 100.81617390546813]
Reward: -2.000000, Currnt Bid: 100.816174
Is done? True
Episode End
Positive: 14, Negative: 19
EPISODE :- 66
Random Player utility: 149.628293
=================Random Agent Turn=================
Action taken: 113.796491
===============Feedback to learned agent round===============
Observation:
[0, 0, 113.79649131345033]
Reward: -1.000000, Currnt Bid: 113.796491
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[47.67853623]
Explore action: 47.678536
Action taken: 47.678536
===============Feedback to random agent round===============
Currnt Bid: 113.796491
=================Random Agent Turn=================
Action taken: 132.716262
===============Feedback to learned agent round===============
Observation:
[1, 0, 113.79649131345033]
Reward: -2.000000, Currnt Bid: 113.796491
Is done? True
Episode End
Positive: 14, Negative: 19
EPISODE :- 67
Random Player utility: 112.702864
=================Random Agent Turn=================
Action taken: 81.058282
===============Feedback to learned agent round===============
Observation:
[0, 0, 81.05828243917186]
Reward: -1.000000, Currnt Bid: 81.058282
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[52.03515325]
Explore action: 52.035153
Action taken: 52.035153
===============Feedback to random agent round===============
Currnt Bid: 81.058282
=================Random Agent Turn=================
Action taken: 83.208972
===============Feedback to learned agent round===============
Observation:
[1, 0, 81.05828243917186]
Reward: -2.000000, Currnt Bid: 81.058282
Is done? True
Episode End
Positive: 14, Negative: 19
EPISODE :- 68
Random Player utility: 123.934692
=================Random Agent Turn=================
Action taken: 71.879815
===============Feedback to learned agent round===============
Observation:
[0, 0, 71.8798154388733]
Reward: -1.000000, Currnt Bid: 71.879815
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[56.22803489]
Explore action: 56.228035
Action taken: 56.228035
===============Feedback to random agent round===============
Currnt Bid: 71.879815
=================Random Agent Turn=================
Action taken: 96.052150
===============Feedback to learned agent round===============
Observation:
[1, 0, 71.8798154388733]
Reward: -2.000000, Currnt Bid: 71.879815
Is done? True
Episode End
Positive: 14, Negative: 19
EPISODE :- 69
Random Player utility: 171.287337
=================Random Agent Turn=================
Action taken: 92.805008
===============Feedback to learned agent round===============
Observation:
[0, 0, 92.80500792032304]
Reward: -1.000000, Currnt Bid: 92.805008
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[39.54078724]
Explore action: 39.540787
Action taken: 39.540787
===============Feedback to random agent round===============
Currnt Bid: 92.805008
=================Random Agent Turn=================
Action taken: 128.717389
===============Feedback to learned agent round===============
Observation:
[1, 0, 92.80500792032304]
Reward: -2.000000, Currnt Bid: 92.805008
Is done? True
Episode End
Positive: 14, Negative: 19
EPISODE :- 70
Random Player utility: 177.052916
=================Random Agent Turn=================
Action taken: 70.442712
===============Feedback to learned agent round===============
Observation:
[0, 0, 70.44271229921904]
Reward: -1.000000, Currnt Bid: 70.442712
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 85.679848
Exploit action: 85.679848
Action taken: 85.679848
===============Feedback to random agent round===============
Currnt Bid: 85.679848
=================Random Agent Turn=================
Action taken: 95.703140
===============Feedback to learned agent round===============
Observation:
[0, array([85.67985], dtype=float32), array([95.70314], dtype=float32)]
Reward: -1.000000, Currnt Bid: 95.703140
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 63.791527
Exploit action: 63.791527
Action taken: 63.791527
===============Feedback to random agent round===============
Currnt Bid: 95.703140
=================Random Agent Turn=================
Action taken: 127.128593
===============Feedback to learned agent round===============
Observation:
[1, array([85.67985], dtype=float32), array([95.70314], dtype=float32)]
Reward: -2.000000, Currnt Bid: 95.703140
Is done? True
Episode End
Positive: 14, Negative: 19
EPISODE :- 71
Random Player utility: 202.425208
=================Random Agent Turn=================
Action taken: 101.733491
===============Feedback to learned agent round===============
Observation:
[0, 0, 101.73349145452433]
Reward: -1.000000, Currnt Bid: 101.733491
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[26.39110615]
Explore action: 26.391106
Action taken: 26.391106
===============Feedback to random agent round===============
Currnt Bid: 101.733491
=================Random Agent Turn=================
Action taken: 158.522891
===============Feedback to learned agent round===============
Observation:
[1, 0, 101.73349145452433]
Reward: -2.000000, Currnt Bid: 101.733491
Is done? True
Episode End
Positive: 14, Negative: 19
EPISODE :- 72
Random Player utility: 233.641720
=================Random Agent Turn=================
Action taken: 45.897964
===============Feedback to learned agent round===============
Observation:
[0, 0, 45.89796365172447]
Reward: -1.000000, Currnt Bid: 45.897964
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[35.42537724]
Explore action: 35.425377
Action taken: 35.425377
===============Feedback to random agent round===============
Currnt Bid: 45.897964
=================Random Agent Turn=================
Action taken: 231.853865
===============Feedback to learned agent round===============
Observation:
[1, 0, 45.89796365172447]
Reward: -2.000000, Currnt Bid: 45.897964
Is done? True
Episode End
Positive: 14, Negative: 19
EPISODE :- 73
Random Player utility: 94.735626
=================Random Agent Turn=================
Action taken: 14.446104
===============Feedback to learned agent round===============
Observation:
[0, 0, 14.446103769332883]
Reward: -1.000000, Currnt Bid: 14.446104
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[40.46124053]
Explore action: 40.461241
Action taken: 40.461241
===============Feedback to random agent round===============
Currnt Bid: 40.461241
=================Random Agent Turn=================
Action taken: 69.839427
===============Feedback to learned agent round===============
Observation:
[0, array([40.46124053]), array([69.83942664])]
Reward: -1.000000, Currnt Bid: 69.839427
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[38.76955799]
Explore action: 38.769558
Action taken: 38.769558
===============Feedback to random agent round===============
Currnt Bid: 69.839427
=================Random Agent Turn=================
Action taken: 70.385034
===============Feedback to learned agent round===============
Observation:
[1, array([40.46124053]), array([69.83942664])]
Reward: -2.000000, Currnt Bid: 69.839427
Is done? True
Episode End
Positive: 14, Negative: 20
EPISODE :- 74
Random Player utility: 34.967112
=================Random Agent Turn=================
Action taken: 29.625434
===============Feedback to learned agent round===============
Observation:
[0, 0, 29.625434042400112]
Reward: -1.000000, Currnt Bid: 29.625434
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[42.31796457]
Explore action: 42.317965
Action taken: 42.317965
===============Feedback to random agent round===============
Currnt Bid: 42.317965
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([42.31796457]), 29.625434042400112]
Reward: 57.682035, Currnt Bid: 42.317965
Is done? True
Episode End
Positive: 15, Negative: 20
EPISODE :- 75
Random Player utility: 154.161934
=================Random Agent Turn=================
Action taken: 134.969920
===============Feedback to learned agent round===============
Observation:
[0, 0, 134.9699195676002]
Reward: -1.000000, Currnt Bid: 134.969920
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 85.053757
Exploit action: 85.053757
Action taken: 85.053757
===============Feedback to random agent round===============
Currnt Bid: 134.969920
=================Random Agent Turn=================
Action taken: 149.953961
===============Feedback to learned agent round===============
Observation:
[1, 0, 134.9699195676002]
Reward: -2.000000, Currnt Bid: 134.969920
Is done? True
Episode End
Positive: 15, Negative: 20
EPISODE :- 76
Random Player utility: 20.680530
=================Random Agent Turn=================
Action taken: 8.186624
===============Feedback to learned agent round===============
Observation:
[0, 0, 8.186623722632527]
Reward: -1.000000, Currnt Bid: 8.186624
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[51.91230177]
Explore action: 51.912302
Action taken: 51.912302
===============Feedback to random agent round===============
Currnt Bid: 51.912302
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([51.91230177]), 8.186623722632527]
Reward: 48.087698, Currnt Bid: 51.912302
Is done? True
Episode End
Positive: 16, Negative: 20
EPISODE :- 77
Random Player utility: 104.578424
=================Random Agent Turn=================
Action taken: 20.394697
===============Feedback to learned agent round===============
Observation:
[0, 0, 20.394696953669346]
Reward: -1.000000, Currnt Bid: 20.394697
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[62.87636506]
Explore action: 62.876365
Action taken: 62.876365
===============Feedback to random agent round===============
Currnt Bid: 62.876365
=================Random Agent Turn=================
Action taken: 98.547110
===============Feedback to learned agent round===============
Observation:
[0, array([62.87636506]), array([98.54711002])]
Reward: -1.000000, Currnt Bid: 98.547110
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[72.09273908]
Explore action: 72.092739
Action taken: 72.092739
===============Feedback to random agent round===============
Currnt Bid: 98.547110
=================Random Agent Turn=================
Action taken: 100.799008
===============Feedback to learned agent round===============
Observation:
[1, array([62.87636506]), array([98.54711002])]
Reward: -2.000000, Currnt Bid: 98.547110
Is done? True
Episode End
Positive: 16, Negative: 20
EPISODE :- 78
Random Player utility: 212.525644
=================Random Agent Turn=================
Action taken: 35.953990
===============Feedback to learned agent round===============
Observation:
[0, 0, 35.953989632802816]
Reward: -1.000000, Currnt Bid: 35.953990
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[72.6037065]
Explore action: 72.603707
Action taken: 72.603707
===============Feedback to random agent round===============
Currnt Bid: 72.603707
=================Random Agent Turn=================
Action taken: 162.553584
===============Feedback to learned agent round===============
Observation:
[0, array([72.6037065]), array([162.55358434])]
Reward: -1.000000, Currnt Bid: 162.553584
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[72.87287117]
Explore action: 72.872871
Action taken: 72.872871
===============Feedback to random agent round===============
Currnt Bid: 162.553584
=================Random Agent Turn=================
Action taken: 166.902050
===============Feedback to learned agent round===============
Observation:
[1, array([72.6037065]), array([162.55358434])]
Reward: -2.000000, Currnt Bid: 162.553584
Is done? True
Episode End
Positive: 16, Negative: 20
EPISODE :- 79
Random Player utility: 58.203675
=================Random Agent Turn=================
Action taken: 39.702003
===============Feedback to learned agent round===============
Observation:
[0, 0, 39.70200328004887]
Reward: -1.000000, Currnt Bid: 39.702003
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[61.67039473]
Explore action: 61.670395
Action taken: 61.670395
===============Feedback to random agent round===============
Currnt Bid: 61.670395
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([61.67039473]), 39.70200328004887]
Reward: 38.329605, Currnt Bid: 61.670395
Is done? True
Episode End
Positive: 17, Negative: 20
EPISODE :- 80
Random Player utility: 7.090840
=================Random Agent Turn=================
Action taken: 0.683107
===============Feedback to learned agent round===============
Observation:
[0, 0, 0.6831069820810811]
Reward: -1.000000, Currnt Bid: 0.683107
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 84.369614
Exploit action: 84.369614
Action taken: 84.369614
===============Feedback to random agent round===============
Currnt Bid: 84.369614
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([84.36961], dtype=float32), 0.6831069820810811]
Reward: 15.630386, Currnt Bid: 84.369614
Is done? True
Episode End
Positive: 18, Negative: 20
EPISODE :- 81
Random Player utility: 41.040443
=================Random Agent Turn=================
Action taken: 22.892861
===============Feedback to learned agent round===============
Observation:
[0, 0, 22.89286088759514]
Reward: -1.000000, Currnt Bid: 22.892861
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[34.23723743]
Explore action: 34.237237
Action taken: 34.237237
===============Feedback to random agent round===============
Currnt Bid: 34.237237
=================Random Agent Turn=================
Action taken: 36.861513
===============Feedback to learned agent round===============
Observation:
[0, array([34.23723743]), array([36.86151307])]
Reward: -1.000000, Currnt Bid: 36.861513
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[35.66455693]
Explore action: 35.664557
Action taken: 35.664557
===============Feedback to random agent round===============
Currnt Bid: 36.861513
=================Random Agent Turn=================
Action taken: 39.195641
===============Feedback to learned agent round===============
Observation:
[1, array([34.23723743]), array([36.86151307])]
Reward: -2.000000, Currnt Bid: 36.861513
Is done? True
Episode End
Positive: 18, Negative: 21
EPISODE :- 82
Random Player utility: 106.715750
=================Random Agent Turn=================
Action taken: 87.628389
===============Feedback to learned agent round===============
Observation:
[0, 0, 87.62838888542704]
Reward: -1.000000, Currnt Bid: 87.628389
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[42.50945852]
Explore action: 42.509459
Action taken: 42.509459
===============Feedback to random agent round===============
Currnt Bid: 87.628389
=================Random Agent Turn=================
Action taken: 93.213309
===============Feedback to learned agent round===============
Observation:
[1, 0, 87.62838888542704]
Reward: -2.000000, Currnt Bid: 87.628389
Is done? True
Episode End
Positive: 18, Negative: 21
EPISODE :- 83
Random Player utility: 106.011755
=================Random Agent Turn=================
Action taken: 12.159324
===============Feedback to learned agent round===============
Observation:
[0, 0, 12.159323591742863]
Reward: -1.000000, Currnt Bid: 12.159324
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[34.16096752]
Explore action: 34.160968
Action taken: 34.160968
===============Feedback to random agent round===============
Currnt Bid: 34.160968
=================Random Agent Turn=================
Action taken: 91.361606
===============Feedback to learned agent round===============
Observation:
[0, array([34.16096752]), array([91.36160553])]
Reward: -1.000000, Currnt Bid: 91.361606
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[40.71334882]
Explore action: 40.713349
Action taken: 40.713349
===============Feedback to random agent round===============
Currnt Bid: 91.361606
=================Random Agent Turn=================
Action taken: 103.970534
===============Feedback to learned agent round===============
Observation:
[1, array([34.16096752]), array([91.36160553])]
Reward: -2.000000, Currnt Bid: 91.361606
Is done? True
Episode End
Positive: 18, Negative: 21
EPISODE :- 84
Random Player utility: 186.690741
=================Random Agent Turn=================
Action taken: 164.741496
===============Feedback to learned agent round===============
Observation:
[0, 0, 164.74149604209845]
Reward: -1.000000, Currnt Bid: 164.741496
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[30.49402277]
Explore action: 30.494023
Action taken: 30.494023
===============Feedback to random agent round===============
Currnt Bid: 164.741496
=================Random Agent Turn=================
Action taken: 182.468735
===============Feedback to learned agent round===============
Observation:
[1, 0, 164.74149604209845]
Reward: -2.000000, Currnt Bid: 164.741496
Is done? True
Episode End
Positive: 18, Negative: 21
EPISODE :- 85
Random Player utility: 62.553687
=================Random Agent Turn=================
Action taken: 11.635342
===============Feedback to learned agent round===============
Observation:
[0, 0, 11.635342023944935]
Reward: -1.000000, Currnt Bid: 11.635342
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 83.615456
Exploit action: 83.615456
Action taken: 83.615456
===============Feedback to random agent round===============
Currnt Bid: 83.615456
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([83.615456], dtype=float32), 11.635342023944935]
Reward: 16.384544, Currnt Bid: 83.615456
Is done? True
Episode End
Positive: 19, Negative: 21
EPISODE :- 86
Random Player utility: 42.274811
=================Random Agent Turn=================
Action taken: 10.862939
===============Feedback to learned agent round===============
Observation:
[0, 0, 10.862939138064096]
Reward: -1.000000, Currnt Bid: 10.862939
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[39.02739402]
Explore action: 39.027394
Action taken: 39.027394
===============Feedback to random agent round===============
Currnt Bid: 39.027394
=================Random Agent Turn=================
Action taken: 41.420867
===============Feedback to learned agent round===============
Observation:
[0, array([39.02739402]), array([41.42086672])]
Reward: -1.000000, Currnt Bid: 41.420867
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[44.22183568]
Explore action: 44.221836
Action taken: 44.221836
===============Feedback to random agent round===============
Currnt Bid: 44.221836
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([44.22183568]), array([41.42086672])]
Reward: 55.778164, Currnt Bid: 44.221836
Is done? True
Episode End
Positive: 20, Negative: 21
EPISODE :- 87
Random Player utility: 152.513117
=================Random Agent Turn=================
Action taken: 86.797585
===============Feedback to learned agent round===============
Observation:
[0, 0, 86.79758526627592]
Reward: -1.000000, Currnt Bid: 86.797585
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[49.07130408]
Explore action: 49.071304
Action taken: 49.071304
===============Feedback to random agent round===============
Currnt Bid: 86.797585
=================Random Agent Turn=================
Action taken: 142.433456
===============Feedback to learned agent round===============
Observation:
[1, 0, 86.79758526627592]
Reward: -2.000000, Currnt Bid: 86.797585
Is done? True
Episode End
Positive: 20, Negative: 21
EPISODE :- 88
Random Player utility: 120.823690
=================Random Agent Turn=================
Action taken: 6.868367
===============Feedback to learned agent round===============
Observation:
[0, 0, 6.868366727263261]
Reward: -1.000000, Currnt Bid: 6.868367
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[47.75948297]
Explore action: 47.759483
Action taken: 47.759483
===============Feedback to random agent round===============
Currnt Bid: 47.759483
=================Random Agent Turn=================
Action taken: 82.592113
===============Feedback to learned agent round===============
Observation:
[0, array([47.75948297]), array([82.59211296])]
Reward: -1.000000, Currnt Bid: 82.592113
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[33.99489596]
Explore action: 33.994896
Action taken: 33.994896
===============Feedback to random agent round===============
Currnt Bid: 82.592113
=================Random Agent Turn=================
Action taken: 96.248748
===============Feedback to learned agent round===============
Observation:
[1, array([47.75948297]), array([82.59211296])]
Reward: -2.000000, Currnt Bid: 82.592113
Is done? True
Episode End
Positive: 20, Negative: 21
EPISODE :- 89
Random Player utility: 116.991257
=================Random Agent Turn=================
Action taken: 108.523739
===============Feedback to learned agent round===============
Observation:
[0, 0, 108.52373850802609]
Reward: -1.000000, Currnt Bid: 108.523739
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[41.21754295]
Explore action: 41.217543
Action taken: 41.217543
===============Feedback to random agent round===============
Currnt Bid: 108.523739
=================Random Agent Turn=================
Action taken: 112.268863
===============Feedback to learned agent round===============
Observation:
[1, 0, 108.52373850802609]
Reward: -2.000000, Currnt Bid: 108.523739
Is done? True
Episode End
Positive: 20, Negative: 21
EPISODE :- 90
Random Player utility: 48.245709
=================Random Agent Turn=================
Action taken: 21.723431
===============Feedback to learned agent round===============
Observation:
[0, 0, 21.72343145377126]
Reward: -1.000000, Currnt Bid: 21.723431
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 82.790054
Exploit action: 82.790054
Action taken: 82.790054
===============Feedback to random agent round===============
Currnt Bid: 82.790054
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([82.790054], dtype=float32), 21.72343145377126]
Reward: 17.209946, Currnt Bid: 82.790054
Is done? True
Episode End
Positive: 21, Negative: 21
EPISODE :- 91
Random Player utility: 45.567530
=================Random Agent Turn=================
Action taken: 24.591767
===============Feedback to learned agent round===============
Observation:
[0, 0, 24.59176669184827]
Reward: -1.000000, Currnt Bid: 24.591767
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[44.47944252]
Explore action: 44.479443
Action taken: 44.479443
===============Feedback to random agent round===============
Currnt Bid: 44.479443
=================Random Agent Turn=================
Action taken: 44.804100
===============Feedback to learned agent round===============
Observation:
[0, array([44.47944252]), array([44.80410005])]
Reward: -1.000000, Currnt Bid: 44.804100
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[43.81854381]
Explore action: 43.818544
Action taken: 43.818544
===============Feedback to random agent round===============
Currnt Bid: 44.804100
=================Random Agent Turn=================
Action taken: 45.136244
===============Feedback to learned agent round===============
Observation:
[1, array([44.47944252]), array([44.80410005])]
Reward: -2.000000, Currnt Bid: 44.804100
Is done? True
Episode End
Positive: 21, Negative: 22
EPISODE :- 92
Random Player utility: 44.914520
=================Random Agent Turn=================
Action taken: 30.884666
===============Feedback to learned agent round===============
Observation:
[0, 0, 30.884665952252195]
Reward: -1.000000, Currnt Bid: 30.884666
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[38.59650723]
Explore action: 38.596507
Action taken: 38.596507
===============Feedback to random agent round===============
Currnt Bid: 38.596507
=================Random Agent Turn=================
Action taken: 38.900508
===============Feedback to learned agent round===============
Observation:
[0, array([38.59650723]), array([38.90050752])]
Reward: -1.000000, Currnt Bid: 38.900508
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.70274172]
Explore action: 48.702742
Action taken: 48.702742
===============Feedback to random agent round===============
Currnt Bid: 48.702742
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([48.70274172]), array([38.90050752])]
Reward: 51.297258, Currnt Bid: 48.702742
Is done? True
Episode End
Positive: 22, Negative: 22
EPISODE :- 93
Random Player utility: 125.075425
=================Random Agent Turn=================
Action taken: 94.028263
===============Feedback to learned agent round===============
Observation:
[0, 0, 94.02826339594023]
Reward: -1.000000, Currnt Bid: 94.028263
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[60.31666729]
Explore action: 60.316667
Action taken: 60.316667
===============Feedback to random agent round===============
Currnt Bid: 94.028263
=================Random Agent Turn=================
Action taken: 96.965792
===============Feedback to learned agent round===============
Observation:
[1, 0, 94.02826339594023]
Reward: -2.000000, Currnt Bid: 94.028263
Is done? True
Episode End
Positive: 22, Negative: 22
EPISODE :- 94
Random Player utility: 76.822150
=================Random Agent Turn=================
Action taken: 76.771257
===============Feedback to learned agent round===============
Observation:
[0, 0, 76.77125697333265]
Reward: -1.000000, Currnt Bid: 76.771257
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[54.67610922]
Explore action: 54.676109
Action taken: 54.676109
===============Feedback to random agent round===============
Currnt Bid: 76.771257
=================Random Agent Turn=================
Action taken: 76.813991
===============Feedback to learned agent round===============
Observation:
[1, 0, 76.77125697333265]
Reward: -2.000000, Currnt Bid: 76.771257
Is done? True
Episode End
Positive: 22, Negative: 23
EPISODE :- 95
Random Player utility: 63.495094
=================Random Agent Turn=================
Action taken: 8.915240
===============Feedback to learned agent round===============
Observation:
[0, 0, 8.915240204735586]
Reward: -1.000000, Currnt Bid: 8.915240
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 81.899811
Exploit action: 81.899811
Action taken: 81.899811
===============Feedback to random agent round===============
Currnt Bid: 81.899811
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([81.89981], dtype=float32), 8.915240204735586]
Reward: 18.100189, Currnt Bid: 81.899811
Is done? True
Episode End
Positive: 23, Negative: 23
EPISODE :- 96
Random Player utility: 45.062821
=================Random Agent Turn=================
Action taken: 43.836386
===============Feedback to learned agent round===============
Observation:
[0, 0, 43.83638592766718]
Reward: -1.000000, Currnt Bid: 43.836386
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[55.77857414]
Explore action: 55.778574
Action taken: 55.778574
===============Feedback to random agent round===============
Currnt Bid: 55.778574
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([55.77857414]), 43.83638592766718]
Reward: 44.221426, Currnt Bid: 55.778574
Is done? True
Episode End
Positive: 24, Negative: 23
EPISODE :- 97
Random Player utility: 84.927575
=================Random Agent Turn=================
Action taken: 27.737335
===============Feedback to learned agent round===============
Observation:
[0, 0, 27.737335126594022]
Reward: -1.000000, Currnt Bid: 27.737335
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[55.33832497]
Explore action: 55.338325
Action taken: 55.338325
===============Feedback to random agent round===============
Currnt Bid: 55.338325
=================Random Agent Turn=================
Action taken: 83.399402
===============Feedback to learned agent round===============
Observation:
[0, array([55.33832497]), array([83.39940151])]
Reward: -1.000000, Currnt Bid: 83.399402
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[44.98925734]
Explore action: 44.989257
Action taken: 44.989257
===============Feedback to random agent round===============
Currnt Bid: 83.399402
=================Random Agent Turn=================
Action taken: 84.316578
===============Feedback to learned agent round===============
Observation:
[1, array([55.33832497]), array([83.39940151])]
Reward: -2.000000, Currnt Bid: 83.399402
Is done? True
Episode End
Positive: 24, Negative: 24
EPISODE :- 98
Random Player utility: 118.106430
=================Random Agent Turn=================
Action taken: 65.575358
===============Feedback to learned agent round===============
Observation:
[0, 0, 65.57535816180776]
Reward: -1.000000, Currnt Bid: 65.575358
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[42.80439579]
Explore action: 42.804396
Action taken: 42.804396
===============Feedback to random agent round===============
Currnt Bid: 65.575358
=================Random Agent Turn=================
Action taken: 92.124215
===============Feedback to learned agent round===============
Observation:
[1, 0, 65.57535816180776]
Reward: -2.000000, Currnt Bid: 65.575358
Is done? True
Episode End
Positive: 24, Negative: 24
EPISODE :- 99
Random Player utility: 23.068917
=================Random Agent Turn=================
Action taken: 13.463501
===============Feedback to learned agent round===============
Observation:
[0, 0, 13.463501367550702]
Reward: -1.000000, Currnt Bid: 13.463501
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[37.30553051]
Explore action: 37.305531
Action taken: 37.305531
===============Feedback to random agent round===============
Currnt Bid: 37.305531
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([37.30553051]), 13.463501367550702]
Reward: 62.694469, Currnt Bid: 37.305531
Is done? True
Episode End
Positive: 25, Negative: 24
EPISODE :- 100
Random Player utility: 27.805484
=================Random Agent Turn=================
Action taken: 6.227460
===============Feedback to learned agent round===============
Observation:
[0, 0, 6.227459834328748]
Reward: -1.000000, Currnt Bid: 6.227460
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 81.023048
Exploit action: 81.023048
Action taken: 81.023048
===============Feedback to random agent round===============
Currnt Bid: 81.023048
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([81.02305], dtype=float32), 6.227459834328748]
Reward: 18.976952, Currnt Bid: 81.023048
Is done? True
Episode End
Positive: 26, Negative: 24
Models saved successfully
EPISODE :- 101
Random Player utility: 76.313615
=================Random Agent Turn=================
Action taken: 14.346173
===============Feedback to learned agent round===============
Observation:
[0, 0, 14.34617319892132]
Reward: -1.000000, Currnt Bid: 14.346173
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[34.19738658]
Explore action: 34.197387
Action taken: 34.197387
===============Feedback to random agent round===============
Currnt Bid: 34.197387
=================Random Agent Turn=================
Action taken: 36.451858
===============Feedback to learned agent round===============
Observation:
[0, array([34.19738658]), array([36.45185832])]
Reward: -1.000000, Currnt Bid: 36.451858
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[31.98543405]
Explore action: 31.985434
Action taken: 31.985434
===============Feedback to random agent round===============
Currnt Bid: 36.451858
=================Random Agent Turn=================
Action taken: 46.512273
===============Feedback to learned agent round===============
Observation:
[1, array([34.19738658]), array([36.45185832])]
Reward: -2.000000, Currnt Bid: 36.451858
Is done? True
Episode End
Positive: 26, Negative: 25
EPISODE :- 102
Random Player utility: 202.250274
=================Random Agent Turn=================
Action taken: 185.668919
===============Feedback to learned agent round===============
Observation:
[0, 0, 185.66891851723327]
Reward: -1.000000, Currnt Bid: 185.668919
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[28.13649095]
Explore action: 28.136491
Action taken: 28.136491
===============Feedback to random agent round===============
Currnt Bid: 185.668919
=================Random Agent Turn=================
Action taken: 194.122090
===============Feedback to learned agent round===============
Observation:
[1, 0, 185.66891851723327]
Reward: -2.000000, Currnt Bid: 185.668919
Is done? True
Episode End
Positive: 26, Negative: 25
EPISODE :- 103
Random Player utility: 144.650477
=================Random Agent Turn=================
Action taken: 81.873336
===============Feedback to learned agent round===============
Observation:
[0, 0, 81.87333622194588]
Reward: -1.000000, Currnt Bid: 81.873336
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[13.4493349]
Explore action: 13.449335
Action taken: 13.449335
===============Feedback to random agent round===============
Currnt Bid: 81.873336
=================Random Agent Turn=================
Action taken: 122.617838
===============Feedback to learned agent round===============
Observation:
[1, 0, 81.87333622194588]
Reward: -2.000000, Currnt Bid: 81.873336
Is done? True
Episode End
Positive: 26, Negative: 25
EPISODE :- 104
Random Player utility: 97.796370
=================Random Agent Turn=================
Action taken: 84.645434
===============Feedback to learned agent round===============
Observation:
[0, 0, 84.64543350038552]
Reward: -1.000000, Currnt Bid: 84.645434
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[28.64294617]
Explore action: 28.642946
Action taken: 28.642946
===============Feedback to random agent round===============
Currnt Bid: 84.645434
=================Random Agent Turn=================
Action taken: 91.838994
===============Feedback to learned agent round===============
Observation:
[1, 0, 84.64543350038552]
Reward: -2.000000, Currnt Bid: 84.645434
Is done? True
Episode End
Positive: 26, Negative: 26
EPISODE :- 105
Random Player utility: 96.001778
=================Random Agent Turn=================
Action taken: 21.652356
===============Feedback to learned agent round===============
Observation:
[0, 0, 21.65235640799506]
Reward: -1.000000, Currnt Bid: 21.652356
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 80.078590
Exploit action: 80.078590
Action taken: 80.078590
===============Feedback to random agent round===============
Currnt Bid: 80.078590
=================Random Agent Turn=================
Action taken: 88.606354
===============Feedback to learned agent round===============
Observation:
[0, array([80.07859], dtype=float32), array([88.60635], dtype=float32)]
Reward: -1.000000, Currnt Bid: 88.606354
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 67.445587
Exploit action: 67.445587
Action taken: 67.445587
===============Feedback to random agent round===============
Currnt Bid: 88.606354
=================Random Agent Turn=================
Action taken: 93.205406
===============Feedback to learned agent round===============
Observation:
[1, array([80.07859], dtype=float32), array([88.60635], dtype=float32)]
Reward: -2.000000, Currnt Bid: 88.606354
Is done? True
Episode End
Positive: 26, Negative: 27
EPISODE :- 106
Random Player utility: 124.888440
=================Random Agent Turn=================
Action taken: 114.214170
===============Feedback to learned agent round===============
Observation:
[0, 0, 114.21417003543303]
Reward: -1.000000, Currnt Bid: 114.214170
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[23.09447521]
Explore action: 23.094475
Action taken: 23.094475
===============Feedback to random agent round===============
Currnt Bid: 114.214170
=================Random Agent Turn=================
Action taken: 115.216650
===============Feedback to learned agent round===============
Observation:
[1, 0, 114.21417003543303]
Reward: -2.000000, Currnt Bid: 114.214170
Is done? True
Episode End
Positive: 26, Negative: 27
EPISODE :- 107
Random Player utility: 236.233151
=================Random Agent Turn=================
Action taken: 64.663290
===============Feedback to learned agent round===============
Observation:
[0, 0, 64.66329022408333]
Reward: -1.000000, Currnt Bid: 64.663290
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[17.50990419]
Explore action: 17.509904
Action taken: 17.509904
===============Feedback to random agent round===============
Currnt Bid: 64.663290
=================Random Agent Turn=================
Action taken: 71.717732
===============Feedback to learned agent round===============
Observation:
[1, 0, 64.66329022408333]
Reward: -2.000000, Currnt Bid: 64.663290
Is done? True
Episode End
Positive: 26, Negative: 27
EPISODE :- 108
Random Player utility: 233.959905
=================Random Agent Turn=================
Action taken: 80.459259
===============Feedback to learned agent round===============
Observation:
[0, 0, 80.45925904306948]
Reward: -1.000000, Currnt Bid: 80.459259
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[16.14076716]
Explore action: 16.140767
Action taken: 16.140767
===============Feedback to random agent round===============
Currnt Bid: 80.459259
=================Random Agent Turn=================
Action taken: 190.961970
===============Feedback to learned agent round===============
Observation:
[1, 0, 80.45925904306948]
Reward: -2.000000, Currnt Bid: 80.459259
Is done? True
Episode End
Positive: 26, Negative: 27
EPISODE :- 109
Random Player utility: 181.636794
=================Random Agent Turn=================
Action taken: 139.619551
===============Feedback to learned agent round===============
Observation:
[0, 0, 139.61955085138712]
Reward: -1.000000, Currnt Bid: 139.619551
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[47.77137735]
Explore action: 47.771377
Action taken: 47.771377
===============Feedback to random agent round===============
Currnt Bid: 139.619551
=================Random Agent Turn=================
Action taken: 148.124068
===============Feedback to learned agent round===============
Observation:
[1, 0, 139.61955085138712]
Reward: -2.000000, Currnt Bid: 139.619551
Is done? True
Episode End
Positive: 26, Negative: 27
EPISODE :- 110
Random Player utility: 217.930763
=================Random Agent Turn=================
Action taken: 77.383146
===============Feedback to learned agent round===============
Observation:
[0, 0, 77.38314602991512]
Reward: -1.000000, Currnt Bid: 77.383146
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 79.076065
Exploit action: 79.076065
Action taken: 79.076065
===============Feedback to random agent round===============
Currnt Bid: 79.076065
=================Random Agent Turn=================
Action taken: 131.743103
===============Feedback to learned agent round===============
Observation:
[0, array([79.076065], dtype=float32), array([131.7431], dtype=float32)]
Reward: -1.000000, Currnt Bid: 131.743103
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 26.352358
Exploit action: 26.352358
Action taken: 26.352358
===============Feedback to random agent round===============
Currnt Bid: 131.743103
=================Random Agent Turn=================
Action taken: 204.426239
===============Feedback to learned agent round===============
Observation:
[1, array([79.076065], dtype=float32), array([131.7431], dtype=float32)]
Reward: -2.000000, Currnt Bid: 131.743103
Is done? True
Episode End
Positive: 26, Negative: 27
EPISODE :- 111
Random Player utility: 121.207513
=================Random Agent Turn=================
Action taken: 26.260933
===============Feedback to learned agent round===============
Observation:
[0, 0, 26.26093276608864]
Reward: -1.000000, Currnt Bid: 26.260933
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[56.81727999]
Explore action: 56.817280
Action taken: 56.817280
===============Feedback to random agent round===============
Currnt Bid: 56.817280
=================Random Agent Turn=================
Action taken: 72.365045
===============Feedback to learned agent round===============
Observation:
[0, array([56.81727999]), array([72.36504521])]
Reward: -1.000000, Currnt Bid: 72.365045
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[71.62130665]
Explore action: 71.621307
Action taken: 71.621307
===============Feedback to random agent round===============
Currnt Bid: 72.365045
=================Random Agent Turn=================
Action taken: 84.682080
===============Feedback to learned agent round===============
Observation:
[1, array([56.81727999]), array([72.36504521])]
Reward: -2.000000, Currnt Bid: 72.365045
Is done? True
Episode End
Positive: 26, Negative: 27
EPISODE :- 112
Random Player utility: 177.222280
=================Random Agent Turn=================
Action taken: 93.121632
===============Feedback to learned agent round===============
Observation:
[0, 0, 93.12163209559301]
Reward: -1.000000, Currnt Bid: 93.121632
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[74.13311112]
Explore action: 74.133111
Action taken: 74.133111
===============Feedback to random agent round===============
Currnt Bid: 93.121632
=================Random Agent Turn=================
Action taken: 96.326927
===============Feedback to learned agent round===============
Observation:
[1, 0, 93.12163209559301]
Reward: -2.000000, Currnt Bid: 93.121632
Is done? True
Episode End
Positive: 26, Negative: 27
EPISODE :- 113
Random Player utility: 121.695132
=================Random Agent Turn=================
Action taken: 12.474899
===============Feedback to learned agent round===============
Observation:
[0, 0, 12.474899490644317]
Reward: -1.000000, Currnt Bid: 12.474899
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[60.92585801]
Explore action: 60.925858
Action taken: 60.925858
===============Feedback to random agent round===============
Currnt Bid: 60.925858
=================Random Agent Turn=================
Action taken: 67.904939
===============Feedback to learned agent round===============
Observation:
[0, array([60.92585801]), array([67.90493896])]
Reward: -1.000000, Currnt Bid: 67.904939
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[53.28881809]
Explore action: 53.288818
Action taken: 53.288818
===============Feedback to random agent round===============
Currnt Bid: 67.904939
=================Random Agent Turn=================
Action taken: 73.194706
===============Feedback to learned agent round===============
Observation:
[1, array([60.92585801]), array([67.90493896])]
Reward: -2.000000, Currnt Bid: 67.904939
Is done? True
Episode End
Positive: 26, Negative: 27
EPISODE :- 114
Random Player utility: 94.356375
=================Random Agent Turn=================
Action taken: 74.339594
===============Feedback to learned agent round===============
Observation:
[0, 0, 74.33959411679554]
Reward: -1.000000, Currnt Bid: 74.339594
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[57.04193299]
Explore action: 57.041933
Action taken: 57.041933
===============Feedback to random agent round===============
Currnt Bid: 74.339594
=================Random Agent Turn=================
Action taken: 80.574279
===============Feedback to learned agent round===============
Observation:
[1, 0, 74.33959411679554]
Reward: -2.000000, Currnt Bid: 74.339594
Is done? True
Episode End
Positive: 26, Negative: 28
EPISODE :- 115
Random Player utility: 70.975031
=================Random Agent Turn=================
Action taken: 1.281332
===============Feedback to learned agent round===============
Observation:
[0, 0, 1.2813319972864308]
Reward: -1.000000, Currnt Bid: 1.281332
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 77.820435
Exploit action: 77.820435
Action taken: 77.820435
===============Feedback to random agent round===============
Currnt Bid: 77.820435
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([77.820435], dtype=float32), 1.2813319972864308]
Reward: 22.179565, Currnt Bid: 77.820435
Is done? True
Episode End
Positive: 27, Negative: 28
EPISODE :- 116
Random Player utility: 110.488280
=================Random Agent Turn=================
Action taken: 27.881777
===============Feedback to learned agent round===============
Observation:
[0, 0, 27.8817766622053]
Reward: -1.000000, Currnt Bid: 27.881777
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[69.97618323]
Explore action: 69.976183
Action taken: 69.976183
===============Feedback to random agent round===============
Currnt Bid: 69.976183
=================Random Agent Turn=================
Action taken: 90.024923
===============Feedback to learned agent round===============
Observation:
[0, array([69.97618323]), array([90.02492308])]
Reward: -1.000000, Currnt Bid: 90.024923
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[84.25991138]
Explore action: 84.259911
Action taken: 84.259911
===============Feedback to random agent round===============
Currnt Bid: 90.024923
=================Random Agent Turn=================
Action taken: 93.311782
===============Feedback to learned agent round===============
Observation:
[1, array([69.97618323]), array([90.02492308])]
Reward: -2.000000, Currnt Bid: 90.024923
Is done? True
Episode End
Positive: 27, Negative: 28
EPISODE :- 117
Random Player utility: 182.907197
=================Random Agent Turn=================
Action taken: 60.621824
===============Feedback to learned agent round===============
Observation:
[0, 0, 60.62182409227931]
Reward: -1.000000, Currnt Bid: 60.621824
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[75.20096734]
Explore action: 75.200967
Action taken: 75.200967
===============Feedback to random agent round===============
Currnt Bid: 75.200967
=================Random Agent Turn=================
Action taken: 124.490509
===============Feedback to learned agent round===============
Observation:
[0, array([75.20096734]), array([124.49050934])]
Reward: -1.000000, Currnt Bid: 124.490509
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[76.1341692]
Explore action: 76.134169
Action taken: 76.134169
===============Feedback to random agent round===============
Currnt Bid: 124.490509
=================Random Agent Turn=================
Action taken: 164.060284
===============Feedback to learned agent round===============
Observation:
[1, array([75.20096734]), array([124.49050934])]
Reward: -2.000000, Currnt Bid: 124.490509
Is done? True
Episode End
Positive: 27, Negative: 28
EPISODE :- 118
Random Player utility: 151.636213
=================Random Agent Turn=================
Action taken: 34.925797
===============Feedback to learned agent round===============
Observation:
[0, 0, 34.92579656604639]
Reward: -1.000000, Currnt Bid: 34.925797
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[84.58308806]
Explore action: 84.583088
Action taken: 84.583088
===============Feedback to random agent round===============
Currnt Bid: 84.583088
=================Random Agent Turn=================
Action taken: 103.493606
===============Feedback to learned agent round===============
Observation:
[0, array([84.58308806]), array([103.49360601])]
Reward: -1.000000, Currnt Bid: 103.493606
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[90.76617399]
Explore action: 90.766174
Action taken: 90.766174
===============Feedback to random agent round===============
Currnt Bid: 103.493606
=================Random Agent Turn=================
Action taken: 146.980141
===============Feedback to learned agent round===============
Observation:
[1, array([84.58308806]), array([103.49360601])]
Reward: -2.000000, Currnt Bid: 103.493606
Is done? True
Episode End
Positive: 27, Negative: 28
EPISODE :- 119
Random Player utility: 71.324891
=================Random Agent Turn=================
Action taken: 38.374705
===============Feedback to learned agent round===============
Observation:
[0, 0, 38.37470479683641]
Reward: -1.000000, Currnt Bid: 38.374705
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[97.16896992]
Explore action: 97.168970
Action taken: 97.168970
===============Feedback to random agent round===============
Currnt Bid: 97.168970
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([97.16896992]), 38.37470479683641]
Reward: 2.831030, Currnt Bid: 97.168970
Is done? True
Episode End
Positive: 28, Negative: 28
EPISODE :- 120
Random Player utility: 109.466765
=================Random Agent Turn=================
Action taken: 23.332193
===============Feedback to learned agent round===============
Observation:
[0, 0, 23.332193304230728]
Reward: -1.000000, Currnt Bid: 23.332193
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 76.481041
Exploit action: 76.481041
Action taken: 76.481041
===============Feedback to random agent round===============
Currnt Bid: 76.481041
=================Random Agent Turn=================
Action taken: 84.529694
===============Feedback to learned agent round===============
Observation:
[0, array([76.48104], dtype=float32), array([84.52969], dtype=float32)]
Reward: -1.000000, Currnt Bid: 84.529694
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 57.958675
Exploit action: 57.958675
Action taken: 57.958675
===============Feedback to random agent round===============
Currnt Bid: 84.529694
=================Random Agent Turn=================
Action taken: 93.192825
===============Feedback to learned agent round===============
Observation:
[1, array([76.48104], dtype=float32), array([84.52969], dtype=float32)]
Reward: -2.000000, Currnt Bid: 84.529694
Is done? True
Episode End
Positive: 28, Negative: 28
EPISODE :- 121
Random Player utility: 104.530509
=================Random Agent Turn=================
Action taken: 13.418418
===============Feedback to learned agent round===============
Observation:
[0, 0, 13.418417583230703]
Reward: -1.000000, Currnt Bid: 13.418418
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[86.42097385]
Explore action: 86.420974
Action taken: 86.420974
===============Feedback to random agent round===============
Currnt Bid: 86.420974
=================Random Agent Turn=================
Action taken: 90.346509
===============Feedback to learned agent round===============
Observation:
[0, array([86.42097385]), array([90.34650921])]
Reward: -1.000000, Currnt Bid: 90.346509
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[73.64143967]
Explore action: 73.641440
Action taken: 73.641440
===============Feedback to random agent round===============
Currnt Bid: 90.346509
=================Random Agent Turn=================
Action taken: 96.810961
===============Feedback to learned agent round===============
Observation:
[1, array([86.42097385]), array([90.34650921])]
Reward: -2.000000, Currnt Bid: 90.346509
Is done? True
Episode End
Positive: 28, Negative: 28
EPISODE :- 122
Random Player utility: 71.584354
=================Random Agent Turn=================
Action taken: 65.865940
===============Feedback to learned agent round===============
Observation:
[0, 0, 65.865939593913]
Reward: -1.000000, Currnt Bid: 65.865940
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[49.76248116]
Explore action: 49.762481
Action taken: 49.762481
===============Feedback to random agent round===============
Currnt Bid: 65.865940
=================Random Agent Turn=================
Action taken: 70.691319
===============Feedback to learned agent round===============
Observation:
[1, 0, 65.865939593913]
Reward: -2.000000, Currnt Bid: 65.865940
Is done? True
Episode End
Positive: 28, Negative: 29
EPISODE :- 123
Random Player utility: 94.729221
=================Random Agent Turn=================
Action taken: 66.967752
===============Feedback to learned agent round===============
Observation:
[0, 0, 66.96775244508156]
Reward: -1.000000, Currnt Bid: 66.967752
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[60.36489897]
Explore action: 60.364899
Action taken: 60.364899
===============Feedback to random agent round===============
Currnt Bid: 66.967752
=================Random Agent Turn=================
Action taken: 73.918086
===============Feedback to learned agent round===============
Observation:
[1, 0, 66.96775244508156]
Reward: -2.000000, Currnt Bid: 66.967752
Is done? True
Episode End
Positive: 28, Negative: 30
EPISODE :- 124
Random Player utility: 121.232820
=================Random Agent Turn=================
Action taken: 48.748721
===============Feedback to learned agent round===============
Observation:
[0, 0, 48.74872124239267]
Reward: -1.000000, Currnt Bid: 48.748721
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[56.52302834]
Explore action: 56.523028
Action taken: 56.523028
===============Feedback to random agent round===============
Currnt Bid: 56.523028
=================Random Agent Turn=================
Action taken: 113.715198
===============Feedback to learned agent round===============
Observation:
[0, array([56.52302834]), array([113.71519832])]
Reward: -1.000000, Currnt Bid: 113.715198
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[49.07940965]
Explore action: 49.079410
Action taken: 49.079410
===============Feedback to random agent round===============
Currnt Bid: 113.715198
=================Random Agent Turn=================
Action taken: 117.288901
===============Feedback to learned agent round===============
Observation:
[1, array([56.52302834]), array([113.71519832])]
Reward: -2.000000, Currnt Bid: 113.715198
Is done? True
Episode End
Positive: 28, Negative: 30
EPISODE :- 125
Random Player utility: 38.602517
=================Random Agent Turn=================
Action taken: 7.983574
===============Feedback to learned agent round===============
Observation:
[0, 0, 7.983573966805369]
Reward: -1.000000, Currnt Bid: 7.983574
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 75.043915
Exploit action: 75.043915
Action taken: 75.043915
===============Feedback to random agent round===============
Currnt Bid: 75.043915
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([75.043915], dtype=float32), 7.983573966805369]
Reward: 24.956085, Currnt Bid: 75.043915
Is done? True
Episode End
Positive: 29, Negative: 30
EPISODE :- 126
Random Player utility: 32.595303
=================Random Agent Turn=================
Action taken: 9.545020
===============Feedback to learned agent round===============
Observation:
[0, 0, 9.545020487368728]
Reward: -1.000000, Currnt Bid: 9.545020
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[47.56535005]
Explore action: 47.565350
Action taken: 47.565350
===============Feedback to random agent round===============
Currnt Bid: 47.565350
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([47.56535005]), 9.545020487368728]
Reward: 52.434650, Currnt Bid: 47.565350
Is done? True
Episode End
Positive: 30, Negative: 30
EPISODE :- 127
Random Player utility: 90.255430
=================Random Agent Turn=================
Action taken: 26.993917
===============Feedback to learned agent round===============
Observation:
[0, 0, 26.993916644288593]
Reward: -1.000000, Currnt Bid: 26.993917
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.52863662]
Explore action: 48.528637
Action taken: 48.528637
===============Feedback to random agent round===============
Currnt Bid: 48.528637
=================Random Agent Turn=================
Action taken: 80.752339
===============Feedback to learned agent round===============
Observation:
[0, array([48.52863662]), array([80.75233873])]
Reward: -1.000000, Currnt Bid: 80.752339
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[44.46923964]
Explore action: 44.469240
Action taken: 44.469240
===============Feedback to random agent round===============
Currnt Bid: 80.752339
=================Random Agent Turn=================
Action taken: 81.868025
===============Feedback to learned agent round===============
Observation:
[1, array([48.52863662]), array([80.75233873])]
Reward: -2.000000, Currnt Bid: 80.752339
Is done? True
Episode End
Positive: 30, Negative: 31
EPISODE :- 128
Random Player utility: 70.292969
=================Random Agent Turn=================
Action taken: 62.747194
===============Feedback to learned agent round===============
Observation:
[0, 0, 62.74719426146285]
Reward: -1.000000, Currnt Bid: 62.747194
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[27.55215544]
Explore action: 27.552155
Action taken: 27.552155
===============Feedback to random agent round===============
Currnt Bid: 62.747194
=================Random Agent Turn=================
Action taken: 64.151920
===============Feedback to learned agent round===============
Observation:
[1, 0, 62.74719426146285]
Reward: -2.000000, Currnt Bid: 62.747194
Is done? True
Episode End
Positive: 30, Negative: 32
EPISODE :- 129
Random Player utility: 65.218613
=================Random Agent Turn=================
Action taken: 49.072490
===============Feedback to learned agent round===============
Observation:
[0, 0, 49.07249030028242]
Reward: -1.000000, Currnt Bid: 49.072490
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[30.53756494]
Explore action: 30.537565
Action taken: 30.537565
===============Feedback to random agent round===============
Currnt Bid: 49.072490
=================Random Agent Turn=================
Action taken: 62.987365
===============Feedback to learned agent round===============
Observation:
[1, 0, 49.07249030028242]
Reward: -2.000000, Currnt Bid: 49.072490
Is done? True
Episode End
Positive: 30, Negative: 33
EPISODE :- 130
Random Player utility: 123.203557
=================Random Agent Turn=================
Action taken: 52.257672
===============Feedback to learned agent round===============
Observation:
[0, 0, 52.25767220827136]
Reward: -1.000000, Currnt Bid: 52.257672
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 73.760338
Exploit action: 73.760338
Action taken: 73.760338
===============Feedback to random agent round===============
Currnt Bid: 73.760338
=================Random Agent Turn=================
Action taken: 101.887589
===============Feedback to learned agent round===============
Observation:
[0, array([73.76034], dtype=float32), array([101.88759], dtype=float32)]
Reward: -1.000000, Currnt Bid: 101.887589
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 25.158304
Exploit action: 25.158304
Action taken: 25.158304
===============Feedback to random agent round===============
Currnt Bid: 101.887589
=================Random Agent Turn=================
Action taken: 110.164246
===============Feedback to learned agent round===============
Observation:
[1, array([73.76034], dtype=float32), array([101.88759], dtype=float32)]
Reward: -2.000000, Currnt Bid: 101.887589
Is done? True
Episode End
Positive: 30, Negative: 33
EPISODE :- 131
Random Player utility: 168.249650
=================Random Agent Turn=================
Action taken: 145.528872
===============Feedback to learned agent round===============
Observation:
[0, 0, 145.52887240494687]
Reward: -1.000000, Currnt Bid: 145.528872
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[25.84815674]
Explore action: 25.848157
Action taken: 25.848157
===============Feedback to random agent round===============
Currnt Bid: 145.528872
=================Random Agent Turn=================
Action taken: 148.932863
===============Feedback to learned agent round===============
Observation:
[1, 0, 145.52887240494687]
Reward: -2.000000, Currnt Bid: 145.528872
Is done? True
Episode End
Positive: 30, Negative: 33
EPISODE :- 132
Random Player utility: 19.951230
=================Random Agent Turn=================
Action taken: 12.469407
===============Feedback to learned agent round===============
Observation:
[0, 0, 12.469406845675065]
Reward: -1.000000, Currnt Bid: 12.469407
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[29.70818227]
Explore action: 29.708182
Action taken: 29.708182
===============Feedback to random agent round===============
Currnt Bid: 29.708182
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([29.70818227]), 12.469406845675065]
Reward: 70.291818, Currnt Bid: 29.708182
Is done? True
Episode End
Positive: 31, Negative: 33
EPISODE :- 133
Random Player utility: 151.629924
=================Random Agent Turn=================
Action taken: 130.952411
===============Feedback to learned agent round===============
Observation:
[0, 0, 130.95241113420266]
Reward: -1.000000, Currnt Bid: 130.952411
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[20.92765777]
Explore action: 20.927658
Action taken: 20.927658
===============Feedback to random agent round===============
Currnt Bid: 130.952411
=================Random Agent Turn=================
Action taken: 143.122195
===============Feedback to learned agent round===============
Observation:
[1, 0, 130.95241113420266]
Reward: -2.000000, Currnt Bid: 130.952411
Is done? True
Episode End
Positive: 31, Negative: 33
EPISODE :- 134
Random Player utility: 94.479142
=================Random Agent Turn=================
Action taken: 12.547140
===============Feedback to learned agent round===============
Observation:
[0, 0, 12.547139743175443]
Reward: -1.000000, Currnt Bid: 12.547140
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[22.14620247]
Explore action: 22.146202
Action taken: 22.146202
===============Feedback to random agent round===============
Currnt Bid: 22.146202
=================Random Agent Turn=================
Action taken: 72.544839
===============Feedback to learned agent round===============
Observation:
[0, array([22.14620247]), array([72.544839])]
Reward: -1.000000, Currnt Bid: 72.544839
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[22.01373336]
Explore action: 22.013733
Action taken: 22.013733
===============Feedback to random agent round===============
Currnt Bid: 72.544839
=================Random Agent Turn=================
Action taken: 81.499657
===============Feedback to learned agent round===============
Observation:
[1, array([22.14620247]), array([72.544839])]
Reward: -2.000000, Currnt Bid: 72.544839
Is done? True
Episode End
Positive: 31, Negative: 34
EPISODE :- 135
Random Player utility: 112.165691
=================Random Agent Turn=================
Action taken: 21.501983
===============Feedback to learned agent round===============
Observation:
[0, 0, 21.501982989963558]
Reward: -1.000000, Currnt Bid: 21.501983
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 72.298523
Exploit action: 72.298523
Action taken: 72.298523
===============Feedback to random agent round===============
Currnt Bid: 72.298523
=================Random Agent Turn=================
Action taken: 92.342804
===============Feedback to learned agent round===============
Observation:
[0, array([72.29852], dtype=float32), array([92.342804], dtype=float32)]
Reward: -1.000000, Currnt Bid: 92.342804
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 51.688530
Exploit action: 51.688530
Action taken: 51.688530
===============Feedback to random agent round===============
Currnt Bid: 92.342804
=================Random Agent Turn=================
Action taken: 104.651443
===============Feedback to learned agent round===============
Observation:
[1, array([72.29852], dtype=float32), array([92.342804], dtype=float32)]
Reward: -2.000000, Currnt Bid: 92.342804
Is done? True
Episode End
Positive: 31, Negative: 34
EPISODE :- 136
Random Player utility: 47.164725
=================Random Agent Turn=================
Action taken: 33.807797
===============Feedback to learned agent round===============
Observation:
[0, 0, 33.80779722927337]
Reward: -1.000000, Currnt Bid: 33.807797
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[13.25666829]
Explore action: 13.256668
Action taken: 13.256668
===============Feedback to random agent round===============
Currnt Bid: 33.807797
=================Random Agent Turn=================
Action taken: 46.572006
===============Feedback to learned agent round===============
Observation:
[1, 0, 33.80779722927337]
Reward: -2.000000, Currnt Bid: 33.807797
Is done? True
Episode End
Positive: 31, Negative: 35
EPISODE :- 137
Random Player utility: 165.528693
=================Random Agent Turn=================
Action taken: 117.761597
===============Feedback to learned agent round===============
Observation:
[0, 0, 117.76159693003274]
Reward: -1.000000, Currnt Bid: 117.761597
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[27.33736137]
Explore action: 27.337361
Action taken: 27.337361
===============Feedback to random agent round===============
Currnt Bid: 117.761597
=================Random Agent Turn=================
Action taken: 158.209715
===============Feedback to learned agent round===============
Observation:
[1, 0, 117.76159693003274]
Reward: -2.000000, Currnt Bid: 117.761597
Is done? True
Episode End
Positive: 31, Negative: 35
EPISODE :- 138
Random Player utility: 46.966690
=================Random Agent Turn=================
Action taken: 32.746310
===============Feedback to learned agent round===============
Observation:
[0, 0, 32.74631011172768]
Reward: -1.000000, Currnt Bid: 32.746310
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[12.18308452]
Explore action: 12.183085
Action taken: 12.183085
===============Feedback to random agent round===============
Currnt Bid: 32.746310
=================Random Agent Turn=================
Action taken: 41.465045
===============Feedback to learned agent round===============
Observation:
[1, 0, 32.74631011172768]
Reward: -2.000000, Currnt Bid: 32.746310
Is done? True
Episode End
Positive: 31, Negative: 36
EPISODE :- 139
Random Player utility: 98.754009
=================Random Agent Turn=================
Action taken: 2.823702
===============Feedback to learned agent round===============
Observation:
[0, 0, 2.823702242837889]
Reward: -1.000000, Currnt Bid: 2.823702
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[34.2944077]
Explore action: 34.294408
Action taken: 34.294408
===============Feedback to random agent round===============
Currnt Bid: 34.294408
=================Random Agent Turn=================
Action taken: 38.398997
===============Feedback to learned agent round===============
Observation:
[0, array([34.2944077]), array([38.39899667])]
Reward: -1.000000, Currnt Bid: 38.398997
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[34.64471626]
Explore action: 34.644716
Action taken: 34.644716
===============Feedback to random agent round===============
Currnt Bid: 38.398997
=================Random Agent Turn=================
Action taken: 84.272493
===============Feedback to learned agent round===============
Observation:
[1, array([34.2944077]), array([38.39899667])]
Reward: -2.000000, Currnt Bid: 38.398997
Is done? True
Episode End
Positive: 31, Negative: 37
EPISODE :- 140
Random Player utility: 48.046016
=================Random Agent Turn=================
Action taken: 18.343352
===============Feedback to learned agent round===============
Observation:
[0, 0, 18.343352429085904]
Reward: -1.000000, Currnt Bid: 18.343352
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 70.775688
Exploit action: 70.775688
Action taken: 70.775688
===============Feedback to random agent round===============
Currnt Bid: 70.775688
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([70.77569], dtype=float32), 18.343352429085904]
Reward: 29.224312, Currnt Bid: 70.775688
Is done? True
Episode End
Positive: 32, Negative: 37
EPISODE :- 141
Random Player utility: 144.425202
=================Random Agent Turn=================
Action taken: 127.863628
===============Feedback to learned agent round===============
Observation:
[0, 0, 127.86362760600353]
Reward: -1.000000, Currnt Bid: 127.863628
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[45.77235753]
Explore action: 45.772358
Action taken: 45.772358
===============Feedback to random agent round===============
Currnt Bid: 127.863628
=================Random Agent Turn=================
Action taken: 142.123216
===============Feedback to learned agent round===============
Observation:
[1, 0, 127.86362760600353]
Reward: -2.000000, Currnt Bid: 127.863628
Is done? True
Episode End
Positive: 32, Negative: 37
EPISODE :- 142
Random Player utility: 134.052520
=================Random Agent Turn=================
Action taken: 108.016935
===============Feedback to learned agent round===============
Observation:
[0, 0, 108.01693490791415]
Reward: -1.000000, Currnt Bid: 108.016935
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[47.622968]
Explore action: 47.622968
Action taken: 47.622968
===============Feedback to random agent round===============
Currnt Bid: 108.016935
=================Random Agent Turn=================
Action taken: 126.596583
===============Feedback to learned agent round===============
Observation:
[1, 0, 108.01693490791415]
Reward: -2.000000, Currnt Bid: 108.016935
Is done? True
Episode End
Positive: 32, Negative: 37
EPISODE :- 143
Random Player utility: 165.018416
=================Random Agent Turn=================
Action taken: 66.730843
===============Feedback to learned agent round===============
Observation:
[0, 0, 66.7308433327789]
Reward: -1.000000, Currnt Bid: 66.730843
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[54.80520796]
Explore action: 54.805208
Action taken: 54.805208
===============Feedback to random agent round===============
Currnt Bid: 66.730843
=================Random Agent Turn=================
Action taken: 107.562744
===============Feedback to learned agent round===============
Observation:
[1, 0, 66.7308433327789]
Reward: -2.000000, Currnt Bid: 66.730843
Is done? True
Episode End
Positive: 32, Negative: 37
EPISODE :- 144
Random Player utility: 28.238019
=================Random Agent Turn=================
Action taken: 3.306404
===============Feedback to learned agent round===============
Observation:
[0, 0, 3.30640441917004]
Reward: -1.000000, Currnt Bid: 3.306404
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[46.54405205]
Explore action: 46.544052
Action taken: 46.544052
===============Feedback to random agent round===============
Currnt Bid: 46.544052
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([46.54405205]), 3.30640441917004]
Reward: 53.455948, Currnt Bid: 46.544052
Is done? True
Episode End
Positive: 33, Negative: 37
EPISODE :- 145
Random Player utility: 30.377473
=================Random Agent Turn=================
Action taken: 11.220947
===============Feedback to learned agent round===============
Observation:
[0, 0, 11.220946630509038]
Reward: -1.000000, Currnt Bid: 11.220947
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 69.448174
Exploit action: 69.448174
Action taken: 69.448174
===============Feedback to random agent round===============
Currnt Bid: 69.448174
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([69.44817], dtype=float32), 11.220946630509038]
Reward: 30.551826, Currnt Bid: 69.448174
Is done? True
Episode End
Positive: 34, Negative: 37
EPISODE :- 146
Random Player utility: 147.236234
=================Random Agent Turn=================
Action taken: 16.767535
===============Feedback to learned agent round===============
Observation:
[0, 0, 16.76753532579167]
Reward: -1.000000, Currnt Bid: 16.767535
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[39.75982883]
Explore action: 39.759829
Action taken: 39.759829
===============Feedback to random agent round===============
Currnt Bid: 39.759829
=================Random Agent Turn=================
Action taken: 101.200770
===============Feedback to learned agent round===============
Observation:
[0, array([39.75982883]), array([101.20076987])]
Reward: -1.000000, Currnt Bid: 101.200770
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[43.89738911]
Explore action: 43.897389
Action taken: 43.897389
===============Feedback to random agent round===============
Currnt Bid: 101.200770
=================Random Agent Turn=================
Action taken: 106.139616
===============Feedback to learned agent round===============
Observation:
[1, array([39.75982883]), array([101.20076987])]
Reward: -2.000000, Currnt Bid: 101.200770
Is done? True
Episode End
Positive: 34, Negative: 37
EPISODE :- 147
Random Player utility: 22.707394
=================Random Agent Turn=================
Action taken: 12.711201
===============Feedback to learned agent round===============
Observation:
[0, 0, 12.711200534155672]
Reward: -1.000000, Currnt Bid: 12.711201
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[44.37125672]
Explore action: 44.371257
Action taken: 44.371257
===============Feedback to random agent round===============
Currnt Bid: 44.371257
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([44.37125672]), 12.711200534155672]
Reward: 55.628743, Currnt Bid: 44.371257
Is done? True
Episode End
Positive: 35, Negative: 37
EPISODE :- 148
Random Player utility: 76.550586
=================Random Agent Turn=================
Action taken: 36.323579
===============Feedback to learned agent round===============
Observation:
[0, 0, 36.323579365045084]
Reward: -1.000000, Currnt Bid: 36.323579
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[29.91810867]
Explore action: 29.918109
Action taken: 29.918109
===============Feedback to random agent round===============
Currnt Bid: 36.323579
=================Random Agent Turn=================
Action taken: 49.369480
===============Feedback to learned agent round===============
Observation:
[1, 0, 36.323579365045084]
Reward: -2.000000, Currnt Bid: 36.323579
Is done? True
Episode End
Positive: 35, Negative: 38
EPISODE :- 149
Random Player utility: 52.290348
=================Random Agent Turn=================
Action taken: 31.677854
===============Feedback to learned agent round===============
Observation:
[0, 0, 31.677853522200444]
Reward: -1.000000, Currnt Bid: 31.677854
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[34.86812461]
Explore action: 34.868125
Action taken: 34.868125
===============Feedback to random agent round===============
Currnt Bid: 34.868125
=================Random Agent Turn=================
Action taken: 48.902876
===============Feedback to learned agent round===============
Observation:
[0, array([34.86812461]), array([48.90287562])]
Reward: -1.000000, Currnt Bid: 48.902876
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[40.55328651]
Explore action: 40.553287
Action taken: 40.553287
===============Feedback to random agent round===============
Currnt Bid: 48.902876
=================Random Agent Turn=================
Action taken: 49.107268
===============Feedback to learned agent round===============
Observation:
[1, array([34.86812461]), array([48.90287562])]
Reward: -2.000000, Currnt Bid: 48.902876
Is done? True
Episode End
Positive: 35, Negative: 39
EPISODE :- 150
Random Player utility: 134.881808
=================Random Agent Turn=================
Action taken: 36.151189
===============Feedback to learned agent round===============
Observation:
[0, 0, 36.151188987437074]
Reward: -1.000000, Currnt Bid: 36.151189
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 67.799843
Exploit action: 67.799843
Action taken: 67.799843
===============Feedback to random agent round===============
Currnt Bid: 67.799843
=================Random Agent Turn=================
Action taken: 131.839172
===============Feedback to learned agent round===============
Observation:
[0, array([67.79984], dtype=float32), array([131.83917], dtype=float32)]
Reward: -1.000000, Currnt Bid: 131.839172
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 26.095522
Exploit action: 26.095522
Action taken: 26.095522
===============Feedback to random agent round===============
Currnt Bid: 131.839172
=================Random Agent Turn=================
Action taken: 132.432526
===============Feedback to learned agent round===============
Observation:
[1, array([67.79984], dtype=float32), array([131.83917], dtype=float32)]
Reward: -2.000000, Currnt Bid: 131.839172
Is done? True
Episode End
Positive: 35, Negative: 39
EPISODE :- 151
Random Player utility: 168.357289
=================Random Agent Turn=================
Action taken: 21.119242
===============Feedback to learned agent round===============
Observation:
[0, 0, 21.119242238274136]
Reward: -1.000000, Currnt Bid: 21.119242
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[33.86027446]
Explore action: 33.860274
Action taken: 33.860274
===============Feedback to random agent round===============
Currnt Bid: 33.860274
=================Random Agent Turn=================
Action taken: 146.747143
===============Feedback to learned agent round===============
Observation:
[0, array([33.86027446]), array([146.74714349])]
Reward: -1.000000, Currnt Bid: 146.747143
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[33.90597766]
Explore action: 33.905978
Action taken: 33.905978
===============Feedback to random agent round===============
Currnt Bid: 146.747143
=================Random Agent Turn=================
Action taken: 146.933738
===============Feedback to learned agent round===============
Observation:
[1, array([33.86027446]), array([146.74714349])]
Reward: -2.000000, Currnt Bid: 146.747143
Is done? True
Episode End
Positive: 35, Negative: 39
EPISODE :- 152
Random Player utility: 204.044075
=================Random Agent Turn=================
Action taken: 87.880784
===============Feedback to learned agent round===============
Observation:
[0, 0, 87.8807839991419]
Reward: -1.000000, Currnt Bid: 87.880784
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[26.37224923]
Explore action: 26.372249
Action taken: 26.372249
===============Feedback to random agent round===============
Currnt Bid: 87.880784
=================Random Agent Turn=================
Action taken: 197.752210
===============Feedback to learned agent round===============
Observation:
[1, 0, 87.8807839991419]
Reward: -2.000000, Currnt Bid: 87.880784
Is done? True
Episode End
Positive: 35, Negative: 39
EPISODE :- 153
Random Player utility: 19.561997
=================Random Agent Turn=================
Action taken: 6.333848
===============Feedback to learned agent round===============
Observation:
[0, 0, 6.333848096081148]
Reward: -1.000000, Currnt Bid: 6.333848
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[32.86266308]
Explore action: 32.862663
Action taken: 32.862663
===============Feedback to random agent round===============
Currnt Bid: 32.862663
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([32.86266308]), 6.333848096081148]
Reward: 67.137337, Currnt Bid: 32.862663
Is done? True
Episode End
Positive: 36, Negative: 39
EPISODE :- 154
Random Player utility: 100.435080
=================Random Agent Turn=================
Action taken: 10.223745
===============Feedback to learned agent round===============
Observation:
[0, 0, 10.223745385493531]
Reward: -1.000000, Currnt Bid: 10.223745
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[29.3656041]
Explore action: 29.365604
Action taken: 29.365604
===============Feedback to random agent round===============
Currnt Bid: 29.365604
=================Random Agent Turn=================
Action taken: 73.498510
===============Feedback to learned agent round===============
Observation:
[0, array([29.3656041]), array([73.49850991])]
Reward: -1.000000, Currnt Bid: 73.498510
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[45.45456173]
Explore action: 45.454562
Action taken: 45.454562
===============Feedback to random agent round===============
Currnt Bid: 73.498510
=================Random Agent Turn=================
Action taken: 92.768245
===============Feedback to learned agent round===============
Observation:
[1, array([29.3656041]), array([73.49850991])]
Reward: -2.000000, Currnt Bid: 73.498510
Is done? True
Episode End
Positive: 36, Negative: 39
EPISODE :- 155
Random Player utility: 217.709928
=================Random Agent Turn=================
Action taken: 87.745233
===============Feedback to learned agent round===============
Observation:
[0, 0, 87.74523318103046]
Reward: -1.000000, Currnt Bid: 87.745233
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 65.954147
Exploit action: 65.954147
Action taken: 65.954147
===============Feedback to random agent round===============
Currnt Bid: 87.745233
=================Random Agent Turn=================
Action taken: 134.220876
===============Feedback to learned agent round===============
Observation:
[1, 0, 87.74523318103046]
Reward: -2.000000, Currnt Bid: 87.745233
Is done? True
Episode End
Positive: 36, Negative: 39
EPISODE :- 156
Random Player utility: 39.044258
=================Random Agent Turn=================
Action taken: 21.284587
===============Feedback to learned agent round===============
Observation:
[0, 0, 21.28458680066908]
Reward: -1.000000, Currnt Bid: 21.284587
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[47.12018576]
Explore action: 47.120186
Action taken: 47.120186
===============Feedback to random agent round===============
Currnt Bid: 47.120186
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([47.12018576]), 21.28458680066908]
Reward: 52.879814, Currnt Bid: 47.120186
Is done? True
Episode End
Positive: 37, Negative: 39
EPISODE :- 157
Random Player utility: 196.792343
=================Random Agent Turn=================
Action taken: 165.865910
===============Feedback to learned agent round===============
Observation:
[0, 0, 165.86591005843354]
Reward: -1.000000, Currnt Bid: 165.865910
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[33.48655484]
Explore action: 33.486555
Action taken: 33.486555
===============Feedback to random agent round===============
Currnt Bid: 165.865910
=================Random Agent Turn=================
Action taken: 167.503121
===============Feedback to learned agent round===============
Observation:
[1, 0, 165.86591005843354]
Reward: -2.000000, Currnt Bid: 165.865910
Is done? True
Episode End
Positive: 37, Negative: 39
EPISODE :- 158
Random Player utility: 109.701638
=================Random Agent Turn=================
Action taken: 91.055663
===============Feedback to learned agent round===============
Observation:
[0, 0, 91.0556634816932]
Reward: -1.000000, Currnt Bid: 91.055663
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[15.57939047]
Explore action: 15.579390
Action taken: 15.579390
===============Feedback to random agent round===============
Currnt Bid: 91.055663
=================Random Agent Turn=================
Action taken: 103.605673
===============Feedback to learned agent round===============
Observation:
[1, 0, 91.0556634816932]
Reward: -2.000000, Currnt Bid: 91.055663
Is done? True
Episode End
Positive: 37, Negative: 39
EPISODE :- 159
Random Player utility: 135.873862
=================Random Agent Turn=================
Action taken: 57.049849
===============Feedback to learned agent round===============
Observation:
[0, 0, 57.049848745555316]
Reward: -1.000000, Currnt Bid: 57.049849
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[35.23597787]
Explore action: 35.235978
Action taken: 35.235978
===============Feedback to random agent round===============
Currnt Bid: 57.049849
=================Random Agent Turn=================
Action taken: 60.133616
===============Feedback to learned agent round===============
Observation:
[1, 0, 57.049848745555316]
Reward: -2.000000, Currnt Bid: 57.049849
Is done? True
Episode End
Positive: 37, Negative: 39
EPISODE :- 160
Random Player utility: 181.219764
=================Random Agent Turn=================
Action taken: 6.476225
===============Feedback to learned agent round===============
Observation:
[0, 0, 6.476225477983198]
Reward: -1.000000, Currnt Bid: 6.476225
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 64.495026
Exploit action: 64.495026
Action taken: 64.495026
===============Feedback to random agent round===============
Currnt Bid: 64.495026
=================Random Agent Turn=================
Action taken: 120.257996
===============Feedback to learned agent round===============
Observation:
[0, array([64.495026], dtype=float32), array([120.257996], dtype=float32)]
Reward: -1.000000, Currnt Bid: 120.257996
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 60.168327
Exploit action: 60.168327
Action taken: 60.168327
===============Feedback to random agent round===============
Currnt Bid: 120.257996
=================Random Agent Turn=================
Action taken: 160.259338
===============Feedback to learned agent round===============
Observation:
[1, array([64.495026], dtype=float32), array([120.257996], dtype=float32)]
Reward: -2.000000, Currnt Bid: 120.257996
Is done? True
Episode End
Positive: 37, Negative: 39
EPISODE :- 161
Random Player utility: 85.088079
=================Random Agent Turn=================
Action taken: 33.042563
===============Feedback to learned agent round===============
Observation:
[0, 0, 33.04256254479517]
Reward: -1.000000, Currnt Bid: 33.042563
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[36.16167836]
Explore action: 36.161678
Action taken: 36.161678
===============Feedback to random agent round===============
Currnt Bid: 36.161678
=================Random Agent Turn=================
Action taken: 62.564835
===============Feedback to learned agent round===============
Observation:
[0, array([36.16167836]), array([62.56483485])]
Reward: -1.000000, Currnt Bid: 62.564835
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[33.62551176]
Explore action: 33.625512
Action taken: 33.625512
===============Feedback to random agent round===============
Currnt Bid: 62.564835
=================Random Agent Turn=================
Action taken: 70.690794
===============Feedback to learned agent round===============
Observation:
[1, array([36.16167836]), array([62.56483485])]
Reward: -2.000000, Currnt Bid: 62.564835
Is done? True
Episode End
Positive: 37, Negative: 40
EPISODE :- 162
Random Player utility: 114.509495
=================Random Agent Turn=================
Action taken: 92.026946
===============Feedback to learned agent round===============
Observation:
[0, 0, 92.02694580384598]
Reward: -1.000000, Currnt Bid: 92.026946
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[31.36285419]
Explore action: 31.362854
Action taken: 31.362854
===============Feedback to random agent round===============
Currnt Bid: 92.026946
=================Random Agent Turn=================
Action taken: 93.164767
===============Feedback to learned agent round===============
Observation:
[1, 0, 92.02694580384598]
Reward: -2.000000, Currnt Bid: 92.026946
Is done? True
Episode End
Positive: 37, Negative: 40
EPISODE :- 163
Random Player utility: 222.343956
=================Random Agent Turn=================
Action taken: 142.846211
===============Feedback to learned agent round===============
Observation:
[0, 0, 142.84621121240565]
Reward: -1.000000, Currnt Bid: 142.846211
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[39.13767018]
Explore action: 39.137670
Action taken: 39.137670
===============Feedback to random agent round===============
Currnt Bid: 142.846211
=================Random Agent Turn=================
Action taken: 188.559319
===============Feedback to learned agent round===============
Observation:
[1, 0, 142.84621121240565]
Reward: -2.000000, Currnt Bid: 142.846211
Is done? True
Episode End
Positive: 37, Negative: 40
EPISODE :- 164
Random Player utility: 5.536259
=================Random Agent Turn=================
Action taken: 1.552111
===============Feedback to learned agent round===============
Observation:
[0, 0, 1.5521106693709852]
Reward: -1.000000, Currnt Bid: 1.552111
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[56.68446408]
Explore action: 56.684464
Action taken: 56.684464
===============Feedback to random agent round===============
Currnt Bid: 56.684464
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([56.68446408]), 1.5521106693709852]
Reward: 43.315536, Currnt Bid: 56.684464
Is done? True
Episode End
Positive: 38, Negative: 40
EPISODE :- 165
Random Player utility: 177.965398
=================Random Agent Turn=================
Action taken: 27.382608
===============Feedback to learned agent round===============
Observation:
[0, 0, 27.382608305497314]
Reward: -1.000000, Currnt Bid: 27.382608
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 62.703335
Exploit action: 62.703335
Action taken: 62.703335
===============Feedback to random agent round===============
Currnt Bid: 62.703335
=================Random Agent Turn=================
Action taken: 175.755798
===============Feedback to learned agent round===============
Observation:
[0, array([62.703335], dtype=float32), array([175.7558], dtype=float32)]
Reward: -1.000000, Currnt Bid: 175.755798
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 27.252747
Exploit action: 27.252747
Action taken: 27.252747
===============Feedback to random agent round===============
Currnt Bid: 175.755798
=================Random Agent Turn=================
Action taken: 177.502167
===============Feedback to learned agent round===============
Observation:
[1, array([62.703335], dtype=float32), array([175.7558], dtype=float32)]
Reward: -2.000000, Currnt Bid: 175.755798
Is done? True
Episode End
Positive: 38, Negative: 40
EPISODE :- 166
Random Player utility: 79.544709
=================Random Agent Turn=================
Action taken: 74.193428
===============Feedback to learned agent round===============
Observation:
[0, 0, 74.1934279377029]
Reward: -1.000000, Currnt Bid: 74.193428
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[60.12382771]
Explore action: 60.123828
Action taken: 60.123828
===============Feedback to random agent round===============
Currnt Bid: 74.193428
=================Random Agent Turn=================
Action taken: 77.341867
===============Feedback to learned agent round===============
Observation:
[1, 0, 74.1934279377029]
Reward: -2.000000, Currnt Bid: 74.193428
Is done? True
Episode End
Positive: 38, Negative: 41
EPISODE :- 167
Random Player utility: 158.728177
=================Random Agent Turn=================
Action taken: 56.179932
===============Feedback to learned agent round===============
Observation:
[0, 0, 56.17993184829001]
Reward: -1.000000, Currnt Bid: 56.179932
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[71.70258953]
Explore action: 71.702590
Action taken: 71.702590
===============Feedback to random agent round===============
Currnt Bid: 71.702590
=================Random Agent Turn=================
Action taken: 94.995187
===============Feedback to learned agent round===============
Observation:
[0, array([71.70258953]), array([94.99518667])]
Reward: -1.000000, Currnt Bid: 94.995187
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[64.16497665]
Explore action: 64.164977
Action taken: 64.164977
===============Feedback to random agent round===============
Currnt Bid: 94.995187
=================Random Agent Turn=================
Action taken: 145.491435
===============Feedback to learned agent round===============
Observation:
[1, array([71.70258953]), array([94.99518667])]
Reward: -2.000000, Currnt Bid: 94.995187
Is done? True
Episode End
Positive: 38, Negative: 41
EPISODE :- 168
Random Player utility: 134.927759
=================Random Agent Turn=================
Action taken: 4.027954
===============Feedback to learned agent round===============
Observation:
[0, 0, 4.027953953858066]
Reward: -1.000000, Currnt Bid: 4.027954
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[87.66593864]
Explore action: 87.665939
Action taken: 87.665939
===============Feedback to random agent round===============
Currnt Bid: 87.665939
=================Random Agent Turn=================
Action taken: 130.337901
===============Feedback to learned agent round===============
Observation:
[0, array([87.66593864]), array([130.3379011])]
Reward: -1.000000, Currnt Bid: 130.337901
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[84.53509223]
Explore action: 84.535092
Action taken: 84.535092
===============Feedback to random agent round===============
Currnt Bid: 130.337901
=================Random Agent Turn=================
Action taken: 132.278193
===============Feedback to learned agent round===============
Observation:
[1, array([87.66593864]), array([130.3379011])]
Reward: -2.000000, Currnt Bid: 130.337901
Is done? True
Episode End
Positive: 38, Negative: 41
EPISODE :- 169
Random Player utility: 43.897404
=================Random Agent Turn=================
Action taken: 7.642452
===============Feedback to learned agent round===============
Observation:
[0, 0, 7.642452386627508]
Reward: -1.000000, Currnt Bid: 7.642452
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[92.36400711]
Explore action: 92.364007
Action taken: 92.364007
===============Feedback to random agent round===============
Currnt Bid: 92.364007
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([92.36400711]), 7.642452386627508]
Reward: 7.635993, Currnt Bid: 92.364007
Is done? True
Episode End
Positive: 39, Negative: 41
EPISODE :- 170
Random Player utility: 109.899936
=================Random Agent Turn=================
Action taken: 10.623521
===============Feedback to learned agent round===============
Observation:
[0, 0, 10.623521053068972]
Reward: -1.000000, Currnt Bid: 10.623521
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 60.717731
Exploit action: 60.717731
Action taken: 60.717731
===============Feedback to random agent round===============
Currnt Bid: 60.717731
=================Random Agent Turn=================
Action taken: 61.350971
===============Feedback to learned agent round===============
Observation:
[0, array([60.71773], dtype=float32), array([61.35097], dtype=float32)]
Reward: -1.000000, Currnt Bid: 61.350971
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 49.332745
Exploit action: 49.332745
Action taken: 49.332745
===============Feedback to random agent round===============
Currnt Bid: 61.350971
=================Random Agent Turn=================
Action taken: 93.726036
===============Feedback to learned agent round===============
Observation:
[1, array([60.71773], dtype=float32), array([61.35097], dtype=float32)]
Reward: -2.000000, Currnt Bid: 61.350971
Is done? True
Episode End
Positive: 39, Negative: 41
EPISODE :- 171
Random Player utility: 74.585991
=================Random Agent Turn=================
Action taken: 55.538772
===============Feedback to learned agent round===============
Observation:
[0, 0, 55.53877223964151]
Reward: -1.000000, Currnt Bid: 55.538772
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[69.11971903]
Explore action: 69.119719
Action taken: 69.119719
===============Feedback to random agent round===============
Currnt Bid: 69.119719
=================Random Agent Turn=================
Action taken: 69.656749
===============Feedback to learned agent round===============
Observation:
[0, array([69.11971903]), array([69.65674916])]
Reward: -1.000000, Currnt Bid: 69.656749
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[67.02591995]
Explore action: 67.025920
Action taken: 67.025920
===============Feedback to random agent round===============
Currnt Bid: 69.656749
=================Random Agent Turn=================
Action taken: 71.738592
===============Feedback to learned agent round===============
Observation:
[1, array([69.11971903]), array([69.65674916])]
Reward: -2.000000, Currnt Bid: 69.656749
Is done? True
Episode End
Positive: 39, Negative: 42
EPISODE :- 172
Random Player utility: 66.664592
=================Random Agent Turn=================
Action taken: 25.136848
===============Feedback to learned agent round===============
Observation:
[0, 0, 25.136847936353305]
Reward: -1.000000, Currnt Bid: 25.136848
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[49.44259194]
Explore action: 49.442592
Action taken: 49.442592
===============Feedback to random agent round===============
Currnt Bid: 49.442592
=================Random Agent Turn=================
Action taken: 59.236058
===============Feedback to learned agent round===============
Observation:
[0, array([49.44259194]), array([59.23605837])]
Reward: -1.000000, Currnt Bid: 59.236058
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[34.15195761]
Explore action: 34.151958
Action taken: 34.151958
===============Feedback to random agent round===============
Currnt Bid: 59.236058
=================Random Agent Turn=================
Action taken: 63.970158
===============Feedback to learned agent round===============
Observation:
[1, array([49.44259194]), array([59.23605837])]
Reward: -2.000000, Currnt Bid: 59.236058
Is done? True
Episode End
Positive: 39, Negative: 43
EPISODE :- 173
Random Player utility: 133.303998
=================Random Agent Turn=================
Action taken: 119.772680
===============Feedback to learned agent round===============
Observation:
[0, 0, 119.77268006426377]
Reward: -1.000000, Currnt Bid: 119.772680
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[28.91825789]
Explore action: 28.918258
Action taken: 28.918258
===============Feedback to random agent round===============
Currnt Bid: 119.772680
=================Random Agent Turn=================
Action taken: 123.316529
===============Feedback to learned agent round===============
Observation:
[1, 0, 119.77268006426377]
Reward: -2.000000, Currnt Bid: 119.772680
Is done? True
Episode End
Positive: 39, Negative: 43
EPISODE :- 174
Random Player utility: 179.027523
=================Random Agent Turn=================
Action taken: 116.151609
===============Feedback to learned agent round===============
Observation:
[0, 0, 116.15160924900954]
Reward: -1.000000, Currnt Bid: 116.151609
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.64123688]
Explore action: 48.641237
Action taken: 48.641237
===============Feedback to random agent round===============
Currnt Bid: 116.151609
=================Random Agent Turn=================
Action taken: 128.245067
===============Feedback to learned agent round===============
Observation:
[1, 0, 116.15160924900954]
Reward: -2.000000, Currnt Bid: 116.151609
Is done? True
Episode End
Positive: 39, Negative: 43
EPISODE :- 175
Random Player utility: 69.207471
=================Random Agent Turn=================
Action taken: 41.362031
===============Feedback to learned agent round===============
Observation:
[0, 0, 41.362030740380746]
Reward: -1.000000, Currnt Bid: 41.362031
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 58.691872
Exploit action: 58.691872
Action taken: 58.691872
===============Feedback to random agent round===============
Currnt Bid: 58.691872
=================Random Agent Turn=================
Action taken: 67.362793
===============Feedback to learned agent round===============
Observation:
[0, array([58.69187], dtype=float32), array([67.36279], dtype=float32)]
Reward: -1.000000, Currnt Bid: 67.362793
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 9.819990
Exploit action: 9.819990
Action taken: 9.819990
===============Feedback to random agent round===============
Currnt Bid: 67.362793
=================Random Agent Turn=================
Action taken: 67.634995
===============Feedback to learned agent round===============
Observation:
[1, array([58.69187], dtype=float32), array([67.36279], dtype=float32)]
Reward: -2.000000, Currnt Bid: 67.362793
Is done? True
Episode End
Positive: 39, Negative: 44
EPISODE :- 176
Random Player utility: 58.053109
=================Random Agent Turn=================
Action taken: 21.142831
===============Feedback to learned agent round===============
Observation:
[0, 0, 21.142830754213946]
Reward: -1.000000, Currnt Bid: 21.142831
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[51.86458586]
Explore action: 51.864586
Action taken: 51.864586
===============Feedback to random agent round===============
Currnt Bid: 51.864586
=================Random Agent Turn=================
Action taken: 53.746020
===============Feedback to learned agent round===============
Observation:
[0, array([51.86458586]), array([53.74602037])]
Reward: -1.000000, Currnt Bid: 53.746020
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[70.63554741]
Explore action: 70.635547
Action taken: 70.635547
===============Feedback to random agent round===============
Currnt Bid: 70.635547
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([70.63554741]), array([53.74602037])]
Reward: 29.364453, Currnt Bid: 70.635547
Is done? True
Episode End
Positive: 40, Negative: 44
EPISODE :- 177
Random Player utility: 141.010814
=================Random Agent Turn=================
Action taken: 53.314798
===============Feedback to learned agent round===============
Observation:
[0, 0, 53.314798313880594]
Reward: -1.000000, Currnt Bid: 53.314798
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[75.97470809]
Explore action: 75.974708
Action taken: 75.974708
===============Feedback to random agent round===============
Currnt Bid: 75.974708
=================Random Agent Turn=================
Action taken: 116.254644
===============Feedback to learned agent round===============
Observation:
[0, array([75.97470809]), array([116.2546442])]
Reward: -1.000000, Currnt Bid: 116.254644
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[80.67899347]
Explore action: 80.678993
Action taken: 80.678993
===============Feedback to random agent round===============
Currnt Bid: 116.254644
=================Random Agent Turn=================
Action taken: 123.516455
===============Feedback to learned agent round===============
Observation:
[1, array([75.97470809]), array([116.2546442])]
Reward: -2.000000, Currnt Bid: 116.254644
Is done? True
Episode End
Positive: 40, Negative: 44
EPISODE :- 178
Random Player utility: 111.198221
=================Random Agent Turn=================
Action taken: 23.017941
===============Feedback to learned agent round===============
Observation:
[0, 0, 23.01794121712877]
Reward: -1.000000, Currnt Bid: 23.017941
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[73.17090788]
Explore action: 73.170908
Action taken: 73.170908
===============Feedback to random agent round===============
Currnt Bid: 73.170908
=================Random Agent Turn=================
Action taken: 86.935664
===============Feedback to learned agent round===============
Observation:
[0, array([73.17090788]), array([86.93566419])]
Reward: -1.000000, Currnt Bid: 86.935664
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[72.03853522]
Explore action: 72.038535
Action taken: 72.038535
===============Feedback to random agent round===============
Currnt Bid: 86.935664
=================Random Agent Turn=================
Action taken: 103.022419
===============Feedback to learned agent round===============
Observation:
[1, array([73.17090788]), array([86.93566419])]
Reward: -2.000000, Currnt Bid: 86.935664
Is done? True
Episode End
Positive: 40, Negative: 44
EPISODE :- 179
Random Player utility: 17.945446
=================Random Agent Turn=================
Action taken: 15.520564
===============Feedback to learned agent round===============
Observation:
[0, 0, 15.52056380164759]
Reward: -1.000000, Currnt Bid: 15.520564
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[89.84772925]
Explore action: 89.847729
Action taken: 89.847729
===============Feedback to random agent round===============
Currnt Bid: 89.847729
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([89.84772925]), 15.52056380164759]
Reward: 10.152271, Currnt Bid: 89.847729
Is done? True
Episode End
Positive: 41, Negative: 44
EPISODE :- 180
Random Player utility: 242.019814
=================Random Agent Turn=================
Action taken: 206.235749
===============Feedback to learned agent round===============
Observation:
[0, 0, 206.23574920311995]
Reward: -1.000000, Currnt Bid: 206.235749
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 56.471588
Exploit action: 56.471588
Action taken: 56.471588
===============Feedback to random agent round===============
Currnt Bid: 206.235749
=================Random Agent Turn=================
Action taken: 233.206488
===============Feedback to learned agent round===============
Observation:
[1, 0, 206.23574920311995]
Reward: -2.000000, Currnt Bid: 206.235749
Is done? True
Episode End
Positive: 41, Negative: 44
EPISODE :- 181
Random Player utility: 125.926712
=================Random Agent Turn=================
Action taken: 29.082855
===============Feedback to learned agent round===============
Observation:
[0, 0, 29.082854876531652]
Reward: -1.000000, Currnt Bid: 29.082855
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[89.90236737]
Explore action: 89.902367
Action taken: 89.902367
===============Feedback to random agent round===============
Currnt Bid: 89.902367
=================Random Agent Turn=================
Action taken: 116.599573
===============Feedback to learned agent round===============
Observation:
[0, array([89.90236737]), array([116.59957325])]
Reward: -1.000000, Currnt Bid: 116.599573
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[83.62606523]
Explore action: 83.626065
Action taken: 83.626065
===============Feedback to random agent round===============
Currnt Bid: 116.599573
=================Random Agent Turn=================
Action taken: 120.502467
===============Feedback to learned agent round===============
Observation:
[1, array([89.90236737]), array([116.59957325])]
Reward: -2.000000, Currnt Bid: 116.599573
Is done? True
Episode End
Positive: 41, Negative: 44
EPISODE :- 182
Random Player utility: 87.943605
=================Random Agent Turn=================
Action taken: 36.636265
===============Feedback to learned agent round===============
Observation:
[0, 0, 36.63626508604964]
Reward: -1.000000, Currnt Bid: 36.636265
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[87.33746083]
Explore action: 87.337461
Action taken: 87.337461
===============Feedback to random agent round===============
Currnt Bid: 87.337461
=================Random Agent Turn=================
Action taken: 87.692369
===============Feedback to learned agent round===============
Observation:
[0, array([87.33746083]), array([87.69236949])]
Reward: -1.000000, Currnt Bid: 87.692369
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[108.00004207]
Explore action: 108.000042
Action taken: 108.000042
===============Feedback to random agent round===============
Currnt Bid: 108.000042
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([108.00004207]), array([87.69236949])]
Reward: -8.000042, Currnt Bid: 108.000042
Is done? True
Episode End
Positive: 41, Negative: 45
EPISODE :- 183
Random Player utility: 65.046411
=================Random Agent Turn=================
Action taken: 28.139017
===============Feedback to learned agent round===============
Observation:
[0, 0, 28.139016709468734]
Reward: -1.000000, Currnt Bid: 28.139017
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[106.14082857]
Explore action: 106.140829
Action taken: 106.140829
===============Feedback to random agent round===============
Currnt Bid: 106.140829
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([106.14082857]), 28.139016709468734]
Reward: -6.140829, Currnt Bid: 106.140829
Is done? True
Episode End
Positive: 41, Negative: 46
EPISODE :- 184
Random Player utility: 71.715429
=================Random Agent Turn=================
Action taken: 50.335642
===============Feedback to learned agent round===============
Observation:
[0, 0, 50.3356420527315]
Reward: -1.000000, Currnt Bid: 50.335642
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[86.64854083]
Explore action: 86.648541
Action taken: 86.648541
===============Feedback to random agent round===============
Currnt Bid: 86.648541
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([86.64854083]), 50.3356420527315]
Reward: 13.351459, Currnt Bid: 86.648541
Is done? True
Episode End
Positive: 42, Negative: 46
EPISODE :- 185
Random Player utility: 225.000737
=================Random Agent Turn=================
Action taken: 188.040921
===============Feedback to learned agent round===============
Observation:
[0, 0, 188.0409208906627]
Reward: -1.000000, Currnt Bid: 188.040921
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 54.543804
Exploit action: 54.543804
Action taken: 54.543804
===============Feedback to random agent round===============
Currnt Bid: 188.040921
=================Random Agent Turn=================
Action taken: 190.929535
===============Feedback to learned agent round===============
Observation:
[1, 0, 188.0409208906627]
Reward: -2.000000, Currnt Bid: 188.040921
Is done? True
Episode End
Positive: 42, Negative: 46
EPISODE :- 186
Random Player utility: 137.610701
=================Random Agent Turn=================
Action taken: 128.943375
===============Feedback to learned agent round===============
Observation:
[0, 0, 128.9433747660275]
Reward: -1.000000, Currnt Bid: 128.943375
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[47.76979693]
Explore action: 47.769797
Action taken: 47.769797
===============Feedback to random agent round===============
Currnt Bid: 128.943375
=================Random Agent Turn=================
Action taken: 129.515593
===============Feedback to learned agent round===============
Observation:
[1, 0, 128.9433747660275]
Reward: -2.000000, Currnt Bid: 128.943375
Is done? True
Episode End
Positive: 42, Negative: 46
EPISODE :- 187
Random Player utility: 105.301187
=================Random Agent Turn=================
Action taken: 85.784633
===============Feedback to learned agent round===============
Observation:
[0, 0, 85.7846326203447]
Reward: -1.000000, Currnt Bid: 85.784633
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[47.59673317]
Explore action: 47.596733
Action taken: 47.596733
===============Feedback to random agent round===============
Currnt Bid: 85.784633
=================Random Agent Turn=================
Action taken: 98.292442
===============Feedback to learned agent round===============
Observation:
[1, 0, 85.7846326203447]
Reward: -2.000000, Currnt Bid: 85.784633
Is done? True
Episode End
Positive: 42, Negative: 46
EPISODE :- 188
Random Player utility: 65.063202
=================Random Agent Turn=================
Action taken: 43.867672
===============Feedback to learned agent round===============
Observation:
[0, 0, 43.86767242993526]
Reward: -1.000000, Currnt Bid: 43.867672
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[52.90901167]
Explore action: 52.909012
Action taken: 52.909012
===============Feedback to random agent round===============
Currnt Bid: 52.909012
=================Random Agent Turn=================
Action taken: 56.240350
===============Feedback to learned agent round===============
Observation:
[0, array([52.90901167]), array([56.24035008])]
Reward: -1.000000, Currnt Bid: 56.240350
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[63.32926814]
Explore action: 63.329268
Action taken: 63.329268
===============Feedback to random agent round===============
Currnt Bid: 63.329268
=================Random Agent Turn=================
Action taken: 63.840729
===============Feedback to learned agent round===============
Observation:
[0, array([63.32926814]), array([63.84072886])]
Reward: -1.000000, Currnt Bid: 63.840729
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[37.06899746]
Explore action: 37.068997
Action taken: 37.068997
===============Feedback to random agent round===============
Currnt Bid: 63.840729
=================Random Agent Turn=================
Action taken: 64.203841
===============Feedback to learned agent round===============
Observation:
[1, array([63.32926814]), array([63.84072886])]
Reward: -2.000000, Currnt Bid: 63.840729
Is done? True
Episode End
Positive: 42, Negative: 47
EPISODE :- 189
Random Player utility: 79.404990
=================Random Agent Turn=================
Action taken: 0.240790
===============Feedback to learned agent round===============
Observation:
[0, 0, 0.24079007558605475]
Reward: -1.000000, Currnt Bid: 0.240790
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[45.43160376]
Explore action: 45.431604
Action taken: 45.431604
===============Feedback to random agent round===============
Currnt Bid: 45.431604
=================Random Agent Turn=================
Action taken: 73.533494
===============Feedback to learned agent round===============
Observation:
[0, array([45.43160376]), array([73.5334936])]
Reward: -1.000000, Currnt Bid: 73.533494
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[63.62710168]
Explore action: 63.627102
Action taken: 63.627102
===============Feedback to random agent round===============
Currnt Bid: 73.533494
=================Random Agent Turn=================
Action taken: 74.211599
===============Feedback to learned agent round===============
Observation:
[1, array([45.43160376]), array([73.5334936])]
Reward: -2.000000, Currnt Bid: 73.533494
Is done? True
Episode End
Positive: 42, Negative: 48
EPISODE :- 190
Random Player utility: 143.054779
=================Random Agent Turn=================
Action taken: 106.040473
===============Feedback to learned agent round===============
Observation:
[0, 0, 106.04047281146926]
Reward: -1.000000, Currnt Bid: 106.040473
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 52.436127
Exploit action: 52.436127
Action taken: 52.436127
===============Feedback to random agent round===============
Currnt Bid: 106.040473
=================Random Agent Turn=================
Action taken: 121.599197
===============Feedback to learned agent round===============
Observation:
[1, 0, 106.04047281146926]
Reward: -2.000000, Currnt Bid: 106.040473
Is done? True
Episode End
Positive: 42, Negative: 48
EPISODE :- 191
Random Player utility: 117.412769
=================Random Agent Turn=================
Action taken: 31.782749
===============Feedback to learned agent round===============
Observation:
[0, 0, 31.782748823429603]
Reward: -1.000000, Currnt Bid: 31.782749
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[68.10286748]
Explore action: 68.102867
Action taken: 68.102867
===============Feedback to random agent round===============
Currnt Bid: 68.102867
=================Random Agent Turn=================
Action taken: 97.267546
===============Feedback to learned agent round===============
Observation:
[0, array([68.10286748]), array([97.26754594])]
Reward: -1.000000, Currnt Bid: 97.267546
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[86.61518086]
Explore action: 86.615181
Action taken: 86.615181
===============Feedback to random agent round===============
Currnt Bid: 97.267546
=================Random Agent Turn=================
Action taken: 106.843199
===============Feedback to learned agent round===============
Observation:
[1, array([68.10286748]), array([97.26754594])]
Reward: -2.000000, Currnt Bid: 97.267546
Is done? True
Episode End
Positive: 42, Negative: 48
EPISODE :- 192
Random Player utility: 85.242527
=================Random Agent Turn=================
Action taken: 34.449465
===============Feedback to learned agent round===============
Observation:
[0, 0, 34.4494645987516]
Reward: -1.000000, Currnt Bid: 34.449465
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[78.736988]
Explore action: 78.736988
Action taken: 78.736988
===============Feedback to random agent round===============
Currnt Bid: 78.736988
=================Random Agent Turn=================
Action taken: 81.776976
===============Feedback to learned agent round===============
Observation:
[0, array([78.736988]), array([81.77697566])]
Reward: -1.000000, Currnt Bid: 81.776976
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[68.35065135]
Explore action: 68.350651
Action taken: 68.350651
===============Feedback to random agent round===============
Currnt Bid: 81.776976
=================Random Agent Turn=================
Action taken: 82.261089
===============Feedback to learned agent round===============
Observation:
[1, array([78.736988]), array([81.77697566])]
Reward: -2.000000, Currnt Bid: 81.776976
Is done? True
Episode End
Positive: 42, Negative: 49
EPISODE :- 193
Random Player utility: 38.007197
=================Random Agent Turn=================
Action taken: 22.591833
===============Feedback to learned agent round===============
Observation:
[0, 0, 22.59183328019595]
Reward: -1.000000, Currnt Bid: 22.591833
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[70.16100967]
Explore action: 70.161010
Action taken: 70.161010
===============Feedback to random agent round===============
Currnt Bid: 70.161010
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([70.16100967]), 22.59183328019595]
Reward: 29.838990, Currnt Bid: 70.161010
Is done? True
Episode End
Positive: 43, Negative: 49
EPISODE :- 194
Random Player utility: 5.485292
=================Random Agent Turn=================
Action taken: 2.227961
===============Feedback to learned agent round===============
Observation:
[0, 0, 2.227961491242457]
Reward: -1.000000, Currnt Bid: 2.227961
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[75.66229784]
Explore action: 75.662298
Action taken: 75.662298
===============Feedback to random agent round===============
Currnt Bid: 75.662298
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([75.66229784]), 2.227961491242457]
Reward: 24.337702, Currnt Bid: 75.662298
Is done? True
Episode End
Positive: 44, Negative: 49
EPISODE :- 195
Random Player utility: 194.400811
=================Random Agent Turn=================
Action taken: 167.067769
===============Feedback to learned agent round===============
Observation:
[0, 0, 167.06776885268113]
Reward: -1.000000, Currnt Bid: 167.067769
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 50.478725
Exploit action: 50.478725
Action taken: 50.478725
===============Feedback to random agent round===============
Currnt Bid: 167.067769
=================Random Agent Turn=================
Action taken: 178.262874
===============Feedback to learned agent round===============
Observation:
[1, 0, 167.06776885268113]
Reward: -2.000000, Currnt Bid: 167.067769
Is done? True
Episode End
Positive: 44, Negative: 49
EPISODE :- 196
Random Player utility: 144.034565
=================Random Agent Turn=================
Action taken: 75.956324
===============Feedback to learned agent round===============
Observation:
[0, 0, 75.9563243573241]
Reward: -1.000000, Currnt Bid: 75.956324
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[77.77293106]
Explore action: 77.772931
Action taken: 77.772931
===============Feedback to random agent round===============
Currnt Bid: 77.772931
=================Random Agent Turn=================
Action taken: 88.596144
===============Feedback to learned agent round===============
Observation:
[0, array([77.77293106]), array([88.59614449])]
Reward: -1.000000, Currnt Bid: 88.596144
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[73.825688]
Explore action: 73.825688
Action taken: 73.825688
===============Feedback to random agent round===============
Currnt Bid: 88.596144
=================Random Agent Turn=================
Action taken: 116.534180
===============Feedback to learned agent round===============
Observation:
[1, array([77.77293106]), array([88.59614449])]
Reward: -2.000000, Currnt Bid: 88.596144
Is done? True
Episode End
Positive: 44, Negative: 49
EPISODE :- 197
Random Player utility: 92.710238
=================Random Agent Turn=================
Action taken: 25.712489
===============Feedback to learned agent round===============
Observation:
[0, 0, 25.712489144886423]
Reward: -1.000000, Currnt Bid: 25.712489
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[62.06672076]
Explore action: 62.066721
Action taken: 62.066721
===============Feedback to random agent round===============
Currnt Bid: 62.066721
=================Random Agent Turn=================
Action taken: 81.358071
===============Feedback to learned agent round===============
Observation:
[0, array([62.06672076]), array([81.35807052])]
Reward: -1.000000, Currnt Bid: 81.358071
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[60.24209427]
Explore action: 60.242094
Action taken: 60.242094
===============Feedback to random agent round===============
Currnt Bid: 81.358071
=================Random Agent Turn=================
Action taken: 86.998576
===============Feedback to learned agent round===============
Observation:
[1, array([62.06672076]), array([81.35807052])]
Reward: -2.000000, Currnt Bid: 81.358071
Is done? True
Episode End
Positive: 44, Negative: 50
EPISODE :- 198
Random Player utility: 159.146369
=================Random Agent Turn=================
Action taken: 68.194849
===============Feedback to learned agent round===============
Observation:
[0, 0, 68.1948489652145]
Reward: -1.000000, Currnt Bid: 68.194849
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[65.26626859]
Explore action: 65.266269
Action taken: 65.266269
===============Feedback to random agent round===============
Currnt Bid: 68.194849
=================Random Agent Turn=================
Action taken: 116.860211
===============Feedback to learned agent round===============
Observation:
[1, 0, 68.1948489652145]
Reward: -2.000000, Currnt Bid: 68.194849
Is done? True
Episode End
Positive: 44, Negative: 50
EPISODE :- 199
Random Player utility: 154.561704
=================Random Agent Turn=================
Action taken: 141.570382
===============Feedback to learned agent round===============
Observation:
[0, 0, 141.57038153548874]
Reward: -1.000000, Currnt Bid: 141.570382
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[66.40758513]
Explore action: 66.407585
Action taken: 66.407585
===============Feedback to random agent round===============
Currnt Bid: 141.570382
=================Random Agent Turn=================
Action taken: 147.468621
===============Feedback to learned agent round===============
Observation:
[1, 0, 141.57038153548874]
Reward: -2.000000, Currnt Bid: 141.570382
Is done? True
Episode End
Positive: 44, Negative: 50
EPISODE :- 200
Random Player utility: 64.337695
=================Random Agent Turn=================
Action taken: 22.094917
===============Feedback to learned agent round===============
Observation:
[0, 0, 22.094917495641564]
Reward: -1.000000, Currnt Bid: 22.094917
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 48.516388
Exploit action: 48.516388
Action taken: 48.516388
===============Feedback to random agent round===============
Currnt Bid: 48.516388
=================Random Agent Turn=================
Action taken: 59.303387
===============Feedback to learned agent round===============
Observation:
[0, array([48.516388], dtype=float32), array([59.303387], dtype=float32)]
Reward: -1.000000, Currnt Bid: 59.303387
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 16.181416
Exploit action: 16.181416
Action taken: 16.181416
===============Feedback to random agent round===============
Currnt Bid: 59.303387
=================Random Agent Turn=================
Action taken: 64.168793
===============Feedback to learned agent round===============
Observation:
[1, array([48.516388], dtype=float32), array([59.303387], dtype=float32)]
Reward: -2.000000, Currnt Bid: 59.303387
Is done? True
Episode End
Positive: 44, Negative: 51
Models saved successfully
EPISODE :- 201
Random Player utility: 169.949552
=================Random Agent Turn=================
Action taken: 154.391041
===============Feedback to learned agent round===============
Observation:
[0, 0, 154.39104094746267]
Reward: -1.000000, Currnt Bid: 154.391041
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[63.86384881]
Explore action: 63.863849
Action taken: 63.863849
===============Feedback to random agent round===============
Currnt Bid: 154.391041
=================Random Agent Turn=================
Action taken: 156.362391
===============Feedback to learned agent round===============
Observation:
[1, 0, 154.39104094746267]
Reward: -2.000000, Currnt Bid: 154.391041
Is done? True
Episode End
Positive: 44, Negative: 51
EPISODE :- 202
Random Player utility: 69.592576
=================Random Agent Turn=================
Action taken: 2.861075
===============Feedback to learned agent round===============
Observation:
[0, 0, 2.8610749456234195]
Reward: -1.000000, Currnt Bid: 2.861075
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[53.0191142]
Explore action: 53.019114
Action taken: 53.019114
===============Feedback to random agent round===============
Currnt Bid: 53.019114
=================Random Agent Turn=================
Action taken: 67.276682
===============Feedback to learned agent round===============
Observation:
[0, array([53.0191142]), array([67.27668209])]
Reward: -1.000000, Currnt Bid: 67.276682
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[61.84638138]
Explore action: 61.846381
Action taken: 61.846381
===============Feedback to random agent round===============
Currnt Bid: 67.276682
=================Random Agent Turn=================
Action taken: 69.425196
===============Feedback to learned agent round===============
Observation:
[1, array([53.0191142]), array([67.27668209])]
Reward: -2.000000, Currnt Bid: 67.276682
Is done? True
Episode End
Positive: 44, Negative: 52
EPISODE :- 203
Random Player utility: 138.275972
=================Random Agent Turn=================
Action taken: 125.294984
===============Feedback to learned agent round===============
Observation:
[0, 0, 125.2949836091579]
Reward: -1.000000, Currnt Bid: 125.294984
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[46.96804414]
Explore action: 46.968044
Action taken: 46.968044
===============Feedback to random agent round===============
Currnt Bid: 125.294984
=================Random Agent Turn=================
Action taken: 135.534406
===============Feedback to learned agent round===============
Observation:
[1, 0, 125.2949836091579]
Reward: -2.000000, Currnt Bid: 125.294984
Is done? True
Episode End
Positive: 44, Negative: 52
EPISODE :- 204
Random Player utility: 146.693336
=================Random Agent Turn=================
Action taken: 34.584852
===============Feedback to learned agent round===============
Observation:
[0, 0, 34.58485237813034]
Reward: -1.000000, Currnt Bid: 34.584852
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[51.00497588]
Explore action: 51.004976
Action taken: 51.004976
===============Feedback to random agent round===============
Currnt Bid: 51.004976
=================Random Agent Turn=================
Action taken: 52.117564
===============Feedback to learned agent round===============
Observation:
[0, array([51.00497588]), array([52.11756435])]
Reward: -1.000000, Currnt Bid: 52.117564
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[50.86767438]
Explore action: 50.867674
Action taken: 50.867674
===============Feedback to random agent round===============
Currnt Bid: 52.117564
=================Random Agent Turn=================
Action taken: 66.355810
===============Feedback to learned agent round===============
Observation:
[1, array([51.00497588]), array([52.11756435])]
Reward: -2.000000, Currnt Bid: 52.117564
Is done? True
Episode End
Positive: 44, Negative: 52
EPISODE :- 205
Random Player utility: 92.229456
=================Random Agent Turn=================
Action taken: 52.201988
===============Feedback to learned agent round===============
Observation:
[0, 0, 52.20198810862785]
Reward: -1.000000, Currnt Bid: 52.201988
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 46.376980
Exploit action: 46.376980
Action taken: 46.376980
===============Feedback to random agent round===============
Currnt Bid: 52.201988
=================Random Agent Turn=================
Action taken: 91.727800
===============Feedback to learned agent round===============
Observation:
[1, 0, 52.20198810862785]
Reward: -2.000000, Currnt Bid: 52.201988
Is done? True
Episode End
Positive: 44, Negative: 53
EPISODE :- 206
Random Player utility: 83.455417
=================Random Agent Turn=================
Action taken: 75.668670
===============Feedback to learned agent round===============
Observation:
[0, 0, 75.6686696721336]
Reward: -1.000000, Currnt Bid: 75.668670
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[63.88527344]
Explore action: 63.885273
Action taken: 63.885273
===============Feedback to random agent round===============
Currnt Bid: 75.668670
=================Random Agent Turn=================
Action taken: 77.969151
===============Feedback to learned agent round===============
Observation:
[1, 0, 75.6686696721336]
Reward: -2.000000, Currnt Bid: 75.668670
Is done? True
Episode End
Positive: 44, Negative: 54
EPISODE :- 207
Random Player utility: 103.868863
=================Random Agent Turn=================
Action taken: 93.385891
===============Feedback to learned agent round===============
Observation:
[0, 0, 93.38589108567916]
Reward: -1.000000, Currnt Bid: 93.385891
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[54.64549741]
Explore action: 54.645497
Action taken: 54.645497
===============Feedback to random agent round===============
Currnt Bid: 93.385891
=================Random Agent Turn=================
Action taken: 95.719257
===============Feedback to learned agent round===============
Observation:
[1, 0, 93.38589108567916]
Reward: -2.000000, Currnt Bid: 93.385891
Is done? True
Episode End
Positive: 44, Negative: 54
EPISODE :- 208
Random Player utility: 56.875292
=================Random Agent Turn=================
Action taken: 40.296082
===============Feedback to learned agent round===============
Observation:
[0, 0, 40.29608236991843]
Reward: -1.000000, Currnt Bid: 40.296082
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[61.53028748]
Explore action: 61.530287
Action taken: 61.530287
===============Feedback to random agent round===============
Currnt Bid: 61.530287
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([61.53028748]), 40.29608236991843]
Reward: 38.469713, Currnt Bid: 61.530287
Is done? True
Episode End
Positive: 45, Negative: 54
EPISODE :- 209
Random Player utility: 72.851127
=================Random Agent Turn=================
Action taken: 44.011371
===============Feedback to learned agent round===============
Observation:
[0, 0, 44.01137134630593]
Reward: -1.000000, Currnt Bid: 44.011371
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[45.5031092]
Explore action: 45.503109
Action taken: 45.503109
===============Feedback to random agent round===============
Currnt Bid: 45.503109
=================Random Agent Turn=================
Action taken: 64.399295
===============Feedback to learned agent round===============
Observation:
[0, array([45.5031092]), array([64.39929501])]
Reward: -1.000000, Currnt Bid: 64.399295
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[47.36024253]
Explore action: 47.360243
Action taken: 47.360243
===============Feedback to random agent round===============
Currnt Bid: 64.399295
=================Random Agent Turn=================
Action taken: 67.516858
===============Feedback to learned agent round===============
Observation:
[1, array([45.5031092]), array([64.39929501])]
Reward: -2.000000, Currnt Bid: 64.399295
Is done? True
Episode End
Positive: 45, Negative: 55
EPISODE :- 210
Random Player utility: 162.441727
=================Random Agent Turn=================
Action taken: 82.240594
===============Feedback to learned agent round===============
Observation:
[0, 0, 82.24059396046226]
Reward: -1.000000, Currnt Bid: 82.240594
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 44.571613
Exploit action: 44.571613
Action taken: 44.571613
===============Feedback to random agent round===============
Currnt Bid: 82.240594
=================Random Agent Turn=================
Action taken: 114.289754
===============Feedback to learned agent round===============
Observation:
[1, 0, 82.24059396046226]
Reward: -2.000000, Currnt Bid: 82.240594
Is done? True
Episode End
Positive: 45, Negative: 55
EPISODE :- 211
Random Player utility: 147.692737
=================Random Agent Turn=================
Action taken: 124.480969
===============Feedback to learned agent round===============
Observation:
[0, 0, 124.48096922042403]
Reward: -1.000000, Currnt Bid: 124.480969
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.90672472]
Explore action: 48.906725
Action taken: 48.906725
===============Feedback to random agent round===============
Currnt Bid: 124.480969
=================Random Agent Turn=================
Action taken: 142.457731
===============Feedback to learned agent round===============
Observation:
[1, 0, 124.48096922042403]
Reward: -2.000000, Currnt Bid: 124.480969
Is done? True
Episode End
Positive: 45, Negative: 55
EPISODE :- 212
Random Player utility: 50.922486
=================Random Agent Turn=================
Action taken: 44.074578
===============Feedback to learned agent round===============
Observation:
[0, 0, 44.07457833414372]
Reward: -1.000000, Currnt Bid: 44.074578
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[42.23708876]
Explore action: 42.237089
Action taken: 42.237089
===============Feedback to random agent round===============
Currnt Bid: 44.074578
=================Random Agent Turn=================
Action taken: 48.440560
===============Feedback to learned agent round===============
Observation:
[1, 0, 44.07457833414372]
Reward: -2.000000, Currnt Bid: 44.074578
Is done? True
Episode End
Positive: 45, Negative: 56
EPISODE :- 213
Random Player utility: 244.391443
=================Random Agent Turn=================
Action taken: 58.661973
===============Feedback to learned agent round===============
Observation:
[0, 0, 58.66197305059791]
Reward: -1.000000, Currnt Bid: 58.661973
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[34.78167457]
Explore action: 34.781675
Action taken: 34.781675
===============Feedback to random agent round===============
Currnt Bid: 58.661973
=================Random Agent Turn=================
Action taken: 113.466018
===============Feedback to learned agent round===============
Observation:
[1, 0, 58.66197305059791]
Reward: -2.000000, Currnt Bid: 58.661973
Is done? True
Episode End
Positive: 45, Negative: 56
EPISODE :- 214
Random Player utility: 3.753463
=================Random Agent Turn=================
Action taken: 3.063634
===============Feedback to learned agent round===============
Observation:
[0, 0, 3.063634291896478]
Reward: -1.000000, Currnt Bid: 3.063634
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[24.05261428]
Explore action: 24.052614
Action taken: 24.052614
===============Feedback to random agent round===============
Currnt Bid: 24.052614
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([24.05261428]), 3.063634291896478]
Reward: 75.947386, Currnt Bid: 24.052614
Is done? True
Episode End
Positive: 46, Negative: 56
EPISODE :- 215
Random Player utility: 45.247507
=================Random Agent Turn=================
Action taken: 8.999904
===============Feedback to learned agent round===============
Observation:
[0, 0, 8.999904171342894]
Reward: -1.000000, Currnt Bid: 8.999904
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 42.938774
Exploit action: 42.938774
Action taken: 42.938774
===============Feedback to random agent round===============
Currnt Bid: 42.938774
=================Random Agent Turn=================
Action taken: 44.545471
===============Feedback to learned agent round===============
Observation:
[0, array([42.938774], dtype=float32), array([44.54547], dtype=float32)]
Reward: -1.000000, Currnt Bid: 44.545471
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 31.111681
Exploit action: 31.111681
Action taken: 31.111681
===============Feedback to random agent round===============
Currnt Bid: 44.545471
=================Random Agent Turn=================
Action taken: 45.180573
===============Feedback to learned agent round===============
Observation:
[1, array([42.938774], dtype=float32), array([44.54547], dtype=float32)]
Reward: -2.000000, Currnt Bid: 44.545471
Is done? True
Episode End
Positive: 46, Negative: 57
EPISODE :- 216
Random Player utility: 176.169872
=================Random Agent Turn=================
Action taken: 42.476452
===============Feedback to learned agent round===============
Observation:
[0, 0, 42.476452339474434]
Reward: -1.000000, Currnt Bid: 42.476452
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[39.02656984]
Explore action: 39.026570
Action taken: 39.026570
===============Feedback to random agent round===============
Currnt Bid: 42.476452
=================Random Agent Turn=================
Action taken: 129.600704
===============Feedback to learned agent round===============
Observation:
[1, 0, 42.476452339474434]
Reward: -2.000000, Currnt Bid: 42.476452
Is done? True
Episode End
Positive: 46, Negative: 57
EPISODE :- 217
Random Player utility: 0.363254
=================Random Agent Turn=================
Action taken: 0.103615
===============Feedback to learned agent round===============
Observation:
[0, 0, 0.10361451386809793]
Reward: -1.000000, Currnt Bid: 0.103615
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[30.65925642]
Explore action: 30.659256
Action taken: 30.659256
===============Feedback to random agent round===============
Currnt Bid: 30.659256
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([30.65925642]), 0.10361451386809793]
Reward: 69.340744, Currnt Bid: 30.659256
Is done? True
Episode End
Positive: 47, Negative: 57
EPISODE :- 218
Random Player utility: 59.302345
=================Random Agent Turn=================
Action taken: 20.218692
===============Feedback to learned agent round===============
Observation:
[0, 0, 20.21869172862937]
Reward: -1.000000, Currnt Bid: 20.218692
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[29.02487658]
Explore action: 29.024877
Action taken: 29.024877
===============Feedback to random agent round===============
Currnt Bid: 29.024877
=================Random Agent Turn=================
Action taken: 44.887381
===============Feedback to learned agent round===============
Observation:
[0, array([29.02487658]), array([44.88738101])]
Reward: -1.000000, Currnt Bid: 44.887381
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[37.02098796]
Explore action: 37.020988
Action taken: 37.020988
===============Feedback to random agent round===============
Currnt Bid: 44.887381
=================Random Agent Turn=================
Action taken: 48.233425
===============Feedback to learned agent round===============
Observation:
[1, array([29.02487658]), array([44.88738101])]
Reward: -2.000000, Currnt Bid: 44.887381
Is done? True
Episode End
Positive: 47, Negative: 58
EPISODE :- 219
Random Player utility: 104.065847
=================Random Agent Turn=================
Action taken: 3.879888
===============Feedback to learned agent round===============
Observation:
[0, 0, 3.8798878891168136]
Reward: -1.000000, Currnt Bid: 3.879888
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[43.16397794]
Explore action: 43.163978
Action taken: 43.163978
===============Feedback to random agent round===============
Currnt Bid: 43.163978
=================Random Agent Turn=================
Action taken: 48.927039
===============Feedback to learned agent round===============
Observation:
[0, array([43.16397794]), array([48.92703932])]
Reward: -1.000000, Currnt Bid: 48.927039
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[39.57458033]
Explore action: 39.574580
Action taken: 39.574580
===============Feedback to random agent round===============
Currnt Bid: 48.927039
=================Random Agent Turn=================
Action taken: 74.441876
===============Feedback to learned agent round===============
Observation:
[1, array([43.16397794]), array([48.92703932])]
Reward: -2.000000, Currnt Bid: 48.927039
Is done? True
Episode End
Positive: 47, Negative: 58
EPISODE :- 220
Random Player utility: 103.922978
=================Random Agent Turn=================
Action taken: 67.429601
===============Feedback to learned agent round===============
Observation:
[0, 0, 67.42960117467608]
Reward: -1.000000, Currnt Bid: 67.429601
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 40.833710
Exploit action: 40.833710
Action taken: 40.833710
===============Feedback to random agent round===============
Currnt Bid: 67.429601
=================Random Agent Turn=================
Action taken: 102.162892
===============Feedback to learned agent round===============
Observation:
[1, 0, 67.42960117467608]
Reward: -2.000000, Currnt Bid: 67.429601
Is done? True
Episode End
Positive: 47, Negative: 58
EPISODE :- 221
Random Player utility: 124.110979
=================Random Agent Turn=================
Action taken: 2.328392
===============Feedback to learned agent round===============
Observation:
[0, 0, 2.3283923057415747]
Reward: -1.000000, Currnt Bid: 2.328392
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[35.91886549]
Explore action: 35.918865
Action taken: 35.918865
===============Feedback to random agent round===============
Currnt Bid: 35.918865
=================Random Agent Turn=================
Action taken: 103.726085
===============Feedback to learned agent round===============
Observation:
[0, array([35.91886549]), array([103.72608477])]
Reward: -1.000000, Currnt Bid: 103.726085
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[24.02993252]
Explore action: 24.029933
Action taken: 24.029933
===============Feedback to random agent round===============
Currnt Bid: 103.726085
=================Random Agent Turn=================
Action taken: 104.977426
===============Feedback to learned agent round===============
Observation:
[1, array([35.91886549]), array([103.72608477])]
Reward: -2.000000, Currnt Bid: 103.726085
Is done? True
Episode End
Positive: 47, Negative: 58
EPISODE :- 222
Random Player utility: 24.336986
=================Random Agent Turn=================
Action taken: 24.247756
===============Feedback to learned agent round===============
Observation:
[0, 0, 24.24775598350904]
Reward: -1.000000, Currnt Bid: 24.247756
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[30.60319023]
Explore action: 30.603190
Action taken: 30.603190
===============Feedback to random agent round===============
Currnt Bid: 30.603190
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([30.60319023]), 24.24775598350904]
Reward: 69.396810, Currnt Bid: 30.603190
Is done? True
Episode End
Positive: 48, Negative: 58
EPISODE :- 223
Random Player utility: 90.186829
=================Random Agent Turn=================
Action taken: 59.046426
===============Feedback to learned agent round===============
Observation:
[0, 0, 59.04642563595255]
Reward: -1.000000, Currnt Bid: 59.046426
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[42.80870838]
Explore action: 42.808708
Action taken: 42.808708
===============Feedback to random agent round===============
Currnt Bid: 59.046426
=================Random Agent Turn=================
Action taken: 87.860487
===============Feedback to learned agent round===============
Observation:
[1, 0, 59.04642563595255]
Reward: -2.000000, Currnt Bid: 59.046426
Is done? True
Episode End
Positive: 48, Negative: 59
EPISODE :- 224
Random Player utility: 103.107987
=================Random Agent Turn=================
Action taken: 69.223180
===============Feedback to learned agent round===============
Observation:
[0, 0, 69.22318028590755]
Reward: -1.000000, Currnt Bid: 69.223180
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[56.46888166]
Explore action: 56.468882
Action taken: 56.468882
===============Feedback to random agent round===============
Currnt Bid: 69.223180
=================Random Agent Turn=================
Action taken: 98.679942
===============Feedback to learned agent round===============
Observation:
[1, 0, 69.22318028590755]
Reward: -2.000000, Currnt Bid: 69.223180
Is done? True
Episode End
Positive: 48, Negative: 59
EPISODE :- 225
Random Player utility: 169.856413
=================Random Agent Turn=================
Action taken: 1.505432
===============Feedback to learned agent round===============
Observation:
[0, 0, 1.5054323206431353]
Reward: -1.000000, Currnt Bid: 1.505432
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 39.072914
Exploit action: 39.072914
Action taken: 39.072914
===============Feedback to random agent round===============
Currnt Bid: 39.072914
=================Random Agent Turn=================
Action taken: 113.221756
===============Feedback to learned agent round===============
Observation:
[0, array([39.072914], dtype=float32), array([113.221756], dtype=float32)]
Reward: -1.000000, Currnt Bid: 113.221756
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 37.857445
Exploit action: 37.857445
Action taken: 37.857445
===============Feedback to random agent round===============
Currnt Bid: 113.221756
=================Random Agent Turn=================
Action taken: 132.330719
===============Feedback to learned agent round===============
Observation:
[1, array([39.072914], dtype=float32), array([113.221756], dtype=float32)]
Reward: -2.000000, Currnt Bid: 113.221756
Is done? True
Episode End
Positive: 48, Negative: 59
EPISODE :- 226
Random Player utility: 46.188313
=================Random Agent Turn=================
Action taken: 2.831897
===============Feedback to learned agent round===============
Observation:
[0, 0, 2.831897015745487]
Reward: -1.000000, Currnt Bid: 2.831897
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[66.28015621]
Explore action: 66.280156
Action taken: 66.280156
===============Feedback to random agent round===============
Currnt Bid: 66.280156
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([66.28015621]), 2.831897015745487]
Reward: 33.719844, Currnt Bid: 66.280156
Is done? True
Episode End
Positive: 49, Negative: 59
EPISODE :- 227
Random Player utility: 107.803863
=================Random Agent Turn=================
Action taken: 35.452113
===============Feedback to learned agent round===============
Observation:
[0, 0, 35.452112803092724]
Reward: -1.000000, Currnt Bid: 35.452113
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[59.42646044]
Explore action: 59.426460
Action taken: 59.426460
===============Feedback to random agent round===============
Currnt Bid: 59.426460
=================Random Agent Turn=================
Action taken: 67.099491
===============Feedback to learned agent round===============
Observation:
[0, array([59.42646044]), array([67.09949085])]
Reward: -1.000000, Currnt Bid: 67.099491
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[50.02197695]
Explore action: 50.021977
Action taken: 50.021977
===============Feedback to random agent round===============
Currnt Bid: 67.099491
=================Random Agent Turn=================
Action taken: 85.719177
===============Feedback to learned agent round===============
Observation:
[1, array([59.42646044]), array([67.09949085])]
Reward: -2.000000, Currnt Bid: 67.099491
Is done? True
Episode End
Positive: 49, Negative: 59
EPISODE :- 228
Random Player utility: 88.956608
=================Random Agent Turn=================
Action taken: 34.436886
===============Feedback to learned agent round===============
Observation:
[0, 0, 34.43688561030552]
Reward: -1.000000, Currnt Bid: 34.436886
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[54.40579525]
Explore action: 54.405795
Action taken: 54.405795
===============Feedback to random agent round===============
Currnt Bid: 54.405795
=================Random Agent Turn=================
Action taken: 56.585400
===============Feedback to learned agent round===============
Observation:
[0, array([54.40579525]), array([56.5853997])]
Reward: -1.000000, Currnt Bid: 56.585400
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[40.72473555]
Explore action: 40.724736
Action taken: 40.724736
===============Feedback to random agent round===============
Currnt Bid: 56.585400
=================Random Agent Turn=================
Action taken: 63.351686
===============Feedback to learned agent round===============
Observation:
[1, array([54.40579525]), array([56.5853997])]
Reward: -2.000000, Currnt Bid: 56.585400
Is done? True
Episode End
Positive: 49, Negative: 60
EPISODE :- 229
Random Player utility: 75.331880
=================Random Agent Turn=================
Action taken: 7.315596
===============Feedback to learned agent round===============
Observation:
[0, 0, 7.315596320455368]
Reward: -1.000000, Currnt Bid: 7.315596
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[46.86651737]
Explore action: 46.866517
Action taken: 46.866517
===============Feedback to random agent round===============
Currnt Bid: 46.866517
=================Random Agent Turn=================
Action taken: 59.028150
===============Feedback to learned agent round===============
Observation:
[0, array([46.86651737]), array([59.02815049])]
Reward: -1.000000, Currnt Bid: 59.028150
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[49.48440939]
Explore action: 49.484409
Action taken: 49.484409
===============Feedback to random agent round===============
Currnt Bid: 59.028150
=================Random Agent Turn=================
Action taken: 73.979941
===============Feedback to learned agent round===============
Observation:
[1, array([46.86651737]), array([59.02815049])]
Reward: -2.000000, Currnt Bid: 59.028150
Is done? True
Episode End
Positive: 49, Negative: 61
EPISODE :- 230
Random Player utility: 124.313377
=================Random Agent Turn=================
Action taken: 13.441209
===============Feedback to learned agent round===============
Observation:
[0, 0, 13.44120856316995]
Reward: -1.000000, Currnt Bid: 13.441209
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 36.865841
Exploit action: 36.865841
Action taken: 36.865841
===============Feedback to random agent round===============
Currnt Bid: 36.865841
=================Random Agent Turn=================
Action taken: 91.424850
===============Feedback to learned agent round===============
Observation:
[0, array([36.86584], dtype=float32), array([91.42485], dtype=float32)]
Reward: -1.000000, Currnt Bid: 91.424850
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 17.174507
Exploit action: 17.174507
Action taken: 17.174507
===============Feedback to random agent round===============
Currnt Bid: 91.424850
=================Random Agent Turn=================
Action taken: 93.858208
===============Feedback to learned agent round===============
Observation:
[1, array([36.86584], dtype=float32), array([91.42485], dtype=float32)]
Reward: -2.000000, Currnt Bid: 91.424850
Is done? True
Episode End
Positive: 49, Negative: 61
EPISODE :- 231
Random Player utility: 150.803470
=================Random Agent Turn=================
Action taken: 113.637203
===============Feedback to learned agent round===============
Observation:
[0, 0, 113.63720332419673]
Reward: -1.000000, Currnt Bid: 113.637203
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[37.74403407]
Explore action: 37.744034
Action taken: 37.744034
===============Feedback to random agent round===============
Currnt Bid: 113.637203
=================Random Agent Turn=================
Action taken: 113.821360
===============Feedback to learned agent round===============
Observation:
[1, 0, 113.63720332419673]
Reward: -2.000000, Currnt Bid: 113.637203
Is done? True
Episode End
Positive: 49, Negative: 61
EPISODE :- 232
Random Player utility: 129.276039
=================Random Agent Turn=================
Action taken: 114.732061
===============Feedback to learned agent round===============
Observation:
[0, 0, 114.73206053679338]
Reward: -1.000000, Currnt Bid: 114.732061
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[44.12272765]
Explore action: 44.122728
Action taken: 44.122728
===============Feedback to random agent round===============
Currnt Bid: 114.732061
=================Random Agent Turn=================
Action taken: 124.632287
===============Feedback to learned agent round===============
Observation:
[1, 0, 114.73206053679338]
Reward: -2.000000, Currnt Bid: 114.732061
Is done? True
Episode End
Positive: 49, Negative: 61
EPISODE :- 233
Random Player utility: 126.893675
=================Random Agent Turn=================
Action taken: 27.172771
===============Feedback to learned agent round===============
Observation:
[0, 0, 27.172771157509672]
Reward: -1.000000, Currnt Bid: 27.172771
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[37.45101149]
Explore action: 37.451011
Action taken: 37.451011
===============Feedback to random agent round===============
Currnt Bid: 37.451011
=================Random Agent Turn=================
Action taken: 43.370968
===============Feedback to learned agent round===============
Observation:
[0, array([37.45101149]), array([43.37096764])]
Reward: -1.000000, Currnt Bid: 43.370968
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[34.93389919]
Explore action: 34.933899
Action taken: 34.933899
===============Feedback to random agent round===============
Currnt Bid: 43.370968
=================Random Agent Turn=================
Action taken: 89.367360
===============Feedback to learned agent round===============
Observation:
[1, array([37.45101149]), array([43.37096764])]
Reward: -2.000000, Currnt Bid: 43.370968
Is done? True
Episode End
Positive: 49, Negative: 61
EPISODE :- 234
Random Player utility: 108.740320
=================Random Agent Turn=================
Action taken: 102.322221
===============Feedback to learned agent round===============
Observation:
[0, 0, 102.32222098295769]
Reward: -1.000000, Currnt Bid: 102.322221
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[61.59667026]
Explore action: 61.596670
Action taken: 61.596670
===============Feedback to random agent round===============
Currnt Bid: 102.322221
=================Random Agent Turn=================
Action taken: 107.802830
===============Feedback to learned agent round===============
Observation:
[1, 0, 102.32222098295769]
Reward: -2.000000, Currnt Bid: 102.322221
Is done? True
Episode End
Positive: 49, Negative: 61
EPISODE :- 235
Random Player utility: 125.295274
=================Random Agent Turn=================
Action taken: 99.133962
===============Feedback to learned agent round===============
Observation:
[0, 0, 99.13396241676264]
Reward: -1.000000, Currnt Bid: 99.133962
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 35.009968
Exploit action: 35.009968
Action taken: 35.009968
===============Feedback to random agent round===============
Currnt Bid: 99.133962
=================Random Agent Turn=================
Action taken: 122.604249
===============Feedback to learned agent round===============
Observation:
[1, 0, 99.13396241676264]
Reward: -2.000000, Currnt Bid: 99.133962
Is done? True
Episode End
Positive: 49, Negative: 61
EPISODE :- 236
Random Player utility: 260.979026
=================Random Agent Turn=================
Action taken: 99.696534
===============Feedback to learned agent round===============
Observation:
[0, 0, 99.69653382092223]
Reward: -1.000000, Currnt Bid: 99.696534
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[66.5998722]
Explore action: 66.599872
Action taken: 66.599872
===============Feedback to random agent round===============
Currnt Bid: 99.696534
=================Random Agent Turn=================
Action taken: 189.864172
===============Feedback to learned agent round===============
Observation:
[1, 0, 99.69653382092223]
Reward: -2.000000, Currnt Bid: 99.696534
Is done? True
Episode End
Positive: 49, Negative: 61
EPISODE :- 237
Random Player utility: 38.187536
=================Random Agent Turn=================
Action taken: 16.801349
===============Feedback to learned agent round===============
Observation:
[0, 0, 16.80134855678614]
Reward: -1.000000, Currnt Bid: 16.801349
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[57.25945344]
Explore action: 57.259453
Action taken: 57.259453
===============Feedback to random agent round===============
Currnt Bid: 57.259453
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([57.25945344]), 16.80134855678614]
Reward: 42.740547, Currnt Bid: 57.259453
Is done? True
Episode End
Positive: 50, Negative: 61
EPISODE :- 238
Random Player utility: 260.123540
=================Random Agent Turn=================
Action taken: 235.261829
===============Feedback to learned agent round===============
Observation:
[0, 0, 235.26182865047127]
Reward: -1.000000, Currnt Bid: 235.261829
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[42.29789513]
Explore action: 42.297895
Action taken: 42.297895
===============Feedback to random agent round===============
Currnt Bid: 235.261829
=================Random Agent Turn=================
Action taken: 260.051416
===============Feedback to learned agent round===============
Observation:
[1, 0, 235.26182865047127]
Reward: -2.000000, Currnt Bid: 235.261829
Is done? True
Episode End
Positive: 50, Negative: 61
EPISODE :- 239
Random Player utility: 192.435304
=================Random Agent Turn=================
Action taken: 95.346311
===============Feedback to learned agent round===============
Observation:
[0, 0, 95.34631084413653]
Reward: -1.000000, Currnt Bid: 95.346311
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.2062279]
Explore action: 48.206228
Action taken: 48.206228
===============Feedback to random agent round===============
Currnt Bid: 95.346311
=================Random Agent Turn=================
Action taken: 147.709326
===============Feedback to learned agent round===============
Observation:
[1, 0, 95.34631084413653]
Reward: -2.000000, Currnt Bid: 95.346311
Is done? True
Episode End
Positive: 50, Negative: 61
EPISODE :- 240
Random Player utility: 136.479815
=================Random Agent Turn=================
Action taken: 20.639807
===============Feedback to learned agent round===============
Observation:
[0, 0, 20.639806506256413]
Reward: -1.000000, Currnt Bid: 20.639807
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 33.492344
Exploit action: 33.492344
Action taken: 33.492344
===============Feedback to random agent round===============
Currnt Bid: 33.492344
=================Random Agent Turn=================
Action taken: 89.170731
===============Feedback to learned agent round===============
Observation:
[0, array([33.492344], dtype=float32), array([89.17073], dtype=float32)]
Reward: -1.000000, Currnt Bid: 89.170731
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 6.543464
Exploit action: 6.543464
Action taken: 6.543464
===============Feedback to random agent round===============
Currnt Bid: 89.170731
=================Random Agent Turn=================
Action taken: 130.369080
===============Feedback to learned agent round===============
Observation:
[1, array([33.492344], dtype=float32), array([89.17073], dtype=float32)]
Reward: -2.000000, Currnt Bid: 89.170731
Is done? True
Episode End
Positive: 50, Negative: 61
EPISODE :- 241
Random Player utility: 67.348065
=================Random Agent Turn=================
Action taken: 37.720369
===============Feedback to learned agent round===============
Observation:
[0, 0, 37.72036904418551]
Reward: -1.000000, Currnt Bid: 37.720369
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[62.55648961]
Explore action: 62.556490
Action taken: 62.556490
===============Feedback to random agent round===============
Currnt Bid: 62.556490
=================Random Agent Turn=================
Action taken: 65.944871
===============Feedback to learned agent round===============
Observation:
[0, array([62.55648961]), array([65.94487118])]
Reward: -1.000000, Currnt Bid: 65.944871
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[43.3677072]
Explore action: 43.367707
Action taken: 43.367707
===============Feedback to random agent round===============
Currnt Bid: 65.944871
=================Random Agent Turn=================
Action taken: 65.994812
===============Feedback to learned agent round===============
Observation:
[1, array([62.55648961]), array([65.94487118])]
Reward: -2.000000, Currnt Bid: 65.944871
Is done? True
Episode End
Positive: 50, Negative: 62
EPISODE :- 242
Random Player utility: 70.778816
=================Random Agent Turn=================
Action taken: 35.892534
===============Feedback to learned agent round===============
Observation:
[0, 0, 35.89253427632445]
Reward: -1.000000, Currnt Bid: 35.892534
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[31.46588587]
Explore action: 31.465886
Action taken: 31.465886
===============Feedback to random agent round===============
Currnt Bid: 35.892534
=================Random Agent Turn=================
Action taken: 64.820804
===============Feedback to learned agent round===============
Observation:
[1, 0, 35.89253427632445]
Reward: -2.000000, Currnt Bid: 35.892534
Is done? True
Episode End
Positive: 50, Negative: 63
EPISODE :- 243
Random Player utility: 132.164800
=================Random Agent Turn=================
Action taken: 70.373506
===============Feedback to learned agent round===============
Observation:
[0, 0, 70.37350581822737]
Reward: -1.000000, Currnt Bid: 70.373506
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[29.30886036]
Explore action: 29.308860
Action taken: 29.308860
===============Feedback to random agent round===============
Currnt Bid: 70.373506
=================Random Agent Turn=================
Action taken: 125.125313
===============Feedback to learned agent round===============
Observation:
[1, 0, 70.37350581822737]
Reward: -2.000000, Currnt Bid: 70.373506
Is done? True
Episode End
Positive: 50, Negative: 63
EPISODE :- 244
Random Player utility: 117.544128
=================Random Agent Turn=================
Action taken: 1.564657
===============Feedback to learned agent round===============
Observation:
[0, 0, 1.5646567368898712]
Reward: -1.000000, Currnt Bid: 1.564657
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[40.85448365]
Explore action: 40.854484
Action taken: 40.854484
===============Feedback to random agent round===============
Currnt Bid: 40.854484
=================Random Agent Turn=================
Action taken: 61.611786
===============Feedback to learned agent round===============
Observation:
[0, array([40.85448365]), array([61.61178642])]
Reward: -1.000000, Currnt Bid: 61.611786
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[50.16378743]
Explore action: 50.163787
Action taken: 50.163787
===============Feedback to random agent round===============
Currnt Bid: 61.611786
=================Random Agent Turn=================
Action taken: 80.069525
===============Feedback to learned agent round===============
Observation:
[1, array([40.85448365]), array([61.61178642])]
Reward: -2.000000, Currnt Bid: 61.611786
Is done? True
Episode End
Positive: 50, Negative: 63
EPISODE :- 245
Random Player utility: 102.155222
=================Random Agent Turn=================
Action taken: 94.620849
===============Feedback to learned agent round===============
Observation:
[0, 0, 94.62084908800928]
Reward: -1.000000, Currnt Bid: 94.620849
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 31.563164
Exploit action: 31.563164
Action taken: 31.563164
===============Feedback to random agent round===============
Currnt Bid: 94.620849
=================Random Agent Turn=================
Action taken: 99.228766
===============Feedback to learned agent round===============
Observation:
[1, 0, 94.62084908800928]
Reward: -2.000000, Currnt Bid: 94.620849
Is done? True
Episode End
Positive: 50, Negative: 63
EPISODE :- 246
Random Player utility: 68.721956
=================Random Agent Turn=================
Action taken: 26.769633
===============Feedback to learned agent round===============
Observation:
[0, 0, 26.769633317235375]
Reward: -1.000000, Currnt Bid: 26.769633
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[42.12328434]
Explore action: 42.123284
Action taken: 42.123284
===============Feedback to random agent round===============
Currnt Bid: 42.123284
=================Random Agent Turn=================
Action taken: 62.333168
===============Feedback to learned agent round===============
Observation:
[0, array([42.12328434]), array([62.33316773])]
Reward: -1.000000, Currnt Bid: 62.333168
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[56.2039623]
Explore action: 56.203962
Action taken: 56.203962
===============Feedback to random agent round===============
Currnt Bid: 62.333168
=================Random Agent Turn=================
Action taken: 67.738702
===============Feedback to learned agent round===============
Observation:
[1, array([42.12328434]), array([62.33316773])]
Reward: -2.000000, Currnt Bid: 62.333168
Is done? True
Episode End
Positive: 50, Negative: 64
EPISODE :- 247
Random Player utility: 147.458510
=================Random Agent Turn=================
Action taken: 43.816819
===============Feedback to learned agent round===============
Observation:
[0, 0, 43.81681882518581]
Reward: -1.000000, Currnt Bid: 43.816819
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[74.56444446]
Explore action: 74.564444
Action taken: 74.564444
===============Feedback to random agent round===============
Currnt Bid: 74.564444
=================Random Agent Turn=================
Action taken: 141.589472
===============Feedback to learned agent round===============
Observation:
[0, array([74.56444446]), array([141.58947178])]
Reward: -1.000000, Currnt Bid: 141.589472
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[77.64870749]
Explore action: 77.648707
Action taken: 77.648707
===============Feedback to random agent round===============
Currnt Bid: 141.589472
=================Random Agent Turn=================
Action taken: 144.553384
===============Feedback to learned agent round===============
Observation:
[1, array([74.56444446]), array([141.58947178])]
Reward: -2.000000, Currnt Bid: 141.589472
Is done? True
Episode End
Positive: 50, Negative: 64
EPISODE :- 248
Random Player utility: 81.966770
=================Random Agent Turn=================
Action taken: 50.294005
===============Feedback to learned agent round===============
Observation:
[0, 0, 50.29400490229489]
Reward: -1.000000, Currnt Bid: 50.294005
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[62.93029248]
Explore action: 62.930292
Action taken: 62.930292
===============Feedback to random agent round===============
Currnt Bid: 62.930292
=================Random Agent Turn=================
Action taken: 81.391697
===============Feedback to learned agent round===============
Observation:
[0, array([62.93029248]), array([81.39169748])]
Reward: -1.000000, Currnt Bid: 81.391697
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[52.00666818]
Explore action: 52.006668
Action taken: 52.006668
===============Feedback to random agent round===============
Currnt Bid: 81.391697
=================Random Agent Turn=================
Action taken: 81.497331
===============Feedback to learned agent round===============
Observation:
[1, array([62.93029248]), array([81.39169748])]
Reward: -2.000000, Currnt Bid: 81.391697
Is done? True
Episode End
Positive: 50, Negative: 65
EPISODE :- 249
Random Player utility: 78.996654
=================Random Agent Turn=================
Action taken: 16.123818
===============Feedback to learned agent round===============
Observation:
[0, 0, 16.1238179611232]
Reward: -1.000000, Currnt Bid: 16.123818
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.35471323]
Explore action: 48.354713
Action taken: 48.354713
===============Feedback to random agent round===============
Currnt Bid: 48.354713
=================Random Agent Turn=================
Action taken: 60.051529
===============Feedback to learned agent round===============
Observation:
[0, array([48.35471323]), array([60.05152921])]
Reward: -1.000000, Currnt Bid: 60.051529
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[54.13186041]
Explore action: 54.131860
Action taken: 54.131860
===============Feedback to random agent round===============
Currnt Bid: 60.051529
=================Random Agent Turn=================
Action taken: 64.028371
===============Feedback to learned agent round===============
Observation:
[1, array([48.35471323]), array([60.05152921])]
Reward: -2.000000, Currnt Bid: 60.051529
Is done? True
Episode End
Positive: 50, Negative: 66
EPISODE :- 250
Random Player utility: 67.053441
=================Random Agent Turn=================
Action taken: 55.154258
===============Feedback to learned agent round===============
Observation:
[0, 0, 55.15425833566828]
Reward: -1.000000, Currnt Bid: 55.154258
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 29.546196
Exploit action: 29.546196
Action taken: 29.546196
===============Feedback to random agent round===============
Currnt Bid: 55.154258
=================Random Agent Turn=================
Action taken: 59.733879
===============Feedback to learned agent round===============
Observation:
[1, 0, 55.15425833566828]
Reward: -2.000000, Currnt Bid: 55.154258
Is done? True
Episode End
Positive: 50, Negative: 67
EPISODE :- 251
Random Player utility: 90.071379
=================Random Agent Turn=================
Action taken: 82.907885
===============Feedback to learned agent round===============
Observation:
[0, 0, 82.90788478920713]
Reward: -1.000000, Currnt Bid: 82.907885
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.2309314]
Explore action: 48.230931
Action taken: 48.230931
===============Feedback to random agent round===============
Currnt Bid: 82.907885
=================Random Agent Turn=================
Action taken: 89.592740
===============Feedback to learned agent round===============
Observation:
[1, 0, 82.90788478920713]
Reward: -2.000000, Currnt Bid: 82.907885
Is done? True
Episode End
Positive: 50, Negative: 68
EPISODE :- 252
Random Player utility: 129.729462
=================Random Agent Turn=================
Action taken: 19.055189
===============Feedback to learned agent round===============
Observation:
[0, 0, 19.055189265537383]
Reward: -1.000000, Currnt Bid: 19.055189
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[45.54077809]
Explore action: 45.540778
Action taken: 45.540778
===============Feedback to random agent round===============
Currnt Bid: 45.540778
=================Random Agent Turn=================
Action taken: 110.121367
===============Feedback to learned agent round===============
Observation:
[0, array([45.54077809]), array([110.12136702])]
Reward: -1.000000, Currnt Bid: 110.121367
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[37.64902288]
Explore action: 37.649023
Action taken: 37.649023
===============Feedback to random agent round===============
Currnt Bid: 110.121367
=================Random Agent Turn=================
Action taken: 124.345440
===============Feedback to learned agent round===============
Observation:
[1, array([45.54077809]), array([110.12136702])]
Reward: -2.000000, Currnt Bid: 110.121367
Is done? True
Episode End
Positive: 50, Negative: 68
EPISODE :- 253
Random Player utility: 110.336177
=================Random Agent Turn=================
Action taken: 79.913311
===============Feedback to learned agent round===============
Observation:
[0, 0, 79.91331144820815]
Reward: -1.000000, Currnt Bid: 79.913311
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[39.8259549]
Explore action: 39.825955
Action taken: 39.825955
===============Feedback to random agent round===============
Currnt Bid: 79.913311
=================Random Agent Turn=================
Action taken: 108.074771
===============Feedback to learned agent round===============
Observation:
[1, 0, 79.91331144820815]
Reward: -2.000000, Currnt Bid: 79.913311
Is done? True
Episode End
Positive: 50, Negative: 68
EPISODE :- 254
Random Player utility: 130.955821
=================Random Agent Turn=================
Action taken: 35.554734
===============Feedback to learned agent round===============
Observation:
[0, 0, 35.554733697978634]
Reward: -1.000000, Currnt Bid: 35.554734
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[53.77838045]
Explore action: 53.778380
Action taken: 53.778380
===============Feedback to random agent round===============
Currnt Bid: 53.778380
=================Random Agent Turn=================
Action taken: 96.108844
===============Feedback to learned agent round===============
Observation:
[0, array([53.77838045]), array([96.10884364])]
Reward: -1.000000, Currnt Bid: 96.108844
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[50.62118309]
Explore action: 50.621183
Action taken: 50.621183
===============Feedback to random agent round===============
Currnt Bid: 96.108844
=================Random Agent Turn=================
Action taken: 104.127505
===============Feedback to learned agent round===============
Observation:
[1, array([53.77838045]), array([96.10884364])]
Reward: -2.000000, Currnt Bid: 96.108844
Is done? True
Episode End
Positive: 50, Negative: 68
EPISODE :- 255
Random Player utility: 87.856595
=================Random Agent Turn=================
Action taken: 66.976191
===============Feedback to learned agent round===============
Observation:
[0, 0, 66.97619143214524]
Reward: -1.000000, Currnt Bid: 66.976191
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 27.871519
Exploit action: 27.871519
Action taken: 27.871519
===============Feedback to random agent round===============
Currnt Bid: 66.976191
=================Random Agent Turn=================
Action taken: 77.683841
===============Feedback to learned agent round===============
Observation:
[1, 0, 66.97619143214524]
Reward: -2.000000, Currnt Bid: 66.976191
Is done? True
Episode End
Positive: 50, Negative: 69
EPISODE :- 256
Random Player utility: 19.461743
=================Random Agent Turn=================
Action taken: 11.657391
===============Feedback to learned agent round===============
Observation:
[0, 0, 11.657391440258229]
Reward: -1.000000, Currnt Bid: 11.657391
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[53.75286112]
Explore action: 53.752861
Action taken: 53.752861
===============Feedback to random agent round===============
Currnt Bid: 53.752861
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([53.75286112]), 11.657391440258229]
Reward: 46.247139, Currnt Bid: 53.752861
Is done? True
Episode End
Positive: 51, Negative: 69
EPISODE :- 257
Random Player utility: 118.473710
=================Random Agent Turn=================
Action taken: 43.116316
===============Feedback to learned agent round===============
Observation:
[0, 0, 43.11631606595562]
Reward: -1.000000, Currnt Bid: 43.116316
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[56.53963285]
Explore action: 56.539633
Action taken: 56.539633
===============Feedback to random agent round===============
Currnt Bid: 56.539633
=================Random Agent Turn=================
Action taken: 86.717578
===============Feedback to learned agent round===============
Observation:
[0, array([56.53963285]), array([86.71757796])]
Reward: -1.000000, Currnt Bid: 86.717578
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[45.88434175]
Explore action: 45.884342
Action taken: 45.884342
===============Feedback to random agent round===============
Currnt Bid: 86.717578
=================Random Agent Turn=================
Action taken: 115.921192
===============Feedback to learned agent round===============
Observation:
[1, array([56.53963285]), array([86.71757796])]
Reward: -2.000000, Currnt Bid: 86.717578
Is done? True
Episode End
Positive: 51, Negative: 69
EPISODE :- 258
Random Player utility: 106.187221
=================Random Agent Turn=================
Action taken: 76.879509
===============Feedback to learned agent round===============
Observation:
[0, 0, 76.87950852490745]
Reward: -1.000000, Currnt Bid: 76.879509
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[37.68270908]
Explore action: 37.682709
Action taken: 37.682709
===============Feedback to random agent round===============
Currnt Bid: 76.879509
=================Random Agent Turn=================
Action taken: 77.761615
===============Feedback to learned agent round===============
Observation:
[1, 0, 76.87950852490745]
Reward: -2.000000, Currnt Bid: 76.879509
Is done? True
Episode End
Positive: 51, Negative: 69
EPISODE :- 259
Random Player utility: 223.903058
=================Random Agent Turn=================
Action taken: 77.810589
===============Feedback to learned agent round===============
Observation:
[0, 0, 77.81058914068203]
Reward: -1.000000, Currnt Bid: 77.810589
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[37.66862515]
Explore action: 37.668625
Action taken: 37.668625
===============Feedback to random agent round===============
Currnt Bid: 77.810589
=================Random Agent Turn=================
Action taken: 197.481362
===============Feedback to learned agent round===============
Observation:
[1, 0, 77.81058914068203]
Reward: -2.000000, Currnt Bid: 77.810589
Is done? True
Episode End
Positive: 51, Negative: 69
EPISODE :- 260
Random Player utility: 147.891927
=================Random Agent Turn=================
Action taken: 116.163727
===============Feedback to learned agent round===============
Observation:
[0, 0, 116.1637268058375]
Reward: -1.000000, Currnt Bid: 116.163727
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 26.383060
Exploit action: 26.383060
Action taken: 26.383060
===============Feedback to random agent round===============
Currnt Bid: 116.163727
=================Random Agent Turn=================
Action taken: 143.479458
===============Feedback to learned agent round===============
Observation:
[1, 0, 116.1637268058375]
Reward: -2.000000, Currnt Bid: 116.163727
Is done? True
Episode End
Positive: 51, Negative: 69
EPISODE :- 261
Random Player utility: 176.581309
=================Random Agent Turn=================
Action taken: 102.276907
===============Feedback to learned agent round===============
Observation:
[0, 0, 102.27690682931913]
Reward: -1.000000, Currnt Bid: 102.276907
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[57.28589014]
Explore action: 57.285890
Action taken: 57.285890
===============Feedback to random agent round===============
Currnt Bid: 102.276907
=================Random Agent Turn=================
Action taken: 146.031968
===============Feedback to learned agent round===============
Observation:
[1, 0, 102.27690682931913]
Reward: -2.000000, Currnt Bid: 102.276907
Is done? True
Episode End
Positive: 51, Negative: 69
EPISODE :- 262
Random Player utility: 151.249879
=================Random Agent Turn=================
Action taken: 120.789785
===============Feedback to learned agent round===============
Observation:
[0, 0, 120.78978502261245]
Reward: -1.000000, Currnt Bid: 120.789785
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[69.288392]
Explore action: 69.288392
Action taken: 69.288392
===============Feedback to random agent round===============
Currnt Bid: 120.789785
=================Random Agent Turn=================
Action taken: 150.596056
===============Feedback to learned agent round===============
Observation:
[1, 0, 120.78978502261245]
Reward: -2.000000, Currnt Bid: 120.789785
Is done? True
Episode End
Positive: 51, Negative: 69
EPISODE :- 263
Random Player utility: 112.278245
=================Random Agent Turn=================
Action taken: 26.939060
===============Feedback to learned agent round===============
Observation:
[0, 0, 26.93905999881065]
Reward: -1.000000, Currnt Bid: 26.939060
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[75.14627383]
Explore action: 75.146274
Action taken: 75.146274
===============Feedback to random agent round===============
Currnt Bid: 75.146274
=================Random Agent Turn=================
Action taken: 111.739393
===============Feedback to learned agent round===============
Observation:
[0, array([75.14627383]), array([111.73939325])]
Reward: -1.000000, Currnt Bid: 111.739393
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[67.41755144]
Explore action: 67.417551
Action taken: 67.417551
===============Feedback to random agent round===============
Currnt Bid: 111.739393
=================Random Agent Turn=================
Action taken: 111.773155
===============Feedback to learned agent round===============
Observation:
[1, array([75.14627383]), array([111.73939325])]
Reward: -2.000000, Currnt Bid: 111.739393
Is done? True
Episode End
Positive: 51, Negative: 69
EPISODE :- 264
Random Player utility: 21.399259
=================Random Agent Turn=================
Action taken: 13.723732
===============Feedback to learned agent round===============
Observation:
[0, 0, 13.723731852283244]
Reward: -1.000000, Currnt Bid: 13.723732
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[57.92586576]
Explore action: 57.925866
Action taken: 57.925866
===============Feedback to random agent round===============
Currnt Bid: 57.925866
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([57.92586576]), 13.723731852283244]
Reward: 42.074134, Currnt Bid: 57.925866
Is done? True
Episode End
Positive: 52, Negative: 69
EPISODE :- 265
Random Player utility: 3.286509
=================Random Agent Turn=================
Action taken: 2.524190
===============Feedback to learned agent round===============
Observation:
[0, 0, 2.524190412594442]
Reward: -1.000000, Currnt Bid: 2.524190
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 24.941277
Exploit action: 24.941277
Action taken: 24.941277
===============Feedback to random agent round===============
Currnt Bid: 24.941277
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([24.941277], dtype=float32), 2.524190412594442]
Reward: 75.058723, Currnt Bid: 24.941277
Is done? True
Episode End
Positive: 53, Negative: 69
EPISODE :- 266
Random Player utility: 82.687890
=================Random Agent Turn=================
Action taken: 57.098067
===============Feedback to learned agent round===============
Observation:
[0, 0, 57.09806674658681]
Reward: -1.000000, Currnt Bid: 57.098067
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[57.63876969]
Explore action: 57.638770
Action taken: 57.638770
===============Feedback to random agent round===============
Currnt Bid: 57.638770
=================Random Agent Turn=================
Action taken: 67.191480
===============Feedback to learned agent round===============
Observation:
[0, array([57.63876969]), array([67.19148047])]
Reward: -1.000000, Currnt Bid: 67.191480
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[52.82847677]
Explore action: 52.828477
Action taken: 52.828477
===============Feedback to random agent round===============
Currnt Bid: 67.191480
=================Random Agent Turn=================
Action taken: 74.165594
===============Feedback to learned agent round===============
Observation:
[1, array([57.63876969]), array([67.19148047])]
Reward: -2.000000, Currnt Bid: 67.191480
Is done? True
Episode End
Positive: 53, Negative: 70
EPISODE :- 267
Random Player utility: 127.018677
=================Random Agent Turn=================
Action taken: 88.665932
===============Feedback to learned agent round===============
Observation:
[0, 0, 88.66593227090956]
Reward: -1.000000, Currnt Bid: 88.665932
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[38.34958486]
Explore action: 38.349585
Action taken: 38.349585
===============Feedback to random agent round===============
Currnt Bid: 88.665932
=================Random Agent Turn=================
Action taken: 113.338026
===============Feedback to learned agent round===============
Observation:
[1, 0, 88.66593227090956]
Reward: -2.000000, Currnt Bid: 88.665932
Is done? True
Episode End
Positive: 53, Negative: 70
EPISODE :- 268
Random Player utility: 5.285872
=================Random Agent Turn=================
Action taken: 2.756209
===============Feedback to learned agent round===============
Observation:
[0, 0, 2.7562092825043436]
Reward: -1.000000, Currnt Bid: 2.756209
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[30.80120779]
Explore action: 30.801208
Action taken: 30.801208
===============Feedback to random agent round===============
Currnt Bid: 30.801208
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([30.80120779]), 2.7562092825043436]
Reward: 69.198792, Currnt Bid: 30.801208
Is done? True
Episode End
Positive: 54, Negative: 70
EPISODE :- 269
Random Player utility: 75.516701
=================Random Agent Turn=================
Action taken: 15.773937
===============Feedback to learned agent round===============
Observation:
[0, 0, 15.773936922320878]
Reward: -1.000000, Currnt Bid: 15.773937
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[29.60900911]
Explore action: 29.609009
Action taken: 29.609009
===============Feedback to random agent round===============
Currnt Bid: 29.609009
=================Random Agent Turn=================
Action taken: 32.990971
===============Feedback to learned agent round===============
Observation:
[0, array([29.60900911]), array([32.99097139])]
Reward: -1.000000, Currnt Bid: 32.990971
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[32.52124989]
Explore action: 32.521250
Action taken: 32.521250
===============Feedback to random agent round===============
Currnt Bid: 32.990971
=================Random Agent Turn=================
Action taken: 64.516458
===============Feedback to learned agent round===============
Observation:
[1, array([29.60900911]), array([32.99097139])]
Reward: -2.000000, Currnt Bid: 32.990971
Is done? True
Episode End
Positive: 54, Negative: 71
EPISODE :- 270
Random Player utility: 125.380314
=================Random Agent Turn=================
Action taken: 78.568144
===============Feedback to learned agent round===============
Observation:
[0, 0, 78.56814428757527]
Reward: -1.000000, Currnt Bid: 78.568144
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 23.423599
Exploit action: 23.423599
Action taken: 23.423599
===============Feedback to random agent round===============
Currnt Bid: 78.568144
=================Random Agent Turn=================
Action taken: 110.431979
===============Feedback to learned agent round===============
Observation:
[1, 0, 78.56814428757527]
Reward: -2.000000, Currnt Bid: 78.568144
Is done? True
Episode End
Positive: 54, Negative: 71
EPISODE :- 271
Random Player utility: 97.809572
=================Random Agent Turn=================
Action taken: 46.697697
===============Feedback to learned agent round===============
Observation:
[0, 0, 46.697697083602336]
Reward: -1.000000, Currnt Bid: 46.697697
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[29.59496209]
Explore action: 29.594962
Action taken: 29.594962
===============Feedback to random agent round===============
Currnt Bid: 46.697697
=================Random Agent Turn=================
Action taken: 85.934678
===============Feedback to learned agent round===============
Observation:
[1, 0, 46.697697083602336]
Reward: -2.000000, Currnt Bid: 46.697697
Is done? True
Episode End
Positive: 54, Negative: 72
EPISODE :- 272
Random Player utility: 81.178105
=================Random Agent Turn=================
Action taken: 64.059981
===============Feedback to learned agent round===============
Observation:
[0, 0, 64.05998126679417]
Reward: -1.000000, Currnt Bid: 64.059981
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[39.33600011]
Explore action: 39.336000
Action taken: 39.336000
===============Feedback to random agent round===============
Currnt Bid: 64.059981
=================Random Agent Turn=================
Action taken: 71.617266
===============Feedback to learned agent round===============
Observation:
[1, 0, 64.05998126679417]
Reward: -2.000000, Currnt Bid: 64.059981
Is done? True
Episode End
Positive: 54, Negative: 73
EPISODE :- 273
Random Player utility: 53.026104
=================Random Agent Turn=================
Action taken: 18.648041
===============Feedback to learned agent round===============
Observation:
[0, 0, 18.64804116252934]
Reward: -1.000000, Currnt Bid: 18.648041
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[41.85750262]
Explore action: 41.857503
Action taken: 41.857503
===============Feedback to random agent round===============
Currnt Bid: 41.857503
=================Random Agent Turn=================
Action taken: 46.384627
===============Feedback to learned agent round===============
Observation:
[0, array([41.85750262]), array([46.3846275])]
Reward: -1.000000, Currnt Bid: 46.384627
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[38.02175799]
Explore action: 38.021758
Action taken: 38.021758
===============Feedback to random agent round===============
Currnt Bid: 46.384627
=================Random Agent Turn=================
Action taken: 47.002696
===============Feedback to learned agent round===============
Observation:
[1, array([41.85750262]), array([46.3846275])]
Reward: -2.000000, Currnt Bid: 46.384627
Is done? True
Episode End
Positive: 54, Negative: 74
EPISODE :- 274
Random Player utility: 115.887935
=================Random Agent Turn=================
Action taken: 25.635789
===============Feedback to learned agent round===============
Observation:
[0, 0, 25.635788830871054]
Reward: -1.000000, Currnt Bid: 25.635789
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[63.15470886]
Explore action: 63.154709
Action taken: 63.154709
===============Feedback to random agent round===============
Currnt Bid: 63.154709
=================Random Agent Turn=================
Action taken: 63.335321
===============Feedback to learned agent round===============
Observation:
[0, array([63.15470886]), array([63.3353205])]
Reward: -1.000000, Currnt Bid: 63.335321
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[69.94119297]
Explore action: 69.941193
Action taken: 69.941193
===============Feedback to random agent round===============
Currnt Bid: 69.941193
=================Random Agent Turn=================
Action taken: 76.349267
===============Feedback to learned agent round===============
Observation:
[0, array([69.94119297]), array([76.34926743])]
Reward: -1.000000, Currnt Bid: 76.349267
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[54.68068466]
Explore action: 54.680685
Action taken: 54.680685
===============Feedback to random agent round===============
Currnt Bid: 76.349267
=================Random Agent Turn=================
Action taken: 87.837734
===============Feedback to learned agent round===============
Observation:
[1, array([69.94119297]), array([76.34926743])]
Reward: -2.000000, Currnt Bid: 76.349267
Is done? True
Episode End
Positive: 54, Negative: 74
EPISODE :- 275
Random Player utility: 21.450432
=================Random Agent Turn=================
Action taken: 9.893315
===============Feedback to learned agent round===============
Observation:
[0, 0, 9.89331507318112]
Reward: -1.000000, Currnt Bid: 9.893315
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 21.846336
Exploit action: 21.846336
Action taken: 21.846336
===============Feedback to random agent round===============
Currnt Bid: 21.846336
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([21.846336], dtype=float32), 9.89331507318112]
Reward: 78.153664, Currnt Bid: 21.846336
Is done? True
Episode End
Positive: 55, Negative: 74
EPISODE :- 276
Random Player utility: 73.805115
=================Random Agent Turn=================
Action taken: 60.892684
===============Feedback to learned agent round===============
Observation:
[0, 0, 60.89268439446359]
Reward: -1.000000, Currnt Bid: 60.892684
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[66.77790735]
Explore action: 66.777907
Action taken: 66.777907
===============Feedback to random agent round===============
Currnt Bid: 66.777907
=================Random Agent Turn=================
Action taken: 67.460812
===============Feedback to learned agent round===============
Observation:
[0, array([66.77790735]), array([67.46081233])]
Reward: -1.000000, Currnt Bid: 67.460812
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[73.13427304]
Explore action: 73.134273
Action taken: 73.134273
===============Feedback to random agent round===============
Currnt Bid: 73.134273
=================Random Agent Turn=================
Action taken: 73.399636
===============Feedback to learned agent round===============
Observation:
[0, array([73.13427304]), array([73.39963611])]
Reward: -1.000000, Currnt Bid: 73.399636
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[71.64291955]
Explore action: 71.642920
Action taken: 71.642920
===============Feedback to random agent round===============
Currnt Bid: 73.399636
=================Random Agent Turn=================
Action taken: 73.763424
===============Feedback to learned agent round===============
Observation:
[1, array([73.13427304]), array([73.39963611])]
Reward: -2.000000, Currnt Bid: 73.399636
Is done? True
Episode End
Positive: 55, Negative: 75
EPISODE :- 277
Random Player utility: 69.601882
=================Random Agent Turn=================
Action taken: 54.657014
===============Feedback to learned agent round===============
Observation:
[0, 0, 54.657013702611906]
Reward: -1.000000, Currnt Bid: 54.657014
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[77.39543734]
Explore action: 77.395437
Action taken: 77.395437
===============Feedback to random agent round===============
Currnt Bid: 77.395437
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([77.39543734]), 54.657013702611906]
Reward: 22.604563, Currnt Bid: 77.395437
Is done? True
Episode End
Positive: 56, Negative: 75
EPISODE :- 278
Random Player utility: 84.168660
=================Random Agent Turn=================
Action taken: 10.393261
===============Feedback to learned agent round===============
Observation:
[0, 0, 10.39326107585935]
Reward: -1.000000, Currnt Bid: 10.393261
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[63.48888047]
Explore action: 63.488880
Action taken: 63.488880
===============Feedback to random agent round===============
Currnt Bid: 63.488880
=================Random Agent Turn=================
Action taken: 63.981509
===============Feedback to learned agent round===============
Observation:
[0, array([63.48888047]), array([63.9815094])]
Reward: -1.000000, Currnt Bid: 63.981509
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[78.76293542]
Explore action: 78.762935
Action taken: 78.762935
===============Feedback to random agent round===============
Currnt Bid: 78.762935
=================Random Agent Turn=================
Action taken: 83.025108
===============Feedback to learned agent round===============
Observation:
[0, array([78.76293542]), array([83.02510776])]
Reward: -1.000000, Currnt Bid: 83.025108
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[70.88631633]
Explore action: 70.886316
Action taken: 70.886316
===============Feedback to random agent round===============
Currnt Bid: 83.025108
=================Random Agent Turn=================
Action taken: 83.585045
===============Feedback to learned agent round===============
Observation:
[1, array([78.76293542]), array([83.02510776])]
Reward: -2.000000, Currnt Bid: 83.025108
Is done? True
Episode End
Positive: 56, Negative: 76
EPISODE :- 279
Random Player utility: 87.595961
=================Random Agent Turn=================
Action taken: 65.234919
===============Feedback to learned agent round===============
Observation:
[0, 0, 65.23491946654744]
Reward: -1.000000, Currnt Bid: 65.234919
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[68.02936723]
Explore action: 68.029367
Action taken: 68.029367
===============Feedback to random agent round===============
Currnt Bid: 68.029367
=================Random Agent Turn=================
Action taken: 74.372105
===============Feedback to learned agent round===============
Observation:
[0, array([68.02936723]), array([74.37210458])]
Reward: -1.000000, Currnt Bid: 74.372105
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[56.80710654]
Explore action: 56.807107
Action taken: 56.807107
===============Feedback to random agent round===============
Currnt Bid: 74.372105
=================Random Agent Turn=================
Action taken: 81.069919
===============Feedback to learned agent round===============
Observation:
[1, array([68.02936723]), array([74.37210458])]
Reward: -2.000000, Currnt Bid: 74.372105
Is done? True
Episode End
Positive: 56, Negative: 77
EPISODE :- 280
Random Player utility: 82.054454
=================Random Agent Turn=================
Action taken: 43.073605
===============Feedback to learned agent round===============
Observation:
[0, 0, 43.0736052878647]
Reward: -1.000000, Currnt Bid: 43.073605
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 20.114809
Exploit action: 20.114809
Action taken: 20.114809
===============Feedback to random agent round===============
Currnt Bid: 43.073605
=================Random Agent Turn=================
Action taken: 49.390407
===============Feedback to learned agent round===============
Observation:
[1, 0, 43.0736052878647]
Reward: -2.000000, Currnt Bid: 43.073605
Is done? True
Episode End
Positive: 56, Negative: 78
EPISODE :- 281
Random Player utility: 151.041380
=================Random Agent Turn=================
Action taken: 82.021512
===============Feedback to learned agent round===============
Observation:
[0, 0, 82.0215122966458]
Reward: -1.000000, Currnt Bid: 82.021512
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[84.30932916]
Explore action: 84.309329
Action taken: 84.309329
===============Feedback to random agent round===============
Currnt Bid: 84.309329
=================Random Agent Turn=================
Action taken: 100.832875
===============Feedback to learned agent round===============
Observation:
[0, array([84.30932916]), array([100.83287451])]
Reward: -1.000000, Currnt Bid: 100.832875
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[67.7915513]
Explore action: 67.791551
Action taken: 67.791551
===============Feedback to random agent round===============
Currnt Bid: 100.832875
=================Random Agent Turn=================
Action taken: 127.465152
===============Feedback to learned agent round===============
Observation:
[1, array([84.30932916]), array([100.83287451])]
Reward: -2.000000, Currnt Bid: 100.832875
Is done? True
Episode End
Positive: 56, Negative: 78
EPISODE :- 282
Random Player utility: 132.417856
=================Random Agent Turn=================
Action taken: 22.310637
===============Feedback to learned agent round===============
Observation:
[0, 0, 22.310637161637295]
Reward: -1.000000, Currnt Bid: 22.310637
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[71.45714578]
Explore action: 71.457146
Action taken: 71.457146
===============Feedback to random agent round===============
Currnt Bid: 71.457146
=================Random Agent Turn=================
Action taken: 83.936795
===============Feedback to learned agent round===============
Observation:
[0, array([71.45714578]), array([83.93679485])]
Reward: -1.000000, Currnt Bid: 83.936795
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[69.04916671]
Explore action: 69.049167
Action taken: 69.049167
===============Feedback to random agent round===============
Currnt Bid: 83.936795
=================Random Agent Turn=================
Action taken: 127.303238
===============Feedback to learned agent round===============
Observation:
[1, array([71.45714578]), array([83.93679485])]
Reward: -2.000000, Currnt Bid: 83.936795
Is done? True
Episode End
Positive: 56, Negative: 78
EPISODE :- 283
Random Player utility: 137.253618
=================Random Agent Turn=================
Action taken: 104.403034
===============Feedback to learned agent round===============
Observation:
[0, 0, 104.40303353256063]
Reward: -1.000000, Currnt Bid: 104.403034
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[70.71540261]
Explore action: 70.715403
Action taken: 70.715403
===============Feedback to random agent round===============
Currnt Bid: 104.403034
=================Random Agent Turn=================
Action taken: 115.914617
===============Feedback to learned agent round===============
Observation:
[1, 0, 104.40303353256063]
Reward: -2.000000, Currnt Bid: 104.403034
Is done? True
Episode End
Positive: 56, Negative: 78
EPISODE :- 284
Random Player utility: 138.078764
=================Random Agent Turn=================
Action taken: 13.305957
===============Feedback to learned agent round===============
Observation:
[0, 0, 13.30595725248737]
Reward: -1.000000, Currnt Bid: 13.305957
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[76.60263844]
Explore action: 76.602638
Action taken: 76.602638
===============Feedback to random agent round===============
Currnt Bid: 76.602638
=================Random Agent Turn=================
Action taken: 100.555932
===============Feedback to learned agent round===============
Observation:
[0, array([76.60263844]), array([100.55593154])]
Reward: -1.000000, Currnt Bid: 100.555932
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[70.88078963]
Explore action: 70.880790
Action taken: 70.880790
===============Feedback to random agent round===============
Currnt Bid: 100.555932
=================Random Agent Turn=================
Action taken: 124.522019
===============Feedback to learned agent round===============
Observation:
[1, array([76.60263844]), array([100.55593154])]
Reward: -2.000000, Currnt Bid: 100.555932
Is done? True
Episode End
Positive: 56, Negative: 78
EPISODE :- 285
Random Player utility: 45.340028
=================Random Agent Turn=================
Action taken: 23.518071
===============Feedback to learned agent round===============
Observation:
[0, 0, 23.51807118722404]
Reward: -1.000000, Currnt Bid: 23.518071
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 18.691820
Exploit action: 18.691820
Action taken: 18.691820
===============Feedback to random agent round===============
Currnt Bid: 23.518071
=================Random Agent Turn=================
Action taken: 35.555715
===============Feedback to learned agent round===============
Observation:
[1, 0, 23.51807118722404]
Reward: -2.000000, Currnt Bid: 23.518071
Is done? True
Episode End
Positive: 56, Negative: 79
EPISODE :- 286
Random Player utility: 75.863598
=================Random Agent Turn=================
Action taken: 72.407345
===============Feedback to learned agent round===============
Observation:
[0, 0, 72.40734458544297]
Reward: -1.000000, Currnt Bid: 72.407345
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[78.06291134]
Explore action: 78.062911
Action taken: 78.062911
===============Feedback to random agent round===============
Currnt Bid: 78.062911
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([78.06291134]), 72.40734458544297]
Reward: 21.937089, Currnt Bid: 78.062911
Is done? True
Episode End
Positive: 57, Negative: 79
EPISODE :- 287
Random Player utility: 169.429308
=================Random Agent Turn=================
Action taken: 125.610890
===============Feedback to learned agent round===============
Observation:
[0, 0, 125.61088966766356]
Reward: -1.000000, Currnt Bid: 125.610890
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[79.37374292]
Explore action: 79.373743
Action taken: 79.373743
===============Feedback to random agent round===============
Currnt Bid: 125.610890
=================Random Agent Turn=================
Action taken: 136.878552
===============Feedback to learned agent round===============
Observation:
[1, 0, 125.61088966766356]
Reward: -2.000000, Currnt Bid: 125.610890
Is done? True
Episode End
Positive: 57, Negative: 79
EPISODE :- 288
Random Player utility: 117.296277
=================Random Agent Turn=================
Action taken: 19.681281
===============Feedback to learned agent round===============
Observation:
[0, 0, 19.68128083901824]
Reward: -1.000000, Currnt Bid: 19.681281
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[60.69189186]
Explore action: 60.691892
Action taken: 60.691892
===============Feedback to random agent round===============
Currnt Bid: 60.691892
=================Random Agent Turn=================
Action taken: 63.618163
===============Feedback to learned agent round===============
Observation:
[0, array([60.69189186]), array([63.61816333])]
Reward: -1.000000, Currnt Bid: 63.618163
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[53.69528408]
Explore action: 53.695284
Action taken: 53.695284
===============Feedback to random agent round===============
Currnt Bid: 63.618163
=================Random Agent Turn=================
Action taken: 65.140535
===============Feedback to learned agent round===============
Observation:
[1, array([60.69189186]), array([63.61816333])]
Reward: -2.000000, Currnt Bid: 63.618163
Is done? True
Episode End
Positive: 57, Negative: 79
EPISODE :- 289
Random Player utility: 53.950492
=================Random Agent Turn=================
Action taken: 32.955959
===============Feedback to learned agent round===============
Observation:
[0, 0, 32.95595906771831]
Reward: -1.000000, Currnt Bid: 32.955959
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[47.92109526]
Explore action: 47.921095
Action taken: 47.921095
===============Feedback to random agent round===============
Currnt Bid: 47.921095
=================Random Agent Turn=================
Action taken: 50.650438
===============Feedback to learned agent round===============
Observation:
[0, array([47.92109526]), array([50.65043816])]
Reward: -1.000000, Currnt Bid: 50.650438
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[39.27225048]
Explore action: 39.272250
Action taken: 39.272250
===============Feedback to random agent round===============
Currnt Bid: 50.650438
=================Random Agent Turn=================
Action taken: 52.543730
===============Feedback to learned agent round===============
Observation:
[1, array([47.92109526]), array([50.65043816])]
Reward: -2.000000, Currnt Bid: 50.650438
Is done? True
Episode End
Positive: 57, Negative: 80
EPISODE :- 290
Random Player utility: 99.018957
=================Random Agent Turn=================
Action taken: 35.991776
===============Feedback to learned agent round===============
Observation:
[0, 0, 35.991776385166226]
Reward: -1.000000, Currnt Bid: 35.991776
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 17.442631
Exploit action: 17.442631
Action taken: 17.442631
===============Feedback to random agent round===============
Currnt Bid: 35.991776
=================Random Agent Turn=================
Action taken: 42.171221
===============Feedback to learned agent round===============
Observation:
[1, 0, 35.991776385166226]
Reward: -2.000000, Currnt Bid: 35.991776
Is done? True
Episode End
Positive: 57, Negative: 81
EPISODE :- 291
Random Player utility: 16.213818
=================Random Agent Turn=================
Action taken: 1.654128
===============Feedback to learned agent round===============
Observation:
[0, 0, 1.6541280167580503]
Reward: -1.000000, Currnt Bid: 1.654128
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[55.25759361]
Explore action: 55.257594
Action taken: 55.257594
===============Feedback to random agent round===============
Currnt Bid: 55.257594
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([55.25759361]), 1.6541280167580503]
Reward: 44.742406, Currnt Bid: 55.257594
Is done? True
Episode End
Positive: 58, Negative: 81
EPISODE :- 292
Random Player utility: 20.271809
=================Random Agent Turn=================
Action taken: 16.209560
===============Feedback to learned agent round===============
Observation:
[0, 0, 16.209560166189007]
Reward: -1.000000, Currnt Bid: 16.209560
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.61526592]
Explore action: 48.615266
Action taken: 48.615266
===============Feedback to random agent round===============
Currnt Bid: 48.615266
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([48.61526592]), 16.209560166189007]
Reward: 51.384734, Currnt Bid: 48.615266
Is done? True
Episode End
Positive: 59, Negative: 81
EPISODE :- 293
Random Player utility: 70.379150
=================Random Agent Turn=================
Action taken: 62.396931
===============Feedback to learned agent round===============
Observation:
[0, 0, 62.39693121293766]
Reward: -1.000000, Currnt Bid: 62.396931
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[32.73106047]
Explore action: 32.731060
Action taken: 32.731060
===============Feedback to random agent round===============
Currnt Bid: 62.396931
=================Random Agent Turn=================
Action taken: 63.410345
===============Feedback to learned agent round===============
Observation:
[1, 0, 62.39693121293766]
Reward: -2.000000, Currnt Bid: 62.396931
Is done? True
Episode End
Positive: 59, Negative: 82
EPISODE :- 294
Random Player utility: 126.043105
=================Random Agent Turn=================
Action taken: 118.826445
===============Feedback to learned agent round===============
Observation:
[0, 0, 118.82644456611251]
Reward: -1.000000, Currnt Bid: 118.826445
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[36.35670552]
Explore action: 36.356706
Action taken: 36.356706
===============Feedback to random agent round===============
Currnt Bid: 118.826445
=================Random Agent Turn=================
Action taken: 121.051629
===============Feedback to learned agent round===============
Observation:
[1, 0, 118.82644456611251]
Reward: -2.000000, Currnt Bid: 118.826445
Is done? True
Episode End
Positive: 59, Negative: 82
EPISODE :- 295
Random Player utility: 57.913893
=================Random Agent Turn=================
Action taken: 51.476509
===============Feedback to learned agent round===============
Observation:
[0, 0, 51.476509164958266]
Reward: -1.000000, Currnt Bid: 51.476509
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 16.449070
Exploit action: 16.449070
Action taken: 16.449070
===============Feedback to random agent round===============
Currnt Bid: 51.476509
=================Random Agent Turn=================
Action taken: 52.260213
===============Feedback to learned agent round===============
Observation:
[1, 0, 51.476509164958266]
Reward: -2.000000, Currnt Bid: 51.476509
Is done? True
Episode End
Positive: 59, Negative: 83
EPISODE :- 296
Random Player utility: 29.934833
=================Random Agent Turn=================
Action taken: 17.665655
===============Feedback to learned agent round===============
Observation:
[0, 0, 17.66565522640363]
Reward: -1.000000, Currnt Bid: 17.665655
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[35.49910818]
Explore action: 35.499108
Action taken: 35.499108
===============Feedback to random agent round===============
Currnt Bid: 35.499108
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([35.49910818]), 17.66565522640363]
Reward: 64.500892, Currnt Bid: 35.499108
Is done? True
Episode End
Positive: 60, Negative: 83
EPISODE :- 297
Random Player utility: 95.568866
=================Random Agent Turn=================
Action taken: 22.742352
===============Feedback to learned agent round===============
Observation:
[0, 0, 22.74235181672467]
Reward: -1.000000, Currnt Bid: 22.742352
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[35.78137727]
Explore action: 35.781377
Action taken: 35.781377
===============Feedback to random agent round===============
Currnt Bid: 35.781377
=================Random Agent Turn=================
Action taken: 93.355588
===============Feedback to learned agent round===============
Observation:
[0, array([35.78137727]), array([93.35558777])]
Reward: -1.000000, Currnt Bid: 93.355588
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[31.92558851]
Explore action: 31.925589
Action taken: 31.925589
===============Feedback to random agent round===============
Currnt Bid: 93.355588
=================Random Agent Turn=================
Action taken: 94.948753
===============Feedback to learned agent round===============
Observation:
[1, array([35.78137727]), array([93.35558777])]
Reward: -2.000000, Currnt Bid: 93.355588
Is done? True
Episode End
Positive: 60, Negative: 84
EPISODE :- 298
Random Player utility: 4.816062
=================Random Agent Turn=================
Action taken: 4.248626
===============Feedback to learned agent round===============
Observation:
[0, 0, 4.24862628890184]
Reward: -1.000000, Currnt Bid: 4.248626
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[36.06053217]
Explore action: 36.060532
Action taken: 36.060532
===============Feedback to random agent round===============
Currnt Bid: 36.060532
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([36.06053217]), 4.24862628890184]
Reward: 63.939468, Currnt Bid: 36.060532
Is done? True
Episode End
Positive: 61, Negative: 84
EPISODE :- 299
Random Player utility: 1.013198
=================Random Agent Turn=================
Action taken: 0.807679
===============Feedback to learned agent round===============
Observation:
[0, 0, 0.8076788598615375]
Reward: -1.000000, Currnt Bid: 0.807679
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[19.77294028]
Explore action: 19.772940
Action taken: 19.772940
===============Feedback to random agent round===============
Currnt Bid: 19.772940
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([19.77294028]), 0.8076788598615375]
Reward: 80.227060, Currnt Bid: 19.772940
Is done? True
Episode End
Positive: 62, Negative: 84
EPISODE :- 300
Random Player utility: 114.251434
=================Random Agent Turn=================
Action taken: 113.966217
===============Feedback to learned agent round===============
Observation:
[0, 0, 113.96621673646479]
Reward: -1.000000, Currnt Bid: 113.966217
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 15.405947
Exploit action: 15.405947
Action taken: 15.405947
===============Feedback to random agent round===============
Currnt Bid: 113.966217
=================Random Agent Turn=================
Action taken: 114.048715
===============Feedback to learned agent round===============
Observation:
[1, 0, 113.96621673646479]
Reward: -2.000000, Currnt Bid: 113.966217
Is done? True
Episode End
Positive: 62, Negative: 84
Models saved successfully
EPISODE :- 301
Random Player utility: 178.109061
=================Random Agent Turn=================
Action taken: 90.196833
===============Feedback to learned agent round===============
Observation:
[0, 0, 90.19683283365546]
Reward: -1.000000, Currnt Bid: 90.196833
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[36.01708299]
Explore action: 36.017083
Action taken: 36.017083
===============Feedback to random agent round===============
Currnt Bid: 90.196833
=================Random Agent Turn=================
Action taken: 164.148568
===============Feedback to learned agent round===============
Observation:
[1, 0, 90.19683283365546]
Reward: -2.000000, Currnt Bid: 90.196833
Is done? True
Episode End
Positive: 62, Negative: 84
EPISODE :- 302
Random Player utility: 83.616251
=================Random Agent Turn=================
Action taken: 66.994515
===============Feedback to learned agent round===============
Observation:
[0, 0, 66.9945150692187]
Reward: -1.000000, Currnt Bid: 66.994515
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[39.82788825]
Explore action: 39.827888
Action taken: 39.827888
===============Feedback to random agent round===============
Currnt Bid: 66.994515
=================Random Agent Turn=================
Action taken: 73.954734
===============Feedback to learned agent round===============
Observation:
[1, 0, 66.9945150692187]
Reward: -2.000000, Currnt Bid: 66.994515
Is done? True
Episode End
Positive: 62, Negative: 85
EPISODE :- 303
Random Player utility: 44.017736
=================Random Agent Turn=================
Action taken: 14.198679
===============Feedback to learned agent round===============
Observation:
[0, 0, 14.198678691464345]
Reward: -1.000000, Currnt Bid: 14.198679
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[53.49610469]
Explore action: 53.496105
Action taken: 53.496105
===============Feedback to random agent round===============
Currnt Bid: 53.496105
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([53.49610469]), 14.198678691464345]
Reward: 46.503895, Currnt Bid: 53.496105
Is done? True
Episode End
Positive: 63, Negative: 85
EPISODE :- 304
Random Player utility: 151.181144
=================Random Agent Turn=================
Action taken: 128.030893
===============Feedback to learned agent round===============
Observation:
[0, 0, 128.03089250237673]
Reward: -1.000000, Currnt Bid: 128.030893
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[63.50991683]
Explore action: 63.509917
Action taken: 63.509917
===============Feedback to random agent round===============
Currnt Bid: 128.030893
=================Random Agent Turn=================
Action taken: 133.530257
===============Feedback to learned agent round===============
Observation:
[1, 0, 128.03089250237673]
Reward: -2.000000, Currnt Bid: 128.030893
Is done? True
Episode End
Positive: 63, Negative: 85
EPISODE :- 305
Random Player utility: 103.768806
=================Random Agent Turn=================
Action taken: 1.837897
===============Feedback to learned agent round===============
Observation:
[0, 0, 1.8378969639291722]
Reward: -1.000000, Currnt Bid: 1.837897
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 14.501715
Exploit action: 14.501715
Action taken: 14.501715
===============Feedback to random agent round===============
Currnt Bid: 14.501715
=================Random Agent Turn=================
Action taken: 42.833557
===============Feedback to learned agent round===============
Observation:
[0, array([14.501715], dtype=float32), array([42.833557], dtype=float32)]
Reward: -1.000000, Currnt Bid: 42.833557
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 13.127428
Exploit action: 13.127428
Action taken: 13.127428
===============Feedback to random agent round===============
Currnt Bid: 42.833557
=================Random Agent Turn=================
Action taken: 52.950760
===============Feedback to learned agent round===============
Observation:
[1, array([14.501715], dtype=float32), array([42.833557], dtype=float32)]
Reward: -2.000000, Currnt Bid: 42.833557
Is done? True
Episode End
Positive: 63, Negative: 85
EPISODE :- 306
Random Player utility: 194.481213
=================Random Agent Turn=================
Action taken: 6.532401
===============Feedback to learned agent round===============
Observation:
[0, 0, 6.532401044479228]
Reward: -1.000000, Currnt Bid: 6.532401
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[55.64675767]
Explore action: 55.646758
Action taken: 55.646758
===============Feedback to random agent round===============
Currnt Bid: 55.646758
=================Random Agent Turn=================
Action taken: 177.096750
===============Feedback to learned agent round===============
Observation:
[0, array([55.64675767]), array([177.0967503])]
Reward: -1.000000, Currnt Bid: 177.096750
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[60.01371596]
Explore action: 60.013716
Action taken: 60.013716
===============Feedback to random agent round===============
Currnt Bid: 177.096750
=================Random Agent Turn=================
Action taken: 182.399432
===============Feedback to learned agent round===============
Observation:
[1, array([55.64675767]), array([177.0967503])]
Reward: -2.000000, Currnt Bid: 177.096750
Is done? True
Episode End
Positive: 63, Negative: 85
EPISODE :- 307
Random Player utility: 196.772256
=================Random Agent Turn=================
Action taken: 103.614946
===============Feedback to learned agent round===============
Observation:
[0, 0, 103.61494594157531]
Reward: -1.000000, Currnt Bid: 103.614946
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[62.12771887]
Explore action: 62.127719
Action taken: 62.127719
===============Feedback to random agent round===============
Currnt Bid: 103.614946
=================Random Agent Turn=================
Action taken: 138.279652
===============Feedback to learned agent round===============
Observation:
[1, 0, 103.61494594157531]
Reward: -2.000000, Currnt Bid: 103.614946
Is done? True
Episode End
Positive: 63, Negative: 85
EPISODE :- 308
Random Player utility: 90.230678
=================Random Agent Turn=================
Action taken: 85.958205
===============Feedback to learned agent round===============
Observation:
[0, 0, 85.95820470903426]
Reward: -1.000000, Currnt Bid: 85.958205
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[51.69963895]
Explore action: 51.699639
Action taken: 51.699639
===============Feedback to random agent round===============
Currnt Bid: 85.958205
=================Random Agent Turn=================
Action taken: 86.198237
===============Feedback to learned agent round===============
Observation:
[1, 0, 85.95820470903426]
Reward: -2.000000, Currnt Bid: 85.958205
Is done? True
Episode End
Positive: 63, Negative: 86
EPISODE :- 309
Random Player utility: 113.537563
=================Random Agent Turn=================
Action taken: 102.499067
===============Feedback to learned agent round===============
Observation:
[0, 0, 102.49906665486546]
Reward: -1.000000, Currnt Bid: 102.499067
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[55.11285447]
Explore action: 55.112854
Action taken: 55.112854
===============Feedback to random agent round===============
Currnt Bid: 102.499067
=================Random Agent Turn=================
Action taken: 107.493874
===============Feedback to learned agent round===============
Observation:
[1, 0, 102.49906665486546]
Reward: -2.000000, Currnt Bid: 102.499067
Is done? True
Episode End
Positive: 63, Negative: 86
EPISODE :- 310
Random Player utility: 68.276555
=================Random Agent Turn=================
Action taken: 38.427642
===============Feedback to learned agent round===============
Observation:
[0, 0, 38.42764222413205]
Reward: -1.000000, Currnt Bid: 38.427642
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 13.471192
Exploit action: 13.471192
Action taken: 13.471192
===============Feedback to random agent round===============
Currnt Bid: 38.427642
=================Random Agent Turn=================
Action taken: 53.586494
===============Feedback to learned agent round===============
Observation:
[1, 0, 38.42764222413205]
Reward: -2.000000, Currnt Bid: 38.427642
Is done? True
Episode End
Positive: 63, Negative: 87
EPISODE :- 311
Random Player utility: 139.596287
=================Random Agent Turn=================
Action taken: 4.551120
===============Feedback to learned agent round===============
Observation:
[0, 0, 4.551120179838528]
Reward: -1.000000, Currnt Bid: 4.551120
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[55.80483239]
Explore action: 55.804832
Action taken: 55.804832
===============Feedback to random agent round===============
Currnt Bid: 55.804832
=================Random Agent Turn=================
Action taken: 131.521986
===============Feedback to learned agent round===============
Observation:
[0, array([55.80483239]), array([131.52198622])]
Reward: -1.000000, Currnt Bid: 131.521986
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[42.49475021]
Explore action: 42.494750
Action taken: 42.494750
===============Feedback to random agent round===============
Currnt Bid: 131.521986
=================Random Agent Turn=================
Action taken: 135.953375
===============Feedback to learned agent round===============
Observation:
[1, array([55.80483239]), array([131.52198622])]
Reward: -2.000000, Currnt Bid: 131.521986
Is done? True
Episode End
Positive: 63, Negative: 87
EPISODE :- 312
Random Player utility: 177.849771
=================Random Agent Turn=================
Action taken: 177.655611
===============Feedback to learned agent round===============
Observation:
[0, 0, 177.6556112778851]
Reward: -1.000000, Currnt Bid: 177.655611
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[28.72439317]
Explore action: 28.724393
Action taken: 28.724393
===============Feedback to random agent round===============
Currnt Bid: 177.655611
=================Random Agent Turn=================
Action taken: 177.763704
===============Feedback to learned agent round===============
Observation:
[1, 0, 177.6556112778851]
Reward: -2.000000, Currnt Bid: 177.655611
Is done? True
Episode End
Positive: 63, Negative: 87
EPISODE :- 313
Random Player utility: 56.452464
=================Random Agent Turn=================
Action taken: 38.625143
===============Feedback to learned agent round===============
Observation:
[0, 0, 38.625143058635345]
Reward: -1.000000, Currnt Bid: 38.625143
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[28.92840095]
Explore action: 28.928401
Action taken: 28.928401
===============Feedback to random agent round===============
Currnt Bid: 38.625143
=================Random Agent Turn=================
Action taken: 54.472209
===============Feedback to learned agent round===============
Observation:
[1, 0, 38.625143058635345]
Reward: -2.000000, Currnt Bid: 38.625143
Is done? True
Episode End
Positive: 63, Negative: 88
EPISODE :- 314
Random Player utility: 134.556446
=================Random Agent Turn=================
Action taken: 115.400905
===============Feedback to learned agent round===============
Observation:
[0, 0, 115.40090503671321]
Reward: -1.000000, Currnt Bid: 115.400905
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[26.03033222]
Explore action: 26.030332
Action taken: 26.030332
===============Feedback to random agent round===============
Currnt Bid: 115.400905
=================Random Agent Turn=================
Action taken: 122.823827
===============Feedback to learned agent round===============
Observation:
[1, 0, 115.40090503671321]
Reward: -2.000000, Currnt Bid: 115.400905
Is done? True
Episode End
Positive: 63, Negative: 88
EPISODE :- 315
Random Player utility: 24.571591
=================Random Agent Turn=================
Action taken: 8.817994
===============Feedback to learned agent round===============
Observation:
[0, 0, 8.817993899906627]
Reward: -1.000000, Currnt Bid: 8.817994
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 12.577820
Exploit action: 12.577820
Action taken: 12.577820
===============Feedback to random agent round===============
Currnt Bid: 12.577820
=================Random Agent Turn=================
Action taken: 21.849739
===============Feedback to learned agent round===============
Observation:
[0, array([12.57782], dtype=float32), array([21.84974], dtype=float32)]
Reward: -1.000000, Currnt Bid: 21.849739
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 5.019689
Exploit action: 5.019689
Action taken: 5.019689
===============Feedback to random agent round===============
Currnt Bid: 21.849739
=================Random Agent Turn=================
Action taken: 22.338943
===============Feedback to learned agent round===============
Observation:
[1, array([12.57782], dtype=float32), array([21.84974], dtype=float32)]
Reward: -2.000000, Currnt Bid: 21.849739
Is done? True
Episode End
Positive: 63, Negative: 89
EPISODE :- 316
Random Player utility: 131.555602
=================Random Agent Turn=================
Action taken: 5.055954
===============Feedback to learned agent round===============
Observation:
[0, 0, 5.055954093924575]
Reward: -1.000000, Currnt Bid: 5.055954
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[21.86159576]
Explore action: 21.861596
Action taken: 21.861596
===============Feedback to random agent round===============
Currnt Bid: 21.861596
=================Random Agent Turn=================
Action taken: 29.617659
===============Feedback to learned agent round===============
Observation:
[0, array([21.86159576]), array([29.61765852])]
Reward: -1.000000, Currnt Bid: 29.617659
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[13.86902361]
Explore action: 13.869024
Action taken: 13.869024
===============Feedback to random agent round===============
Currnt Bid: 29.617659
=================Random Agent Turn=================
Action taken: 109.698687
===============Feedback to learned agent round===============
Observation:
[1, array([21.86159576]), array([29.61765852])]
Reward: -2.000000, Currnt Bid: 29.617659
Is done? True
Episode End
Positive: 63, Negative: 89
EPISODE :- 317
Random Player utility: 48.150739
=================Random Agent Turn=================
Action taken: 35.232642
===============Feedback to learned agent round===============
Observation:
[0, 0, 35.23264166489083]
Reward: -1.000000, Currnt Bid: 35.232642
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[13.8988698]
Explore action: 13.898870
Action taken: 13.898870
===============Feedback to random agent round===============
Currnt Bid: 35.232642
=================Random Agent Turn=================
Action taken: 40.498217
===============Feedback to learned agent round===============
Observation:
[1, 0, 35.23264166489083]
Reward: -2.000000, Currnt Bid: 35.232642
Is done? True
Episode End
Positive: 63, Negative: 90
EPISODE :- 318
Random Player utility: 61.244530
=================Random Agent Turn=================
Action taken: 46.861860
===============Feedback to learned agent round===============
Observation:
[0, 0, 46.86186042576761]
Reward: -1.000000, Currnt Bid: 46.861860
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[13.09451833]
Explore action: 13.094518
Action taken: 13.094518
===============Feedback to random agent round===============
Currnt Bid: 46.861860
=================Random Agent Turn=================
Action taken: 47.295592
===============Feedback to learned agent round===============
Observation:
[1, 0, 46.86186042576761]
Reward: -2.000000, Currnt Bid: 46.861860
Is done? True
Episode End
Positive: 63, Negative: 91
EPISODE :- 319
Random Player utility: 60.502774
=================Random Agent Turn=================
Action taken: 44.999204
===============Feedback to learned agent round===============
Observation:
[0, 0, 44.999204439563975]
Reward: -1.000000, Currnt Bid: 44.999204
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[23.78848921]
Explore action: 23.788489
Action taken: 23.788489
===============Feedback to random agent round===============
Currnt Bid: 44.999204
=================Random Agent Turn=================
Action taken: 49.542386
===============Feedback to learned agent round===============
Observation:
[1, 0, 44.999204439563975]
Reward: -2.000000, Currnt Bid: 44.999204
Is done? True
Episode End
Positive: 63, Negative: 92
EPISODE :- 320
Random Player utility: 97.184692
=================Random Agent Turn=================
Action taken: 2.407501
===============Feedback to learned agent round===============
Observation:
[0, 0, 2.407501018527885]
Reward: -1.000000, Currnt Bid: 2.407501
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 11.657816
Exploit action: 11.657816
Action taken: 11.657816
===============Feedback to random agent round===============
Currnt Bid: 11.657816
=================Random Agent Turn=================
Action taken: 66.702682
===============Feedback to learned agent round===============
Observation:
[0, array([11.657816], dtype=float32), array([66.70268], dtype=float32)]
Reward: -1.000000, Currnt Bid: 66.702682
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 10.025269
Exploit action: 10.025269
Action taken: 10.025269
===============Feedback to random agent round===============
Currnt Bid: 66.702682
=================Random Agent Turn=================
Action taken: 86.290802
===============Feedback to learned agent round===============
Observation:
[1, array([11.657816], dtype=float32), array([66.70268], dtype=float32)]
Reward: -2.000000, Currnt Bid: 66.702682
Is done? True
Episode End
Positive: 63, Negative: 93
EPISODE :- 321
Random Player utility: 214.681830
=================Random Agent Turn=================
Action taken: 211.767615
===============Feedback to learned agent round===============
Observation:
[0, 0, 211.76761529875188]
Reward: -1.000000, Currnt Bid: 211.767615
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[24.83111974]
Explore action: 24.831120
Action taken: 24.831120
===============Feedback to random agent round===============
Currnt Bid: 211.767615
=================Random Agent Turn=================
Action taken: 212.028546
===============Feedback to learned agent round===============
Observation:
[1, 0, 211.76761529875188]
Reward: -2.000000, Currnt Bid: 211.767615
Is done? True
Episode End
Positive: 63, Negative: 93
EPISODE :- 322
Random Player utility: 146.261773
=================Random Agent Turn=================
Action taken: 85.398748
===============Feedback to learned agent round===============
Observation:
[0, 0, 85.39874770049322]
Reward: -1.000000, Currnt Bid: 85.398748
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[44.54607697]
Explore action: 44.546077
Action taken: 44.546077
===============Feedback to random agent round===============
Currnt Bid: 85.398748
=================Random Agent Turn=================
Action taken: 138.301588
===============Feedback to learned agent round===============
Observation:
[1, 0, 85.39874770049322]
Reward: -2.000000, Currnt Bid: 85.398748
Is done? True
Episode End
Positive: 63, Negative: 93
EPISODE :- 323
Random Player utility: 93.469824
=================Random Agent Turn=================
Action taken: 85.623500
===============Feedback to learned agent round===============
Observation:
[0, 0, 85.62349983721943]
Reward: -1.000000, Currnt Bid: 85.623500
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[42.09781174]
Explore action: 42.097812
Action taken: 42.097812
===============Feedback to random agent round===============
Currnt Bid: 85.623500
=================Random Agent Turn=================
Action taken: 91.352127
===============Feedback to learned agent round===============
Observation:
[1, 0, 85.62349983721943]
Reward: -2.000000, Currnt Bid: 85.623500
Is done? True
Episode End
Positive: 63, Negative: 94
EPISODE :- 324
Random Player utility: 118.441341
=================Random Agent Turn=================
Action taken: 72.517914
===============Feedback to learned agent round===============
Observation:
[0, 0, 72.51791389404144]
Reward: -1.000000, Currnt Bid: 72.517914
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[42.69168154]
Explore action: 42.691682
Action taken: 42.691682
===============Feedback to random agent round===============
Currnt Bid: 72.517914
=================Random Agent Turn=================
Action taken: 117.713404
===============Feedback to learned agent round===============
Observation:
[1, 0, 72.51791389404144]
Reward: -2.000000, Currnt Bid: 72.517914
Is done? True
Episode End
Positive: 63, Negative: 94
EPISODE :- 325
Random Player utility: 108.789707
=================Random Agent Turn=================
Action taken: 38.289486
===============Feedback to learned agent round===============
Observation:
[0, 0, 38.289486014569384]
Reward: -1.000000, Currnt Bid: 38.289486
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 10.863132
Exploit action: 10.863132
Action taken: 10.863132
===============Feedback to random agent round===============
Currnt Bid: 38.289486
=================Random Agent Turn=================
Action taken: 43.121590
===============Feedback to learned agent round===============
Observation:
[1, 0, 38.289486014569384]
Reward: -2.000000, Currnt Bid: 38.289486
Is done? True
Episode End
Positive: 63, Negative: 94
EPISODE :- 326
Random Player utility: 159.124800
=================Random Agent Turn=================
Action taken: 95.708333
===============Feedback to learned agent round===============
Observation:
[0, 0, 95.70833283238214]
Reward: -1.000000, Currnt Bid: 95.708333
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[45.36237917]
Explore action: 45.362379
Action taken: 45.362379
===============Feedback to random agent round===============
Currnt Bid: 95.708333
=================Random Agent Turn=================
Action taken: 115.953887
===============Feedback to learned agent round===============
Observation:
[1, 0, 95.70833283238214]
Reward: -2.000000, Currnt Bid: 95.708333
Is done? True
Episode End
Positive: 63, Negative: 94
EPISODE :- 327
Random Player utility: 34.414314
=================Random Agent Turn=================
Action taken: 32.656839
===============Feedback to learned agent round===============
Observation:
[0, 0, 32.656838714305934]
Reward: -1.000000, Currnt Bid: 32.656839
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[40.27561639]
Explore action: 40.275616
Action taken: 40.275616
===============Feedback to random agent round===============
Currnt Bid: 40.275616
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([40.27561639]), 32.656838714305934]
Reward: 59.724384, Currnt Bid: 40.275616
Is done? True
Episode End
Positive: 64, Negative: 94
EPISODE :- 328
Random Player utility: 58.010577
=================Random Agent Turn=================
Action taken: 3.359195
===============Feedback to learned agent round===============
Observation:
[0, 0, 3.359194862560422]
Reward: -1.000000, Currnt Bid: 3.359195
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[46.74518854]
Explore action: 46.745189
Action taken: 46.745189
===============Feedback to random agent round===============
Currnt Bid: 46.745189
=================Random Agent Turn=================
Action taken: 56.300758
===============Feedback to learned agent round===============
Observation:
[0, array([46.74518854]), array([56.30075787])]
Reward: -1.000000, Currnt Bid: 56.300758
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[45.18051825]
Explore action: 45.180518
Action taken: 45.180518
===============Feedback to random agent round===============
Currnt Bid: 56.300758
=================Random Agent Turn=================
Action taken: 56.739658
===============Feedback to learned agent round===============
Observation:
[1, array([46.74518854]), array([56.30075787])]
Reward: -2.000000, Currnt Bid: 56.300758
Is done? True
Episode End
Positive: 64, Negative: 95
EPISODE :- 329
Random Player utility: 166.784759
=================Random Agent Turn=================
Action taken: 97.313423
===============Feedback to learned agent round===============
Observation:
[0, 0, 97.31342305633996]
Reward: -1.000000, Currnt Bid: 97.313423
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[40.97801482]
Explore action: 40.978015
Action taken: 40.978015
===============Feedback to random agent round===============
Currnt Bid: 97.313423
=================Random Agent Turn=================
Action taken: 125.211314
===============Feedback to learned agent round===============
Observation:
[1, 0, 97.31342305633996]
Reward: -2.000000, Currnt Bid: 97.313423
Is done? True
Episode End
Positive: 64, Negative: 95
EPISODE :- 330
Random Player utility: 19.833473
=================Random Agent Turn=================
Action taken: 5.276523
===============Feedback to learned agent round===============
Observation:
[0, 0, 5.276522710129036]
Reward: -1.000000, Currnt Bid: 5.276523
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 10.113562
Exploit action: 10.113562
Action taken: 10.113562
===============Feedback to random agent round===============
Currnt Bid: 10.113562
=================Random Agent Turn=================
Action taken: 16.222841
===============Feedback to learned agent round===============
Observation:
[0, array([10.113562], dtype=float32), array([16.222841], dtype=float32)]
Reward: -1.000000, Currnt Bid: 16.222841
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 6.421381
Exploit action: 6.421381
Action taken: 6.421381
===============Feedback to random agent round===============
Currnt Bid: 16.222841
=================Random Agent Turn=================
Action taken: 18.424198
===============Feedback to learned agent round===============
Observation:
[1, array([10.113562], dtype=float32), array([16.222841], dtype=float32)]
Reward: -2.000000, Currnt Bid: 16.222841
Is done? True
Episode End
Positive: 64, Negative: 96
EPISODE :- 331
Random Player utility: 32.733352
=================Random Agent Turn=================
Action taken: 21.031771
===============Feedback to learned agent round===============
Observation:
[0, 0, 21.031770602172706]
Reward: -1.000000, Currnt Bid: 21.031771
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[42.77843342]
Explore action: 42.778433
Action taken: 42.778433
===============Feedback to random agent round===============
Currnt Bid: 42.778433
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([42.77843342]), 21.031770602172706]
Reward: 57.221567, Currnt Bid: 42.778433
Is done? True
Episode End
Positive: 65, Negative: 96
EPISODE :- 332
Random Player utility: 127.074475
=================Random Agent Turn=================
Action taken: 58.472950
===============Feedback to learned agent round===============
Observation:
[0, 0, 58.47295018661783]
Reward: -1.000000, Currnt Bid: 58.472950
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[49.29697397]
Explore action: 49.296974
Action taken: 49.296974
===============Feedback to random agent round===============
Currnt Bid: 58.472950
=================Random Agent Turn=================
Action taken: 64.992853
===============Feedback to learned agent round===============
Observation:
[1, 0, 58.47295018661783]
Reward: -2.000000, Currnt Bid: 58.472950
Is done? True
Episode End
Positive: 65, Negative: 96
EPISODE :- 333
Random Player utility: 33.473937
=================Random Agent Turn=================
Action taken: 31.206064
===============Feedback to learned agent round===============
Observation:
[0, 0, 31.20606383434182]
Reward: -1.000000, Currnt Bid: 31.206064
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[72.90472116]
Explore action: 72.904721
Action taken: 72.904721
===============Feedback to random agent round===============
Currnt Bid: 72.904721
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([72.90472116]), 31.20606383434182]
Reward: 27.095279, Currnt Bid: 72.904721
Is done? True
Episode End
Positive: 66, Negative: 96
EPISODE :- 334
Random Player utility: 131.188268
=================Random Agent Turn=================
Action taken: 31.891315
===============Feedback to learned agent round===============
Observation:
[0, 0, 31.891314536229086]
Reward: -1.000000, Currnt Bid: 31.891315
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[69.09417043]
Explore action: 69.094170
Action taken: 69.094170
===============Feedback to random agent round===============
Currnt Bid: 69.094170
=================Random Agent Turn=================
Action taken: 125.050539
===============Feedback to learned agent round===============
Observation:
[0, array([69.09417043]), array([125.05053898])]
Reward: -1.000000, Currnt Bid: 125.050539
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[73.01288378]
Explore action: 73.012884
Action taken: 73.012884
===============Feedback to random agent round===============
Currnt Bid: 125.050539
=================Random Agent Turn=================
Action taken: 128.262999
===============Feedback to learned agent round===============
Observation:
[1, array([69.09417043]), array([125.05053898])]
Reward: -2.000000, Currnt Bid: 125.050539
Is done? True
Episode End
Positive: 66, Negative: 96
EPISODE :- 335
Random Player utility: 33.177933
=================Random Agent Turn=================
Action taken: 26.003785
===============Feedback to learned agent round===============
Observation:
[0, 0, 26.00378500767461]
Reward: -1.000000, Currnt Bid: 26.003785
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 9.345531
Exploit action: 9.345531
Action taken: 9.345531
===============Feedback to random agent round===============
Currnt Bid: 26.003785
=================Random Agent Turn=================
Action taken: 28.256346
===============Feedback to learned agent round===============
Observation:
[1, 0, 26.00378500767461]
Reward: -2.000000, Currnt Bid: 26.003785
Is done? True
Episode End
Positive: 66, Negative: 97
EPISODE :- 336
Random Player utility: 151.239178
=================Random Agent Turn=================
Action taken: 50.005577
===============Feedback to learned agent round===============
Observation:
[0, 0, 50.00557676813352]
Reward: -1.000000, Currnt Bid: 50.005577
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[76.05654345]
Explore action: 76.056543
Action taken: 76.056543
===============Feedback to random agent round===============
Currnt Bid: 76.056543
=================Random Agent Turn=================
Action taken: 111.185400
===============Feedback to learned agent round===============
Observation:
[0, array([76.05654345]), array([111.18540041])]
Reward: -1.000000, Currnt Bid: 111.185400
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[65.53864455]
Explore action: 65.538645
Action taken: 65.538645
===============Feedback to random agent round===============
Currnt Bid: 111.185400
=================Random Agent Turn=================
Action taken: 140.983330
===============Feedback to learned agent round===============
Observation:
[1, array([76.05654345]), array([111.18540041])]
Reward: -2.000000, Currnt Bid: 111.185400
Is done? True
Episode End
Positive: 66, Negative: 97
EPISODE :- 337
Random Player utility: 101.204073
=================Random Agent Turn=================
Action taken: 4.517371
===============Feedback to learned agent round===============
Observation:
[0, 0, 4.517371372872168]
Reward: -1.000000, Currnt Bid: 4.517371
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[65.45775325]
Explore action: 65.457753
Action taken: 65.457753
===============Feedback to random agent round===============
Currnt Bid: 65.457753
=================Random Agent Turn=================
Action taken: 81.412782
===============Feedback to learned agent round===============
Observation:
[0, array([65.45775325]), array([81.41278214])]
Reward: -1.000000, Currnt Bid: 81.412782
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[59.58845891]
Explore action: 59.588459
Action taken: 59.588459
===============Feedback to random agent round===============
Currnt Bid: 81.412782
=================Random Agent Turn=================
Action taken: 90.799035
===============Feedback to learned agent round===============
Observation:
[1, array([65.45775325]), array([81.41278214])]
Reward: -2.000000, Currnt Bid: 81.412782
Is done? True
Episode End
Positive: 66, Negative: 97
EPISODE :- 338
Random Player utility: 88.984397
=================Random Agent Turn=================
Action taken: 3.110063
===============Feedback to learned agent round===============
Observation:
[0, 0, 3.1100630529907303]
Reward: -1.000000, Currnt Bid: 3.110063
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[55.1657485]
Explore action: 55.165749
Action taken: 55.165749
===============Feedback to random agent round===============
Currnt Bid: 55.165749
=================Random Agent Turn=================
Action taken: 67.291667
===============Feedback to learned agent round===============
Observation:
[0, array([55.1657485]), array([67.29166681])]
Reward: -1.000000, Currnt Bid: 67.291667
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[54.58517434]
Explore action: 54.585174
Action taken: 54.585174
===============Feedback to random agent round===============
Currnt Bid: 67.291667
=================Random Agent Turn=================
Action taken: 80.720201
===============Feedback to learned agent round===============
Observation:
[1, array([55.1657485]), array([67.29166681])]
Reward: -2.000000, Currnt Bid: 67.291667
Is done? True
Episode End
Positive: 66, Negative: 98
EPISODE :- 339
Random Player utility: 61.809331
=================Random Agent Turn=================
Action taken: 46.113318
===============Feedback to learned agent round===============
Observation:
[0, 0, 46.11331779980117]
Reward: -1.000000, Currnt Bid: 46.113318
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[56.20649098]
Explore action: 56.206491
Action taken: 56.206491
===============Feedback to random agent round===============
Currnt Bid: 56.206491
=================Random Agent Turn=================
Action taken: 61.419033
===============Feedback to learned agent round===============
Observation:
[0, array([56.20649098]), array([61.41903302])]
Reward: -1.000000, Currnt Bid: 61.419033
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[43.58321469]
Explore action: 43.583215
Action taken: 43.583215
===============Feedback to random agent round===============
Currnt Bid: 61.419033
=================Random Agent Turn=================
Action taken: 61.482648
===============Feedback to learned agent round===============
Observation:
[1, array([56.20649098]), array([61.41903302])]
Reward: -2.000000, Currnt Bid: 61.419033
Is done? True
Episode End
Positive: 66, Negative: 99
EPISODE :- 340
Random Player utility: 72.801753
=================Random Agent Turn=================
Action taken: 17.169124
===============Feedback to learned agent round===============
Observation:
[0, 0, 17.169123830496503]
Reward: -1.000000, Currnt Bid: 17.169124
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 8.512449
Exploit action: 8.512449
Action taken: 8.512449
===============Feedback to random agent round===============
Currnt Bid: 17.169124
=================Random Agent Turn=================
Action taken: 57.101514
===============Feedback to learned agent round===============
Observation:
[1, 0, 17.169123830496503]
Reward: -2.000000, Currnt Bid: 17.169124
Is done? True
Episode End
Positive: 66, Negative: 100
EPISODE :- 341
Random Player utility: 139.718142
=================Random Agent Turn=================
Action taken: 30.455448
===============Feedback to learned agent round===============
Observation:
[0, 0, 30.455448435474334]
Reward: -1.000000, Currnt Bid: 30.455448
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[46.14302947]
Explore action: 46.143029
Action taken: 46.143029
===============Feedback to random agent round===============
Currnt Bid: 46.143029
=================Random Agent Turn=================
Action taken: 134.682366
===============Feedback to learned agent round===============
Observation:
[0, array([46.14302947]), array([134.68236578])]
Reward: -1.000000, Currnt Bid: 134.682366
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[52.3349621]
Explore action: 52.334962
Action taken: 52.334962
===============Feedback to random agent round===============
Currnt Bid: 134.682366
=================Random Agent Turn=================
Action taken: 139.603211
===============Feedback to learned agent round===============
Observation:
[1, array([46.14302947]), array([134.68236578])]
Reward: -2.000000, Currnt Bid: 134.682366
Is done? True
Episode End
Positive: 66, Negative: 100
EPISODE :- 342
Random Player utility: 163.609979
=================Random Agent Turn=================
Action taken: 60.911406
===============Feedback to learned agent round===============
Observation:
[0, 0, 60.91140628399743]
Reward: -1.000000, Currnt Bid: 60.911406
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[68.08686024]
Explore action: 68.086860
Action taken: 68.086860
===============Feedback to random agent round===============
Currnt Bid: 68.086860
=================Random Agent Turn=================
Action taken: 94.718810
===============Feedback to learned agent round===============
Observation:
[0, array([68.08686024]), array([94.71881035])]
Reward: -1.000000, Currnt Bid: 94.718810
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[91.24804275]
Explore action: 91.248043
Action taken: 91.248043
===============Feedback to random agent round===============
Currnt Bid: 94.718810
=================Random Agent Turn=================
Action taken: 106.346958
===============Feedback to learned agent round===============
Observation:
[1, array([68.08686024]), array([94.71881035])]
Reward: -2.000000, Currnt Bid: 94.718810
Is done? True
Episode End
Positive: 66, Negative: 100
EPISODE :- 343
Random Player utility: 52.167623
=================Random Agent Turn=================
Action taken: 27.192847
===============Feedback to learned agent round===============
Observation:
[0, 0, 27.192846967607284]
Reward: -1.000000, Currnt Bid: 27.192847
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[103.47802806]
Explore action: 103.478028
Action taken: 103.478028
===============Feedback to random agent round===============
Currnt Bid: 103.478028
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([103.47802806]), 27.192846967607284]
Reward: -3.478028, Currnt Bid: 103.478028
Is done? True
Episode End
Positive: 66, Negative: 101
EPISODE :- 344
Random Player utility: 122.709092
=================Random Agent Turn=================
Action taken: 64.808405
===============Feedback to learned agent round===============
Observation:
[0, 0, 64.80840547059437]
Reward: -1.000000, Currnt Bid: 64.808405
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[82.63307696]
Explore action: 82.633077
Action taken: 82.633077
===============Feedback to random agent round===============
Currnt Bid: 82.633077
=================Random Agent Turn=================
Action taken: 121.532892
===============Feedback to learned agent round===============
Observation:
[0, array([82.63307696]), array([121.53289228])]
Reward: -1.000000, Currnt Bid: 121.532892
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[89.00479221]
Explore action: 89.004792
Action taken: 89.004792
===============Feedback to random agent round===============
Currnt Bid: 121.532892
=================Random Agent Turn=================
Action taken: 122.112723
===============Feedback to learned agent round===============
Observation:
[1, array([82.63307696]), array([121.53289228])]
Reward: -2.000000, Currnt Bid: 121.532892
Is done? True
Episode End
Positive: 66, Negative: 101
EPISODE :- 345
Random Player utility: 63.655921
=================Random Agent Turn=================
Action taken: 50.320556
===============Feedback to learned agent round===============
Observation:
[0, 0, 50.320556218964576]
Reward: -1.000000, Currnt Bid: 50.320556
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 7.796699
Exploit action: 7.796699
Action taken: 7.796699
===============Feedback to random agent round===============
Currnt Bid: 50.320556
=================Random Agent Turn=================
Action taken: 51.650197
===============Feedback to learned agent round===============
Observation:
[1, 0, 50.320556218964576]
Reward: -2.000000, Currnt Bid: 50.320556
Is done? True
Episode End
Positive: 66, Negative: 102
EPISODE :- 346
Random Player utility: 208.533843
=================Random Agent Turn=================
Action taken: 28.959071
===============Feedback to learned agent round===============
Observation:
[0, 0, 28.9590708449009]
Reward: -1.000000, Currnt Bid: 28.959071
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[97.98805133]
Explore action: 97.988051
Action taken: 97.988051
===============Feedback to random agent round===============
Currnt Bid: 97.988051
=================Random Agent Turn=================
Action taken: 128.049376
===============Feedback to learned agent round===============
Observation:
[0, array([97.98805133]), array([128.04937582])]
Reward: -1.000000, Currnt Bid: 128.049376
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[93.46703832]
Explore action: 93.467038
Action taken: 93.467038
===============Feedback to random agent round===============
Currnt Bid: 128.049376
=================Random Agent Turn=================
Action taken: 167.263122
===============Feedback to learned agent round===============
Observation:
[1, array([97.98805133]), array([128.04937582])]
Reward: -2.000000, Currnt Bid: 128.049376
Is done? True
Episode End
Positive: 66, Negative: 102
EPISODE :- 347
Random Player utility: 58.828584
=================Random Agent Turn=================
Action taken: 14.811095
===============Feedback to learned agent round===============
Observation:
[0, 0, 14.811095111452373]
Reward: -1.000000, Currnt Bid: 14.811095
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[90.16146797]
Explore action: 90.161468
Action taken: 90.161468
===============Feedback to random agent round===============
Currnt Bid: 90.161468
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([90.16146797]), 14.811095111452373]
Reward: 9.838532, Currnt Bid: 90.161468
Is done? True
Episode End
Positive: 67, Negative: 102
EPISODE :- 348
Random Player utility: 118.403896
=================Random Agent Turn=================
Action taken: 117.398113
===============Feedback to learned agent round===============
Observation:
[0, 0, 117.39811288426748]
Reward: -1.000000, Currnt Bid: 117.398113
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[70.65599293]
Explore action: 70.655993
Action taken: 70.655993
===============Feedback to random agent round===============
Currnt Bid: 117.398113
=================Random Agent Turn=================
Action taken: 118.075949
===============Feedback to learned agent round===============
Observation:
[1, 0, 117.39811288426748]
Reward: -2.000000, Currnt Bid: 117.398113
Is done? True
Episode End
Positive: 67, Negative: 102
EPISODE :- 349
Random Player utility: 93.140703
=================Random Agent Turn=================
Action taken: 80.628737
===============Feedback to learned agent round===============
Observation:
[0, 0, 80.62873681286295]
Reward: -1.000000, Currnt Bid: 80.628737
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[81.31438241]
Explore action: 81.314382
Action taken: 81.314382
===============Feedback to random agent round===============
Currnt Bid: 81.314382
=================Random Agent Turn=================
Action taken: 88.750911
===============Feedback to learned agent round===============
Observation:
[0, array([81.31438241]), array([88.75091092])]
Reward: -1.000000, Currnt Bid: 88.750911
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[72.57987181]
Explore action: 72.579872
Action taken: 72.579872
===============Feedback to random agent round===============
Currnt Bid: 88.750911
=================Random Agent Turn=================
Action taken: 91.747106
===============Feedback to learned agent round===============
Observation:
[1, array([81.31438241]), array([88.75091092])]
Reward: -2.000000, Currnt Bid: 88.750911
Is done? True
Episode End
Positive: 67, Negative: 103
EPISODE :- 350
Random Player utility: 131.575308
=================Random Agent Turn=================
Action taken: 118.320649
===============Feedback to learned agent round===============
Observation:
[0, 0, 118.3206485114459]
Reward: -1.000000, Currnt Bid: 118.320649
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 7.182932
Exploit action: 7.182932
Action taken: 7.182932
===============Feedback to random agent round===============
Currnt Bid: 118.320649
=================Random Agent Turn=================
Action taken: 121.329071
===============Feedback to learned agent round===============
Observation:
[1, 0, 118.3206485114459]
Reward: -2.000000, Currnt Bid: 118.320649
Is done? True
Episode End
Positive: 67, Negative: 103
EPISODE :- 351
Random Player utility: 264.464279
=================Random Agent Turn=================
Action taken: 107.163000
===============Feedback to learned agent round===============
Observation:
[0, 0, 107.16300020400256]
Reward: -1.000000, Currnt Bid: 107.163000
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[82.64774172]
Explore action: 82.647742
Action taken: 82.647742
===============Feedback to random agent round===============
Currnt Bid: 107.163000
=================Random Agent Turn=================
Action taken: 148.156801
===============Feedback to learned agent round===============
Observation:
[1, 0, 107.16300020400256]
Reward: -2.000000, Currnt Bid: 107.163000
Is done? True
Episode End
Positive: 67, Negative: 103
EPISODE :- 352
Random Player utility: 69.922092
=================Random Agent Turn=================
Action taken: 21.928688
===============Feedback to learned agent round===============
Observation:
[0, 0, 21.928687731130545]
Reward: -1.000000, Currnt Bid: 21.928688
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[66.69496171]
Explore action: 66.694962
Action taken: 66.694962
===============Feedback to random agent round===============
Currnt Bid: 66.694962
=================Random Agent Turn=================
Action taken: 69.606832
===============Feedback to learned agent round===============
Observation:
[0, array([66.69496171]), array([69.60683223])]
Reward: -1.000000, Currnt Bid: 69.606832
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[41.85924243]
Explore action: 41.859242
Action taken: 41.859242
===============Feedback to random agent round===============
Currnt Bid: 69.606832
=================Random Agent Turn=================
Action taken: 69.898530
===============Feedback to learned agent round===============
Observation:
[1, array([66.69496171]), array([69.60683223])]
Reward: -2.000000, Currnt Bid: 69.606832
Is done? True
Episode End
Positive: 67, Negative: 104
EPISODE :- 353
Random Player utility: 24.330375
=================Random Agent Turn=================
Action taken: 15.685145
===============Feedback to learned agent round===============
Observation:
[0, 0, 15.685145353466243]
Reward: -1.000000, Currnt Bid: 15.685145
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[36.55509102]
Explore action: 36.555091
Action taken: 36.555091
===============Feedback to random agent round===============
Currnt Bid: 36.555091
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([36.55509102]), 15.685145353466243]
Reward: 63.444909, Currnt Bid: 36.555091
Is done? True
Episode End
Positive: 68, Negative: 104
EPISODE :- 354
Random Player utility: 114.757122
=================Random Agent Turn=================
Action taken: 72.055411
===============Feedback to learned agent round===============
Observation:
[0, 0, 72.05541060463557]
Reward: -1.000000, Currnt Bid: 72.055411
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[43.80689411]
Explore action: 43.806894
Action taken: 43.806894
===============Feedback to random agent round===============
Currnt Bid: 72.055411
=================Random Agent Turn=================
Action taken: 73.839157
===============Feedback to learned agent round===============
Observation:
[1, 0, 72.05541060463557]
Reward: -2.000000, Currnt Bid: 72.055411
Is done? True
Episode End
Positive: 68, Negative: 104
EPISODE :- 355
Random Player utility: 28.479710
=================Random Agent Turn=================
Action taken: 9.208592
===============Feedback to learned agent round===============
Observation:
[0, 0, 9.208591741295454]
Reward: -1.000000, Currnt Bid: 9.208592
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 6.657940
Exploit action: 6.657940
Action taken: 6.657940
===============Feedback to random agent round===============
Currnt Bid: 9.208592
=================Random Agent Turn=================
Action taken: 9.605680
===============Feedback to learned agent round===============
Observation:
[1, 0, 9.208591741295454]
Reward: -2.000000, Currnt Bid: 9.208592
Is done? True
Episode End
Positive: 68, Negative: 105
EPISODE :- 356
Random Player utility: 80.786951
=================Random Agent Turn=================
Action taken: 1.174771
===============Feedback to learned agent round===============
Observation:
[0, 0, 1.174770744923149]
Reward: -1.000000, Currnt Bid: 1.174771
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[64.61971285]
Explore action: 64.619713
Action taken: 64.619713
===============Feedback to random agent round===============
Currnt Bid: 64.619713
=================Random Agent Turn=================
Action taken: 77.888592
===============Feedback to learned agent round===============
Observation:
[0, array([64.61971285]), array([77.88859213])]
Reward: -1.000000, Currnt Bid: 77.888592
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[55.79779144]
Explore action: 55.797791
Action taken: 55.797791
===============Feedback to random agent round===============
Currnt Bid: 77.888592
=================Random Agent Turn=================
Action taken: 80.291205
===============Feedback to learned agent round===============
Observation:
[1, array([64.61971285]), array([77.88859213])]
Reward: -2.000000, Currnt Bid: 77.888592
Is done? True
Episode End
Positive: 68, Negative: 106
EPISODE :- 357
Random Player utility: 54.014706
=================Random Agent Turn=================
Action taken: 38.590549
===============Feedback to learned agent round===============
Observation:
[0, 0, 38.590549176158405]
Reward: -1.000000, Currnt Bid: 38.590549
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[54.09590461]
Explore action: 54.095905
Action taken: 54.095905
===============Feedback to random agent round===============
Currnt Bid: 54.095905
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([54.09590461]), 38.590549176158405]
Reward: 45.904095, Currnt Bid: 54.095905
Is done? True
Episode End
Positive: 69, Negative: 106
EPISODE :- 358
Random Player utility: 163.039217
=================Random Agent Turn=================
Action taken: 49.595009
===============Feedback to learned agent round===============
Observation:
[0, 0, 49.595009389239635]
Reward: -1.000000, Currnt Bid: 49.595009
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[65.30587907]
Explore action: 65.305879
Action taken: 65.305879
===============Feedback to random agent round===============
Currnt Bid: 65.305879
=================Random Agent Turn=================
Action taken: 141.886377
===============Feedback to learned agent round===============
Observation:
[0, array([65.30587907]), array([141.88637717])]
Reward: -1.000000, Currnt Bid: 141.886377
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[53.21013079]
Explore action: 53.210131
Action taken: 53.210131
===============Feedback to random agent round===============
Currnt Bid: 141.886377
=================Random Agent Turn=================
Action taken: 152.628244
===============Feedback to learned agent round===============
Observation:
[1, array([65.30587907]), array([141.88637717])]
Reward: -2.000000, Currnt Bid: 141.886377
Is done? True
Episode End
Positive: 69, Negative: 106
EPISODE :- 359
Random Player utility: 84.924228
=================Random Agent Turn=================
Action taken: 20.130387
===============Feedback to learned agent round===============
Observation:
[0, 0, 20.13038653978274]
Reward: -1.000000, Currnt Bid: 20.130387
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[51.40275133]
Explore action: 51.402751
Action taken: 51.402751
===============Feedback to random agent round===============
Currnt Bid: 51.402751
=================Random Agent Turn=================
Action taken: 63.682542
===============Feedback to learned agent round===============
Observation:
[0, array([51.40275133]), array([63.68254229])]
Reward: -1.000000, Currnt Bid: 63.682542
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[45.74567254]
Explore action: 45.745673
Action taken: 45.745673
===============Feedback to random agent round===============
Currnt Bid: 63.682542
=================Random Agent Turn=================
Action taken: 64.414334
===============Feedback to learned agent round===============
Observation:
[1, array([51.40275133]), array([63.68254229])]
Reward: -2.000000, Currnt Bid: 63.682542
Is done? True
Episode End
Positive: 69, Negative: 107
EPISODE :- 360
Random Player utility: 39.066843
=================Random Agent Turn=================
Action taken: 14.678528
===============Feedback to learned agent round===============
Observation:
[0, 0, 14.67852787944036]
Reward: -1.000000, Currnt Bid: 14.678528
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 6.081491
Exploit action: 6.081491
Action taken: 6.081491
===============Feedback to random agent round===============
Currnt Bid: 14.678528
=================Random Agent Turn=================
Action taken: 28.749847
===============Feedback to learned agent round===============
Observation:
[1, 0, 14.67852787944036]
Reward: -2.000000, Currnt Bid: 14.678528
Is done? True
Episode End
Positive: 69, Negative: 108
EPISODE :- 361
Random Player utility: 79.565982
=================Random Agent Turn=================
Action taken: 8.856590
===============Feedback to learned agent round===============
Observation:
[0, 0, 8.856590222445387]
Reward: -1.000000, Currnt Bid: 8.856590
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[36.81725658]
Explore action: 36.817257
Action taken: 36.817257
===============Feedback to random agent round===============
Currnt Bid: 36.817257
=================Random Agent Turn=================
Action taken: 48.285907
===============Feedback to learned agent round===============
Observation:
[0, array([36.81725658]), array([48.28590712])]
Reward: -1.000000, Currnt Bid: 48.285907
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[43.94743725]
Explore action: 43.947437
Action taken: 43.947437
===============Feedback to random agent round===============
Currnt Bid: 48.285907
=================Random Agent Turn=================
Action taken: 78.763500
===============Feedback to learned agent round===============
Observation:
[1, array([36.81725658]), array([48.28590712])]
Reward: -2.000000, Currnt Bid: 48.285907
Is done? True
Episode End
Positive: 69, Negative: 109
EPISODE :- 362
Random Player utility: 100.446299
=================Random Agent Turn=================
Action taken: 13.091355
===============Feedback to learned agent round===============
Observation:
[0, 0, 13.091354723837371]
Reward: -1.000000, Currnt Bid: 13.091355
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[44.8571616]
Explore action: 44.857162
Action taken: 44.857162
===============Feedback to random agent round===============
Currnt Bid: 44.857162
=================Random Agent Turn=================
Action taken: 92.933817
===============Feedback to learned agent round===============
Observation:
[0, array([44.8571616]), array([92.93381744])]
Reward: -1.000000, Currnt Bid: 92.933817
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[54.29353823]
Explore action: 54.293538
Action taken: 54.293538
===============Feedback to random agent round===============
Currnt Bid: 92.933817
=================Random Agent Turn=================
Action taken: 98.496051
===============Feedback to learned agent round===============
Observation:
[1, array([44.8571616]), array([92.93381744])]
Reward: -2.000000, Currnt Bid: 92.933817
Is done? True
Episode End
Positive: 69, Negative: 109
EPISODE :- 363
Random Player utility: 8.768484
=================Random Agent Turn=================
Action taken: 6.970916
===============Feedback to learned agent round===============
Observation:
[0, 0, 6.970915695318581]
Reward: -1.000000, Currnt Bid: 6.970916
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[71.82909917]
Explore action: 71.829099
Action taken: 71.829099
===============Feedback to random agent round===============
Currnt Bid: 71.829099
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([71.82909917]), 6.970915695318581]
Reward: 28.170901, Currnt Bid: 71.829099
Is done? True
Episode End
Positive: 70, Negative: 109
EPISODE :- 364
Random Player utility: 31.709368
=================Random Agent Turn=================
Action taken: 2.667346
===============Feedback to learned agent round===============
Observation:
[0, 0, 2.6673463882258677]
Reward: -1.000000, Currnt Bid: 2.667346
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[91.86112662]
Explore action: 91.861127
Action taken: 91.861127
===============Feedback to random agent round===============
Currnt Bid: 91.861127
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([91.86112662]), 2.6673463882258677]
Reward: 8.138873, Currnt Bid: 91.861127
Is done? True
Episode End
Positive: 71, Negative: 109
EPISODE :- 365
Random Player utility: 41.357481
=================Random Agent Turn=================
Action taken: 34.047933
===============Feedback to learned agent round===============
Observation:
[0, 0, 34.04793311818121]
Reward: -1.000000, Currnt Bid: 34.047933
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 5.589384
Exploit action: 5.589384
Action taken: 5.589384
===============Feedback to random agent round===============
Currnt Bid: 34.047933
=================Random Agent Turn=================
Action taken: 38.114682
===============Feedback to learned agent round===============
Observation:
[1, 0, 34.04793311818121]
Reward: -2.000000, Currnt Bid: 34.047933
Is done? True
Episode End
Positive: 71, Negative: 110
EPISODE :- 366
Random Player utility: 184.899688
=================Random Agent Turn=================
Action taken: 86.896762
===============Feedback to learned agent round===============
Observation:
[0, 0, 86.89676218761826]
Reward: -1.000000, Currnt Bid: 86.896762
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[84.96271182]
Explore action: 84.962712
Action taken: 84.962712
===============Feedback to random agent round===============
Currnt Bid: 86.896762
=================Random Agent Turn=================
Action taken: 136.596669
===============Feedback to learned agent round===============
Observation:
[1, 0, 86.89676218761826]
Reward: -2.000000, Currnt Bid: 86.896762
Is done? True
Episode End
Positive: 71, Negative: 110
EPISODE :- 367
Random Player utility: 106.559583
=================Random Agent Turn=================
Action taken: 69.725447
===============Feedback to learned agent round===============
Observation:
[0, 0, 69.72544680611657]
Reward: -1.000000, Currnt Bid: 69.725447
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[86.8992484]
Explore action: 86.899248
Action taken: 86.899248
===============Feedback to random agent round===============
Currnt Bid: 86.899248
=================Random Agent Turn=================
Action taken: 91.355662
===============Feedback to learned agent round===============
Observation:
[0, array([86.8992484]), array([91.35566234])]
Reward: -1.000000, Currnt Bid: 91.355662
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[84.60389277]
Explore action: 84.603893
Action taken: 84.603893
===============Feedback to random agent round===============
Currnt Bid: 91.355662
=================Random Agent Turn=================
Action taken: 102.031878
===============Feedback to learned agent round===============
Observation:
[1, array([86.8992484]), array([91.35566234])]
Reward: -2.000000, Currnt Bid: 91.355662
Is done? True
Episode End
Positive: 71, Negative: 110
EPISODE :- 368
Random Player utility: 185.911058
=================Random Agent Turn=================
Action taken: 138.068520
===============Feedback to learned agent round===============
Observation:
[0, 0, 138.06852031866464]
Reward: -1.000000, Currnt Bid: 138.068520
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[68.2097818]
Explore action: 68.209782
Action taken: 68.209782
===============Feedback to random agent round===============
Currnt Bid: 138.068520
=================Random Agent Turn=================
Action taken: 143.219326
===============Feedback to learned agent round===============
Observation:
[1, 0, 138.06852031866464]
Reward: -2.000000, Currnt Bid: 138.068520
Is done? True
Episode End
Positive: 71, Negative: 110
EPISODE :- 369
Random Player utility: 139.208705
=================Random Agent Turn=================
Action taken: 131.597488
===============Feedback to learned agent round===============
Observation:
[0, 0, 131.59748755975846]
Reward: -1.000000, Currnt Bid: 131.597488
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[69.44121655]
Explore action: 69.441217
Action taken: 69.441217
===============Feedback to random agent round===============
Currnt Bid: 131.597488
=================Random Agent Turn=================
Action taken: 132.106494
===============Feedback to learned agent round===============
Observation:
[1, 0, 131.59748755975846]
Reward: -2.000000, Currnt Bid: 131.597488
Is done? True
Episode End
Positive: 71, Negative: 110
EPISODE :- 370
Random Player utility: 0.825911
=================Random Agent Turn=================
Action taken: 0.281392
===============Feedback to learned agent round===============
Observation:
[0, 0, 0.2813924429212877]
Reward: -1.000000, Currnt Bid: 0.281392
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 5.170095
Exploit action: 5.170095
Action taken: 5.170095
===============Feedback to random agent round===============
Currnt Bid: 5.170095
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([5.170095], dtype=float32), 0.2813924429212877]
Reward: 94.829903, Currnt Bid: 5.170095
Is done? True
Episode End
Positive: 72, Negative: 110
EPISODE :- 371
Random Player utility: 133.728234
=================Random Agent Turn=================
Action taken: 118.197582
===============Feedback to learned agent round===============
Observation:
[0, 0, 118.19758167903927]
Reward: -1.000000, Currnt Bid: 118.197582
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[56.4313055]
Explore action: 56.431305
Action taken: 56.431305
===============Feedback to random agent round===============
Currnt Bid: 118.197582
=================Random Agent Turn=================
Action taken: 124.104441
===============Feedback to learned agent round===============
Observation:
[1, 0, 118.19758167903927]
Reward: -2.000000, Currnt Bid: 118.197582
Is done? True
Episode End
Positive: 72, Negative: 110
EPISODE :- 372
Random Player utility: 34.106373
=================Random Agent Turn=================
Action taken: 12.636964
===============Feedback to learned agent round===============
Observation:
[0, 0, 12.636963815248366]
Reward: -1.000000, Currnt Bid: 12.636964
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[41.47769692]
Explore action: 41.477697
Action taken: 41.477697
===============Feedback to random agent round===============
Currnt Bid: 41.477697
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([41.47769692]), 12.636963815248366]
Reward: 58.522303, Currnt Bid: 41.477697
Is done? True
Episode End
Positive: 73, Negative: 110
EPISODE :- 373
Random Player utility: 57.806830
=================Random Agent Turn=================
Action taken: 52.149199
===============Feedback to learned agent round===============
Observation:
[0, 0, 52.14919907924336]
Reward: -1.000000, Currnt Bid: 52.149199
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[50.28073788]
Explore action: 50.280738
Action taken: 50.280738
===============Feedback to random agent round===============
Currnt Bid: 52.149199
=================Random Agent Turn=================
Action taken: 55.270393
===============Feedback to learned agent round===============
Observation:
[1, 0, 52.14919907924336]
Reward: -2.000000, Currnt Bid: 52.149199
Is done? True
Episode End
Positive: 73, Negative: 111
EPISODE :- 374
Random Player utility: 53.176634
=================Random Agent Turn=================
Action taken: 13.859710
===============Feedback to learned agent round===============
Observation:
[0, 0, 13.859709552170933]
Reward: -1.000000, Currnt Bid: 13.859710
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[41.87536927]
Explore action: 41.875369
Action taken: 41.875369
===============Feedback to random agent round===============
Currnt Bid: 41.875369
=================Random Agent Turn=================
Action taken: 48.613654
===============Feedback to learned agent round===============
Observation:
[0, array([41.87536927]), array([48.61365439])]
Reward: -1.000000, Currnt Bid: 48.613654
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[56.13876237]
Explore action: 56.138762
Action taken: 56.138762
===============Feedback to random agent round===============
Currnt Bid: 56.138762
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([56.13876237]), array([48.61365439])]
Reward: 43.861238, Currnt Bid: 56.138762
Is done? True
Episode End
Positive: 74, Negative: 111
EPISODE :- 375
Random Player utility: 210.614581
=================Random Agent Turn=================
Action taken: 124.190555
===============Feedback to learned agent round===============
Observation:
[0, 0, 124.19055464391455]
Reward: -1.000000, Currnt Bid: 124.190555
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 4.779553
Exploit action: 4.779553
Action taken: 4.779553
===============Feedback to random agent round===============
Currnt Bid: 124.190555
=================Random Agent Turn=================
Action taken: 150.738712
===============Feedback to learned agent round===============
Observation:
[1, 0, 124.19055464391455]
Reward: -2.000000, Currnt Bid: 124.190555
Is done? True
Episode End
Positive: 74, Negative: 111
EPISODE :- 376
Random Player utility: 128.920789
=================Random Agent Turn=================
Action taken: 12.799592
===============Feedback to learned agent round===============
Observation:
[0, 0, 12.799592072714276]
Reward: -1.000000, Currnt Bid: 12.799592
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[67.60895404]
Explore action: 67.608954
Action taken: 67.608954
===============Feedback to random agent round===============
Currnt Bid: 67.608954
=================Random Agent Turn=================
Action taken: 107.369124
===============Feedback to learned agent round===============
Observation:
[0, array([67.60895404]), array([107.36912362])]
Reward: -1.000000, Currnt Bid: 107.369124
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[62.6225401]
Explore action: 62.622540
Action taken: 62.622540
===============Feedback to random agent round===============
Currnt Bid: 107.369124
=================Random Agent Turn=================
Action taken: 118.065025
===============Feedback to learned agent round===============
Observation:
[1, array([67.60895404]), array([107.36912362])]
Reward: -2.000000, Currnt Bid: 107.369124
Is done? True
Episode End
Positive: 74, Negative: 111
EPISODE :- 377
Random Player utility: 101.962741
=================Random Agent Turn=================
Action taken: 84.506767
===============Feedback to learned agent round===============
Observation:
[0, 0, 84.50676749711907]
Reward: -1.000000, Currnt Bid: 84.506767
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[64.61576482]
Explore action: 64.615765
Action taken: 64.615765
===============Feedback to random agent round===============
Currnt Bid: 84.506767
=================Random Agent Turn=================
Action taken: 97.807571
===============Feedback to learned agent round===============
Observation:
[1, 0, 84.50676749711907]
Reward: -2.000000, Currnt Bid: 84.506767
Is done? True
Episode End
Positive: 74, Negative: 111
EPISODE :- 378
Random Player utility: 52.633942
=================Random Agent Turn=================
Action taken: 32.727114
===============Feedback to learned agent round===============
Observation:
[0, 0, 32.72711374526457]
Reward: -1.000000, Currnt Bid: 32.727114
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[65.3451257]
Explore action: 65.345126
Action taken: 65.345126
===============Feedback to random agent round===============
Currnt Bid: 65.345126
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([65.3451257]), 32.72711374526457]
Reward: 34.654874, Currnt Bid: 65.345126
Is done? True
Episode End
Positive: 75, Negative: 111
EPISODE :- 379
Random Player utility: 106.128212
=================Random Agent Turn=================
Action taken: 96.136116
===============Feedback to learned agent round===============
Observation:
[0, 0, 96.13611574018891]
Reward: -1.000000, Currnt Bid: 96.136116
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[53.78333376]
Explore action: 53.783334
Action taken: 53.783334
===============Feedback to random agent round===============
Currnt Bid: 96.136116
=================Random Agent Turn=================
Action taken: 101.875740
===============Feedback to learned agent round===============
Observation:
[1, 0, 96.13611574018891]
Reward: -2.000000, Currnt Bid: 96.136116
Is done? True
Episode End
Positive: 75, Negative: 111
EPISODE :- 380
Random Player utility: 143.878608
=================Random Agent Turn=================
Action taken: 72.130868
===============Feedback to learned agent round===============
Observation:
[0, 0, 72.13086777859921]
Reward: -1.000000, Currnt Bid: 72.130868
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 4.416138
Exploit action: 4.416138
Action taken: 4.416138
===============Feedback to random agent round===============
Currnt Bid: 72.130868
=================Random Agent Turn=================
Action taken: 115.092727
===============Feedback to learned agent round===============
Observation:
[1, 0, 72.13086777859921]
Reward: -2.000000, Currnt Bid: 72.130868
Is done? True
Episode End
Positive: 75, Negative: 111
EPISODE :- 381
Random Player utility: 148.945585
=================Random Agent Turn=================
Action taken: 2.908325
===============Feedback to learned agent round===============
Observation:
[0, 0, 2.9083251736858724]
Reward: -1.000000, Currnt Bid: 2.908325
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[57.06136739]
Explore action: 57.061367
Action taken: 57.061367
===============Feedback to random agent round===============
Currnt Bid: 57.061367
=================Random Agent Turn=================
Action taken: 75.180516
===============Feedback to learned agent round===============
Observation:
[0, array([57.06136739]), array([75.18051634])]
Reward: -1.000000, Currnt Bid: 75.180516
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[56.49937283]
Explore action: 56.499373
Action taken: 56.499373
===============Feedback to random agent round===============
Currnt Bid: 75.180516
=================Random Agent Turn=================
Action taken: 124.792047
===============Feedback to learned agent round===============
Observation:
[1, array([57.06136739]), array([75.18051634])]
Reward: -2.000000, Currnt Bid: 75.180516
Is done? True
Episode End
Positive: 75, Negative: 111
EPISODE :- 382
Random Player utility: 101.122696
=================Random Agent Turn=================
Action taken: 79.130245
===============Feedback to learned agent round===============
Observation:
[0, 0, 79.13024539973442]
Reward: -1.000000, Currnt Bid: 79.130245
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[50.71529334]
Explore action: 50.715293
Action taken: 50.715293
===============Feedback to random agent round===============
Currnt Bid: 79.130245
=================Random Agent Turn=================
Action taken: 91.430901
===============Feedback to learned agent round===============
Observation:
[1, 0, 79.13024539973442]
Reward: -2.000000, Currnt Bid: 79.130245
Is done? True
Episode End
Positive: 75, Negative: 111
EPISODE :- 383
Random Player utility: 111.757451
=================Random Agent Turn=================
Action taken: 87.188416
===============Feedback to learned agent round===============
Observation:
[0, 0, 87.18841642249916]
Reward: -1.000000, Currnt Bid: 87.188416
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[36.21132007]
Explore action: 36.211320
Action taken: 36.211320
===============Feedback to random agent round===============
Currnt Bid: 87.188416
=================Random Agent Turn=================
Action taken: 103.797264
===============Feedback to learned agent round===============
Observation:
[1, 0, 87.18841642249916]
Reward: -2.000000, Currnt Bid: 87.188416
Is done? True
Episode End
Positive: 75, Negative: 111
EPISODE :- 384
Random Player utility: 185.912905
=================Random Agent Turn=================
Action taken: 14.700314
===============Feedback to learned agent round===============
Observation:
[0, 0, 14.700313510842864]
Reward: -1.000000, Currnt Bid: 14.700314
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[26.7239499]
Explore action: 26.723950
Action taken: 26.723950
===============Feedback to random agent round===============
Currnt Bid: 26.723950
=================Random Agent Turn=================
Action taken: 92.848273
===============Feedback to learned agent round===============
Observation:
[0, array([26.7239499]), array([92.84827333])]
Reward: -1.000000, Currnt Bid: 92.848273
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[39.59597337]
Explore action: 39.595973
Action taken: 39.595973
===============Feedback to random agent round===============
Currnt Bid: 92.848273
=================Random Agent Turn=================
Action taken: 152.539656
===============Feedback to learned agent round===============
Observation:
[1, array([26.7239499]), array([92.84827333])]
Reward: -2.000000, Currnt Bid: 92.848273
Is done? True
Episode End
Positive: 75, Negative: 111
EPISODE :- 385
Random Player utility: 163.879518
=================Random Agent Turn=================
Action taken: 85.018996
===============Feedback to learned agent round===============
Observation:
[0, 0, 85.01899602567042]
Reward: -1.000000, Currnt Bid: 85.018996
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 4.048789
Exploit action: 4.048789
Action taken: 4.048789
===============Feedback to random agent round===============
Currnt Bid: 85.018996
=================Random Agent Turn=================
Action taken: 97.136880
===============Feedback to learned agent round===============
Observation:
[1, 0, 85.01899602567042]
Reward: -2.000000, Currnt Bid: 85.018996
Is done? True
Episode End
Positive: 75, Negative: 111
EPISODE :- 386
Random Player utility: 220.414425
=================Random Agent Turn=================
Action taken: 162.445416
===============Feedback to learned agent round===============
Observation:
[0, 0, 162.44541609389134]
Reward: -1.000000, Currnt Bid: 162.445416
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[38.87367568]
Explore action: 38.873676
Action taken: 38.873676
===============Feedback to random agent round===============
Currnt Bid: 162.445416
=================Random Agent Turn=================
Action taken: 201.504889
===============Feedback to learned agent round===============
Observation:
[1, 0, 162.44541609389134]
Reward: -2.000000, Currnt Bid: 162.445416
Is done? True
Episode End
Positive: 75, Negative: 111
EPISODE :- 387
Random Player utility: 39.063873
=================Random Agent Turn=================
Action taken: 10.990899
===============Feedback to learned agent round===============
Observation:
[0, 0, 10.990899337106402]
Reward: -1.000000, Currnt Bid: 10.990899
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[52.7368401]
Explore action: 52.736840
Action taken: 52.736840
===============Feedback to random agent round===============
Currnt Bid: 52.736840
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([52.7368401]), 10.990899337106402]
Reward: 47.263160, Currnt Bid: 52.736840
Is done? True
Episode End
Positive: 76, Negative: 111
EPISODE :- 388
Random Player utility: 148.147593
=================Random Agent Turn=================
Action taken: 80.428305
===============Feedback to learned agent round===============
Observation:
[0, 0, 80.42830523158636]
Reward: -1.000000, Currnt Bid: 80.428305
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[65.61379241]
Explore action: 65.613792
Action taken: 65.613792
===============Feedback to random agent round===============
Currnt Bid: 80.428305
=================Random Agent Turn=================
Action taken: 108.902430
===============Feedback to learned agent round===============
Observation:
[1, 0, 80.42830523158636]
Reward: -2.000000, Currnt Bid: 80.428305
Is done? True
Episode End
Positive: 76, Negative: 111
EPISODE :- 389
Random Player utility: 9.157297
=================Random Agent Turn=================
Action taken: 9.120590
===============Feedback to learned agent round===============
Observation:
[0, 0, 9.120589704707324]
Reward: -1.000000, Currnt Bid: 9.120590
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[76.37199081]
Explore action: 76.371991
Action taken: 76.371991
===============Feedback to random agent round===============
Currnt Bid: 76.371991
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([76.37199081]), 9.120589704707324]
Reward: 23.628009, Currnt Bid: 76.371991
Is done? True
Episode End
Positive: 77, Negative: 111
EPISODE :- 390
Random Player utility: 51.897940
=================Random Agent Turn=================
Action taken: 3.099799
===============Feedback to learned agent round===============
Observation:
[0, 0, 3.0997992421286136]
Reward: -1.000000, Currnt Bid: 3.099799
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 3.764480
Exploit action: 3.764480
Action taken: 3.764480
===============Feedback to random agent round===============
Currnt Bid: 3.764480
=================Random Agent Turn=================
Action taken: 32.509628
===============Feedback to learned agent round===============
Observation:
[0, array([3.7644804], dtype=float32), array([32.50963], dtype=float32)]
Reward: -1.000000, Currnt Bid: 32.509628
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 2.681720
Exploit action: 2.681720
Action taken: 2.681720
===============Feedback to random agent round===============
Currnt Bid: 32.509628
=================Random Agent Turn=================
Action taken: 39.076294
===============Feedback to learned agent round===============
Observation:
[1, array([3.7644804], dtype=float32), array([32.50963], dtype=float32)]
Reward: -2.000000, Currnt Bid: 32.509628
Is done? True
Episode End
Positive: 77, Negative: 112
EPISODE :- 391
Random Player utility: 132.213160
=================Random Agent Turn=================
Action taken: 37.482857
===============Feedback to learned agent round===============
Observation:
[0, 0, 37.48285693378425]
Reward: -1.000000, Currnt Bid: 37.482857
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[73.12617546]
Explore action: 73.126175
Action taken: 73.126175
===============Feedback to random agent round===============
Currnt Bid: 73.126175
=================Random Agent Turn=================
Action taken: 89.939288
===============Feedback to learned agent round===============
Observation:
[0, array([73.12617546]), array([89.93928836])]
Reward: -1.000000, Currnt Bid: 89.939288
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[70.9198701]
Explore action: 70.919870
Action taken: 70.919870
===============Feedback to random agent round===============
Currnt Bid: 89.939288
=================Random Agent Turn=================
Action taken: 92.145950
===============Feedback to learned agent round===============
Observation:
[1, array([73.12617546]), array([89.93928836])]
Reward: -2.000000, Currnt Bid: 89.939288
Is done? True
Episode End
Positive: 77, Negative: 112
EPISODE :- 392
Random Player utility: 106.732566
=================Random Agent Turn=================
Action taken: 88.910647
===============Feedback to learned agent round===============
Observation:
[0, 0, 88.9106474482923]
Reward: -1.000000, Currnt Bid: 88.910647
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[68.22973164]
Explore action: 68.229732
Action taken: 68.229732
===============Feedback to random agent round===============
Currnt Bid: 88.910647
=================Random Agent Turn=================
Action taken: 105.288158
===============Feedback to learned agent round===============
Observation:
[1, 0, 88.9106474482923]
Reward: -2.000000, Currnt Bid: 88.910647
Is done? True
Episode End
Positive: 77, Negative: 112
EPISODE :- 393
Random Player utility: 79.261979
=================Random Agent Turn=================
Action taken: 72.914463
===============Feedback to learned agent round===============
Observation:
[0, 0, 72.91446264432199]
Reward: -1.000000, Currnt Bid: 72.914463
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[52.27884741]
Explore action: 52.278847
Action taken: 52.278847
===============Feedback to random agent round===============
Currnt Bid: 72.914463
=================Random Agent Turn=================
Action taken: 74.430490
===============Feedback to learned agent round===============
Observation:
[1, 0, 72.91446264432199]
Reward: -2.000000, Currnt Bid: 72.914463
Is done? True
Episode End
Positive: 77, Negative: 113
EPISODE :- 394
Random Player utility: 109.331346
=================Random Agent Turn=================
Action taken: 52.512956
===============Feedback to learned agent round===============
Observation:
[0, 0, 52.51295642361915]
Reward: -1.000000, Currnt Bid: 52.512956
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[37.07472387]
Explore action: 37.074724
Action taken: 37.074724
===============Feedback to random agent round===============
Currnt Bid: 52.512956
=================Random Agent Turn=================
Action taken: 79.421826
===============Feedback to learned agent round===============
Observation:
[1, 0, 52.51295642361915]
Reward: -2.000000, Currnt Bid: 52.512956
Is done? True
Episode End
Positive: 77, Negative: 113
EPISODE :- 395
Random Player utility: 114.361737
=================Random Agent Turn=================
Action taken: 67.150061
===============Feedback to learned agent round===============
Observation:
[0, 0, 67.15006076009614]
Reward: -1.000000, Currnt Bid: 67.150061
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 3.447860
Exploit action: 3.447860
Action taken: 3.447860
===============Feedback to random agent round===============
Currnt Bid: 67.150061
=================Random Agent Turn=================
Action taken: 112.074177
===============Feedback to learned agent round===============
Observation:
[1, 0, 67.15006076009614]
Reward: -2.000000, Currnt Bid: 67.150061
Is done? True
Episode End
Positive: 77, Negative: 113
EPISODE :- 396
Random Player utility: 207.946661
=================Random Agent Turn=================
Action taken: 175.966763
===============Feedback to learned agent round===============
Observation:
[0, 0, 175.96676290239407]
Reward: -1.000000, Currnt Bid: 175.966763
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[43.53508717]
Explore action: 43.535087
Action taken: 43.535087
===============Feedback to random agent round===============
Currnt Bid: 175.966763
=================Random Agent Turn=================
Action taken: 186.775921
===============Feedback to learned agent round===============
Observation:
[1, 0, 175.96676290239407]
Reward: -2.000000, Currnt Bid: 175.966763
Is done? True
Episode End
Positive: 77, Negative: 113
EPISODE :- 397
Random Player utility: 59.031706
=================Random Agent Turn=================
Action taken: 30.799838
===============Feedback to learned agent round===============
Observation:
[0, 0, 30.799838103174274]
Reward: -1.000000, Currnt Bid: 30.799838
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[35.12894998]
Explore action: 35.128950
Action taken: 35.128950
===============Feedback to random agent round===============
Currnt Bid: 35.128950
=================Random Agent Turn=================
Action taken: 45.715226
===============Feedback to learned agent round===============
Observation:
[0, array([35.12894998]), array([45.71522647])]
Reward: -1.000000, Currnt Bid: 45.715226
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[24.58949921]
Explore action: 24.589499
Action taken: 24.589499
===============Feedback to random agent round===============
Currnt Bid: 45.715226
=================Random Agent Turn=================
Action taken: 51.443474
===============Feedback to learned agent round===============
Observation:
[1, array([35.12894998]), array([45.71522647])]
Reward: -2.000000, Currnt Bid: 45.715226
Is done? True
Episode End
Positive: 77, Negative: 114
EPISODE :- 398
Random Player utility: 72.897031
=================Random Agent Turn=================
Action taken: 7.332948
===============Feedback to learned agent round===============
Observation:
[0, 0, 7.3329475443872685]
Reward: -1.000000, Currnt Bid: 7.332948
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[10.96376352]
Explore action: 10.963764
Action taken: 10.963764
===============Feedback to random agent round===============
Currnt Bid: 10.963764
=================Random Agent Turn=================
Action taken: 36.889443
===============Feedback to learned agent round===============
Observation:
[0, array([10.96376352]), array([36.8894425])]
Reward: -1.000000, Currnt Bid: 36.889443
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[10.79629952]
Explore action: 10.796300
Action taken: 10.796300
===============Feedback to random agent round===============
Currnt Bid: 36.889443
=================Random Agent Turn=================
Action taken: 72.272617
===============Feedback to learned agent round===============
Observation:
[1, array([10.96376352]), array([36.8894425])]
Reward: -2.000000, Currnt Bid: 36.889443
Is done? True
Episode End
Positive: 77, Negative: 115
EPISODE :- 399
Random Player utility: 171.176702
=================Random Agent Turn=================
Action taken: 123.483317
===============Feedback to learned agent round===============
Observation:
[0, 0, 123.48331685401935]
Reward: -1.000000, Currnt Bid: 123.483317
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[12.91900792]
Explore action: 12.919008
Action taken: 12.919008
===============Feedback to random agent round===============
Currnt Bid: 123.483317
=================Random Agent Turn=================
Action taken: 124.865948
===============Feedback to learned agent round===============
Observation:
[1, 0, 123.48331685401935]
Reward: -2.000000, Currnt Bid: 123.483317
Is done? True
Episode End
Positive: 77, Negative: 115
EPISODE :- 400
Random Player utility: 180.291858
=================Random Agent Turn=================
Action taken: 7.709026
===============Feedback to learned agent round===============
Observation:
[0, 0, 7.709026029636473]
Reward: -1.000000, Currnt Bid: 7.709026
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 3.156292
Exploit action: 3.156292
Action taken: 3.156292
===============Feedback to random agent round===============
Currnt Bid: 7.709026
=================Random Agent Turn=================
Action taken: 113.586828
===============Feedback to learned agent round===============
Observation:
[1, 0, 7.709026029636473]
Reward: -2.000000, Currnt Bid: 7.709026
Is done? True
Episode End
Positive: 77, Negative: 115
Models saved successfully
EPISODE :- 401
Random Player utility: 159.535981
=================Random Agent Turn=================
Action taken: 73.769490
===============Feedback to learned agent round===============
Observation:
[0, 0, 73.76948962792328]
Reward: -1.000000, Currnt Bid: 73.769490
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[17.09199806]
Explore action: 17.091998
Action taken: 17.091998
===============Feedback to random agent round===============
Currnt Bid: 73.769490
=================Random Agent Turn=================
Action taken: 137.633874
===============Feedback to learned agent round===============
Observation:
[1, 0, 73.76948962792328]
Reward: -2.000000, Currnt Bid: 73.769490
Is done? True
Episode End
Positive: 77, Negative: 115
EPISODE :- 402
Random Player utility: 40.518874
=================Random Agent Turn=================
Action taken: 1.811051
===============Feedback to learned agent round===============
Observation:
[0, 0, 1.8110508796850338]
Reward: -1.000000, Currnt Bid: 1.811051
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[18.76728969]
Explore action: 18.767290
Action taken: 18.767290
===============Feedback to random agent round===============
Currnt Bid: 18.767290
=================Random Agent Turn=================
Action taken: 31.404330
===============Feedback to learned agent round===============
Observation:
[0, array([18.76728969]), array([31.40433002])]
Reward: -1.000000, Currnt Bid: 31.404330
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[14.20855372]
Explore action: 14.208554
Action taken: 14.208554
===============Feedback to random agent round===============
Currnt Bid: 31.404330
=================Random Agent Turn=================
Action taken: 34.795781
===============Feedback to learned agent round===============
Observation:
[1, array([18.76728969]), array([31.40433002])]
Reward: -2.000000, Currnt Bid: 31.404330
Is done? True
Episode End
Positive: 77, Negative: 116
EPISODE :- 403
Random Player utility: 135.367070
=================Random Agent Turn=================
Action taken: 58.099340
===============Feedback to learned agent round===============
Observation:
[0, 0, 58.09933974014873]
Reward: -1.000000, Currnt Bid: 58.099340
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[39.87238346]
Explore action: 39.872383
Action taken: 39.872383
===============Feedback to random agent round===============
Currnt Bid: 58.099340
=================Random Agent Turn=================
Action taken: 63.087861
===============Feedback to learned agent round===============
Observation:
[1, 0, 58.09933974014873]
Reward: -2.000000, Currnt Bid: 58.099340
Is done? True
Episode End
Positive: 77, Negative: 116
EPISODE :- 404
Random Player utility: 136.197315
=================Random Agent Turn=================
Action taken: 92.232583
===============Feedback to learned agent round===============
Observation:
[0, 0, 92.23258272882914]
Reward: -1.000000, Currnt Bid: 92.232583
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[12.87031921]
Explore action: 12.870319
Action taken: 12.870319
===============Feedback to random agent round===============
Currnt Bid: 92.232583
=================Random Agent Turn=================
Action taken: 134.000025
===============Feedback to learned agent round===============
Observation:
[1, 0, 92.23258272882914]
Reward: -2.000000, Currnt Bid: 92.232583
Is done? True
Episode End
Positive: 77, Negative: 116
EPISODE :- 405
Random Player utility: 127.150334
=================Random Agent Turn=================
Action taken: 1.775432
===============Feedback to learned agent round===============
Observation:
[0, 0, 1.7754324388668274]
Reward: -1.000000, Currnt Bid: 1.775432
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 2.909553
Exploit action: 2.909553
Action taken: 2.909553
===============Feedback to random agent round===============
Currnt Bid: 2.909553
=================Random Agent Turn=================
Action taken: 116.094101
===============Feedback to learned agent round===============
Observation:
[0, array([2.909553], dtype=float32), array([116.0941], dtype=float32)]
Reward: -1.000000, Currnt Bid: 116.094101
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 2.366990
Exploit action: 2.366990
Action taken: 2.366990
===============Feedback to random agent round===============
Currnt Bid: 116.094101
=================Random Agent Turn=================
Action taken: 121.192070
===============Feedback to learned agent round===============
Observation:
[1, array([2.909553], dtype=float32), array([116.0941], dtype=float32)]
Reward: -2.000000, Currnt Bid: 116.094101
Is done? True
Episode End
Positive: 77, Negative: 116
EPISODE :- 406
Random Player utility: 169.037629
=================Random Agent Turn=================
Action taken: 102.543042
===============Feedback to learned agent round===============
Observation:
[0, 0, 102.54304161940563]
Reward: -1.000000, Currnt Bid: 102.543042
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[24.7595219]
Explore action: 24.759522
Action taken: 24.759522
===============Feedback to random agent round===============
Currnt Bid: 102.543042
=================Random Agent Turn=================
Action taken: 132.861635
===============Feedback to learned agent round===============
Observation:
[1, 0, 102.54304161940563]
Reward: -2.000000, Currnt Bid: 102.543042
Is done? True
Episode End
Positive: 77, Negative: 116
EPISODE :- 407
Random Player utility: 8.690562
=================Random Agent Turn=================
Action taken: 3.554631
===============Feedback to learned agent round===============
Observation:
[0, 0, 3.5546314587068917]
Reward: -1.000000, Currnt Bid: 3.554631
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[27.60722538]
Explore action: 27.607225
Action taken: 27.607225
===============Feedback to random agent round===============
Currnt Bid: 27.607225
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([27.60722538]), 3.5546314587068917]
Reward: 72.392775, Currnt Bid: 27.607225
Is done? True
Episode End
Positive: 78, Negative: 116
EPISODE :- 408
Random Player utility: 48.958647
=================Random Agent Turn=================
Action taken: 44.527346
===============Feedback to learned agent round===============
Observation:
[0, 0, 44.52734570893987]
Reward: -1.000000, Currnt Bid: 44.527346
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[24.13493019]
Explore action: 24.134930
Action taken: 24.134930
===============Feedback to random agent round===============
Currnt Bid: 44.527346
=================Random Agent Turn=================
Action taken: 48.097075
===============Feedback to learned agent round===============
Observation:
[1, 0, 44.52734570893987]
Reward: -2.000000, Currnt Bid: 44.527346
Is done? True
Episode End
Positive: 78, Negative: 117
EPISODE :- 409
Random Player utility: 61.978610
=================Random Agent Turn=================
Action taken: 9.550439
===============Feedback to learned agent round===============
Observation:
[0, 0, 9.55043851791907]
Reward: -1.000000, Currnt Bid: 9.550439
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[14.43857633]
Explore action: 14.438576
Action taken: 14.438576
===============Feedback to random agent round===============
Currnt Bid: 14.438576
=================Random Agent Turn=================
Action taken: 30.939781
===============Feedback to learned agent round===============
Observation:
[0, array([14.43857633]), array([30.93978074])]
Reward: -1.000000, Currnt Bid: 30.939781
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[6.13434234]
Explore action: 6.134342
Action taken: 6.134342
===============Feedback to random agent round===============
Currnt Bid: 30.939781
=================Random Agent Turn=================
Action taken: 48.336227
===============Feedback to learned agent round===============
Observation:
[1, array([14.43857633]), array([30.93978074])]
Reward: -2.000000, Currnt Bid: 30.939781
Is done? True
Episode End
Positive: 78, Negative: 118
EPISODE :- 410
Random Player utility: 147.173668
=================Random Agent Turn=================
Action taken: 37.195819
===============Feedback to learned agent round===============
Observation:
[0, 0, 37.195818951661586]
Reward: -1.000000, Currnt Bid: 37.195819
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 2.661228
Exploit action: 2.661228
Action taken: 2.661228
===============Feedback to random agent round===============
Currnt Bid: 37.195819
=================Random Agent Turn=================
Action taken: 49.309208
===============Feedback to learned agent round===============
Observation:
[1, 0, 37.195818951661586]
Reward: -2.000000, Currnt Bid: 37.195819
Is done? True
Episode End
Positive: 78, Negative: 118
EPISODE :- 411
Random Player utility: 143.835563
=================Random Agent Turn=================
Action taken: 42.186767
===============Feedback to learned agent round===============
Observation:
[0, 0, 42.18676675953946]
Reward: -1.000000, Currnt Bid: 42.186767
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[13.91814362]
Explore action: 13.918144
Action taken: 13.918144
===============Feedback to random agent round===============
Currnt Bid: 42.186767
=================Random Agent Turn=================
Action taken: 56.255619
===============Feedback to learned agent round===============
Observation:
[1, 0, 42.18676675953946]
Reward: -2.000000, Currnt Bid: 42.186767
Is done? True
Episode End
Positive: 78, Negative: 118
EPISODE :- 412
Random Player utility: 165.239718
=================Random Agent Turn=================
Action taken: 33.829186
===============Feedback to learned agent round===============
Observation:
[0, 0, 33.82918623836474]
Reward: -1.000000, Currnt Bid: 33.829186
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[24.91915602]
Explore action: 24.919156
Action taken: 24.919156
===============Feedback to random agent round===============
Currnt Bid: 33.829186
=================Random Agent Turn=================
Action taken: 98.123801
===============Feedback to learned agent round===============
Observation:
[1, 0, 33.82918623836474]
Reward: -2.000000, Currnt Bid: 33.829186
Is done? True
Episode End
Positive: 78, Negative: 118
EPISODE :- 413
Random Player utility: 141.945462
=================Random Agent Turn=================
Action taken: 95.488124
===============Feedback to learned agent round===============
Observation:
[0, 0, 95.48812393748018]
Reward: -1.000000, Currnt Bid: 95.488124
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[32.25147937]
Explore action: 32.251479
Action taken: 32.251479
===============Feedback to random agent round===============
Currnt Bid: 95.488124
=================Random Agent Turn=================
Action taken: 122.089936
===============Feedback to learned agent round===============
Observation:
[1, 0, 95.48812393748018]
Reward: -2.000000, Currnt Bid: 95.488124
Is done? True
Episode End
Positive: 78, Negative: 118
EPISODE :- 414
Random Player utility: 107.707596
=================Random Agent Turn=================
Action taken: 17.273139
===============Feedback to learned agent round===============
Observation:
[0, 0, 17.2731385886534]
Reward: -1.000000, Currnt Bid: 17.273139
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[46.98710786]
Explore action: 46.987108
Action taken: 46.987108
===============Feedback to random agent round===============
Currnt Bid: 46.987108
=================Random Agent Turn=================
Action taken: 98.269433
===============Feedback to learned agent round===============
Observation:
[0, array([46.98710786]), array([98.26943342])]
Reward: -1.000000, Currnt Bid: 98.269433
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[43.24731097]
Explore action: 43.247311
Action taken: 43.247311
===============Feedback to random agent round===============
Currnt Bid: 98.269433
=================Random Agent Turn=================
Action taken: 104.169872
===============Feedback to learned agent round===============
Observation:
[1, array([46.98710786]), array([98.26943342])]
Reward: -2.000000, Currnt Bid: 98.269433
Is done? True
Episode End
Positive: 78, Negative: 118
EPISODE :- 415
Random Player utility: 90.592019
=================Random Agent Turn=================
Action taken: 21.258999
===============Feedback to learned agent round===============
Observation:
[0, 0, 21.25899878394351]
Reward: -1.000000, Currnt Bid: 21.258999
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 2.451402
Exploit action: 2.451402
Action taken: 2.451402
===============Feedback to random agent round===============
Currnt Bid: 21.258999
=================Random Agent Turn=================
Action taken: 47.265288
===============Feedback to learned agent round===============
Observation:
[1, 0, 21.25899878394351]
Reward: -2.000000, Currnt Bid: 21.258999
Is done? True
Episode End
Positive: 78, Negative: 119
EPISODE :- 416
Random Player utility: 118.350545
=================Random Agent Turn=================
Action taken: 101.419396
===============Feedback to learned agent round===============
Observation:
[0, 0, 101.4193960058716]
Reward: -1.000000, Currnt Bid: 101.419396
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[38.42119754]
Explore action: 38.421198
Action taken: 38.421198
===============Feedback to random agent round===============
Currnt Bid: 101.419396
=================Random Agent Turn=================
Action taken: 107.190611
===============Feedback to learned agent round===============
Observation:
[1, 0, 101.4193960058716]
Reward: -2.000000, Currnt Bid: 101.419396
Is done? True
Episode End
Positive: 78, Negative: 119
EPISODE :- 417
Random Player utility: 66.090424
=================Random Agent Turn=================
Action taken: 40.972630
===============Feedback to learned agent round===============
Observation:
[0, 0, 40.97262985583948]
Reward: -1.000000, Currnt Bid: 40.972630
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[24.04356514]
Explore action: 24.043565
Action taken: 24.043565
===============Feedback to random agent round===============
Currnt Bid: 40.972630
=================Random Agent Turn=================
Action taken: 52.499989
===============Feedback to learned agent round===============
Observation:
[1, 0, 40.97262985583948]
Reward: -2.000000, Currnt Bid: 40.972630
Is done? True
Episode End
Positive: 78, Negative: 120
EPISODE :- 418
Random Player utility: 122.914100
=================Random Agent Turn=================
Action taken: 36.968535
===============Feedback to learned agent round===============
Observation:
[0, 0, 36.96853521726081]
Reward: -1.000000, Currnt Bid: 36.968535
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[39.28286916]
Explore action: 39.282869
Action taken: 39.282869
===============Feedback to random agent round===============
Currnt Bid: 39.282869
=================Random Agent Turn=================
Action taken: 91.878720
===============Feedback to learned agent round===============
Observation:
[0, array([39.28286916]), array([91.87871988])]
Reward: -1.000000, Currnt Bid: 91.878720
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[53.06728675]
Explore action: 53.067287
Action taken: 53.067287
===============Feedback to random agent round===============
Currnt Bid: 91.878720
=================Random Agent Turn=================
Action taken: 101.455752
===============Feedback to learned agent round===============
Observation:
[1, array([39.28286916]), array([91.87871988])]
Reward: -2.000000, Currnt Bid: 91.878720
Is done? True
Episode End
Positive: 78, Negative: 120
EPISODE :- 419
Random Player utility: 123.951207
=================Random Agent Turn=================
Action taken: 102.844847
===============Feedback to learned agent round===============
Observation:
[0, 0, 102.84484709418044]
Reward: -1.000000, Currnt Bid: 102.844847
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[53.59173043]
Explore action: 53.591730
Action taken: 53.591730
===============Feedback to random agent round===============
Currnt Bid: 102.844847
=================Random Agent Turn=================
Action taken: 121.522107
===============Feedback to learned agent round===============
Observation:
[1, 0, 102.84484709418044]
Reward: -2.000000, Currnt Bid: 102.844847
Is done? True
Episode End
Positive: 78, Negative: 120
EPISODE :- 420
Random Player utility: 94.720946
=================Random Agent Turn=================
Action taken: 9.890712
===============Feedback to learned agent round===============
Observation:
[0, 0, 9.890712000099619]
Reward: -1.000000, Currnt Bid: 9.890712
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 2.257419
Exploit action: 2.257419
Action taken: 2.257419
===============Feedback to random agent round===============
Currnt Bid: 9.890712
=================Random Agent Turn=================
Action taken: 18.928326
===============Feedback to learned agent round===============
Observation:
[1, 0, 9.890712000099619]
Reward: -2.000000, Currnt Bid: 9.890712
Is done? True
Episode End
Positive: 78, Negative: 121
EPISODE :- 421
Random Player utility: 134.441061
=================Random Agent Turn=================
Action taken: 77.747177
===============Feedback to learned agent round===============
Observation:
[0, 0, 77.7471772247212]
Reward: -1.000000, Currnt Bid: 77.747177
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[55.11230182]
Explore action: 55.112302
Action taken: 55.112302
===============Feedback to random agent round===============
Currnt Bid: 77.747177
=================Random Agent Turn=================
Action taken: 97.850538
===============Feedback to learned agent round===============
Observation:
[1, 0, 77.7471772247212]
Reward: -2.000000, Currnt Bid: 77.747177
Is done? True
Episode End
Positive: 78, Negative: 121
EPISODE :- 422
Random Player utility: 191.435142
=================Random Agent Turn=================
Action taken: 143.401193
===============Feedback to learned agent round===============
Observation:
[0, 0, 143.40119295581863]
Reward: -1.000000, Currnt Bid: 143.401193
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[62.56134812]
Explore action: 62.561348
Action taken: 62.561348
===============Feedback to random agent round===============
Currnt Bid: 143.401193
=================Random Agent Turn=================
Action taken: 181.757480
===============Feedback to learned agent round===============
Observation:
[1, 0, 143.40119295581863]
Reward: -2.000000, Currnt Bid: 143.401193
Is done? True
Episode End
Positive: 78, Negative: 121
EPISODE :- 423
Random Player utility: 197.529462
=================Random Agent Turn=================
Action taken: 74.037695
===============Feedback to learned agent round===============
Observation:
[0, 0, 74.0376945993662]
Reward: -1.000000, Currnt Bid: 74.037695
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[42.45345972]
Explore action: 42.453460
Action taken: 42.453460
===============Feedback to random agent round===============
Currnt Bid: 74.037695
=================Random Agent Turn=================
Action taken: 132.912414
===============Feedback to learned agent round===============
Observation:
[1, 0, 74.0376945993662]
Reward: -2.000000, Currnt Bid: 74.037695
Is done? True
Episode End
Positive: 78, Negative: 121
EPISODE :- 424
Random Player utility: 82.867397
=================Random Agent Turn=================
Action taken: 48.953597
===============Feedback to learned agent round===============
Observation:
[0, 0, 48.953597356552756]
Reward: -1.000000, Currnt Bid: 48.953597
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[32.39128263]
Explore action: 32.391283
Action taken: 32.391283
===============Feedback to random agent round===============
Currnt Bid: 48.953597
=================Random Agent Turn=================
Action taken: 59.402318
===============Feedback to learned agent round===============
Observation:
[1, 0, 48.953597356552756]
Reward: -2.000000, Currnt Bid: 48.953597
Is done? True
Episode End
Positive: 78, Negative: 122
EPISODE :- 425
Random Player utility: 124.521605
=================Random Agent Turn=================
Action taken: 24.767024
===============Feedback to learned agent round===============
Observation:
[0, 0, 24.767024098985978]
Reward: -1.000000, Currnt Bid: 24.767024
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 2.093911
Exploit action: 2.093911
Action taken: 2.093911
===============Feedback to random agent round===============
Currnt Bid: 24.767024
=================Random Agent Turn=================
Action taken: 98.014838
===============Feedback to learned agent round===============
Observation:
[1, 0, 24.767024098985978]
Reward: -2.000000, Currnt Bid: 24.767024
Is done? True
Episode End
Positive: 78, Negative: 122
EPISODE :- 426
Random Player utility: 173.760093
=================Random Agent Turn=================
Action taken: 42.773183
===============Feedback to learned agent round===============
Observation:
[0, 0, 42.77318269849027]
Reward: -1.000000, Currnt Bid: 42.773183
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[22.60161018]
Explore action: 22.601610
Action taken: 22.601610
===============Feedback to random agent round===============
Currnt Bid: 42.773183
=================Random Agent Turn=================
Action taken: 164.536916
===============Feedback to learned agent round===============
Observation:
[1, 0, 42.77318269849027]
Reward: -2.000000, Currnt Bid: 42.773183
Is done? True
Episode End
Positive: 78, Negative: 122
EPISODE :- 427
Random Player utility: 54.695094
=================Random Agent Turn=================
Action taken: 27.486174
===============Feedback to learned agent round===============
Observation:
[0, 0, 27.486173526290667]
Reward: -1.000000, Currnt Bid: 27.486174
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[11.80194894]
Explore action: 11.801949
Action taken: 11.801949
===============Feedback to random agent round===============
Currnt Bid: 27.486174
=================Random Agent Turn=================
Action taken: 30.394918
===============Feedback to learned agent round===============
Observation:
[1, 0, 27.486173526290667]
Reward: -2.000000, Currnt Bid: 27.486174
Is done? True
Episode End
Positive: 78, Negative: 123
EPISODE :- 428
Random Player utility: 41.458986
=================Random Agent Turn=================
Action taken: 15.588815
===============Feedback to learned agent round===============
Observation:
[0, 0, 15.58881542729084]
Reward: -1.000000, Currnt Bid: 15.588815
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[12.76236851]
Explore action: 12.762369
Action taken: 12.762369
===============Feedback to random agent round===============
Currnt Bid: 15.588815
=================Random Agent Turn=================
Action taken: 16.058604
===============Feedback to learned agent round===============
Observation:
[1, 0, 15.58881542729084]
Reward: -2.000000, Currnt Bid: 15.588815
Is done? True
Episode End
Positive: 78, Negative: 124
EPISODE :- 429
Random Player utility: 127.394690
=================Random Agent Turn=================
Action taken: 41.629120
===============Feedback to learned agent round===============
Observation:
[0, 0, 41.62912040929419]
Reward: -1.000000, Currnt Bid: 41.629120
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[26.60439725]
Explore action: 26.604397
Action taken: 26.604397
===============Feedback to random agent round===============
Currnt Bid: 41.629120
=================Random Agent Turn=================
Action taken: 48.048514
===============Feedback to learned agent round===============
Observation:
[1, 0, 41.62912040929419]
Reward: -2.000000, Currnt Bid: 41.629120
Is done? True
Episode End
Positive: 78, Negative: 124
EPISODE :- 430
Random Player utility: 82.400708
=================Random Agent Turn=================
Action taken: 38.424259
===============Feedback to learned agent round===============
Observation:
[0, 0, 38.42425888412215]
Reward: -1.000000, Currnt Bid: 38.424259
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 1.941824
Exploit action: 1.941824
Action taken: 1.941824
===============Feedback to random agent round===============
Currnt Bid: 38.424259
=================Random Agent Turn=================
Action taken: 78.880207
===============Feedback to learned agent round===============
Observation:
[1, 0, 38.42425888412215]
Reward: -2.000000, Currnt Bid: 38.424259
Is done? True
Episode End
Positive: 78, Negative: 125
EPISODE :- 431
Random Player utility: 141.153980
=================Random Agent Turn=================
Action taken: 22.834966
===============Feedback to learned agent round===============
Observation:
[0, 0, 22.834965909099868]
Reward: -1.000000, Currnt Bid: 22.834966
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[15.82625013]
Explore action: 15.826250
Action taken: 15.826250
===============Feedback to random agent round===============
Currnt Bid: 22.834966
=================Random Agent Turn=================
Action taken: 23.240951
===============Feedback to learned agent round===============
Observation:
[1, 0, 22.834965909099868]
Reward: -2.000000, Currnt Bid: 22.834966
Is done? True
Episode End
Positive: 78, Negative: 125
EPISODE :- 432
Random Player utility: 16.064182
=================Random Agent Turn=================
Action taken: 11.254997
===============Feedback to learned agent round===============
Observation:
[0, 0, 11.254997481364638]
Reward: -1.000000, Currnt Bid: 11.254997
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[19.02034329]
Explore action: 19.020343
Action taken: 19.020343
===============Feedback to random agent round===============
Currnt Bid: 19.020343
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([19.02034329]), 11.254997481364638]
Reward: 80.979657, Currnt Bid: 19.020343
Is done? True
Episode End
Positive: 79, Negative: 125
EPISODE :- 433
Random Player utility: 163.346208
=================Random Agent Turn=================
Action taken: 137.827996
===============Feedback to learned agent round===============
Observation:
[0, 0, 137.82799578054073]
Reward: -1.000000, Currnt Bid: 137.827996
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[29.68427994]
Explore action: 29.684280
Action taken: 29.684280
===============Feedback to random agent round===============
Currnt Bid: 137.827996
=================Random Agent Turn=================
Action taken: 148.048125
===============Feedback to learned agent round===============
Observation:
[1, 0, 137.82799578054073]
Reward: -2.000000, Currnt Bid: 137.827996
Is done? True
Episode End
Positive: 79, Negative: 125
EPISODE :- 434
Random Player utility: 22.926897
=================Random Agent Turn=================
Action taken: 4.936176
===============Feedback to learned agent round===============
Observation:
[0, 0, 4.936176226933076]
Reward: -1.000000, Currnt Bid: 4.936176
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[42.86903582]
Explore action: 42.869036
Action taken: 42.869036
===============Feedback to random agent round===============
Currnt Bid: 42.869036
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([42.86903582]), 4.936176226933076]
Reward: 57.130964, Currnt Bid: 42.869036
Is done? True
Episode End
Positive: 80, Negative: 125
EPISODE :- 435
Random Player utility: 121.037175
=================Random Agent Turn=================
Action taken: 7.083396
===============Feedback to learned agent round===============
Observation:
[0, 0, 7.083395893000123]
Reward: -1.000000, Currnt Bid: 7.083396
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 1.800424
Exploit action: 1.800424
Action taken: 1.800424
===============Feedback to random agent round===============
Currnt Bid: 7.083396
=================Random Agent Turn=================
Action taken: 82.883435
===============Feedback to learned agent round===============
Observation:
[1, 0, 7.083395893000123]
Reward: -2.000000, Currnt Bid: 7.083396
Is done? True
Episode End
Positive: 80, Negative: 125
EPISODE :- 436
Random Player utility: 91.898403
=================Random Agent Turn=================
Action taken: 60.248152
===============Feedback to learned agent round===============
Observation:
[0, 0, 60.24815173783103]
Reward: -1.000000, Currnt Bid: 60.248152
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[39.11506382]
Explore action: 39.115064
Action taken: 39.115064
===============Feedback to random agent round===============
Currnt Bid: 60.248152
=================Random Agent Turn=================
Action taken: 83.524916
===============Feedback to learned agent round===============
Observation:
[1, 0, 60.24815173783103]
Reward: -2.000000, Currnt Bid: 60.248152
Is done? True
Episode End
Positive: 80, Negative: 126
EPISODE :- 437
Random Player utility: 137.092707
=================Random Agent Turn=================
Action taken: 17.493950
===============Feedback to learned agent round===============
Observation:
[0, 0, 17.493949582641655]
Reward: -1.000000, Currnt Bid: 17.493950
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[30.91606458]
Explore action: 30.916065
Action taken: 30.916065
===============Feedback to random agent round===============
Currnt Bid: 30.916065
=================Random Agent Turn=================
Action taken: 135.297898
===============Feedback to learned agent round===============
Observation:
[0, array([30.91606458]), array([135.29789795])]
Reward: -1.000000, Currnt Bid: 135.297898
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[39.72003028]
Explore action: 39.720030
Action taken: 39.720030
===============Feedback to random agent round===============
Currnt Bid: 135.297898
=================Random Agent Turn=================
Action taken: 135.467605
===============Feedback to learned agent round===============
Observation:
[1, array([30.91606458]), array([135.29789795])]
Reward: -2.000000, Currnt Bid: 135.297898
Is done? True
Episode End
Positive: 80, Negative: 126
EPISODE :- 438
Random Player utility: 45.205762
=================Random Agent Turn=================
Action taken: 0.304140
===============Feedback to learned agent round===============
Observation:
[0, 0, 0.30414043033871707]
Reward: -1.000000, Currnt Bid: 0.304140
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[38.50086272]
Explore action: 38.500863
Action taken: 38.500863
===============Feedback to random agent round===============
Currnt Bid: 38.500863
=================Random Agent Turn=================
Action taken: 41.519958
===============Feedback to learned agent round===============
Observation:
[0, array([38.50086272]), array([41.51995831])]
Reward: -1.000000, Currnt Bid: 41.519958
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[53.64400785]
Explore action: 53.644008
Action taken: 53.644008
===============Feedback to random agent round===============
Currnt Bid: 53.644008
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([53.64400785]), array([41.51995831])]
Reward: 46.355992, Currnt Bid: 53.644008
Is done? True
Episode End
Positive: 81, Negative: 126
EPISODE :- 439
Random Player utility: 139.767398
=================Random Agent Turn=================
Action taken: 2.240267
===============Feedback to learned agent round===============
Observation:
[0, 0, 2.2402672257221306]
Reward: -1.000000, Currnt Bid: 2.240267
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[51.2160994]
Explore action: 51.216099
Action taken: 51.216099
===============Feedback to random agent round===============
Currnt Bid: 51.216099
=================Random Agent Turn=================
Action taken: 95.597149
===============Feedback to learned agent round===============
Observation:
[0, array([51.2160994]), array([95.5971493])]
Reward: -1.000000, Currnt Bid: 95.597149
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[42.61887083]
Explore action: 42.618871
Action taken: 42.618871
===============Feedback to random agent round===============
Currnt Bid: 95.597149
=================Random Agent Turn=================
Action taken: 136.865420
===============Feedback to learned agent round===============
Observation:
[1, array([51.2160994]), array([95.5971493])]
Reward: -2.000000, Currnt Bid: 95.597149
Is done? True
Episode End
Positive: 81, Negative: 126
EPISODE :- 440
Random Player utility: 18.661468
=================Random Agent Turn=================
Action taken: 4.757869
===============Feedback to learned agent round===============
Observation:
[0, 0, 4.757868848688814]
Reward: -1.000000, Currnt Bid: 4.757869
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 1.631439
Exploit action: 1.631439
Action taken: 1.631439
===============Feedback to random agent round===============
Currnt Bid: 4.757869
=================Random Agent Turn=================
Action taken: 16.406141
===============Feedback to learned agent round===============
Observation:
[1, 0, 4.757868848688814]
Reward: -2.000000, Currnt Bid: 4.757869
Is done? True
Episode End
Positive: 81, Negative: 127
EPISODE :- 441
Random Player utility: 65.112331
=================Random Agent Turn=================
Action taken: 3.416556
===============Feedback to learned agent round===============
Observation:
[0, 0, 3.4165558327075356]
Reward: -1.000000, Currnt Bid: 3.416556
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[43.7869488]
Explore action: 43.786949
Action taken: 43.786949
===============Feedback to random agent round===============
Currnt Bid: 43.786949
=================Random Agent Turn=================
Action taken: 56.506701
===============Feedback to learned agent round===============
Observation:
[0, array([43.7869488]), array([56.50670086])]
Reward: -1.000000, Currnt Bid: 56.506701
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.74019243]
Explore action: 48.740192
Action taken: 48.740192
===============Feedback to random agent round===============
Currnt Bid: 56.506701
=================Random Agent Turn=================
Action taken: 64.099727
===============Feedback to learned agent round===============
Observation:
[1, array([43.7869488]), array([56.50670086])]
Reward: -2.000000, Currnt Bid: 56.506701
Is done? True
Episode End
Positive: 81, Negative: 128
EPISODE :- 442
Random Player utility: 27.436422
=================Random Agent Turn=================
Action taken: 22.614008
===============Feedback to learned agent round===============
Observation:
[0, 0, 22.614008278218495]
Reward: -1.000000, Currnt Bid: 22.614008
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[54.8320448]
Explore action: 54.832045
Action taken: 54.832045
===============Feedback to random agent round===============
Currnt Bid: 54.832045
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([54.8320448]), 22.614008278218495]
Reward: 45.167955, Currnt Bid: 54.832045
Is done? True
Episode End
Positive: 82, Negative: 128
EPISODE :- 443
Random Player utility: 87.966997
=================Random Agent Turn=================
Action taken: 3.684974
===============Feedback to learned agent round===============
Observation:
[0, 0, 3.684973859628807]
Reward: -1.000000, Currnt Bid: 3.684974
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[57.90607444]
Explore action: 57.906074
Action taken: 57.906074
===============Feedback to random agent round===============
Currnt Bid: 57.906074
=================Random Agent Turn=================
Action taken: 59.529677
===============Feedback to learned agent round===============
Observation:
[0, array([57.90607444]), array([59.52967673])]
Reward: -1.000000, Currnt Bid: 59.529677
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[59.00693295]
Explore action: 59.006933
Action taken: 59.006933
===============Feedback to random agent round===============
Currnt Bid: 59.529677
=================Random Agent Turn=================
Action taken: 69.029197
===============Feedback to learned agent round===============
Observation:
[1, array([57.90607444]), array([59.52967673])]
Reward: -2.000000, Currnt Bid: 59.529677
Is done? True
Episode End
Positive: 82, Negative: 129
EPISODE :- 444
Random Player utility: 177.493981
=================Random Agent Turn=================
Action taken: 38.203365
===============Feedback to learned agent round===============
Observation:
[0, 0, 38.20336471269989]
Reward: -1.000000, Currnt Bid: 38.203365
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[49.70148088]
Explore action: 49.701481
Action taken: 49.701481
===============Feedback to random agent round===============
Currnt Bid: 49.701481
=================Random Agent Turn=================
Action taken: 51.743403
===============Feedback to learned agent round===============
Observation:
[0, array([49.70148088]), array([51.74340281])]
Reward: -1.000000, Currnt Bid: 51.743403
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.85151753]
Explore action: 48.851518
Action taken: 48.851518
===============Feedback to random agent round===============
Currnt Bid: 51.743403
=================Random Agent Turn=================
Action taken: 138.934416
===============Feedback to learned agent round===============
Observation:
[1, array([49.70148088]), array([51.74340281])]
Reward: -2.000000, Currnt Bid: 51.743403
Is done? True
Episode End
Positive: 82, Negative: 129
EPISODE :- 445
Random Player utility: 11.817222
=================Random Agent Turn=================
Action taken: 3.996596
===============Feedback to learned agent round===============
Observation:
[0, 0, 3.9965964288127855]
Reward: -1.000000, Currnt Bid: 3.996596
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 1.477915
Exploit action: 1.477915
Action taken: 1.477915
===============Feedback to random agent round===============
Currnt Bid: 3.996596
=================Random Agent Turn=================
Action taken: 7.355616
===============Feedback to learned agent round===============
Observation:
[1, 0, 3.9965964288127855]
Reward: -2.000000, Currnt Bid: 3.996596
Is done? True
Episode End
Positive: 82, Negative: 130
EPISODE :- 446
Random Player utility: 113.422645
=================Random Agent Turn=================
Action taken: 0.797753
===============Feedback to learned agent round===============
Observation:
[0, 0, 0.7977526421252571]
Reward: -1.000000, Currnt Bid: 0.797753
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[33.95260008]
Explore action: 33.952600
Action taken: 33.952600
===============Feedback to random agent round===============
Currnt Bid: 33.952600
=================Random Agent Turn=================
Action taken: 70.366535
===============Feedback to learned agent round===============
Observation:
[0, array([33.95260008]), array([70.36653465])]
Reward: -1.000000, Currnt Bid: 70.366535
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[36.01047618]
Explore action: 36.010476
Action taken: 36.010476
===============Feedback to random agent round===============
Currnt Bid: 70.366535
=================Random Agent Turn=================
Action taken: 82.488389
===============Feedback to learned agent round===============
Observation:
[1, array([33.95260008]), array([70.36653465])]
Reward: -2.000000, Currnt Bid: 70.366535
Is done? True
Episode End
Positive: 82, Negative: 130
EPISODE :- 447
Random Player utility: 169.859541
=================Random Agent Turn=================
Action taken: 141.493619
===============Feedback to learned agent round===============
Observation:
[0, 0, 141.49361935129122]
Reward: -1.000000, Currnt Bid: 141.493619
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[37.25489934]
Explore action: 37.254899
Action taken: 37.254899
===============Feedback to random agent round===============
Currnt Bid: 141.493619
=================Random Agent Turn=================
Action taken: 166.282924
===============Feedback to learned agent round===============
Observation:
[1, 0, 141.49361935129122]
Reward: -2.000000, Currnt Bid: 141.493619
Is done? True
Episode End
Positive: 82, Negative: 130
EPISODE :- 448
Random Player utility: 87.046688
=================Random Agent Turn=================
Action taken: 54.250567
===============Feedback to learned agent round===============
Observation:
[0, 0, 54.25056677741061]
Reward: -1.000000, Currnt Bid: 54.250567
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[39.90749941]
Explore action: 39.907499
Action taken: 39.907499
===============Feedback to random agent round===============
Currnt Bid: 54.250567
=================Random Agent Turn=================
Action taken: 77.525622
===============Feedback to learned agent round===============
Observation:
[1, 0, 54.25056677741061]
Reward: -2.000000, Currnt Bid: 54.250567
Is done? True
Episode End
Positive: 82, Negative: 131
EPISODE :- 449
Random Player utility: 133.229143
=================Random Agent Turn=================
Action taken: 45.920280
===============Feedback to learned agent round===============
Observation:
[0, 0, 45.92027952575363]
Reward: -1.000000, Currnt Bid: 45.920280
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[54.18758089]
Explore action: 54.187581
Action taken: 54.187581
===============Feedback to random agent round===============
Currnt Bid: 54.187581
=================Random Agent Turn=================
Action taken: 105.720101
===============Feedback to learned agent round===============
Observation:
[0, array([54.18758089]), array([105.72010118])]
Reward: -1.000000, Currnt Bid: 105.720101
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[52.99614411]
Explore action: 52.996144
Action taken: 52.996144
===============Feedback to random agent round===============
Currnt Bid: 105.720101
=================Random Agent Turn=================
Action taken: 129.898386
===============Feedback to learned agent round===============
Observation:
[1, array([54.18758089]), array([105.72010118])]
Reward: -2.000000, Currnt Bid: 105.720101
Is done? True
Episode End
Positive: 82, Negative: 131
EPISODE :- 450
Random Player utility: 119.712229
=================Random Agent Turn=================
Action taken: 28.746136
===============Feedback to learned agent round===============
Observation:
[0, 0, 28.746136265018514]
Reward: -1.000000, Currnt Bid: 28.746136
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 1.348776
Exploit action: 1.348776
Action taken: 1.348776
===============Feedback to random agent round===============
Currnt Bid: 28.746136
=================Random Agent Turn=================
Action taken: 95.967221
===============Feedback to learned agent round===============
Observation:
[1, 0, 28.746136265018514]
Reward: -2.000000, Currnt Bid: 28.746136
Is done? True
Episode End
Positive: 82, Negative: 131
EPISODE :- 451
Random Player utility: 124.049279
=================Random Agent Turn=================
Action taken: 91.234546
===============Feedback to learned agent round===============
Observation:
[0, 0, 91.23454578925845]
Reward: -1.000000, Currnt Bid: 91.234546
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[57.02841792]
Explore action: 57.028418
Action taken: 57.028418
===============Feedback to random agent round===============
Currnt Bid: 91.234546
=================Random Agent Turn=================
Action taken: 93.404206
===============Feedback to learned agent round===============
Observation:
[1, 0, 91.23454578925845]
Reward: -2.000000, Currnt Bid: 91.234546
Is done? True
Episode End
Positive: 82, Negative: 131
EPISODE :- 452
Random Player utility: 71.650964
=================Random Agent Turn=================
Action taken: 35.097373
===============Feedback to learned agent round===============
Observation:
[0, 0, 35.09737309658814]
Reward: -1.000000, Currnt Bid: 35.097373
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[49.92590251]
Explore action: 49.925903
Action taken: 49.925903
===============Feedback to random agent round===============
Currnt Bid: 49.925903
=================Random Agent Turn=================
Action taken: 63.788434
===============Feedback to learned agent round===============
Observation:
[0, array([49.92590251]), array([63.78843415])]
Reward: -1.000000, Currnt Bid: 63.788434
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.547097]
Explore action: 48.547097
Action taken: 48.547097
===============Feedback to random agent round===============
Currnt Bid: 63.788434
=================Random Agent Turn=================
Action taken: 70.202892
===============Feedback to learned agent round===============
Observation:
[1, array([49.92590251]), array([63.78843415])]
Reward: -2.000000, Currnt Bid: 63.788434
Is done? True
Episode End
Positive: 82, Negative: 132
EPISODE :- 453
Random Player utility: 136.521475
=================Random Agent Turn=================
Action taken: 47.700075
===============Feedback to learned agent round===============
Observation:
[0, 0, 47.70007467865104]
Reward: -1.000000, Currnt Bid: 47.700075
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.28682431]
Explore action: 48.286824
Action taken: 48.286824
===============Feedback to random agent round===============
Currnt Bid: 48.286824
=================Random Agent Turn=================
Action taken: 54.048014
===============Feedback to learned agent round===============
Observation:
[0, array([48.28682431]), array([54.048014])]
Reward: -1.000000, Currnt Bid: 54.048014
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[54.63068909]
Explore action: 54.630689
Action taken: 54.630689
===============Feedback to random agent round===============
Currnt Bid: 54.630689
=================Random Agent Turn=================
Action taken: 114.439579
===============Feedback to learned agent round===============
Observation:
[0, array([54.63068909]), array([114.43957928])]
Reward: -1.000000, Currnt Bid: 114.439579
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[56.22416827]
Explore action: 56.224168
Action taken: 56.224168
===============Feedback to random agent round===============
Currnt Bid: 114.439579
=================Random Agent Turn=================
Action taken: 118.541453
===============Feedback to learned agent round===============
Observation:
[1, array([54.63068909]), array([114.43957928])]
Reward: -2.000000, Currnt Bid: 114.439579
Is done? True
Episode End
Positive: 82, Negative: 132
EPISODE :- 454
Random Player utility: 122.278168
=================Random Agent Turn=================
Action taken: 77.051370
===============Feedback to learned agent round===============
Observation:
[0, 0, 77.05136964784143]
Reward: -1.000000, Currnt Bid: 77.051370
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[59.8532434]
Explore action: 59.853243
Action taken: 59.853243
===============Feedback to random agent round===============
Currnt Bid: 77.051370
=================Random Agent Turn=================
Action taken: 100.727186
===============Feedback to learned agent round===============
Observation:
[1, 0, 77.05136964784143]
Reward: -2.000000, Currnt Bid: 77.051370
Is done? True
Episode End
Positive: 82, Negative: 132
EPISODE :- 455
Random Player utility: 157.963897
=================Random Agent Turn=================
Action taken: 109.933284
===============Feedback to learned agent round===============
Observation:
[0, 0, 109.93328369326449]
Reward: -1.000000, Currnt Bid: 109.933284
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 1.221335
Exploit action: 1.221335
Action taken: 1.221335
===============Feedback to random agent round===============
Currnt Bid: 109.933284
=================Random Agent Turn=================
Action taken: 138.781657
===============Feedback to learned agent round===============
Observation:
[1, 0, 109.93328369326449]
Reward: -2.000000, Currnt Bid: 109.933284
Is done? True
Episode End
Positive: 82, Negative: 132
EPISODE :- 456
Random Player utility: 3.920953
=================Random Agent Turn=================
Action taken: 1.261588
===============Feedback to learned agent round===============
Observation:
[0, 0, 1.2615880137931024]
Reward: -1.000000, Currnt Bid: 1.261588
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[57.05300536]
Explore action: 57.053005
Action taken: 57.053005
===============Feedback to random agent round===============
Currnt Bid: 57.053005
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([57.05300536]), 1.2615880137931024]
Reward: 42.946995, Currnt Bid: 57.053005
Is done? True
Episode End
Positive: 83, Negative: 132
EPISODE :- 457
Random Player utility: 119.990531
=================Random Agent Turn=================
Action taken: 43.092022
===============Feedback to learned agent round===============
Observation:
[0, 0, 43.09202224049149]
Reward: -1.000000, Currnt Bid: 43.092022
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[70.48245643]
Explore action: 70.482456
Action taken: 70.482456
===============Feedback to random agent round===============
Currnt Bid: 70.482456
=================Random Agent Turn=================
Action taken: 72.573944
===============Feedback to learned agent round===============
Observation:
[0, array([70.48245643]), array([72.57394372])]
Reward: -1.000000, Currnt Bid: 72.573944
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[54.86132015]
Explore action: 54.861320
Action taken: 54.861320
===============Feedback to random agent round===============
Currnt Bid: 72.573944
=================Random Agent Turn=================
Action taken: 91.769464
===============Feedback to learned agent round===============
Observation:
[1, array([70.48245643]), array([72.57394372])]
Reward: -2.000000, Currnt Bid: 72.573944
Is done? True
Episode End
Positive: 83, Negative: 132
EPISODE :- 458
Random Player utility: 42.288193
=================Random Agent Turn=================
Action taken: 30.883974
===============Feedback to learned agent round===============
Observation:
[0, 0, 30.883973891082984]
Reward: -1.000000, Currnt Bid: 30.883974
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[42.49003193]
Explore action: 42.490032
Action taken: 42.490032
===============Feedback to random agent round===============
Currnt Bid: 42.490032
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([42.49003193]), 30.883973891082984]
Reward: 57.509968, Currnt Bid: 42.490032
Is done? True
Episode End
Positive: 84, Negative: 132
EPISODE :- 459
Random Player utility: 107.431512
=================Random Agent Turn=================
Action taken: 24.833825
===============Feedback to learned agent round===============
Observation:
[0, 0, 24.833824723526632]
Reward: -1.000000, Currnt Bid: 24.833825
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[26.59609759]
Explore action: 26.596098
Action taken: 26.596098
===============Feedback to random agent round===============
Currnt Bid: 26.596098
=================Random Agent Turn=================
Action taken: 72.620933
===============Feedback to learned agent round===============
Observation:
[0, array([26.59609759]), array([72.62093327])]
Reward: -1.000000, Currnt Bid: 72.620933
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[25.59423373]
Explore action: 25.594234
Action taken: 25.594234
===============Feedback to random agent round===============
Currnt Bid: 72.620933
=================Random Agent Turn=================
Action taken: 76.374663
===============Feedback to learned agent round===============
Observation:
[1, array([26.59609759]), array([72.62093327])]
Reward: -2.000000, Currnt Bid: 72.620933
Is done? True
Episode End
Positive: 84, Negative: 132
EPISODE :- 460
Random Player utility: 101.970313
=================Random Agent Turn=================
Action taken: 23.231784
===============Feedback to learned agent round===============
Observation:
[0, 0, 23.231784151794173]
Reward: -1.000000, Currnt Bid: 23.231784
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 1.114237
Exploit action: 1.114237
Action taken: 1.114237
===============Feedback to random agent round===============
Currnt Bid: 23.231784
=================Random Agent Turn=================
Action taken: 33.702761
===============Feedback to learned agent round===============
Observation:
[1, 0, 23.231784151794173]
Reward: -2.000000, Currnt Bid: 23.231784
Is done? True
Episode End
Positive: 84, Negative: 132
EPISODE :- 461
Random Player utility: 219.117414
=================Random Agent Turn=================
Action taken: 123.864958
===============Feedback to learned agent round===============
Observation:
[0, 0, 123.86495819633865]
Reward: -1.000000, Currnt Bid: 123.864958
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[25.87843621]
Explore action: 25.878436
Action taken: 25.878436
===============Feedback to random agent round===============
Currnt Bid: 123.864958
=================Random Agent Turn=================
Action taken: 189.511275
===============Feedback to learned agent round===============
Observation:
[1, 0, 123.86495819633865]
Reward: -2.000000, Currnt Bid: 123.864958
Is done? True
Episode End
Positive: 84, Negative: 132
EPISODE :- 462
Random Player utility: 115.486542
=================Random Agent Turn=================
Action taken: 38.466031
===============Feedback to learned agent round===============
Observation:
[0, 0, 38.46603078418478]
Reward: -1.000000, Currnt Bid: 38.466031
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[19.69403475]
Explore action: 19.694035
Action taken: 19.694035
===============Feedback to random agent round===============
Currnt Bid: 38.466031
=================Random Agent Turn=================
Action taken: 51.011889
===============Feedback to learned agent round===============
Observation:
[1, 0, 38.46603078418478]
Reward: -2.000000, Currnt Bid: 38.466031
Is done? True
Episode End
Positive: 84, Negative: 132
EPISODE :- 463
Random Player utility: 66.707541
=================Random Agent Turn=================
Action taken: 33.000162
===============Feedback to learned agent round===============
Observation:
[0, 0, 33.000162467792805]
Reward: -1.000000, Currnt Bid: 33.000162
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[10.18154186]
Explore action: 10.181542
Action taken: 10.181542
===============Feedback to random agent round===============
Currnt Bid: 33.000162
=================Random Agent Turn=================
Action taken: 53.038256
===============Feedback to learned agent round===============
Observation:
[1, 0, 33.000162467792805]
Reward: -2.000000, Currnt Bid: 33.000162
Is done? True
Episode End
Positive: 84, Negative: 133
EPISODE :- 464
Random Player utility: 120.181324
=================Random Agent Turn=================
Action taken: 57.935646
===============Feedback to learned agent round===============
Observation:
[0, 0, 57.935646409426944]
Reward: -1.000000, Currnt Bid: 57.935646
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[21.78484673]
Explore action: 21.784847
Action taken: 21.784847
===============Feedback to random agent round===============
Currnt Bid: 57.935646
=================Random Agent Turn=================
Action taken: 77.822998
===============Feedback to learned agent round===============
Observation:
[1, 0, 57.935646409426944]
Reward: -2.000000, Currnt Bid: 57.935646
Is done? True
Episode End
Positive: 84, Negative: 133
EPISODE :- 465
Random Player utility: 73.078448
=================Random Agent Turn=================
Action taken: 67.230050
===============Feedback to learned agent round===============
Observation:
[0, 0, 67.23005042567631]
Reward: -1.000000, Currnt Bid: 67.230050
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 1.032108
Exploit action: 1.032108
Action taken: 1.032108
===============Feedback to random agent round===============
Currnt Bid: 67.230050
=================Random Agent Turn=================
Action taken: 68.476746
===============Feedback to learned agent round===============
Observation:
[1, 0, 67.23005042567631]
Reward: -2.000000, Currnt Bid: 67.230050
Is done? True
Episode End
Positive: 84, Negative: 134
EPISODE :- 466
Random Player utility: 130.334431
=================Random Agent Turn=================
Action taken: 98.580597
===============Feedback to learned agent round===============
Observation:
[0, 0, 98.58059704908531]
Reward: -1.000000, Currnt Bid: 98.580597
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[24.57302095]
Explore action: 24.573021
Action taken: 24.573021
===============Feedback to random agent round===============
Currnt Bid: 98.580597
=================Random Agent Turn=================
Action taken: 122.822134
===============Feedback to learned agent round===============
Observation:
[1, 0, 98.58059704908531]
Reward: -2.000000, Currnt Bid: 98.580597
Is done? True
Episode End
Positive: 84, Negative: 134
EPISODE :- 467
Random Player utility: 13.370038
=================Random Agent Turn=================
Action taken: 5.775283
===============Feedback to learned agent round===============
Observation:
[0, 0, 5.775283155819878]
Reward: -1.000000, Currnt Bid: 5.775283
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.8162341]
Explore action: 48.816234
Action taken: 48.816234
===============Feedback to random agent round===============
Currnt Bid: 48.816234
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([48.8162341]), 5.775283155819878]
Reward: 51.183766, Currnt Bid: 48.816234
Is done? True
Episode End
Positive: 85, Negative: 134
EPISODE :- 468
Random Player utility: 139.918060
=================Random Agent Turn=================
Action taken: 21.314680
===============Feedback to learned agent round===============
Observation:
[0, 0, 21.314680409534706]
Reward: -1.000000, Currnt Bid: 21.314680
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[40.37401693]
Explore action: 40.374017
Action taken: 40.374017
===============Feedback to random agent round===============
Currnt Bid: 40.374017
=================Random Agent Turn=================
Action taken: 50.335938
===============Feedback to learned agent round===============
Observation:
[0, array([40.37401693]), array([50.33593842])]
Reward: -1.000000, Currnt Bid: 50.335938
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[44.8621093]
Explore action: 44.862109
Action taken: 44.862109
===============Feedback to random agent round===============
Currnt Bid: 50.335938
=================Random Agent Turn=================
Action taken: 56.499184
===============Feedback to learned agent round===============
Observation:
[1, array([40.37401693]), array([50.33593842])]
Reward: -2.000000, Currnt Bid: 50.335938
Is done? True
Episode End
Positive: 85, Negative: 134
EPISODE :- 469
Random Player utility: 163.872593
=================Random Agent Turn=================
Action taken: 159.307428
===============Feedback to learned agent round===============
Observation:
[0, 0, 159.30742826203698]
Reward: -1.000000, Currnt Bid: 159.307428
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[61.26486184]
Explore action: 61.264862
Action taken: 61.264862
===============Feedback to random agent round===============
Currnt Bid: 159.307428
=================Random Agent Turn=================
Action taken: 163.264384
===============Feedback to learned agent round===============
Observation:
[1, 0, 159.30742826203698]
Reward: -2.000000, Currnt Bid: 159.307428
Is done? True
Episode End
Positive: 85, Negative: 134
EPISODE :- 470
Random Player utility: 156.996753
=================Random Agent Turn=================
Action taken: 21.121954
===============Feedback to learned agent round===============
Observation:
[0, 0, 21.12195419127448]
Reward: -1.000000, Currnt Bid: 21.121954
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.948662
Exploit action: 0.948662
Action taken: 0.948662
===============Feedback to random agent round===============
Currnt Bid: 21.121954
=================Random Agent Turn=================
Action taken: 83.904688
===============Feedback to learned agent round===============
Observation:
[1, 0, 21.12195419127448]
Reward: -2.000000, Currnt Bid: 21.121954
Is done? True
Episode End
Positive: 85, Negative: 134
EPISODE :- 471
Random Player utility: 155.519302
=================Random Agent Turn=================
Action taken: 145.195078
===============Feedback to learned agent round===============
Observation:
[0, 0, 145.19507766399616]
Reward: -1.000000, Currnt Bid: 145.195078
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[49.12377385]
Explore action: 49.123774
Action taken: 49.123774
===============Feedback to random agent round===============
Currnt Bid: 145.195078
=================Random Agent Turn=================
Action taken: 146.906559
===============Feedback to learned agent round===============
Observation:
[1, 0, 145.19507766399616]
Reward: -2.000000, Currnt Bid: 145.195078
Is done? True
Episode End
Positive: 85, Negative: 134
EPISODE :- 472
Random Player utility: 67.867238
=================Random Agent Turn=================
Action taken: 22.469818
===============Feedback to learned agent round===============
Observation:
[0, 0, 22.4698178950059]
Reward: -1.000000, Currnt Bid: 22.469818
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[41.71058039]
Explore action: 41.710580
Action taken: 41.710580
===============Feedback to random agent round===============
Currnt Bid: 41.710580
=================Random Agent Turn=================
Action taken: 63.175333
===============Feedback to learned agent round===============
Observation:
[0, array([41.71058039]), array([63.17533316])]
Reward: -1.000000, Currnt Bid: 63.175333
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[42.48441604]
Explore action: 42.484416
Action taken: 42.484416
===============Feedback to random agent round===============
Currnt Bid: 63.175333
=================Random Agent Turn=================
Action taken: 66.277873
===============Feedback to learned agent round===============
Observation:
[1, array([41.71058039]), array([63.17533316])]
Reward: -2.000000, Currnt Bid: 63.175333
Is done? True
Episode End
Positive: 85, Negative: 135
EPISODE :- 473
Random Player utility: 66.074203
=================Random Agent Turn=================
Action taken: 2.063410
===============Feedback to learned agent round===============
Observation:
[0, 0, 2.063409819530587]
Reward: -1.000000, Currnt Bid: 2.063410
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[59.83455708]
Explore action: 59.834557
Action taken: 59.834557
===============Feedback to random agent round===============
Currnt Bid: 59.834557
=================Random Agent Turn=================
Action taken: 62.155935
===============Feedback to learned agent round===============
Observation:
[0, array([59.83455708]), array([62.15593489])]
Reward: -1.000000, Currnt Bid: 62.155935
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[64.49686376]
Explore action: 64.496864
Action taken: 64.496864
===============Feedback to random agent round===============
Currnt Bid: 64.496864
=================Random Agent Turn=================
Action taken: 64.993933
===============Feedback to learned agent round===============
Observation:
[0, array([64.49686376]), array([64.99393348])]
Reward: -1.000000, Currnt Bid: 64.993933
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[65.73056757]
Explore action: 65.730568
Action taken: 65.730568
===============Feedback to random agent round===============
Currnt Bid: 65.730568
=================Random Agent Turn=================
Action taken: 65.737113
===============Feedback to learned agent round===============
Observation:
[0, array([65.73056757]), array([65.73711302])]
Reward: -1.000000, Currnt Bid: 65.737113
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[30.8267703]
Explore action: 30.826770
Action taken: 30.826770
===============Feedback to random agent round===============
Currnt Bid: 65.737113
=================Random Agent Turn=================
Action taken: 65.928270
===============Feedback to learned agent round===============
Observation:
[1, array([65.73056757]), array([65.73711302])]
Reward: -2.000000, Currnt Bid: 65.737113
Is done? True
Episode End
Positive: 85, Negative: 136
EPISODE :- 474
Random Player utility: 98.521349
=================Random Agent Turn=================
Action taken: 38.840003
===============Feedback to learned agent round===============
Observation:
[0, 0, 38.84000306491238]
Reward: -1.000000, Currnt Bid: 38.840003
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[49.56127868]
Explore action: 49.561279
Action taken: 49.561279
===============Feedback to random agent round===============
Currnt Bid: 49.561279
=================Random Agent Turn=================
Action taken: 81.420676
===============Feedback to learned agent round===============
Observation:
[0, array([49.56127868]), array([81.42067588])]
Reward: -1.000000, Currnt Bid: 81.420676
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[47.23002597]
Explore action: 47.230026
Action taken: 47.230026
===============Feedback to random agent round===============
Currnt Bid: 81.420676
=================Random Agent Turn=================
Action taken: 92.934877
===============Feedback to learned agent round===============
Observation:
[1, array([49.56127868]), array([81.42067588])]
Reward: -2.000000, Currnt Bid: 81.420676
Is done? True
Episode End
Positive: 85, Negative: 137
EPISODE :- 475
Random Player utility: 56.251664
=================Random Agent Turn=================
Action taken: 35.165001
===============Feedback to learned agent round===============
Observation:
[0, 0, 35.16500132407257]
Reward: -1.000000, Currnt Bid: 35.165001
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.845551
Exploit action: 0.845551
Action taken: 0.845551
===============Feedback to random agent round===============
Currnt Bid: 35.165001
=================Random Agent Turn=================
Action taken: 52.077275
===============Feedback to learned agent round===============
Observation:
[1, 0, 35.16500132407257]
Reward: -2.000000, Currnt Bid: 35.165001
Is done? True
Episode End
Positive: 85, Negative: 138
EPISODE :- 476
Random Player utility: 103.064987
=================Random Agent Turn=================
Action taken: 34.481110
===============Feedback to learned agent round===============
Observation:
[0, 0, 34.48110960178273]
Reward: -1.000000, Currnt Bid: 34.481110
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[45.75719813]
Explore action: 45.757198
Action taken: 45.757198
===============Feedback to random agent round===============
Currnt Bid: 45.757198
=================Random Agent Turn=================
Action taken: 77.431323
===============Feedback to learned agent round===============
Observation:
[0, array([45.75719813]), array([77.43132292])]
Reward: -1.000000, Currnt Bid: 77.431323
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[45.77297648]
Explore action: 45.772976
Action taken: 45.772976
===============Feedback to random agent round===============
Currnt Bid: 77.431323
=================Random Agent Turn=================
Action taken: 82.493606
===============Feedback to learned agent round===============
Observation:
[1, array([45.75719813]), array([77.43132292])]
Reward: -2.000000, Currnt Bid: 77.431323
Is done? True
Episode End
Positive: 85, Negative: 138
EPISODE :- 477
Random Player utility: 75.391746
=================Random Agent Turn=================
Action taken: 59.649920
===============Feedback to learned agent round===============
Observation:
[0, 0, 59.649920357100385]
Reward: -1.000000, Currnt Bid: 59.649920
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[30.64781604]
Explore action: 30.647816
Action taken: 30.647816
===============Feedback to random agent round===============
Currnt Bid: 59.649920
=================Random Agent Turn=================
Action taken: 59.982645
===============Feedback to learned agent round===============
Observation:
[1, 0, 59.649920357100385]
Reward: -2.000000, Currnt Bid: 59.649920
Is done? True
Episode End
Positive: 85, Negative: 139
EPISODE :- 478
Random Player utility: 145.191105
=================Random Agent Turn=================
Action taken: 94.245481
===============Feedback to learned agent round===============
Observation:
[0, 0, 94.24548092401506]
Reward: -1.000000, Currnt Bid: 94.245481
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[29.67196066]
Explore action: 29.671961
Action taken: 29.671961
===============Feedback to random agent round===============
Currnt Bid: 94.245481
=================Random Agent Turn=================
Action taken: 141.152314
===============Feedback to learned agent round===============
Observation:
[1, 0, 94.24548092401506]
Reward: -2.000000, Currnt Bid: 94.245481
Is done? True
Episode End
Positive: 85, Negative: 139
EPISODE :- 479
Random Player utility: 40.608912
=================Random Agent Turn=================
Action taken: 15.174980
===============Feedback to learned agent round===============
Observation:
[0, 0, 15.17497962205787]
Reward: -1.000000, Currnt Bid: 15.174980
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[31.19371301]
Explore action: 31.193713
Action taken: 31.193713
===============Feedback to random agent round===============
Currnt Bid: 31.193713
=================Random Agent Turn=================
Action taken: 36.586204
===============Feedback to learned agent round===============
Observation:
[0, array([31.19371301]), array([36.58620395])]
Reward: -1.000000, Currnt Bid: 36.586204
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[25.30724304]
Explore action: 25.307243
Action taken: 25.307243
===============Feedback to random agent round===============
Currnt Bid: 36.586204
=================Random Agent Turn=================
Action taken: 37.811797
===============Feedback to learned agent round===============
Observation:
[1, array([31.19371301]), array([36.58620395])]
Reward: -2.000000, Currnt Bid: 36.586204
Is done? True
Episode End
Positive: 85, Negative: 140
EPISODE :- 480
Random Player utility: 148.170674
=================Random Agent Turn=================
Action taken: 52.532718
===============Feedback to learned agent round===============
Observation:
[0, 0, 52.53271818752213]
Reward: -1.000000, Currnt Bid: 52.532718
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.771147
Exploit action: 0.771147
Action taken: 0.771147
===============Feedback to random agent round===============
Currnt Bid: 52.532718
=================Random Agent Turn=================
Action taken: 66.071443
===============Feedback to learned agent round===============
Observation:
[1, 0, 52.53271818752213]
Reward: -2.000000, Currnt Bid: 52.532718
Is done? True
Episode End
Positive: 85, Negative: 140
EPISODE :- 481
Random Player utility: 89.269264
=================Random Agent Turn=================
Action taken: 82.035047
===============Feedback to learned agent round===============
Observation:
[0, 0, 82.03504731873524]
Reward: -1.000000, Currnt Bid: 82.035047
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[28.91939242]
Explore action: 28.919392
Action taken: 28.919392
===============Feedback to random agent round===============
Currnt Bid: 82.035047
=================Random Agent Turn=================
Action taken: 88.863542
===============Feedback to learned agent round===============
Observation:
[1, 0, 82.03504731873524]
Reward: -2.000000, Currnt Bid: 82.035047
Is done? True
Episode End
Positive: 85, Negative: 141
EPISODE :- 482
Random Player utility: 92.653112
=================Random Agent Turn=================
Action taken: 30.619878
===============Feedback to learned agent round===============
Observation:
[0, 0, 30.61987818583969]
Reward: -1.000000, Currnt Bid: 30.619878
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[14.22285255]
Explore action: 14.222853
Action taken: 14.222853
===============Feedback to random agent round===============
Currnt Bid: 30.619878
=================Random Agent Turn=================
Action taken: 54.739722
===============Feedback to learned agent round===============
Observation:
[1, 0, 30.61987818583969]
Reward: -2.000000, Currnt Bid: 30.619878
Is done? True
Episode End
Positive: 85, Negative: 142
EPISODE :- 483
Random Player utility: 134.167077
=================Random Agent Turn=================
Action taken: 104.137670
===============Feedback to learned agent round===============
Observation:
[0, 0, 104.13767012587469]
Reward: -1.000000, Currnt Bid: 104.137670
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[21.70405486]
Explore action: 21.704055
Action taken: 21.704055
===============Feedback to random agent round===============
Currnt Bid: 104.137670
=================Random Agent Turn=================
Action taken: 119.769500
===============Feedback to learned agent round===============
Observation:
[1, 0, 104.13767012587469]
Reward: -2.000000, Currnt Bid: 104.137670
Is done? True
Episode End
Positive: 85, Negative: 142
EPISODE :- 484
Random Player utility: 129.145954
=================Random Agent Turn=================
Action taken: 66.556637
===============Feedback to learned agent round===============
Observation:
[0, 0, 66.55663672727964]
Reward: -1.000000, Currnt Bid: 66.556637
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[29.73228638]
Explore action: 29.732286
Action taken: 29.732286
===============Feedback to random agent round===============
Currnt Bid: 66.556637
=================Random Agent Turn=================
Action taken: 79.557688
===============Feedback to learned agent round===============
Observation:
[1, 0, 66.55663672727964]
Reward: -2.000000, Currnt Bid: 66.556637
Is done? True
Episode End
Positive: 85, Negative: 142
EPISODE :- 485
Random Player utility: 138.194799
=================Random Agent Turn=================
Action taken: 129.759136
===============Feedback to learned agent round===============
Observation:
[0, 0, 129.75913633022023]
Reward: -1.000000, Currnt Bid: 129.759136
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.714153
Exploit action: 0.714153
Action taken: 0.714153
===============Feedback to random agent round===============
Currnt Bid: 129.759136
=================Random Agent Turn=================
Action taken: 135.092461
===============Feedback to learned agent round===============
Observation:
[1, 0, 129.75913633022023]
Reward: -2.000000, Currnt Bid: 129.759136
Is done? True
Episode End
Positive: 85, Negative: 142
EPISODE :- 486
Random Player utility: 147.344190
=================Random Agent Turn=================
Action taken: 125.052181
===============Feedback to learned agent round===============
Observation:
[0, 0, 125.0521810782685]
Reward: -1.000000, Currnt Bid: 125.052181
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[54.44370328]
Explore action: 54.443703
Action taken: 54.443703
===============Feedback to random agent round===============
Currnt Bid: 125.052181
=================Random Agent Turn=================
Action taken: 134.536746
===============Feedback to learned agent round===============
Observation:
[1, 0, 125.0521810782685]
Reward: -2.000000, Currnt Bid: 125.052181
Is done? True
Episode End
Positive: 85, Negative: 142
EPISODE :- 487
Random Player utility: 186.749838
=================Random Agent Turn=================
Action taken: 169.900278
===============Feedback to learned agent round===============
Observation:
[0, 0, 169.9002776433787]
Reward: -1.000000, Currnt Bid: 169.900278
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[54.45240269]
Explore action: 54.452403
Action taken: 54.452403
===============Feedback to random agent round===============
Currnt Bid: 169.900278
=================Random Agent Turn=================
Action taken: 179.959841
===============Feedback to learned agent round===============
Observation:
[1, 0, 169.9002776433787]
Reward: -2.000000, Currnt Bid: 169.900278
Is done? True
Episode End
Positive: 85, Negative: 142
EPISODE :- 488
Random Player utility: 33.262321
=================Random Agent Turn=================
Action taken: 17.119429
===============Feedback to learned agent round===============
Observation:
[0, 0, 17.119429160090643]
Reward: -1.000000, Currnt Bid: 17.119429
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[64.97587398]
Explore action: 64.975874
Action taken: 64.975874
===============Feedback to random agent round===============
Currnt Bid: 64.975874
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([64.97587398]), 17.119429160090643]
Reward: 35.024126, Currnt Bid: 64.975874
Is done? True
Episode End
Positive: 86, Negative: 142
EPISODE :- 489
Random Player utility: 63.136449
=================Random Agent Turn=================
Action taken: 43.774731
===============Feedback to learned agent round===============
Observation:
[0, 0, 43.774730880540915]
Reward: -1.000000, Currnt Bid: 43.774731
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[76.54037042]
Explore action: 76.540370
Action taken: 76.540370
===============Feedback to random agent round===============
Currnt Bid: 76.540370
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([76.54037042]), 43.774730880540915]
Reward: 23.459630, Currnt Bid: 76.540370
Is done? True
Episode End
Positive: 87, Negative: 142
EPISODE :- 490
Random Player utility: 45.797663
=================Random Agent Turn=================
Action taken: 31.835250
===============Feedback to learned agent round===============
Observation:
[0, 0, 31.835250372823822]
Reward: -1.000000, Currnt Bid: 31.835250
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.661367
Exploit action: 0.661367
Action taken: 0.661367
===============Feedback to random agent round===============
Currnt Bid: 31.835250
=================Random Agent Turn=================
Action taken: 40.356828
===============Feedback to learned agent round===============
Observation:
[1, 0, 31.835250372823822]
Reward: -2.000000, Currnt Bid: 31.835250
Is done? True
Episode End
Positive: 87, Negative: 143
EPISODE :- 491
Random Player utility: 171.336579
=================Random Agent Turn=================
Action taken: 169.648589
===============Feedback to learned agent round===============
Observation:
[0, 0, 169.64858896544735]
Reward: -1.000000, Currnt Bid: 169.648589
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[69.90341631]
Explore action: 69.903416
Action taken: 69.903416
===============Feedback to random agent round===============
Currnt Bid: 169.648589
=================Random Agent Turn=================
Action taken: 170.647427
===============Feedback to learned agent round===============
Observation:
[1, 0, 169.64858896544735]
Reward: -2.000000, Currnt Bid: 169.648589
Is done? True
Episode End
Positive: 87, Negative: 143
EPISODE :- 492
Random Player utility: 50.877913
=================Random Agent Turn=================
Action taken: 6.120621
===============Feedback to learned agent round===============
Observation:
[0, 0, 6.120621432003624]
Reward: -1.000000, Currnt Bid: 6.120621
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[71.28416771]
Explore action: 71.284168
Action taken: 71.284168
===============Feedback to random agent round===============
Currnt Bid: 71.284168
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([71.28416771]), 6.120621432003624]
Reward: 28.715832, Currnt Bid: 71.284168
Is done? True
Episode End
Positive: 88, Negative: 143
EPISODE :- 493
Random Player utility: 203.287514
=================Random Agent Turn=================
Action taken: 153.352407
===============Feedback to learned agent round===============
Observation:
[0, 0, 153.35240673146174]
Reward: -1.000000, Currnt Bid: 153.352407
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[71.09778275]
Explore action: 71.097783
Action taken: 71.097783
===============Feedback to random agent round===============
Currnt Bid: 153.352407
=================Random Agent Turn=================
Action taken: 170.291266
===============Feedback to learned agent round===============
Observation:
[1, 0, 153.35240673146174]
Reward: -2.000000, Currnt Bid: 153.352407
Is done? True
Episode End
Positive: 88, Negative: 143
EPISODE :- 494
Random Player utility: 42.336257
=================Random Agent Turn=================
Action taken: 36.478738
===============Feedback to learned agent round===============
Observation:
[0, 0, 36.47873817149344]
Reward: -1.000000, Currnt Bid: 36.478738
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[80.68301384]
Explore action: 80.683014
Action taken: 80.683014
===============Feedback to random agent round===============
Currnt Bid: 80.683014
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([80.68301384]), 36.47873817149344]
Reward: 19.316986, Currnt Bid: 80.683014
Is done? True
Episode End
Positive: 89, Negative: 143
EPISODE :- 495
Random Player utility: 12.578913
=================Random Agent Turn=================
Action taken: 11.901980
===============Feedback to learned agent round===============
Observation:
[0, 0, 11.901979976004045]
Reward: -1.000000, Currnt Bid: 11.901980
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.612491
Exploit action: 0.612491
Action taken: 0.612491
===============Feedback to random agent round===============
Currnt Bid: 11.901980
=================Random Agent Turn=================
Action taken: 12.558941
===============Feedback to learned agent round===============
Observation:
[1, 0, 11.901979976004045]
Reward: -2.000000, Currnt Bid: 11.901980
Is done? True
Episode End
Positive: 89, Negative: 144
EPISODE :- 496
Random Player utility: 265.209840
=================Random Agent Turn=================
Action taken: 190.883127
===============Feedback to learned agent round===============
Observation:
[0, 0, 190.8831268688339]
Reward: -1.000000, Currnt Bid: 190.883127
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[77.11909779]
Explore action: 77.119098
Action taken: 77.119098
===============Feedback to random agent round===============
Currnt Bid: 190.883127
=================Random Agent Turn=================
Action taken: 201.544689
===============Feedback to learned agent round===============
Observation:
[1, 0, 190.8831268688339]
Reward: -2.000000, Currnt Bid: 190.883127
Is done? True
Episode End
Positive: 89, Negative: 144
EPISODE :- 497
Random Player utility: 129.287865
=================Random Agent Turn=================
Action taken: 77.994947
===============Feedback to learned agent round===============
Observation:
[0, 0, 77.99494691089043]
Reward: -1.000000, Currnt Bid: 77.994947
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[72.71398436]
Explore action: 72.713984
Action taken: 72.713984
===============Feedback to random agent round===============
Currnt Bid: 77.994947
=================Random Agent Turn=================
Action taken: 79.446052
===============Feedback to learned agent round===============
Observation:
[1, 0, 77.99494691089043]
Reward: -2.000000, Currnt Bid: 77.994947
Is done? True
Episode End
Positive: 89, Negative: 144
EPISODE :- 498
Random Player utility: 78.104464
=================Random Agent Turn=================
Action taken: 43.540993
===============Feedback to learned agent round===============
Observation:
[0, 0, 43.54099309069699]
Reward: -1.000000, Currnt Bid: 43.540993
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[64.00063604]
Explore action: 64.000636
Action taken: 64.000636
===============Feedback to random agent round===============
Currnt Bid: 64.000636
=================Random Agent Turn=================
Action taken: 70.365993
===============Feedback to learned agent round===============
Observation:
[0, array([64.00063604]), array([70.36599341])]
Reward: -1.000000, Currnt Bid: 70.365993
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[38.68862491]
Explore action: 38.688625
Action taken: 38.688625
===============Feedback to random agent round===============
Currnt Bid: 70.365993
=================Random Agent Turn=================
Action taken: 74.325278
===============Feedback to learned agent round===============
Observation:
[1, array([64.00063604]), array([70.36599341])]
Reward: -2.000000, Currnt Bid: 70.365993
Is done? True
Episode End
Positive: 89, Negative: 145
EPISODE :- 499
Random Player utility: 158.265042
=================Random Agent Turn=================
Action taken: 90.481156
===============Feedback to learned agent round===============
Observation:
[0, 0, 90.48115620412452]
Reward: -1.000000, Currnt Bid: 90.481156
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[60.67885984]
Explore action: 60.678860
Action taken: 60.678860
===============Feedback to random agent round===============
Currnt Bid: 90.481156
=================Random Agent Turn=================
Action taken: 101.062377
===============Feedback to learned agent round===============
Observation:
[1, 0, 90.48115620412452]
Reward: -2.000000, Currnt Bid: 90.481156
Is done? True
Episode End
Positive: 89, Negative: 145
EPISODE :- 500
Random Player utility: 133.160839
=================Random Agent Turn=================
Action taken: 88.471306
===============Feedback to learned agent round===============
Observation:
[0, 0, 88.47130597349434]
Reward: -1.000000, Currnt Bid: 88.471306
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.562900
Exploit action: 0.562900
Action taken: 0.562900
===============Feedback to random agent round===============
Currnt Bid: 88.471306
=================Random Agent Turn=================
Action taken: 98.210626
===============Feedback to learned agent round===============
Observation:
[1, 0, 88.47130597349434]
Reward: -2.000000, Currnt Bid: 88.471306
Is done? True
Episode End
Positive: 89, Negative: 145
Models saved successfully
EPISODE :- 501
Random Player utility: 19.875635
=================Random Agent Turn=================
Action taken: 3.517976
===============Feedback to learned agent round===============
Observation:
[0, 0, 3.5179761254316446]
Reward: -1.000000, Currnt Bid: 3.517976
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[66.33990945]
Explore action: 66.339909
Action taken: 66.339909
===============Feedback to random agent round===============
Currnt Bid: 66.339909
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([66.33990945]), 3.5179761254316446]
Reward: 33.660091, Currnt Bid: 66.339909
Is done? True
Episode End
Positive: 90, Negative: 145
EPISODE :- 502
Random Player utility: 72.288334
=================Random Agent Turn=================
Action taken: 47.774956
===============Feedback to learned agent round===============
Observation:
[0, 0, 47.77495642004441]
Reward: -1.000000, Currnt Bid: 47.774956
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[61.92430945]
Explore action: 61.924309
Action taken: 61.924309
===============Feedback to random agent round===============
Currnt Bid: 61.924309
=================Random Agent Turn=================
Action taken: 65.367751
===============Feedback to learned agent round===============
Observation:
[0, array([61.92430945]), array([65.3677515])]
Reward: -1.000000, Currnt Bid: 65.367751
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[76.168126]
Explore action: 76.168126
Action taken: 76.168126
===============Feedback to random agent round===============
Currnt Bid: 76.168126
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([76.168126]), array([65.3677515])]
Reward: 23.831874, Currnt Bid: 76.168126
Is done? True
Episode End
Positive: 91, Negative: 145
EPISODE :- 503
Random Player utility: 65.285049
=================Random Agent Turn=================
Action taken: 30.722187
===============Feedback to learned agent round===============
Observation:
[0, 0, 30.72218688312879]
Reward: -1.000000, Currnt Bid: 30.722187
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[63.55192764]
Explore action: 63.551928
Action taken: 63.551928
===============Feedback to random agent round===============
Currnt Bid: 63.551928
=================Random Agent Turn=================
Action taken: 64.245244
===============Feedback to learned agent round===============
Observation:
[0, array([63.55192764]), array([64.24524359])]
Reward: -1.000000, Currnt Bid: 64.245244
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[83.71643454]
Explore action: 83.716435
Action taken: 83.716435
===============Feedback to random agent round===============
Currnt Bid: 83.716435
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([83.71643454]), array([64.24524359])]
Reward: 16.283565, Currnt Bid: 83.716435
Is done? True
Episode End
Positive: 92, Negative: 145
EPISODE :- 504
Random Player utility: 36.516466
=================Random Agent Turn=================
Action taken: 23.914213
===============Feedback to learned agent round===============
Observation:
[0, 0, 23.914212544761146]
Reward: -1.000000, Currnt Bid: 23.914213
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[78.43412338]
Explore action: 78.434123
Action taken: 78.434123
===============Feedback to random agent round===============
Currnt Bid: 78.434123
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([78.43412338]), 23.914212544761146]
Reward: 21.565877, Currnt Bid: 78.434123
Is done? True
Episode End
Positive: 93, Negative: 145
EPISODE :- 505
Random Player utility: 201.413025
=================Random Agent Turn=================
Action taken: 133.671139
===============Feedback to learned agent round===============
Observation:
[0, 0, 133.6711386660876]
Reward: -1.000000, Currnt Bid: 133.671139
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.513387
Exploit action: 0.513387
Action taken: 0.513387
===============Feedback to random agent round===============
Currnt Bid: 133.671139
=================Random Agent Turn=================
Action taken: 144.346555
===============Feedback to learned agent round===============
Observation:
[1, 0, 133.6711386660876]
Reward: -2.000000, Currnt Bid: 133.671139
Is done? True
Episode End
Positive: 93, Negative: 145
EPISODE :- 506
Random Player utility: 192.723599
=================Random Agent Turn=================
Action taken: 121.990954
===============Feedback to learned agent round===============
Observation:
[0, 0, 121.99095424585765]
Reward: -1.000000, Currnt Bid: 121.990954
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[80.49507787]
Explore action: 80.495078
Action taken: 80.495078
===============Feedback to random agent round===============
Currnt Bid: 121.990954
=================Random Agent Turn=================
Action taken: 133.663823
===============Feedback to learned agent round===============
Observation:
[1, 0, 121.99095424585765]
Reward: -2.000000, Currnt Bid: 121.990954
Is done? True
Episode End
Positive: 93, Negative: 145
EPISODE :- 507
Random Player utility: 38.487507
=================Random Agent Turn=================
Action taken: 9.706016
===============Feedback to learned agent round===============
Observation:
[0, 0, 9.706016261025988]
Reward: -1.000000, Currnt Bid: 9.706016
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[66.94005659]
Explore action: 66.940057
Action taken: 66.940057
===============Feedback to random agent round===============
Currnt Bid: 66.940057
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([66.94005659]), 9.706016261025988]
Reward: 33.059943, Currnt Bid: 66.940057
Is done? True
Episode End
Positive: 94, Negative: 145
EPISODE :- 508
Random Player utility: 71.638589
=================Random Agent Turn=================
Action taken: 48.957706
===============Feedback to learned agent round===============
Observation:
[0, 0, 48.957705592485844]
Reward: -1.000000, Currnt Bid: 48.957706
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[70.85527135]
Explore action: 70.855271
Action taken: 70.855271
===============Feedback to random agent round===============
Currnt Bid: 70.855271
=================Random Agent Turn=================
Action taken: 70.919331
===============Feedback to learned agent round===============
Observation:
[0, array([70.85527135]), array([70.91933105])]
Reward: -1.000000, Currnt Bid: 70.919331
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[56.62195574]
Explore action: 56.621956
Action taken: 56.621956
===============Feedback to random agent round===============
Currnt Bid: 70.919331
=================Random Agent Turn=================
Action taken: 71.165982
===============Feedback to learned agent round===============
Observation:
[1, array([70.85527135]), array([70.91933105])]
Reward: -2.000000, Currnt Bid: 70.919331
Is done? True
Episode End
Positive: 94, Negative: 146
EPISODE :- 509
Random Player utility: 248.897490
=================Random Agent Turn=================
Action taken: 33.863661
===============Feedback to learned agent round===============
Observation:
[0, 0, 33.86366113266408]
Reward: -1.000000, Currnt Bid: 33.863661
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[45.98168226]
Explore action: 45.981682
Action taken: 45.981682
===============Feedback to random agent round===============
Currnt Bid: 45.981682
=================Random Agent Turn=================
Action taken: 199.918939
===============Feedback to learned agent round===============
Observation:
[0, array([45.98168226]), array([199.91893941])]
Reward: -1.000000, Currnt Bid: 199.918939
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[39.37705199]
Explore action: 39.377052
Action taken: 39.377052
===============Feedback to random agent round===============
Currnt Bid: 199.918939
=================Random Agent Turn=================
Action taken: 203.598172
===============Feedback to learned agent round===============
Observation:
[1, array([45.98168226]), array([199.91893941])]
Reward: -2.000000, Currnt Bid: 199.918939
Is done? True
Episode End
Positive: 94, Negative: 146
EPISODE :- 510
Random Player utility: 8.456982
=================Random Agent Turn=================
Action taken: 8.381615
===============Feedback to learned agent round===============
Observation:
[0, 0, 8.381615290155986]
Reward: -1.000000, Currnt Bid: 8.381615
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.468260
Exploit action: 0.468260
Action taken: 0.468260
===============Feedback to random agent round===============
Currnt Bid: 8.381615
=================Random Agent Turn=================
Action taken: 8.395498
===============Feedback to learned agent round===============
Observation:
[1, 0, 8.381615290155986]
Reward: -2.000000, Currnt Bid: 8.381615
Is done? True
Episode End
Positive: 94, Negative: 147
EPISODE :- 511
Random Player utility: 92.743322
=================Random Agent Turn=================
Action taken: 74.827078
===============Feedback to learned agent round===============
Observation:
[0, 0, 74.8270775812255]
Reward: -1.000000, Currnt Bid: 74.827078
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[33.78602154]
Explore action: 33.786022
Action taken: 33.786022
===============Feedback to random agent round===============
Currnt Bid: 74.827078
=================Random Agent Turn=================
Action taken: 81.222589
===============Feedback to learned agent round===============
Observation:
[1, 0, 74.8270775812255]
Reward: -2.000000, Currnt Bid: 74.827078
Is done? True
Episode End
Positive: 94, Negative: 148
EPISODE :- 512
Random Player utility: 175.871828
=================Random Agent Turn=================
Action taken: 37.395483
===============Feedback to learned agent round===============
Observation:
[0, 0, 37.39548256383533]
Reward: -1.000000, Currnt Bid: 37.395483
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[40.8028034]
Explore action: 40.802803
Action taken: 40.802803
===============Feedback to random agent round===============
Currnt Bid: 40.802803
=================Random Agent Turn=================
Action taken: 46.185516
===============Feedback to learned agent round===============
Observation:
[0, array([40.8028034]), array([46.18551632])]
Reward: -1.000000, Currnt Bid: 46.185516
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[41.70341129]
Explore action: 41.703411
Action taken: 41.703411
===============Feedback to random agent round===============
Currnt Bid: 46.185516
=================Random Agent Turn=================
Action taken: 51.715521
===============Feedback to learned agent round===============
Observation:
[1, array([40.8028034]), array([46.18551632])]
Reward: -2.000000, Currnt Bid: 46.185516
Is done? True
Episode End
Positive: 94, Negative: 148
EPISODE :- 513
Random Player utility: 162.996244
=================Random Agent Turn=================
Action taken: 37.340326
===============Feedback to learned agent round===============
Observation:
[0, 0, 37.340326358342956]
Reward: -1.000000, Currnt Bid: 37.340326
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[39.27967938]
Explore action: 39.279679
Action taken: 39.279679
===============Feedback to random agent round===============
Currnt Bid: 39.279679
=================Random Agent Turn=================
Action taken: 62.156396
===============Feedback to learned agent round===============
Observation:
[0, array([39.27967938]), array([62.15639627])]
Reward: -1.000000, Currnt Bid: 62.156396
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.86209482]
Explore action: 48.862095
Action taken: 48.862095
===============Feedback to random agent round===============
Currnt Bid: 62.156396
=================Random Agent Turn=================
Action taken: 120.658798
===============Feedback to learned agent round===============
Observation:
[1, array([39.27967938]), array([62.15639627])]
Reward: -2.000000, Currnt Bid: 62.156396
Is done? True
Episode End
Positive: 94, Negative: 148
EPISODE :- 514
Random Player utility: 95.439617
=================Random Agent Turn=================
Action taken: 35.361432
===============Feedback to learned agent round===============
Observation:
[0, 0, 35.36143181038375]
Reward: -1.000000, Currnt Bid: 35.361432
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[52.87425783]
Explore action: 52.874258
Action taken: 52.874258
===============Feedback to random agent round===============
Currnt Bid: 52.874258
=================Random Agent Turn=================
Action taken: 89.063799
===============Feedback to learned agent round===============
Observation:
[0, array([52.87425783]), array([89.06379932])]
Reward: -1.000000, Currnt Bid: 89.063799
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[43.96787214]
Explore action: 43.967872
Action taken: 43.967872
===============Feedback to random agent round===============
Currnt Bid: 89.063799
=================Random Agent Turn=================
Action taken: 95.304094
===============Feedback to learned agent round===============
Observation:
[1, array([52.87425783]), array([89.06379932])]
Reward: -2.000000, Currnt Bid: 89.063799
Is done? True
Episode End
Positive: 94, Negative: 149
EPISODE :- 515
Random Player utility: 133.856510
=================Random Agent Turn=================
Action taken: 123.856177
===============Feedback to learned agent round===============
Observation:
[0, 0, 123.85617740969907]
Reward: -1.000000, Currnt Bid: 123.856177
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.423878
Exploit action: 0.423878
Action taken: 0.423878
===============Feedback to random agent round===============
Currnt Bid: 123.856177
=================Random Agent Turn=================
Action taken: 129.684002
===============Feedback to learned agent round===============
Observation:
[1, 0, 123.85617740969907]
Reward: -2.000000, Currnt Bid: 123.856177
Is done? True
Episode End
Positive: 94, Negative: 149
EPISODE :- 516
Random Player utility: 108.298596
=================Random Agent Turn=================
Action taken: 93.521395
===============Feedback to learned agent round===============
Observation:
[0, 0, 93.52139508645891]
Reward: -1.000000, Currnt Bid: 93.521395
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[39.57490532]
Explore action: 39.574905
Action taken: 39.574905
===============Feedback to random agent round===============
Currnt Bid: 93.521395
=================Random Agent Turn=================
Action taken: 105.749351
===============Feedback to learned agent round===============
Observation:
[1, 0, 93.52139508645891]
Reward: -2.000000, Currnt Bid: 93.521395
Is done? True
Episode End
Positive: 94, Negative: 149
EPISODE :- 517
Random Player utility: 22.923159
=================Random Agent Turn=================
Action taken: 15.861835
===============Feedback to learned agent round===============
Observation:
[0, 0, 15.861835303078037]
Reward: -1.000000, Currnt Bid: 15.861835
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[34.16206879]
Explore action: 34.162069
Action taken: 34.162069
===============Feedback to random agent round===============
Currnt Bid: 34.162069
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([34.16206879]), 15.861835303078037]
Reward: 65.837931, Currnt Bid: 34.162069
Is done? True
Episode End
Positive: 95, Negative: 149
EPISODE :- 518
Random Player utility: 111.621301
=================Random Agent Turn=================
Action taken: 60.914698
===============Feedback to learned agent round===============
Observation:
[0, 0, 60.914698221156065]
Reward: -1.000000, Currnt Bid: 60.914698
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[57.26225684]
Explore action: 57.262257
Action taken: 57.262257
===============Feedback to random agent round===============
Currnt Bid: 60.914698
=================Random Agent Turn=================
Action taken: 94.631365
===============Feedback to learned agent round===============
Observation:
[1, 0, 60.914698221156065]
Reward: -2.000000, Currnt Bid: 60.914698
Is done? True
Episode End
Positive: 95, Negative: 149
EPISODE :- 519
Random Player utility: 42.581191
=================Random Agent Turn=================
Action taken: 32.713551
===============Feedback to learned agent round===============
Observation:
[0, 0, 32.713550979887515]
Reward: -1.000000, Currnt Bid: 32.713551
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[62.54850774]
Explore action: 62.548508
Action taken: 62.548508
===============Feedback to random agent round===============
Currnt Bid: 62.548508
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([62.54850774]), 32.713550979887515]
Reward: 37.451492, Currnt Bid: 62.548508
Is done? True
Episode End
Positive: 96, Negative: 149
EPISODE :- 520
Random Player utility: 42.719876
=================Random Agent Turn=================
Action taken: 26.607558
===============Feedback to learned agent round===============
Observation:
[0, 0, 26.60755791054014]
Reward: -1.000000, Currnt Bid: 26.607558
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.392658
Exploit action: 0.392658
Action taken: 0.392658
===============Feedback to random agent round===============
Currnt Bid: 26.607558
=================Random Agent Turn=================
Action taken: 38.212115
===============Feedback to learned agent round===============
Observation:
[1, 0, 26.60755791054014]
Reward: -2.000000, Currnt Bid: 26.607558
Is done? True
Episode End
Positive: 96, Negative: 150
EPISODE :- 521
Random Player utility: 127.377583
=================Random Agent Turn=================
Action taken: 7.573037
===============Feedback to learned agent round===============
Observation:
[0, 0, 7.573037280957687]
Reward: -1.000000, Currnt Bid: 7.573037
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[54.81036617]
Explore action: 54.810366
Action taken: 54.810366
===============Feedback to random agent round===============
Currnt Bid: 54.810366
=================Random Agent Turn=================
Action taken: 124.494496
===============Feedback to learned agent round===============
Observation:
[0, array([54.81036617]), array([124.49449572])]
Reward: -1.000000, Currnt Bid: 124.494496
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[50.70492225]
Explore action: 50.704922
Action taken: 50.704922
===============Feedback to random agent round===============
Currnt Bid: 124.494496
=================Random Agent Turn=================
Action taken: 126.614581
===============Feedback to learned agent round===============
Observation:
[1, array([54.81036617]), array([124.49449572])]
Reward: -2.000000, Currnt Bid: 124.494496
Is done? True
Episode End
Positive: 96, Negative: 150
EPISODE :- 522
Random Player utility: 73.782073
=================Random Agent Turn=================
Action taken: 16.676585
===============Feedback to learned agent round===============
Observation:
[0, 0, 16.676585172588833]
Reward: -1.000000, Currnt Bid: 16.676585
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[47.35672573]
Explore action: 47.356726
Action taken: 47.356726
===============Feedback to random agent round===============
Currnt Bid: 47.356726
=================Random Agent Turn=================
Action taken: 66.963335
===============Feedback to learned agent round===============
Observation:
[0, array([47.35672573]), array([66.96333482])]
Reward: -1.000000, Currnt Bid: 66.963335
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[46.15054453]
Explore action: 46.150545
Action taken: 46.150545
===============Feedback to random agent round===============
Currnt Bid: 66.963335
=================Random Agent Turn=================
Action taken: 69.529049
===============Feedback to learned agent round===============
Observation:
[1, array([47.35672573]), array([66.96333482])]
Reward: -2.000000, Currnt Bid: 66.963335
Is done? True
Episode End
Positive: 96, Negative: 151
EPISODE :- 523
Random Player utility: 52.369096
=================Random Agent Turn=================
Action taken: 37.423075
===============Feedback to learned agent round===============
Observation:
[0, 0, 37.42307481013493]
Reward: -1.000000, Currnt Bid: 37.423075
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[29.5213627]
Explore action: 29.521363
Action taken: 29.521363
===============Feedback to random agent round===============
Currnt Bid: 37.423075
=================Random Agent Turn=================
Action taken: 41.578265
===============Feedback to learned agent round===============
Observation:
[1, 0, 37.42307481013493]
Reward: -2.000000, Currnt Bid: 37.423075
Is done? True
Episode End
Positive: 96, Negative: 152
EPISODE :- 524
Random Player utility: 27.997423
=================Random Agent Turn=================
Action taken: 4.306342
===============Feedback to learned agent round===============
Observation:
[0, 0, 4.3063421930470005]
Reward: -1.000000, Currnt Bid: 4.306342
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.70096501]
Explore action: 48.700965
Action taken: 48.700965
===============Feedback to random agent round===============
Currnt Bid: 48.700965
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([48.70096501]), 4.3063421930470005]
Reward: 51.299035, Currnt Bid: 48.700965
Is done? True
Episode End
Positive: 97, Negative: 152
EPISODE :- 525
Random Player utility: 133.089499
=================Random Agent Turn=================
Action taken: 84.168337
===============Feedback to learned agent round===============
Observation:
[0, 0, 84.16833653462454]
Reward: -1.000000, Currnt Bid: 84.168337
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.358248
Exploit action: 0.358248
Action taken: 0.358248
===============Feedback to random agent round===============
Currnt Bid: 84.168337
=================Random Agent Turn=================
Action taken: 120.291817
===============Feedback to learned agent round===============
Observation:
[1, 0, 84.16833653462454]
Reward: -2.000000, Currnt Bid: 84.168337
Is done? True
Episode End
Positive: 97, Negative: 152
EPISODE :- 526
Random Player utility: 172.006977
=================Random Agent Turn=================
Action taken: 93.891397
===============Feedback to learned agent round===============
Observation:
[0, 0, 93.89139701985081]
Reward: -1.000000, Currnt Bid: 93.891397
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[63.31068762]
Explore action: 63.310688
Action taken: 63.310688
===============Feedback to random agent round===============
Currnt Bid: 93.891397
=================Random Agent Turn=================
Action taken: 145.219345
===============Feedback to learned agent round===============
Observation:
[1, 0, 93.89139701985081]
Reward: -2.000000, Currnt Bid: 93.891397
Is done? True
Episode End
Positive: 97, Negative: 152
EPISODE :- 527
Random Player utility: 54.005688
=================Random Agent Turn=================
Action taken: 47.566979
===============Feedback to learned agent round===============
Observation:
[0, 0, 47.56697875714863]
Reward: -1.000000, Currnt Bid: 47.566979
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[57.77227459]
Explore action: 57.772275
Action taken: 57.772275
===============Feedback to random agent round===============
Currnt Bid: 57.772275
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([57.77227459]), 47.56697875714863]
Reward: 42.227725, Currnt Bid: 57.772275
Is done? True
Episode End
Positive: 98, Negative: 152
EPISODE :- 528
Random Player utility: 253.907926
=================Random Agent Turn=================
Action taken: 35.509077
===============Feedback to learned agent round===============
Observation:
[0, 0, 35.509076977225256]
Reward: -1.000000, Currnt Bid: 35.509077
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[54.41826893]
Explore action: 54.418269
Action taken: 54.418269
===============Feedback to random agent round===============
Currnt Bid: 54.418269
=================Random Agent Turn=================
Action taken: 211.237441
===============Feedback to learned agent round===============
Observation:
[0, array([54.41826893]), array([211.23744124])]
Reward: -1.000000, Currnt Bid: 211.237441
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[70.10253681]
Explore action: 70.102537
Action taken: 70.102537
===============Feedback to random agent round===============
Currnt Bid: 211.237441
=================Random Agent Turn=================
Action taken: 227.031119
===============Feedback to learned agent round===============
Observation:
[1, array([54.41826893]), array([211.23744124])]
Reward: -2.000000, Currnt Bid: 211.237441
Is done? True
Episode End
Positive: 98, Negative: 152
EPISODE :- 529
Random Player utility: 55.176584
=================Random Agent Turn=================
Action taken: 51.226772
===============Feedback to learned agent round===============
Observation:
[0, 0, 51.22677179230722]
Reward: -1.000000, Currnt Bid: 51.226772
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[56.21667403]
Explore action: 56.216674
Action taken: 56.216674
===============Feedback to random agent round===============
Currnt Bid: 56.216674
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([56.21667403]), 51.22677179230722]
Reward: 43.783326, Currnt Bid: 56.216674
Is done? True
Episode End
Positive: 99, Negative: 152
EPISODE :- 530
Random Player utility: 102.521927
=================Random Agent Turn=================
Action taken: 56.640134
===============Feedback to learned agent round===============
Observation:
[0, 0, 56.64013381340932]
Reward: -1.000000, Currnt Bid: 56.640134
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.329399
Exploit action: 0.329399
Action taken: 0.329399
===============Feedback to random agent round===============
Currnt Bid: 56.640134
=================Random Agent Turn=================
Action taken: 72.245856
===============Feedback to learned agent round===============
Observation:
[1, 0, 56.64013381340932]
Reward: -2.000000, Currnt Bid: 56.640134
Is done? True
Episode End
Positive: 99, Negative: 152
EPISODE :- 531
Random Player utility: 117.405390
=================Random Agent Turn=================
Action taken: 19.974567
===============Feedback to learned agent round===============
Observation:
[0, 0, 19.974567480039347]
Reward: -1.000000, Currnt Bid: 19.974567
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[57.34976397]
Explore action: 57.349764
Action taken: 57.349764
===============Feedback to random agent round===============
Currnt Bid: 57.349764
=================Random Agent Turn=================
Action taken: 107.552903
===============Feedback to learned agent round===============
Observation:
[0, array([57.34976397]), array([107.55290319])]
Reward: -1.000000, Currnt Bid: 107.552903
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[59.78844359]
Explore action: 59.788444
Action taken: 59.788444
===============Feedback to random agent round===============
Currnt Bid: 107.552903
=================Random Agent Turn=================
Action taken: 115.263259
===============Feedback to learned agent round===============
Observation:
[1, array([57.34976397]), array([107.55290319])]
Reward: -2.000000, Currnt Bid: 107.552903
Is done? True
Episode End
Positive: 99, Negative: 152
EPISODE :- 532
Random Player utility: 42.068208
=================Random Agent Turn=================
Action taken: 41.167866
===============Feedback to learned agent round===============
Observation:
[0, 0, 41.16786583012186]
Reward: -1.000000, Currnt Bid: 41.167866
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[43.83864363]
Explore action: 43.838644
Action taken: 43.838644
===============Feedback to random agent round===============
Currnt Bid: 43.838644
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([43.83864363]), 41.16786583012186]
Reward: 56.161356, Currnt Bid: 43.838644
Is done? True
Episode End
Positive: 100, Negative: 152
EPISODE :- 533
Random Player utility: 122.058495
=================Random Agent Turn=================
Action taken: 2.571065
===============Feedback to learned agent round===============
Observation:
[0, 0, 2.5710652398030973]
Reward: -1.000000, Currnt Bid: 2.571065
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[54.60770497]
Explore action: 54.607705
Action taken: 54.607705
===============Feedback to random agent round===============
Currnt Bid: 54.607705
=================Random Agent Turn=================
Action taken: 101.880105
===============Feedback to learned agent round===============
Observation:
[0, array([54.60770497]), array([101.8801047])]
Reward: -1.000000, Currnt Bid: 101.880105
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[45.27979228]
Explore action: 45.279792
Action taken: 45.279792
===============Feedback to random agent round===============
Currnt Bid: 101.880105
=================Random Agent Turn=================
Action taken: 119.808443
===============Feedback to learned agent round===============
Observation:
[1, array([54.60770497]), array([101.8801047])]
Reward: -2.000000, Currnt Bid: 101.880105
Is done? True
Episode End
Positive: 100, Negative: 152
EPISODE :- 534
Random Player utility: 270.289328
=================Random Agent Turn=================
Action taken: 126.083336
===============Feedback to learned agent round===============
Observation:
[0, 0, 126.08333636601984]
Reward: -1.000000, Currnt Bid: 126.083336
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[31.68703555]
Explore action: 31.687036
Action taken: 31.687036
===============Feedback to random agent round===============
Currnt Bid: 126.083336
=================Random Agent Turn=================
Action taken: 251.524991
===============Feedback to learned agent round===============
Observation:
[1, 0, 126.08333636601984]
Reward: -2.000000, Currnt Bid: 126.083336
Is done? True
Episode End
Positive: 100, Negative: 152
EPISODE :- 535
Random Player utility: 105.089564
=================Random Agent Turn=================
Action taken: 85.470583
===============Feedback to learned agent round===============
Observation:
[0, 0, 85.47058276932869]
Reward: -1.000000, Currnt Bid: 85.470583
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.300616
Exploit action: 0.300616
Action taken: 0.300616
===============Feedback to random agent round===============
Currnt Bid: 85.470583
=================Random Agent Turn=================
Action taken: 95.596836
===============Feedback to learned agent round===============
Observation:
[1, 0, 85.47058276932869]
Reward: -2.000000, Currnt Bid: 85.470583
Is done? True
Episode End
Positive: 100, Negative: 152
EPISODE :- 536
Random Player utility: 89.544760
=================Random Agent Turn=================
Action taken: 3.459475
===============Feedback to learned agent round===============
Observation:
[0, 0, 3.459474527902177]
Reward: -1.000000, Currnt Bid: 3.459475
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[41.45066672]
Explore action: 41.450667
Action taken: 41.450667
===============Feedback to random agent round===============
Currnt Bid: 41.450667
=================Random Agent Turn=================
Action taken: 64.931550
===============Feedback to learned agent round===============
Observation:
[0, array([41.45066672]), array([64.93155037])]
Reward: -1.000000, Currnt Bid: 64.931550
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[62.34894113]
Explore action: 62.348941
Action taken: 62.348941
===============Feedback to random agent round===============
Currnt Bid: 64.931550
=================Random Agent Turn=================
Action taken: 86.062963
===============Feedback to learned agent round===============
Observation:
[1, array([41.45066672]), array([64.93155037])]
Reward: -2.000000, Currnt Bid: 64.931550
Is done? True
Episode End
Positive: 100, Negative: 153
EPISODE :- 537
Random Player utility: 108.889392
=================Random Agent Turn=================
Action taken: 22.410619
===============Feedback to learned agent round===============
Observation:
[0, 0, 22.410618521334964]
Reward: -1.000000, Currnt Bid: 22.410619
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[59.05918716]
Explore action: 59.059187
Action taken: 59.059187
===============Feedback to random agent round===============
Currnt Bid: 59.059187
=================Random Agent Turn=================
Action taken: 69.865402
===============Feedback to learned agent round===============
Observation:
[0, array([59.05918716]), array([69.86540163])]
Reward: -1.000000, Currnt Bid: 69.865402
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[50.69183883]
Explore action: 50.691839
Action taken: 50.691839
===============Feedback to random agent round===============
Currnt Bid: 69.865402
=================Random Agent Turn=================
Action taken: 98.408610
===============Feedback to learned agent round===============
Observation:
[1, array([59.05918716]), array([69.86540163])]
Reward: -2.000000, Currnt Bid: 69.865402
Is done? True
Episode End
Positive: 100, Negative: 153
EPISODE :- 538
Random Player utility: 100.961825
=================Random Agent Turn=================
Action taken: 85.462549
===============Feedback to learned agent round===============
Observation:
[0, 0, 85.46254907002348]
Reward: -1.000000, Currnt Bid: 85.462549
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[53.7836753]
Explore action: 53.783675
Action taken: 53.783675
===============Feedback to random agent round===============
Currnt Bid: 85.462549
=================Random Agent Turn=================
Action taken: 98.479857
===============Feedback to learned agent round===============
Observation:
[1, 0, 85.46254907002348]
Reward: -2.000000, Currnt Bid: 85.462549
Is done? True
Episode End
Positive: 100, Negative: 153
EPISODE :- 539
Random Player utility: 205.949171
=================Random Agent Turn=================
Action taken: 16.522052
===============Feedback to learned agent round===============
Observation:
[0, 0, 16.522051951909418]
Reward: -1.000000, Currnt Bid: 16.522052
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[50.50124987]
Explore action: 50.501250
Action taken: 50.501250
===============Feedback to random agent round===============
Currnt Bid: 50.501250
=================Random Agent Turn=================
Action taken: 125.605382
===============Feedback to learned agent round===============
Observation:
[0, array([50.50124987]), array([125.60538176])]
Reward: -1.000000, Currnt Bid: 125.605382
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[39.14771872]
Explore action: 39.147719
Action taken: 39.147719
===============Feedback to random agent round===============
Currnt Bid: 125.605382
=================Random Agent Turn=================
Action taken: 173.577768
===============Feedback to learned agent round===============
Observation:
[1, array([50.50124987]), array([125.60538176])]
Reward: -2.000000, Currnt Bid: 125.605382
Is done? True
Episode End
Positive: 100, Negative: 153
EPISODE :- 540
Random Player utility: 194.316968
=================Random Agent Turn=================
Action taken: 119.374183
===============Feedback to learned agent round===============
Observation:
[0, 0, 119.37418288391824]
Reward: -1.000000, Currnt Bid: 119.374183
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.272316
Exploit action: 0.272316
Action taken: 0.272316
===============Feedback to random agent round===============
Currnt Bid: 119.374183
=================Random Agent Turn=================
Action taken: 177.965720
===============Feedback to learned agent round===============
Observation:
[1, 0, 119.37418288391824]
Reward: -2.000000, Currnt Bid: 119.374183
Is done? True
Episode End
Positive: 100, Negative: 153
EPISODE :- 541
Random Player utility: 99.960740
=================Random Agent Turn=================
Action taken: 88.753321
===============Feedback to learned agent round===============
Observation:
[0, 0, 88.75332099161709]
Reward: -1.000000, Currnt Bid: 88.753321
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[29.17478955]
Explore action: 29.174790
Action taken: 29.174790
===============Feedback to random agent round===============
Currnt Bid: 88.753321
=================Random Agent Turn=================
Action taken: 92.237548
===============Feedback to learned agent round===============
Observation:
[1, 0, 88.75332099161709]
Reward: -2.000000, Currnt Bid: 88.753321
Is done? True
Episode End
Positive: 100, Negative: 154
EPISODE :- 542
Random Player utility: 173.446356
=================Random Agent Turn=================
Action taken: 49.771817
===============Feedback to learned agent round===============
Observation:
[0, 0, 49.7718170879394]
Reward: -1.000000, Currnt Bid: 49.771817
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[33.13343519]
Explore action: 33.133435
Action taken: 33.133435
===============Feedback to random agent round===============
Currnt Bid: 49.771817
=================Random Agent Turn=================
Action taken: 91.936307
===============Feedback to learned agent round===============
Observation:
[1, 0, 49.7718170879394]
Reward: -2.000000, Currnt Bid: 49.771817
Is done? True
Episode End
Positive: 100, Negative: 154
EPISODE :- 543
Random Player utility: 164.246489
=================Random Agent Turn=================
Action taken: 20.872553
===============Feedback to learned agent round===============
Observation:
[0, 0, 20.872552919764125]
Reward: -1.000000, Currnt Bid: 20.872553
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[44.64133922]
Explore action: 44.641339
Action taken: 44.641339
===============Feedback to random agent round===============
Currnt Bid: 44.641339
=================Random Agent Turn=================
Action taken: 112.069263
===============Feedback to learned agent round===============
Observation:
[0, array([44.64133922]), array([112.069263])]
Reward: -1.000000, Currnt Bid: 112.069263
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[47.2633057]
Explore action: 47.263306
Action taken: 47.263306
===============Feedback to random agent round===============
Currnt Bid: 112.069263
=================Random Agent Turn=================
Action taken: 116.718475
===============Feedback to learned agent round===============
Observation:
[1, array([44.64133922]), array([112.069263])]
Reward: -2.000000, Currnt Bid: 112.069263
Is done? True
Episode End
Positive: 100, Negative: 154
EPISODE :- 544
Random Player utility: 63.544571
=================Random Agent Turn=================
Action taken: 11.949553
===============Feedback to learned agent round===============
Observation:
[0, 0, 11.949552872908772]
Reward: -1.000000, Currnt Bid: 11.949553
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[71.21347231]
Explore action: 71.213472
Action taken: 71.213472
===============Feedback to random agent round===============
Currnt Bid: 71.213472
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([71.21347231]), 11.949552872908772]
Reward: 28.786528, Currnt Bid: 71.213472
Is done? True
Episode End
Positive: 101, Negative: 154
EPISODE :- 545
Random Player utility: 104.915138
=================Random Agent Turn=================
Action taken: 74.130542
===============Feedback to learned agent round===============
Observation:
[0, 0, 74.13054207167676]
Reward: -1.000000, Currnt Bid: 74.130542
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.250506
Exploit action: 0.250506
Action taken: 0.250506
===============Feedback to random agent round===============
Currnt Bid: 74.130542
=================Random Agent Turn=================
Action taken: 82.169983
===============Feedback to learned agent round===============
Observation:
[1, 0, 74.13054207167676]
Reward: -2.000000, Currnt Bid: 74.130542
Is done? True
Episode End
Positive: 101, Negative: 154
EPISODE :- 546
Random Player utility: 100.510149
=================Random Agent Turn=================
Action taken: 54.964785
===============Feedback to learned agent round===============
Observation:
[0, 0, 54.964785391983476]
Reward: -1.000000, Currnt Bid: 54.964785
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[81.77438106]
Explore action: 81.774381
Action taken: 81.774381
===============Feedback to random agent round===============
Currnt Bid: 81.774381
=================Random Agent Turn=================
Action taken: 90.448551
===============Feedback to learned agent round===============
Observation:
[0, array([81.77438106]), array([90.44855069])]
Reward: -1.000000, Currnt Bid: 90.448551
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[100.45241219]
Explore action: 100.452412
Action taken: 100.452412
===============Feedback to random agent round===============
Currnt Bid: 100.452412
=================Random Agent Turn=================
Action taken: 100.468405
===============Feedback to learned agent round===============
Observation:
[0, array([100.45241219]), array([100.46840467])]
Reward: -1.000000, Currnt Bid: 100.468405
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[111.42794574]
Explore action: 111.427946
Action taken: 111.427946
===============Feedback to random agent round===============
Currnt Bid: 111.427946
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([111.42794574]), array([100.46840467])]
Reward: -11.427946, Currnt Bid: 111.427946
Is done? True
Episode End
Positive: 101, Negative: 154
EPISODE :- 547
Random Player utility: 39.440999
=================Random Agent Turn=================
Action taken: 4.120543
===============Feedback to learned agent round===============
Observation:
[0, 0, 4.120543198491724]
Reward: -1.000000, Currnt Bid: 4.120543
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[108.89327835]
Explore action: 108.893278
Action taken: 108.893278
===============Feedback to random agent round===============
Currnt Bid: 108.893278
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([108.89327835]), 4.120543198491724]
Reward: -8.893278, Currnt Bid: 108.893278
Is done? True
Episode End
Positive: 101, Negative: 155
EPISODE :- 548
Random Player utility: 56.230640
=================Random Agent Turn=================
Action taken: 2.549066
===============Feedback to learned agent round===============
Observation:
[0, 0, 2.5490659105921667]
Reward: -1.000000, Currnt Bid: 2.549066
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[122.35593934]
Explore action: 122.355939
Action taken: 122.355939
===============Feedback to random agent round===============
Currnt Bid: 122.355939
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([122.35593934]), 2.5490659105921667]
Reward: -22.355939, Currnt Bid: 122.355939
Is done? True
Episode End
Positive: 101, Negative: 156
EPISODE :- 549
Random Player utility: 18.542606
=================Random Agent Turn=================
Action taken: 4.810056
===============Feedback to learned agent round===============
Observation:
[0, 0, 4.810055879998133]
Reward: -1.000000, Currnt Bid: 4.810056
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[116.01453441]
Explore action: 116.014534
Action taken: 116.014534
===============Feedback to random agent round===============
Currnt Bid: 116.014534
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([116.01453441]), 4.810055879998133]
Reward: -16.014534, Currnt Bid: 116.014534
Is done? True
Episode End
Positive: 101, Negative: 157
EPISODE :- 550
Random Player utility: 99.596098
=================Random Agent Turn=================
Action taken: 48.175691
===============Feedback to learned agent round===============
Observation:
[0, 0, 48.175690726115924]
Reward: -1.000000, Currnt Bid: 48.175691
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.228739
Exploit action: 0.228739
Action taken: 0.228739
===============Feedback to random agent round===============
Currnt Bid: 48.175691
=================Random Agent Turn=================
Action taken: 56.799929
===============Feedback to learned agent round===============
Observation:
[1, 0, 48.175690726115924]
Reward: -2.000000, Currnt Bid: 48.175691
Is done? True
Episode End
Positive: 101, Negative: 158
EPISODE :- 551
Random Player utility: 10.116183
=================Random Agent Turn=================
Action taken: 6.692318
===============Feedback to learned agent round===============
Observation:
[0, 0, 6.6923181306846695]
Reward: -1.000000, Currnt Bid: 6.692318
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[104.14258081]
Explore action: 104.142581
Action taken: 104.142581
===============Feedback to random agent round===============
Currnt Bid: 104.142581
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([104.14258081]), 6.6923181306846695]
Reward: -4.142581, Currnt Bid: 104.142581
Is done? True
Episode End
Positive: 101, Negative: 159
EPISODE :- 552
Random Player utility: 112.460158
=================Random Agent Turn=================
Action taken: 94.180406
===============Feedback to learned agent round===============
Observation:
[0, 0, 94.18040607609998]
Reward: -1.000000, Currnt Bid: 94.180406
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[108.38387153]
Explore action: 108.383872
Action taken: 108.383872
===============Feedback to random agent round===============
Currnt Bid: 108.383872
=================Random Agent Turn=================
Action taken: 109.386164
===============Feedback to learned agent round===============
Observation:
[0, array([108.38387153]), array([109.38616442])]
Reward: -1.000000, Currnt Bid: 109.386164
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[102.92105579]
Explore action: 102.921056
Action taken: 102.921056
===============Feedback to random agent round===============
Currnt Bid: 109.386164
=================Random Agent Turn=================
Action taken: 110.468988
===============Feedback to learned agent round===============
Observation:
[1, array([108.38387153]), array([109.38616442])]
Reward: -2.000000, Currnt Bid: 109.386164
Is done? True
Episode End
Positive: 101, Negative: 159
EPISODE :- 553
Random Player utility: 95.119619
=================Random Agent Turn=================
Action taken: 64.151961
===============Feedback to learned agent round===============
Observation:
[0, 0, 64.1519605754101]
Reward: -1.000000, Currnt Bid: 64.151961
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[114.60165001]
Explore action: 114.601650
Action taken: 114.601650
===============Feedback to random agent round===============
Currnt Bid: 114.601650
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([114.60165001]), 64.1519605754101]
Reward: -14.601650, Currnt Bid: 114.601650
Is done? True
Episode End
Positive: 101, Negative: 160
EPISODE :- 554
Random Player utility: 150.755458
=================Random Agent Turn=================
Action taken: 39.774085
===============Feedback to learned agent round===============
Observation:
[0, 0, 39.77408540430649]
Reward: -1.000000, Currnt Bid: 39.774085
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[101.23967198]
Explore action: 101.239672
Action taken: 101.239672
===============Feedback to random agent round===============
Currnt Bid: 101.239672
=================Random Agent Turn=================
Action taken: 114.766001
===============Feedback to learned agent round===============
Observation:
[0, array([101.23967198]), array([114.76600142])]
Reward: -1.000000, Currnt Bid: 114.766001
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[84.92315419]
Explore action: 84.923154
Action taken: 84.923154
===============Feedback to random agent round===============
Currnt Bid: 114.766001
=================Random Agent Turn=================
Action taken: 123.527596
===============Feedback to learned agent round===============
Observation:
[1, array([101.23967198]), array([114.76600142])]
Reward: -2.000000, Currnt Bid: 114.766001
Is done? True
Episode End
Positive: 101, Negative: 160
EPISODE :- 555
Random Player utility: 52.632281
=================Random Agent Turn=================
Action taken: 31.100601
===============Feedback to learned agent round===============
Observation:
[0, 0, 31.10060114379495]
Reward: -1.000000, Currnt Bid: 31.100601
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.208908
Exploit action: 0.208908
Action taken: 0.208908
===============Feedback to random agent round===============
Currnt Bid: 31.100601
=================Random Agent Turn=================
Action taken: 36.413425
===============Feedback to learned agent round===============
Observation:
[1, 0, 31.10060114379495]
Reward: -2.000000, Currnt Bid: 31.100601
Is done? True
Episode End
Positive: 101, Negative: 161
EPISODE :- 556
Random Player utility: 117.769146
=================Random Agent Turn=================
Action taken: 19.535189
===============Feedback to learned agent round===============
Observation:
[0, 0, 19.535188557991894]
Reward: -1.000000, Currnt Bid: 19.535189
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[91.14939632]
Explore action: 91.149396
Action taken: 91.149396
===============Feedback to random agent round===============
Currnt Bid: 91.149396
=================Random Agent Turn=================
Action taken: 102.769611
===============Feedback to learned agent round===============
Observation:
[0, array([91.14939632]), array([102.76961131])]
Reward: -1.000000, Currnt Bid: 102.769611
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[71.21754842]
Explore action: 71.217548
Action taken: 71.217548
===============Feedback to random agent round===============
Currnt Bid: 102.769611
=================Random Agent Turn=================
Action taken: 110.902997
===============Feedback to learned agent round===============
Observation:
[1, array([91.14939632]), array([102.76961131])]
Reward: -2.000000, Currnt Bid: 102.769611
Is done? True
Episode End
Positive: 101, Negative: 161
EPISODE :- 557
Random Player utility: 135.806914
=================Random Agent Turn=================
Action taken: 40.470130
===============Feedback to learned agent round===============
Observation:
[0, 0, 40.4701298940049]
Reward: -1.000000, Currnt Bid: 40.470130
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[79.7526448]
Explore action: 79.752645
Action taken: 79.752645
===============Feedback to random agent round===============
Currnt Bid: 79.752645
=================Random Agent Turn=================
Action taken: 98.759798
===============Feedback to learned agent round===============
Observation:
[0, array([79.7526448]), array([98.7597984])]
Reward: -1.000000, Currnt Bid: 98.759798
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[78.26321299]
Explore action: 78.263213
Action taken: 78.263213
===============Feedback to random agent round===============
Currnt Bid: 98.759798
=================Random Agent Turn=================
Action taken: 105.956049
===============Feedback to learned agent round===============
Observation:
[1, array([79.7526448]), array([98.7597984])]
Reward: -2.000000, Currnt Bid: 98.759798
Is done? True
Episode End
Positive: 101, Negative: 161
EPISODE :- 558
Random Player utility: 21.842268
=================Random Agent Turn=================
Action taken: 11.089652
===============Feedback to learned agent round===============
Observation:
[0, 0, 11.089652225442535]
Reward: -1.000000, Currnt Bid: 11.089652
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.46209915]
Explore action: 48.462099
Action taken: 48.462099
===============Feedback to random agent round===============
Currnt Bid: 48.462099
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([48.46209915]), 11.089652225442535]
Reward: 51.537901, Currnt Bid: 48.462099
Is done? True
Episode End
Positive: 102, Negative: 161
EPISODE :- 559
Random Player utility: 160.410351
=================Random Agent Turn=================
Action taken: 1.721905
===============Feedback to learned agent round===============
Observation:
[0, 0, 1.7219050378143705]
Reward: -1.000000, Currnt Bid: 1.721905
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[52.57744007]
Explore action: 52.577440
Action taken: 52.577440
===============Feedback to random agent round===============
Currnt Bid: 52.577440
=================Random Agent Turn=================
Action taken: 139.315679
===============Feedback to learned agent round===============
Observation:
[0, array([52.57744007]), array([139.3156788])]
Reward: -1.000000, Currnt Bid: 139.315679
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[42.86904926]
Explore action: 42.869049
Action taken: 42.869049
===============Feedback to random agent round===============
Currnt Bid: 139.315679
=================Random Agent Turn=================
Action taken: 142.900573
===============Feedback to learned agent round===============
Observation:
[1, array([52.57744007]), array([139.3156788])]
Reward: -2.000000, Currnt Bid: 139.315679
Is done? True
Episode End
Positive: 102, Negative: 161
EPISODE :- 560
Random Player utility: 159.060335
=================Random Agent Turn=================
Action taken: 154.009067
===============Feedback to learned agent round===============
Observation:
[0, 0, 154.0090668118781]
Reward: -1.000000, Currnt Bid: 154.009067
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.189412
Exploit action: 0.189412
Action taken: 0.189412
===============Feedback to random agent round===============
Currnt Bid: 154.009067
=================Random Agent Turn=================
Action taken: 154.112098
===============Feedback to learned agent round===============
Observation:
[1, 0, 154.0090668118781]
Reward: -2.000000, Currnt Bid: 154.009067
Is done? True
Episode End
Positive: 102, Negative: 161
EPISODE :- 561
Random Player utility: 70.633693
=================Random Agent Turn=================
Action taken: 6.135245
===============Feedback to learned agent round===============
Observation:
[0, 0, 6.13524456135641]
Reward: -1.000000, Currnt Bid: 6.135245
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[64.38618592]
Explore action: 64.386186
Action taken: 64.386186
===============Feedback to random agent round===============
Currnt Bid: 64.386186
=================Random Agent Turn=================
Action taken: 69.500611
===============Feedback to learned agent round===============
Observation:
[0, array([64.38618592]), array([69.50061053])]
Reward: -1.000000, Currnt Bid: 69.500611
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[75.86470331]
Explore action: 75.864703
Action taken: 75.864703
===============Feedback to random agent round===============
Currnt Bid: 75.864703
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([75.86470331]), array([69.50061053])]
Reward: 24.135297, Currnt Bid: 75.864703
Is done? True
Episode End
Positive: 103, Negative: 161
EPISODE :- 562
Random Player utility: 215.286219
=================Random Agent Turn=================
Action taken: 27.398051
===============Feedback to learned agent round===============
Observation:
[0, 0, 27.39805086737494]
Reward: -1.000000, Currnt Bid: 27.398051
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[91.21742376]
Explore action: 91.217424
Action taken: 91.217424
===============Feedback to random agent round===============
Currnt Bid: 91.217424
=================Random Agent Turn=================
Action taken: 207.304130
===============Feedback to learned agent round===============
Observation:
[0, array([91.21742376]), array([207.30413005])]
Reward: -1.000000, Currnt Bid: 207.304130
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[77.55865342]
Explore action: 77.558653
Action taken: 77.558653
===============Feedback to random agent round===============
Currnt Bid: 207.304130
=================Random Agent Turn=================
Action taken: 212.529745
===============Feedback to learned agent round===============
Observation:
[1, array([91.21742376]), array([207.30413005])]
Reward: -2.000000, Currnt Bid: 207.304130
Is done? True
Episode End
Positive: 103, Negative: 161
EPISODE :- 563
Random Player utility: 108.328917
=================Random Agent Turn=================
Action taken: 14.173287
===============Feedback to learned agent round===============
Observation:
[0, 0, 14.173287338102188]
Reward: -1.000000, Currnt Bid: 14.173287
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[78.81988875]
Explore action: 78.819889
Action taken: 78.819889
===============Feedback to random agent round===============
Currnt Bid: 78.819889
=================Random Agent Turn=================
Action taken: 87.326786
===============Feedback to learned agent round===============
Observation:
[0, array([78.81988875]), array([87.32678594])]
Reward: -1.000000, Currnt Bid: 87.326786
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[61.09619611]
Explore action: 61.096196
Action taken: 61.096196
===============Feedback to random agent round===============
Currnt Bid: 87.326786
=================Random Agent Turn=================
Action taken: 96.184081
===============Feedback to learned agent round===============
Observation:
[1, array([78.81988875]), array([87.32678594])]
Reward: -2.000000, Currnt Bid: 87.326786
Is done? True
Episode End
Positive: 103, Negative: 161
EPISODE :- 564
Random Player utility: 46.941606
=================Random Agent Turn=================
Action taken: 23.011970
===============Feedback to learned agent round===============
Observation:
[0, 0, 23.01196994234333]
Reward: -1.000000, Currnt Bid: 23.011970
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[64.80438631]
Explore action: 64.804386
Action taken: 64.804386
===============Feedback to random agent round===============
Currnt Bid: 64.804386
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([64.80438631]), 23.01196994234333]
Reward: 35.195614, Currnt Bid: 64.804386
Is done? True
Episode End
Positive: 104, Negative: 161
EPISODE :- 565
Random Player utility: 119.964207
=================Random Agent Turn=================
Action taken: 5.855463
===============Feedback to learned agent round===============
Observation:
[0, 0, 5.855462700201113]
Reward: -1.000000, Currnt Bid: 5.855463
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.171781
Exploit action: 0.171781
Action taken: 0.171781
===============Feedback to random agent round===============
Currnt Bid: 5.855463
=================Random Agent Turn=================
Action taken: 87.100287
===============Feedback to learned agent round===============
Observation:
[1, 0, 5.855462700201113]
Reward: -2.000000, Currnt Bid: 5.855463
Is done? True
Episode End
Positive: 104, Negative: 161
EPISODE :- 566
Random Player utility: 90.030377
=================Random Agent Turn=================
Action taken: 69.189853
===============Feedback to learned agent round===============
Observation:
[0, 0, 69.18985346077412]
Reward: -1.000000, Currnt Bid: 69.189853
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[94.0816013]
Explore action: 94.081601
Action taken: 94.081601
===============Feedback to random agent round===============
Currnt Bid: 94.081601
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([94.0816013]), 69.18985346077412]
Reward: 5.918399, Currnt Bid: 94.081601
Is done? True
Episode End
Positive: 105, Negative: 161
EPISODE :- 567
Random Player utility: 89.265517
=================Random Agent Turn=================
Action taken: 82.210267
===============Feedback to learned agent round===============
Observation:
[0, 0, 82.21026708525629]
Reward: -1.000000, Currnt Bid: 82.210267
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[94.34755871]
Explore action: 94.347559
Action taken: 94.347559
===============Feedback to random agent round===============
Currnt Bid: 94.347559
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([94.34755871]), 82.21026708525629]
Reward: 5.652441, Currnt Bid: 94.347559
Is done? True
Episode End
Positive: 106, Negative: 161
EPISODE :- 568
Random Player utility: 72.290813
=================Random Agent Turn=================
Action taken: 13.648140
===============Feedback to learned agent round===============
Observation:
[0, 0, 13.648140283746653]
Reward: -1.000000, Currnt Bid: 13.648140
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[77.19630571]
Explore action: 77.196306
Action taken: 77.196306
===============Feedback to random agent round===============
Currnt Bid: 77.196306
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([77.19630571]), 13.648140283746653]
Reward: 22.803694, Currnt Bid: 77.196306
Is done? True
Episode End
Positive: 107, Negative: 161
EPISODE :- 569
Random Player utility: 22.805957
=================Random Agent Turn=================
Action taken: 10.604333
===============Feedback to learned agent round===============
Observation:
[0, 0, 10.60433281659317]
Reward: -1.000000, Currnt Bid: 10.604333
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[73.30958494]
Explore action: 73.309585
Action taken: 73.309585
===============Feedback to random agent round===============
Currnt Bid: 73.309585
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([73.30958494]), 10.60433281659317]
Reward: 26.690415, Currnt Bid: 73.309585
Is done? True
Episode End
Positive: 108, Negative: 161
EPISODE :- 570
Random Player utility: 31.554453
=================Random Agent Turn=================
Action taken: 8.187277
===============Feedback to learned agent round===============
Observation:
[0, 0, 8.187277464952082]
Reward: -1.000000, Currnt Bid: 8.187277
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.159377
Exploit action: 0.159377
Action taken: 0.159377
===============Feedback to random agent round===============
Currnt Bid: 8.187277
=================Random Agent Turn=================
Action taken: 25.629759
===============Feedback to learned agent round===============
Observation:
[1, 0, 8.187277464952082]
Reward: -2.000000, Currnt Bid: 8.187277
Is done? True
Episode End
Positive: 108, Negative: 162
EPISODE :- 571
Random Player utility: 60.821440
=================Random Agent Turn=================
Action taken: 8.110055
===============Feedback to learned agent round===============
Observation:
[0, 0, 8.110054965248958]
Reward: -1.000000, Currnt Bid: 8.110055
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[66.541958]
Explore action: 66.541958
Action taken: 66.541958
===============Feedback to random agent round===============
Currnt Bid: 66.541958
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([66.541958]), 8.110054965248958]
Reward: 33.458042, Currnt Bid: 66.541958
Is done? True
Episode End
Positive: 109, Negative: 162
EPISODE :- 572
Random Player utility: 129.026725
=================Random Agent Turn=================
Action taken: 108.183901
===============Feedback to learned agent round===============
Observation:
[0, 0, 108.18390119114638]
Reward: -1.000000, Currnt Bid: 108.183901
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[65.35221229]
Explore action: 65.352212
Action taken: 65.352212
===============Feedback to random agent round===============
Currnt Bid: 108.183901
=================Random Agent Turn=================
Action taken: 122.011286
===============Feedback to learned agent round===============
Observation:
[1, 0, 108.18390119114638]
Reward: -2.000000, Currnt Bid: 108.183901
Is done? True
Episode End
Positive: 109, Negative: 162
EPISODE :- 573
Random Player utility: 171.858506
=================Random Agent Turn=================
Action taken: 158.531544
===============Feedback to learned agent round===============
Observation:
[0, 0, 158.53154356541944]
Reward: -1.000000, Currnt Bid: 158.531544
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[67.78560958]
Explore action: 67.785610
Action taken: 67.785610
===============Feedback to random agent round===============
Currnt Bid: 158.531544
=================Random Agent Turn=================
Action taken: 159.002902
===============Feedback to learned agent round===============
Observation:
[1, 0, 158.53154356541944]
Reward: -2.000000, Currnt Bid: 158.531544
Is done? True
Episode End
Positive: 109, Negative: 162
EPISODE :- 574
Random Player utility: 60.599875
=================Random Agent Turn=================
Action taken: 4.672517
===============Feedback to learned agent round===============
Observation:
[0, 0, 4.67251670767117]
Reward: -1.000000, Currnt Bid: 4.672517
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[57.04723354]
Explore action: 57.047234
Action taken: 57.047234
===============Feedback to random agent round===============
Currnt Bid: 57.047234
=================Random Agent Turn=================
Action taken: 59.787657
===============Feedback to learned agent round===============
Observation:
[0, array([57.04723354]), array([59.78765746])]
Reward: -1.000000, Currnt Bid: 59.787657
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[50.34048296]
Explore action: 50.340483
Action taken: 50.340483
===============Feedback to random agent round===============
Currnt Bid: 59.787657
=================Random Agent Turn=================
Action taken: 60.059878
===============Feedback to learned agent round===============
Observation:
[1, array([57.04723354]), array([59.78765746])]
Reward: -2.000000, Currnt Bid: 59.787657
Is done? True
Episode End
Positive: 109, Negative: 163
EPISODE :- 575
Random Player utility: 60.312919
=================Random Agent Turn=================
Action taken: 15.075090
===============Feedback to learned agent round===============
Observation:
[0, 0, 15.075089697050721]
Reward: -1.000000, Currnt Bid: 15.075090
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.146794
Exploit action: 0.146794
Action taken: 0.146794
===============Feedback to random agent round===============
Currnt Bid: 15.075090
=================Random Agent Turn=================
Action taken: 38.926212
===============Feedback to learned agent round===============
Observation:
[1, 0, 15.075089697050721]
Reward: -2.000000, Currnt Bid: 15.075090
Is done? True
Episode End
Positive: 109, Negative: 164
EPISODE :- 576
Random Player utility: 13.607672
=================Random Agent Turn=================
Action taken: 2.394342
===============Feedback to learned agent round===============
Observation:
[0, 0, 2.3943415728551614]
Reward: -1.000000, Currnt Bid: 2.394342
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[58.10435114]
Explore action: 58.104351
Action taken: 58.104351
===============Feedback to random agent round===============
Currnt Bid: 58.104351
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([58.10435114]), 2.3943415728551614]
Reward: 41.895649, Currnt Bid: 58.104351
Is done? True
Episode End
Positive: 110, Negative: 164
EPISODE :- 577
Random Player utility: 71.276480
=================Random Agent Turn=================
Action taken: 30.411176
===============Feedback to learned agent round===============
Observation:
[0, 0, 30.411176311654845]
Reward: -1.000000, Currnt Bid: 30.411176
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[59.57257683]
Explore action: 59.572577
Action taken: 59.572577
===============Feedback to random agent round===============
Currnt Bid: 59.572577
=================Random Agent Turn=================
Action taken: 59.729377
===============Feedback to learned agent round===============
Observation:
[0, array([59.57257683]), array([59.72937739])]
Reward: -1.000000, Currnt Bid: 59.729377
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[56.8966138]
Explore action: 56.896614
Action taken: 56.896614
===============Feedback to random agent round===============
Currnt Bid: 59.729377
=================Random Agent Turn=================
Action taken: 66.913465
===============Feedback to learned agent round===============
Observation:
[1, array([59.57257683]), array([59.72937739])]
Reward: -2.000000, Currnt Bid: 59.729377
Is done? True
Episode End
Positive: 110, Negative: 165
EPISODE :- 578
Random Player utility: 58.955165
=================Random Agent Turn=================
Action taken: 15.865542
===============Feedback to learned agent round===============
Observation:
[0, 0, 15.865542174023146]
Reward: -1.000000, Currnt Bid: 15.865542
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[57.85106876]
Explore action: 57.851069
Action taken: 57.851069
===============Feedback to random agent round===============
Currnt Bid: 57.851069
=================Random Agent Turn=================
Action taken: 58.914862
===============Feedback to learned agent round===============
Observation:
[0, array([57.85106876]), array([58.91486151])]
Reward: -1.000000, Currnt Bid: 58.914862
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[45.92176129]
Explore action: 45.921761
Action taken: 45.921761
===============Feedback to random agent round===============
Currnt Bid: 58.914862
=================Random Agent Turn=================
Action taken: 58.944806
===============Feedback to learned agent round===============
Observation:
[1, array([57.85106876]), array([58.91486151])]
Reward: -2.000000, Currnt Bid: 58.914862
Is done? True
Episode End
Positive: 110, Negative: 166
EPISODE :- 579
Random Player utility: 57.820936
=================Random Agent Turn=================
Action taken: 53.703053
===============Feedback to learned agent round===============
Observation:
[0, 0, 53.70305259782679]
Reward: -1.000000, Currnt Bid: 53.703053
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[60.15644412]
Explore action: 60.156444
Action taken: 60.156444
===============Feedback to random agent round===============
Currnt Bid: 60.156444
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([60.15644412]), 53.70305259782679]
Reward: 39.843556, Currnt Bid: 60.156444
Is done? True
Episode End
Positive: 111, Negative: 166
EPISODE :- 580
Random Player utility: 17.637292
=================Random Agent Turn=================
Action taken: 5.000675
===============Feedback to learned agent round===============
Observation:
[0, 0, 5.0006745287780285]
Reward: -1.000000, Currnt Bid: 5.000675
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.134236
Exploit action: 0.134236
Action taken: 0.134236
===============Feedback to random agent round===============
Currnt Bid: 5.000675
=================Random Agent Turn=================
Action taken: 9.223937
===============Feedback to learned agent round===============
Observation:
[1, 0, 5.0006745287780285]
Reward: -2.000000, Currnt Bid: 5.000675
Is done? True
Episode End
Positive: 111, Negative: 167
EPISODE :- 581
Random Player utility: 123.691226
=================Random Agent Turn=================
Action taken: 14.404751
===============Feedback to learned agent round===============
Observation:
[0, 0, 14.404751079339091]
Reward: -1.000000, Currnt Bid: 14.404751
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[66.99748758]
Explore action: 66.997488
Action taken: 66.997488
===============Feedback to random agent round===============
Currnt Bid: 66.997488
=================Random Agent Turn=================
Action taken: 71.947120
===============Feedback to learned agent round===============
Observation:
[0, array([66.99748758]), array([71.94711984])]
Reward: -1.000000, Currnt Bid: 71.947120
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[73.26254346]
Explore action: 73.262543
Action taken: 73.262543
===============Feedback to random agent round===============
Currnt Bid: 73.262543
=================Random Agent Turn=================
Action taken: 79.777497
===============Feedback to learned agent round===============
Observation:
[0, array([73.26254346]), array([79.77749701])]
Reward: -1.000000, Currnt Bid: 79.777497
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[89.44891261]
Explore action: 89.448913
Action taken: 89.448913
===============Feedback to random agent round===============
Currnt Bid: 89.448913
=================Random Agent Turn=================
Action taken: 97.978390
===============Feedback to learned agent round===============
Observation:
[0, array([89.44891261]), array([97.97839018])]
Reward: -1.000000, Currnt Bid: 97.978390
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[74.5324062]
Explore action: 74.532406
Action taken: 74.532406
===============Feedback to random agent round===============
Currnt Bid: 97.978390
=================Random Agent Turn=================
Action taken: 105.120062
===============Feedback to learned agent round===============
Observation:
[1, array([89.44891261]), array([97.97839018])]
Reward: -2.000000, Currnt Bid: 97.978390
Is done? True
Episode End
Positive: 111, Negative: 167
EPISODE :- 582
Random Player utility: 33.745582
=================Random Agent Turn=================
Action taken: 0.938900
===============Feedback to learned agent round===============
Observation:
[0, 0, 0.9389002160481783]
Reward: -1.000000, Currnt Bid: 0.938900
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[64.5039138]
Explore action: 64.503914
Action taken: 64.503914
===============Feedback to random agent round===============
Currnt Bid: 64.503914
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([64.5039138]), 0.9389002160481783]
Reward: 35.496086, Currnt Bid: 64.503914
Is done? True
Episode End
Positive: 112, Negative: 167
EPISODE :- 583
Random Player utility: 158.849516
=================Random Agent Turn=================
Action taken: 32.134090
===============Feedback to learned agent round===============
Observation:
[0, 0, 32.1340895301264]
Reward: -1.000000, Currnt Bid: 32.134090
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[64.56541239]
Explore action: 64.565412
Action taken: 64.565412
===============Feedback to random agent round===============
Currnt Bid: 64.565412
=================Random Agent Turn=================
Action taken: 157.719940
===============Feedback to learned agent round===============
Observation:
[0, array([64.56541239]), array([157.71994009])]
Reward: -1.000000, Currnt Bid: 157.719940
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[69.54880243]
Explore action: 69.548802
Action taken: 69.548802
===============Feedback to random agent round===============
Currnt Bid: 157.719940
=================Random Agent Turn=================
Action taken: 158.739510
===============Feedback to learned agent round===============
Observation:
[1, array([64.56541239]), array([157.71994009])]
Reward: -2.000000, Currnt Bid: 157.719940
Is done? True
Episode End
Positive: 112, Negative: 167
EPISODE :- 584
Random Player utility: 49.234646
=================Random Agent Turn=================
Action taken: 42.851135
===============Feedback to learned agent round===============
Observation:
[0, 0, 42.85113483416622]
Reward: -1.000000, Currnt Bid: 42.851135
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[74.29017237]
Explore action: 74.290172
Action taken: 74.290172
===============Feedback to random agent round===============
Currnt Bid: 74.290172
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([74.29017237]), 42.85113483416622]
Reward: 25.709828, Currnt Bid: 74.290172
Is done? True
Episode End
Positive: 113, Negative: 167
EPISODE :- 585
Random Player utility: 104.376163
=================Random Agent Turn=================
Action taken: 38.759310
===============Feedback to learned agent round===============
Observation:
[0, 0, 38.75930992454997]
Reward: -1.000000, Currnt Bid: 38.759310
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.120980
Exploit action: 0.120980
Action taken: 0.120980
===============Feedback to random agent round===============
Currnt Bid: 38.759310
=================Random Agent Turn=================
Action taken: 48.481902
===============Feedback to learned agent round===============
Observation:
[1, 0, 38.75930992454997]
Reward: -2.000000, Currnt Bid: 38.759310
Is done? True
Episode End
Positive: 113, Negative: 167
EPISODE :- 586
Random Player utility: 170.184580
=================Random Agent Turn=================
Action taken: 13.082138
===============Feedback to learned agent round===============
Observation:
[0, 0, 13.082138491513383]
Reward: -1.000000, Currnt Bid: 13.082138
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[77.13585909]
Explore action: 77.135859
Action taken: 77.135859
===============Feedback to random agent round===============
Currnt Bid: 77.135859
=================Random Agent Turn=================
Action taken: 135.083724
===============Feedback to learned agent round===============
Observation:
[0, array([77.13585909]), array([135.08372429])]
Reward: -1.000000, Currnt Bid: 135.083724
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[88.52278871]
Explore action: 88.522789
Action taken: 88.522789
===============Feedback to random agent round===============
Currnt Bid: 135.083724
=================Random Agent Turn=================
Action taken: 166.635645
===============Feedback to learned agent round===============
Observation:
[1, array([77.13585909]), array([135.08372429])]
Reward: -2.000000, Currnt Bid: 135.083724
Is done? True
Episode End
Positive: 113, Negative: 167
EPISODE :- 587
Random Player utility: 135.917935
=================Random Agent Turn=================
Action taken: 132.087702
===============Feedback to learned agent round===============
Observation:
[0, 0, 132.08770182227147]
Reward: -1.000000, Currnt Bid: 132.087702
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[81.07310552]
Explore action: 81.073106
Action taken: 81.073106
===============Feedback to random agent round===============
Currnt Bid: 132.087702
=================Random Agent Turn=================
Action taken: 132.140181
===============Feedback to learned agent round===============
Observation:
[1, 0, 132.08770182227147]
Reward: -2.000000, Currnt Bid: 132.087702
Is done? True
Episode End
Positive: 113, Negative: 167
EPISODE :- 588
Random Player utility: 151.190435
=================Random Agent Turn=================
Action taken: 10.037336
===============Feedback to learned agent round===============
Observation:
[0, 0, 10.037336116110097]
Reward: -1.000000, Currnt Bid: 10.037336
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[74.59852351]
Explore action: 74.598524
Action taken: 74.598524
===============Feedback to random agent round===============
Currnt Bid: 74.598524
=================Random Agent Turn=================
Action taken: 85.220344
===============Feedback to learned agent round===============
Observation:
[0, array([74.59852351]), array([85.22034404])]
Reward: -1.000000, Currnt Bid: 85.220344
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[58.05134887]
Explore action: 58.051349
Action taken: 58.051349
===============Feedback to random agent round===============
Currnt Bid: 85.220344
=================Random Agent Turn=================
Action taken: 124.112742
===============Feedback to learned agent round===============
Observation:
[1, array([74.59852351]), array([85.22034404])]
Reward: -2.000000, Currnt Bid: 85.220344
Is done? True
Episode End
Positive: 113, Negative: 167
EPISODE :- 589
Random Player utility: 54.393457
=================Random Agent Turn=================
Action taken: 32.252129
===============Feedback to learned agent round===============
Observation:
[0, 0, 32.25212868011007]
Reward: -1.000000, Currnt Bid: 32.252129
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[61.00845579]
Explore action: 61.008456
Action taken: 61.008456
===============Feedback to random agent round===============
Currnt Bid: 61.008456
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([61.00845579]), 32.25212868011007]
Reward: 38.991544, Currnt Bid: 61.008456
Is done? True
Episode End
Positive: 114, Negative: 167
EPISODE :- 590
Random Player utility: 108.165661
=================Random Agent Turn=================
Action taken: 45.356304
===============Feedback to learned agent round===============
Observation:
[0, 0, 45.35630357498177]
Reward: -1.000000, Currnt Bid: 45.356304
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.110698
Exploit action: 0.110698
Action taken: 0.110698
===============Feedback to random agent round===============
Currnt Bid: 45.356304
=================Random Agent Turn=================
Action taken: 106.941587
===============Feedback to learned agent round===============
Observation:
[1, 0, 45.35630357498177]
Reward: -2.000000, Currnt Bid: 45.356304
Is done? True
Episode End
Positive: 114, Negative: 167
EPISODE :- 591
Random Player utility: 60.526460
=================Random Agent Turn=================
Action taken: 56.212590
===============Feedback to learned agent round===============
Observation:
[0, 0, 56.21259016774737]
Reward: -1.000000, Currnt Bid: 56.212590
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[60.27329617]
Explore action: 60.273296
Action taken: 60.273296
===============Feedback to random agent round===============
Currnt Bid: 60.273296
=================Random Agent Turn=================
Action taken: 60.300237
===============Feedback to learned agent round===============
Observation:
[0, array([60.27329617]), array([60.30023731])]
Reward: -1.000000, Currnt Bid: 60.300237
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.16251681]
Explore action: 48.162517
Action taken: 48.162517
===============Feedback to random agent round===============
Currnt Bid: 60.300237
=================Random Agent Turn=================
Action taken: 60.415213
===============Feedback to learned agent round===============
Observation:
[1, array([60.27329617]), array([60.30023731])]
Reward: -2.000000, Currnt Bid: 60.300237
Is done? True
Episode End
Positive: 114, Negative: 168
EPISODE :- 592
Random Player utility: 125.010403
=================Random Agent Turn=================
Action taken: 90.163944
===============Feedback to learned agent round===============
Observation:
[0, 0, 90.16394405545444]
Reward: -1.000000, Currnt Bid: 90.163944
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[65.54394428]
Explore action: 65.543944
Action taken: 65.543944
===============Feedback to random agent round===============
Currnt Bid: 90.163944
=================Random Agent Turn=================
Action taken: 121.137962
===============Feedback to learned agent round===============
Observation:
[1, 0, 90.16394405545444]
Reward: -2.000000, Currnt Bid: 90.163944
Is done? True
Episode End
Positive: 114, Negative: 168
EPISODE :- 593
Random Player utility: 136.522741
=================Random Agent Turn=================
Action taken: 136.520663
===============Feedback to learned agent round===============
Observation:
[0, 0, 136.5206629685534]
Reward: -1.000000, Currnt Bid: 136.520663
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[55.31204562]
Explore action: 55.312046
Action taken: 55.312046
===============Feedback to random agent round===============
Currnt Bid: 136.520663
=================Random Agent Turn=================
Action taken: 136.521757
===============Feedback to learned agent round===============
Observation:
[1, 0, 136.5206629685534]
Reward: -2.000000, Currnt Bid: 136.520663
Is done? True
Episode End
Positive: 114, Negative: 168
EPISODE :- 594
Random Player utility: 7.335223
=================Random Agent Turn=================
Action taken: 0.871189
===============Feedback to learned agent round===============
Observation:
[0, 0, 0.8711890873398093]
Reward: -1.000000, Currnt Bid: 0.871189
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[69.4612854]
Explore action: 69.461285
Action taken: 69.461285
===============Feedback to random agent round===============
Currnt Bid: 69.461285
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([69.4612854]), 0.8711890873398093]
Reward: 30.538715, Currnt Bid: 69.461285
Is done? True
Episode End
Positive: 115, Negative: 168
EPISODE :- 595
Random Player utility: 129.951765
=================Random Agent Turn=================
Action taken: 67.982649
===============Feedback to learned agent round===============
Observation:
[0, 0, 67.98264946079192]
Reward: -1.000000, Currnt Bid: 67.982649
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.102073
Exploit action: 0.102073
Action taken: 0.102073
===============Feedback to random agent round===============
Currnt Bid: 67.982649
=================Random Agent Turn=================
Action taken: 90.126279
===============Feedback to learned agent round===============
Observation:
[1, 0, 67.98264946079192]
Reward: -2.000000, Currnt Bid: 67.982649
Is done? True
Episode End
Positive: 115, Negative: 168
EPISODE :- 596
Random Player utility: 48.261138
=================Random Agent Turn=================
Action taken: 35.309235
===============Feedback to learned agent round===============
Observation:
[0, 0, 35.309235441232985]
Reward: -1.000000, Currnt Bid: 35.309235
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[78.07938331]
Explore action: 78.079383
Action taken: 78.079383
===============Feedback to random agent round===============
Currnt Bid: 78.079383
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([78.07938331]), 35.309235441232985]
Reward: 21.920617, Currnt Bid: 78.079383
Is done? True
Episode End
Positive: 116, Negative: 168
EPISODE :- 597
Random Player utility: 79.396457
=================Random Agent Turn=================
Action taken: 4.791484
===============Feedback to learned agent round===============
Observation:
[0, 0, 4.791484008695167]
Reward: -1.000000, Currnt Bid: 4.791484
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[60.36699336]
Explore action: 60.366993
Action taken: 60.366993
===============Feedback to random agent round===============
Currnt Bid: 60.366993
=================Random Agent Turn=================
Action taken: 74.874708
===============Feedback to learned agent round===============
Observation:
[0, array([60.36699336]), array([74.87470791])]
Reward: -1.000000, Currnt Bid: 74.874708
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[47.33446635]
Explore action: 47.334466
Action taken: 47.334466
===============Feedback to random agent round===============
Currnt Bid: 74.874708
=================Random Agent Turn=================
Action taken: 75.564400
===============Feedback to learned agent round===============
Observation:
[1, array([60.36699336]), array([74.87470791])]
Reward: -2.000000, Currnt Bid: 74.874708
Is done? True
Episode End
Positive: 116, Negative: 169
EPISODE :- 598
Random Player utility: 16.754557
=================Random Agent Turn=================
Action taken: 0.238901
===============Feedback to learned agent round===============
Observation:
[0, 0, 0.2389009890231331]
Reward: -1.000000, Currnt Bid: 0.238901
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[53.0652008]
Explore action: 53.065201
Action taken: 53.065201
===============Feedback to random agent round===============
Currnt Bid: 53.065201
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([53.0652008]), 0.2389009890231331]
Reward: 46.934799, Currnt Bid: 53.065201
Is done? True
Episode End
Positive: 117, Negative: 169
EPISODE :- 599
Random Player utility: 98.392953
=================Random Agent Turn=================
Action taken: 89.848404
===============Feedback to learned agent round===============
Observation:
[0, 0, 89.84840425696453]
Reward: -1.000000, Currnt Bid: 89.848404
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[57.48473814]
Explore action: 57.484738
Action taken: 57.484738
===============Feedback to random agent round===============
Currnt Bid: 89.848404
=================Random Agent Turn=================
Action taken: 92.568743
===============Feedback to learned agent round===============
Observation:
[1, 0, 89.84840425696453]
Reward: -2.000000, Currnt Bid: 89.848404
Is done? True
Episode End
Positive: 117, Negative: 170
EPISODE :- 600
Random Player utility: 68.312787
=================Random Agent Turn=================
Action taken: 48.619026
===============Feedback to learned agent round===============
Observation:
[0, 0, 48.61902615765905]
Reward: -1.000000, Currnt Bid: 48.619026
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.094146
Exploit action: 0.094146
Action taken: 0.094146
===============Feedback to random agent round===============
Currnt Bid: 48.619026
=================Random Agent Turn=================
Action taken: 49.231170
===============Feedback to learned agent round===============
Observation:
[1, 0, 48.61902615765905]
Reward: -2.000000, Currnt Bid: 48.619026
Is done? True
Episode End
Positive: 117, Negative: 171
Models saved successfully
EPISODE :- 601
Random Player utility: 173.506489
=================Random Agent Turn=================
Action taken: 73.877240
===============Feedback to learned agent round===============
Observation:
[0, 0, 73.87723997436879]
Reward: -1.000000, Currnt Bid: 73.877240
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[50.94456281]
Explore action: 50.944563
Action taken: 50.944563
===============Feedback to random agent round===============
Currnt Bid: 73.877240
=================Random Agent Turn=================
Action taken: 105.263205
===============Feedback to learned agent round===============
Observation:
[1, 0, 73.87723997436879]
Reward: -2.000000, Currnt Bid: 73.877240
Is done? True
Episode End
Positive: 117, Negative: 171
EPISODE :- 602
Random Player utility: 238.710441
=================Random Agent Turn=================
Action taken: 180.556505
===============Feedback to learned agent round===============
Observation:
[0, 0, 180.55650456215463]
Reward: -1.000000, Currnt Bid: 180.556505
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[44.1025178]
Explore action: 44.102518
Action taken: 44.102518
===============Feedback to random agent round===============
Currnt Bid: 180.556505
=================Random Agent Turn=================
Action taken: 203.750914
===============Feedback to learned agent round===============
Observation:
[1, 0, 180.55650456215463]
Reward: -2.000000, Currnt Bid: 180.556505
Is done? True
Episode End
Positive: 117, Negative: 171
EPISODE :- 603
Random Player utility: 8.289065
=================Random Agent Turn=================
Action taken: 4.028149
===============Feedback to learned agent round===============
Observation:
[0, 0, 4.028148539515947]
Reward: -1.000000, Currnt Bid: 4.028149
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.31449686]
Explore action: 48.314497
Action taken: 48.314497
===============Feedback to random agent round===============
Currnt Bid: 48.314497
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([48.31449686]), 4.028148539515947]
Reward: 51.685503, Currnt Bid: 48.314497
Is done? True
Episode End
Positive: 118, Negative: 171
EPISODE :- 604
Random Player utility: 87.375427
=================Random Agent Turn=================
Action taken: 32.862366
===============Feedback to learned agent round===============
Observation:
[0, 0, 32.86236611679215]
Reward: -1.000000, Currnt Bid: 32.862366
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[56.00818266]
Explore action: 56.008183
Action taken: 56.008183
===============Feedback to random agent round===============
Currnt Bid: 56.008183
=================Random Agent Turn=================
Action taken: 78.587561
===============Feedback to learned agent round===============
Observation:
[0, array([56.00818266]), array([78.58756093])]
Reward: -1.000000, Currnt Bid: 78.587561
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[66.24680365]
Explore action: 66.246804
Action taken: 66.246804
===============Feedback to random agent round===============
Currnt Bid: 78.587561
=================Random Agent Turn=================
Action taken: 81.883084
===============Feedback to learned agent round===============
Observation:
[1, array([56.00818266]), array([78.58756093])]
Reward: -2.000000, Currnt Bid: 78.587561
Is done? True
Episode End
Positive: 118, Negative: 172
EPISODE :- 605
Random Player utility: 114.433447
=================Random Agent Turn=================
Action taken: 42.553487
===============Feedback to learned agent round===============
Observation:
[0, 0, 42.55348740636204]
Reward: -1.000000, Currnt Bid: 42.553487
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.086862
Exploit action: 0.086862
Action taken: 0.086862
===============Feedback to random agent round===============
Currnt Bid: 42.553487
=================Random Agent Turn=================
Action taken: 65.483541
===============Feedback to learned agent round===============
Observation:
[1, 0, 42.55348740636204]
Reward: -2.000000, Currnt Bid: 42.553487
Is done? True
Episode End
Positive: 118, Negative: 172
EPISODE :- 606
Random Player utility: 45.814772
=================Random Agent Turn=================
Action taken: 20.591195
===============Feedback to learned agent round===============
Observation:
[0, 0, 20.59119507473029]
Reward: -1.000000, Currnt Bid: 20.591195
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[67.80217054]
Explore action: 67.802171
Action taken: 67.802171
===============Feedback to random agent round===============
Currnt Bid: 67.802171
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([67.80217054]), 20.59119507473029]
Reward: 32.197829, Currnt Bid: 67.802171
Is done? True
Episode End
Positive: 119, Negative: 172
EPISODE :- 607
Random Player utility: 136.737751
=================Random Agent Turn=================
Action taken: 3.051391
===============Feedback to learned agent round===============
Observation:
[0, 0, 3.0513912030267933]
Reward: -1.000000, Currnt Bid: 3.051391
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[50.42375752]
Explore action: 50.423758
Action taken: 50.423758
===============Feedback to random agent round===============
Currnt Bid: 50.423758
=================Random Agent Turn=================
Action taken: 74.042760
===============Feedback to learned agent round===============
Observation:
[0, array([50.42375752]), array([74.04275956])]
Reward: -1.000000, Currnt Bid: 74.042760
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.46724935]
Explore action: 48.467249
Action taken: 48.467249
===============Feedback to random agent round===============
Currnt Bid: 74.042760
=================Random Agent Turn=================
Action taken: 99.268324
===============Feedback to learned agent round===============
Observation:
[1, array([50.42375752]), array([74.04275956])]
Reward: -2.000000, Currnt Bid: 74.042760
Is done? True
Episode End
Positive: 119, Negative: 172
EPISODE :- 608
Random Player utility: 161.192272
=================Random Agent Turn=================
Action taken: 145.372947
===============Feedback to learned agent round===============
Observation:
[0, 0, 145.3729469558702]
Reward: -1.000000, Currnt Bid: 145.372947
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[46.55925126]
Explore action: 46.559251
Action taken: 46.559251
===============Feedback to random agent round===============
Currnt Bid: 145.372947
=================Random Agent Turn=================
Action taken: 147.295308
===============Feedback to learned agent round===============
Observation:
[1, 0, 145.3729469558702]
Reward: -2.000000, Currnt Bid: 145.372947
Is done? True
Episode End
Positive: 119, Negative: 172
EPISODE :- 609
Random Player utility: 155.749834
=================Random Agent Turn=================
Action taken: 122.214690
===============Feedback to learned agent round===============
Observation:
[0, 0, 122.21469020807845]
Reward: -1.000000, Currnt Bid: 122.214690
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[52.24268173]
Explore action: 52.242682
Action taken: 52.242682
===============Feedback to random agent round===============
Currnt Bid: 122.214690
=================Random Agent Turn=================
Action taken: 130.394838
===============Feedback to learned agent round===============
Observation:
[1, 0, 122.21469020807845]
Reward: -2.000000, Currnt Bid: 122.214690
Is done? True
Episode End
Positive: 119, Negative: 172
EPISODE :- 610
Random Player utility: 110.446250
=================Random Agent Turn=================
Action taken: 18.281409
===============Feedback to learned agent round===============
Observation:
[0, 0, 18.2814091208665]
Reward: -1.000000, Currnt Bid: 18.281409
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.080156
Exploit action: 0.080156
Action taken: 0.080156
===============Feedback to random agent round===============
Currnt Bid: 18.281409
=================Random Agent Turn=================
Action taken: 44.992285
===============Feedback to learned agent round===============
Observation:
[1, 0, 18.2814091208665]
Reward: -2.000000, Currnt Bid: 18.281409
Is done? True
Episode End
Positive: 119, Negative: 172
EPISODE :- 611
Random Player utility: 99.275294
=================Random Agent Turn=================
Action taken: 17.876989
===============Feedback to learned agent round===============
Observation:
[0, 0, 17.876988532917146]
Reward: -1.000000, Currnt Bid: 17.876989
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.46876536]
Explore action: 48.468765
Action taken: 48.468765
===============Feedback to random agent round===============
Currnt Bid: 48.468765
=================Random Agent Turn=================
Action taken: 77.400780
===============Feedback to learned agent round===============
Observation:
[0, array([48.46876536]), array([77.40078047])]
Reward: -1.000000, Currnt Bid: 77.400780
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[54.25625891]
Explore action: 54.256259
Action taken: 54.256259
===============Feedback to random agent round===============
Currnt Bid: 77.400780
=================Random Agent Turn=================
Action taken: 94.653385
===============Feedback to learned agent round===============
Observation:
[1, array([48.46876536]), array([77.40078047])]
Reward: -2.000000, Currnt Bid: 77.400780
Is done? True
Episode End
Positive: 119, Negative: 173
EPISODE :- 612
Random Player utility: 113.576876
=================Random Agent Turn=================
Action taken: 80.160039
===============Feedback to learned agent round===============
Observation:
[0, 0, 80.16003875687889]
Reward: -1.000000, Currnt Bid: 80.160039
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[59.10293788]
Explore action: 59.102938
Action taken: 59.102938
===============Feedback to random agent round===============
Currnt Bid: 80.160039
=================Random Agent Turn=================
Action taken: 110.510099
===============Feedback to learned agent round===============
Observation:
[1, 0, 80.16003875687889]
Reward: -2.000000, Currnt Bid: 80.160039
Is done? True
Episode End
Positive: 119, Negative: 173
EPISODE :- 613
Random Player utility: 191.137056
=================Random Agent Turn=================
Action taken: 22.019428
===============Feedback to learned agent round===============
Observation:
[0, 0, 22.019428411823323]
Reward: -1.000000, Currnt Bid: 22.019428
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[46.8046775]
Explore action: 46.804677
Action taken: 46.804677
===============Feedback to random agent round===============
Currnt Bid: 46.804677
=================Random Agent Turn=================
Action taken: 48.718330
===============Feedback to learned agent round===============
Observation:
[0, array([46.8046775]), array([48.71833019])]
Reward: -1.000000, Currnt Bid: 48.718330
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[65.0044471]
Explore action: 65.004447
Action taken: 65.004447
===============Feedback to random agent round===============
Currnt Bid: 65.004447
=================Random Agent Turn=================
Action taken: 83.021566
===============Feedback to learned agent round===============
Observation:
[0, array([65.0044471]), array([83.02156569])]
Reward: -1.000000, Currnt Bid: 83.021566
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[44.88636768]
Explore action: 44.886368
Action taken: 44.886368
===============Feedback to random agent round===============
Currnt Bid: 83.021566
=================Random Agent Turn=================
Action taken: 110.204858
===============Feedback to learned agent round===============
Observation:
[1, array([65.0044471]), array([83.02156569])]
Reward: -2.000000, Currnt Bid: 83.021566
Is done? True
Episode End
Positive: 119, Negative: 173
EPISODE :- 614
Random Player utility: 56.005193
=================Random Agent Turn=================
Action taken: 32.376012
===============Feedback to learned agent round===============
Observation:
[0, 0, 32.376011697249865]
Reward: -1.000000, Currnt Bid: 32.376012
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[40.84779111]
Explore action: 40.847791
Action taken: 40.847791
===============Feedback to random agent round===============
Currnt Bid: 40.847791
=================Random Agent Turn=================
Action taken: 46.106034
===============Feedback to learned agent round===============
Observation:
[0, array([40.84779111]), array([46.1060336])]
Reward: -1.000000, Currnt Bid: 46.106034
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[43.79121771]
Explore action: 43.791218
Action taken: 43.791218
===============Feedback to random agent round===============
Currnt Bid: 46.106034
=================Random Agent Turn=================
Action taken: 48.931192
===============Feedback to learned agent round===============
Observation:
[1, array([40.84779111]), array([46.1060336])]
Reward: -2.000000, Currnt Bid: 46.106034
Is done? True
Episode End
Positive: 119, Negative: 174
EPISODE :- 615
Random Player utility: 77.450202
=================Random Agent Turn=================
Action taken: 40.031490
===============Feedback to learned agent round===============
Observation:
[0, 0, 40.031489878702025]
Reward: -1.000000, Currnt Bid: 40.031490
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.072402
Exploit action: 0.072402
Action taken: 0.072402
===============Feedback to random agent round===============
Currnt Bid: 40.031490
=================Random Agent Turn=================
Action taken: 71.461356
===============Feedback to learned agent round===============
Observation:
[1, 0, 40.031489878702025]
Reward: -2.000000, Currnt Bid: 40.031490
Is done? True
Episode End
Positive: 119, Negative: 175
EPISODE :- 616
Random Player utility: 212.331932
=================Random Agent Turn=================
Action taken: 115.269612
===============Feedback to learned agent round===============
Observation:
[0, 0, 115.26961213643666]
Reward: -1.000000, Currnt Bid: 115.269612
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.21572465]
Explore action: 48.215725
Action taken: 48.215725
===============Feedback to random agent round===============
Currnt Bid: 115.269612
=================Random Agent Turn=================
Action taken: 211.045779
===============Feedback to learned agent round===============
Observation:
[1, 0, 115.26961213643666]
Reward: -2.000000, Currnt Bid: 115.269612
Is done? True
Episode End
Positive: 119, Negative: 175
EPISODE :- 617
Random Player utility: 23.986271
=================Random Agent Turn=================
Action taken: 2.373172
===============Feedback to learned agent round===============
Observation:
[0, 0, 2.373172210711809]
Reward: -1.000000, Currnt Bid: 2.373172
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[30.41007219]
Explore action: 30.410072
Action taken: 30.410072
===============Feedback to random agent round===============
Currnt Bid: 30.410072
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([30.41007219]), 2.373172210711809]
Reward: 69.589928, Currnt Bid: 30.410072
Is done? True
Episode End
Positive: 120, Negative: 175
EPISODE :- 618
Random Player utility: 194.880549
=================Random Agent Turn=================
Action taken: 77.978318
===============Feedback to learned agent round===============
Observation:
[0, 0, 77.97831826186332]
Reward: -1.000000, Currnt Bid: 77.978318
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[24.74955651]
Explore action: 24.749557
Action taken: 24.749557
===============Feedback to random agent round===============
Currnt Bid: 77.978318
=================Random Agent Turn=================
Action taken: 177.585311
===============Feedback to learned agent round===============
Observation:
[1, 0, 77.97831826186332]
Reward: -2.000000, Currnt Bid: 77.978318
Is done? True
Episode End
Positive: 120, Negative: 175
EPISODE :- 619
Random Player utility: 157.548643
=================Random Agent Turn=================
Action taken: 111.552527
===============Feedback to learned agent round===============
Observation:
[0, 0, 111.55252709653519]
Reward: -1.000000, Currnt Bid: 111.552527
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[5.8758063]
Explore action: 5.875806
Action taken: 5.875806
===============Feedback to random agent round===============
Currnt Bid: 111.552527
=================Random Agent Turn=================
Action taken: 152.177978
===============Feedback to learned agent round===============
Observation:
[1, 0, 111.55252709653519]
Reward: -2.000000, Currnt Bid: 111.552527
Is done? True
Episode End
Positive: 120, Negative: 175
EPISODE :- 620
Random Player utility: 75.683524
=================Random Agent Turn=================
Action taken: 58.789940
===============Feedback to learned agent round===============
Observation:
[0, 0, 58.789939800164326]
Reward: -1.000000, Currnt Bid: 58.789940
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.067347
Exploit action: 0.067347
Action taken: 0.067347
===============Feedback to random agent round===============
Currnt Bid: 58.789940
=================Random Agent Turn=================
Action taken: 65.379514
===============Feedback to learned agent round===============
Observation:
[1, 0, 58.789939800164326]
Reward: -2.000000, Currnt Bid: 58.789940
Is done? True
Episode End
Positive: 120, Negative: 176
EPISODE :- 621
Random Player utility: 108.524375
=================Random Agent Turn=================
Action taken: 91.099321
===============Feedback to learned agent round===============
Observation:
[0, 0, 91.09932067326807]
Reward: -1.000000, Currnt Bid: 91.099321
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[0.95659027]
Explore action: 0.956590
Action taken: 0.956590
===============Feedback to random agent round===============
Currnt Bid: 91.099321
=================Random Agent Turn=================
Action taken: 103.257676
===============Feedback to learned agent round===============
Observation:
[1, 0, 91.09932067326807]
Reward: -2.000000, Currnt Bid: 91.099321
Is done? True
Episode End
Positive: 120, Negative: 176
EPISODE :- 622
Random Player utility: 36.711694
=================Random Agent Turn=================
Action taken: 11.090050
===============Feedback to learned agent round===============
Observation:
[0, 0, 11.090050488848474]
Reward: -1.000000, Currnt Bid: 11.090050
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[-1.41560033]
Explore action: -1.415600
Action taken: -1.415600
===============Feedback to random agent round===============
Currnt Bid: 11.090050
=================Random Agent Turn=================
Action taken: 11.728701
===============Feedback to learned agent round===============
Observation:
[1, 0, 11.090050488848474]
Reward: -2.000000, Currnt Bid: 11.090050
Is done? True
Episode End
Positive: 120, Negative: 177
EPISODE :- 623
Random Player utility: 60.553802
=================Random Agent Turn=================
Action taken: 46.199226
===============Feedback to learned agent round===============
Observation:
[0, 0, 46.1992258725152]
Reward: -1.000000, Currnt Bid: 46.199226
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[-0.33539815]
Explore action: -0.335398
Action taken: -0.335398
===============Feedback to random agent round===============
Currnt Bid: 46.199226
=================Random Agent Turn=================
Action taken: 48.928530
===============Feedback to learned agent round===============
Observation:
[1, 0, 46.1992258725152]
Reward: -2.000000, Currnt Bid: 46.199226
Is done? True
Episode End
Positive: 120, Negative: 178
EPISODE :- 624
Random Player utility: 76.093075
=================Random Agent Turn=================
Action taken: 71.510470
===============Feedback to learned agent round===============
Observation:
[0, 0, 71.51046966307857]
Reward: -1.000000, Currnt Bid: 71.510470
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[10.19951024]
Explore action: 10.199510
Action taken: 10.199510
===============Feedback to random agent round===============
Currnt Bid: 71.510470
=================Random Agent Turn=================
Action taken: 74.964193
===============Feedback to learned agent round===============
Observation:
[1, 0, 71.51046966307857]
Reward: -2.000000, Currnt Bid: 71.510470
Is done? True
Episode End
Positive: 120, Negative: 179
EPISODE :- 625
Random Player utility: 68.735091
=================Random Agent Turn=================
Action taken: 42.919531
===============Feedback to learned agent round===============
Observation:
[0, 0, 42.919531027692535]
Reward: -1.000000, Currnt Bid: 42.919531
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.062662
Exploit action: 0.062662
Action taken: 0.062662
===============Feedback to random agent round===============
Currnt Bid: 42.919531
=================Random Agent Turn=================
Action taken: 63.471394
===============Feedback to learned agent round===============
Observation:
[1, 0, 42.919531027692535]
Reward: -2.000000, Currnt Bid: 42.919531
Is done? True
Episode End
Positive: 120, Negative: 180
EPISODE :- 626
Random Player utility: 95.130926
=================Random Agent Turn=================
Action taken: 68.494232
===============Feedback to learned agent round===============
Observation:
[0, 0, 68.49423154116178]
Reward: -1.000000, Currnt Bid: 68.494232
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[16.05754459]
Explore action: 16.057545
Action taken: 16.057545
===============Feedback to random agent round===============
Currnt Bid: 68.494232
=================Random Agent Turn=================
Action taken: 89.988713
===============Feedback to learned agent round===============
Observation:
[1, 0, 68.49423154116178]
Reward: -2.000000, Currnt Bid: 68.494232
Is done? True
Episode End
Positive: 120, Negative: 181
EPISODE :- 627
Random Player utility: 144.026387
=================Random Agent Turn=================
Action taken: 72.870931
===============Feedback to learned agent round===============
Observation:
[0, 0, 72.87093129691189]
Reward: -1.000000, Currnt Bid: 72.870931
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[0.33285581]
Explore action: 0.332856
Action taken: 0.332856
===============Feedback to random agent round===============
Currnt Bid: 72.870931
=================Random Agent Turn=================
Action taken: 138.012075
===============Feedback to learned agent round===============
Observation:
[1, 0, 72.87093129691189]
Reward: -2.000000, Currnt Bid: 72.870931
Is done? True
Episode End
Positive: 120, Negative: 181
EPISODE :- 628
Random Player utility: 121.161288
=================Random Agent Turn=================
Action taken: 68.467345
===============Feedback to learned agent round===============
Observation:
[0, 0, 68.46734511873912]
Reward: -1.000000, Currnt Bid: 68.467345
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[10.98951234]
Explore action: 10.989512
Action taken: 10.989512
===============Feedback to random agent round===============
Currnt Bid: 68.467345
=================Random Agent Turn=================
Action taken: 114.101656
===============Feedback to learned agent round===============
Observation:
[1, 0, 68.46734511873912]
Reward: -2.000000, Currnt Bid: 68.467345
Is done? True
Episode End
Positive: 120, Negative: 181
EPISODE :- 629
Random Player utility: 34.650670
=================Random Agent Turn=================
Action taken: 17.040975
===============Feedback to learned agent round===============
Observation:
[0, 0, 17.040974567925577]
Reward: -1.000000, Currnt Bid: 17.040975
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[17.99538894]
Explore action: 17.995389
Action taken: 17.995389
===============Feedback to random agent round===============
Currnt Bid: 17.995389
=================Random Agent Turn=================
Action taken: 22.926198
===============Feedback to learned agent round===============
Observation:
[0, array([17.99538894]), array([22.92619757])]
Reward: -1.000000, Currnt Bid: 22.926198
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[29.03085684]
Explore action: 29.030857
Action taken: 29.030857
===============Feedback to random agent round===============
Currnt Bid: 29.030857
=================Random Agent Turn=================
Action taken: 33.620713
===============Feedback to learned agent round===============
Observation:
[0, array([29.03085684]), array([33.62071326])]
Reward: -1.000000, Currnt Bid: 33.620713
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[40.52212649]
Explore action: 40.522126
Action taken: 40.522126
===============Feedback to random agent round===============
Currnt Bid: 40.522126
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([40.52212649]), array([33.62071326])]
Reward: 59.477874, Currnt Bid: 40.522126
Is done? True
Episode End
Positive: 121, Negative: 181
EPISODE :- 630
Random Player utility: 114.949013
=================Random Agent Turn=================
Action taken: 31.784233
===============Feedback to learned agent round===============
Observation:
[0, 0, 31.784232829802015]
Reward: -1.000000, Currnt Bid: 31.784233
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.057489
Exploit action: 0.057489
Action taken: 0.057489
===============Feedback to random agent round===============
Currnt Bid: 31.784233
=================Random Agent Turn=================
Action taken: 108.290918
===============Feedback to learned agent round===============
Observation:
[1, 0, 31.784232829802015]
Reward: -2.000000, Currnt Bid: 31.784233
Is done? True
Episode End
Positive: 121, Negative: 181
EPISODE :- 631
Random Player utility: 88.402040
=================Random Agent Turn=================
Action taken: 5.546179
===============Feedback to learned agent round===============
Observation:
[0, 0, 5.546178673446852]
Reward: -1.000000, Currnt Bid: 5.546179
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[51.53696306]
Explore action: 51.536963
Action taken: 51.536963
===============Feedback to random agent round===============
Currnt Bid: 51.536963
=================Random Agent Turn=================
Action taken: 75.700836
===============Feedback to learned agent round===============
Observation:
[0, array([51.53696306]), array([75.70083648])]
Reward: -1.000000, Currnt Bid: 75.700836
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[45.88538051]
Explore action: 45.885381
Action taken: 45.885381
===============Feedback to random agent round===============
Currnt Bid: 75.700836
=================Random Agent Turn=================
Action taken: 82.491334
===============Feedback to learned agent round===============
Observation:
[1, array([51.53696306]), array([75.70083648])]
Reward: -2.000000, Currnt Bid: 75.700836
Is done? True
Episode End
Positive: 121, Negative: 182
EPISODE :- 632
Random Player utility: 81.740683
=================Random Agent Turn=================
Action taken: 58.857039
===============Feedback to learned agent round===============
Observation:
[0, 0, 58.85703918612569]
Reward: -1.000000, Currnt Bid: 58.857039
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[47.9407982]
Explore action: 47.940798
Action taken: 47.940798
===============Feedback to random agent round===============
Currnt Bid: 58.857039
=================Random Agent Turn=================
Action taken: 70.034220
===============Feedback to learned agent round===============
Observation:
[1, 0, 58.85703918612569]
Reward: -2.000000, Currnt Bid: 58.857039
Is done? True
Episode End
Positive: 121, Negative: 183
EPISODE :- 633
Random Player utility: 158.497302
=================Random Agent Turn=================
Action taken: 53.069360
===============Feedback to learned agent round===============
Observation:
[0, 0, 53.06935966289509]
Reward: -1.000000, Currnt Bid: 53.069360
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[29.45975743]
Explore action: 29.459757
Action taken: 29.459757
===============Feedback to random agent round===============
Currnt Bid: 53.069360
=================Random Agent Turn=================
Action taken: 56.310191
===============Feedback to learned agent round===============
Observation:
[1, 0, 53.06935966289509]
Reward: -2.000000, Currnt Bid: 53.069360
Is done? True
Episode End
Positive: 121, Negative: 183
EPISODE :- 634
Random Player utility: 33.730001
=================Random Agent Turn=================
Action taken: 24.879539
===============Feedback to learned agent round===============
Observation:
[0, 0, 24.87953907254735]
Reward: -1.000000, Currnt Bid: 24.879539
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[44.09017572]
Explore action: 44.090176
Action taken: 44.090176
===============Feedback to random agent round===============
Currnt Bid: 44.090176
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([44.09017572]), 24.87953907254735]
Reward: 55.909824, Currnt Bid: 44.090176
Is done? True
Episode End
Positive: 122, Negative: 183
EPISODE :- 635
Random Player utility: 79.941252
=================Random Agent Turn=================
Action taken: 43.170700
===============Feedback to learned agent round===============
Observation:
[0, 0, 43.17069998073737]
Reward: -1.000000, Currnt Bid: 43.170700
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.053138
Exploit action: 0.053138
Action taken: 0.053138
===============Feedback to random agent round===============
Currnt Bid: 43.170700
=================Random Agent Turn=================
Action taken: 55.169471
===============Feedback to learned agent round===============
Observation:
[1, 0, 43.17069998073737]
Reward: -2.000000, Currnt Bid: 43.170700
Is done? True
Episode End
Positive: 122, Negative: 184
EPISODE :- 636
Random Player utility: 54.677848
=================Random Agent Turn=================
Action taken: 18.551514
===============Feedback to learned agent round===============
Observation:
[0, 0, 18.551513641752788]
Reward: -1.000000, Currnt Bid: 18.551514
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[34.3282922]
Explore action: 34.328292
Action taken: 34.328292
===============Feedback to random agent round===============
Currnt Bid: 34.328292
=================Random Agent Turn=================
Action taken: 45.820626
===============Feedback to learned agent round===============
Observation:
[0, array([34.3282922]), array([45.82062554])]
Reward: -1.000000, Currnt Bid: 45.820626
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[30.59756921]
Explore action: 30.597569
Action taken: 30.597569
===============Feedback to random agent round===============
Currnt Bid: 45.820626
=================Random Agent Turn=================
Action taken: 53.789444
===============Feedback to learned agent round===============
Observation:
[1, array([34.3282922]), array([45.82062554])]
Reward: -2.000000, Currnt Bid: 45.820626
Is done? True
Episode End
Positive: 122, Negative: 185
EPISODE :- 637
Random Player utility: 141.903685
=================Random Agent Turn=================
Action taken: 108.317860
===============Feedback to learned agent round===============
Observation:
[0, 0, 108.3178597218563]
Reward: -1.000000, Currnt Bid: 108.317860
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[31.41042972]
Explore action: 31.410430
Action taken: 31.410430
===============Feedback to random agent round===============
Currnt Bid: 108.317860
=================Random Agent Turn=================
Action taken: 116.529348
===============Feedback to learned agent round===============
Observation:
[1, 0, 108.3178597218563]
Reward: -2.000000, Currnt Bid: 108.317860
Is done? True
Episode End
Positive: 122, Negative: 185
EPISODE :- 638
Random Player utility: 121.419352
=================Random Agent Turn=================
Action taken: 7.104506
===============Feedback to learned agent round===============
Observation:
[0, 0, 7.104505544695311]
Reward: -1.000000, Currnt Bid: 7.104506
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[32.72774105]
Explore action: 32.727741
Action taken: 32.727741
===============Feedback to random agent round===============
Currnt Bid: 32.727741
=================Random Agent Turn=================
Action taken: 76.907777
===============Feedback to learned agent round===============
Observation:
[0, array([32.72774105]), array([76.90777693])]
Reward: -1.000000, Currnt Bid: 76.907777
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[55.53148538]
Explore action: 55.531485
Action taken: 55.531485
===============Feedback to random agent round===============
Currnt Bid: 76.907777
=================Random Agent Turn=================
Action taken: 111.934310
===============Feedback to learned agent round===============
Observation:
[1, array([32.72774105]), array([76.90777693])]
Reward: -2.000000, Currnt Bid: 76.907777
Is done? True
Episode End
Positive: 122, Negative: 185
EPISODE :- 639
Random Player utility: 102.515977
=================Random Agent Turn=================
Action taken: 26.840916
===============Feedback to learned agent round===============
Observation:
[0, 0, 26.840916438349492]
Reward: -1.000000, Currnt Bid: 26.840916
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[38.55781556]
Explore action: 38.557816
Action taken: 38.557816
===============Feedback to random agent round===============
Currnt Bid: 38.557816
=================Random Agent Turn=================
Action taken: 45.953679
===============Feedback to learned agent round===============
Observation:
[0, array([38.55781556]), array([45.95367881])]
Reward: -1.000000, Currnt Bid: 45.953679
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[35.66831957]
Explore action: 35.668320
Action taken: 35.668320
===============Feedback to random agent round===============
Currnt Bid: 45.953679
=================Random Agent Turn=================
Action taken: 92.212733
===============Feedback to learned agent round===============
Observation:
[1, array([38.55781556]), array([45.95367881])]
Reward: -2.000000, Currnt Bid: 45.953679
Is done? True
Episode End
Positive: 122, Negative: 185
EPISODE :- 640
Random Player utility: 67.733785
=================Random Agent Turn=================
Action taken: 3.255017
===============Feedback to learned agent round===============
Observation:
[0, 0, 3.255016571652993]
Reward: -1.000000, Currnt Bid: 3.255017
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.048441
Exploit action: 0.048441
Action taken: 0.048441
===============Feedback to random agent round===============
Currnt Bid: 3.255017
=================Random Agent Turn=================
Action taken: 31.531555
===============Feedback to learned agent round===============
Observation:
[1, 0, 3.255016571652993]
Reward: -2.000000, Currnt Bid: 3.255017
Is done? True
Episode End
Positive: 122, Negative: 186
EPISODE :- 641
Random Player utility: 132.252329
=================Random Agent Turn=================
Action taken: 99.980383
===============Feedback to learned agent round===============
Observation:
[0, 0, 99.9803829397626]
Reward: -1.000000, Currnt Bid: 99.980383
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[40.3682065]
Explore action: 40.368207
Action taken: 40.368207
===============Feedback to random agent round===============
Currnt Bid: 99.980383
=================Random Agent Turn=================
Action taken: 111.827718
===============Feedback to learned agent round===============
Observation:
[1, 0, 99.9803829397626]
Reward: -2.000000, Currnt Bid: 99.980383
Is done? True
Episode End
Positive: 122, Negative: 186
EPISODE :- 642
Random Player utility: 55.942227
=================Random Agent Turn=================
Action taken: 25.949157
===============Feedback to learned agent round===============
Observation:
[0, 0, 25.949156836383743]
Reward: -1.000000, Currnt Bid: 25.949157
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[57.43681337]
Explore action: 57.436813
Action taken: 57.436813
===============Feedback to random agent round===============
Currnt Bid: 57.436813
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([57.43681337]), 25.949156836383743]
Reward: 42.563187, Currnt Bid: 57.436813
Is done? True
Episode End
Positive: 123, Negative: 186
EPISODE :- 643
Random Player utility: 67.297068
=================Random Agent Turn=================
Action taken: 14.041467
===============Feedback to learned agent round===============
Observation:
[0, 0, 14.041466898222822]
Reward: -1.000000, Currnt Bid: 14.041467
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[46.50643312]
Explore action: 46.506433
Action taken: 46.506433
===============Feedback to random agent round===============
Currnt Bid: 46.506433
=================Random Agent Turn=================
Action taken: 58.191385
===============Feedback to learned agent round===============
Observation:
[0, array([46.50643312]), array([58.19138461])]
Reward: -1.000000, Currnt Bid: 58.191385
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[47.31029109]
Explore action: 47.310291
Action taken: 47.310291
===============Feedback to random agent round===============
Currnt Bid: 58.191385
=================Random Agent Turn=================
Action taken: 63.428423
===============Feedback to learned agent round===============
Observation:
[1, array([46.50643312]), array([58.19138461])]
Reward: -2.000000, Currnt Bid: 58.191385
Is done? True
Episode End
Positive: 123, Negative: 187
EPISODE :- 644
Random Player utility: 60.323749
=================Random Agent Turn=================
Action taken: 11.184924
===============Feedback to learned agent round===============
Observation:
[0, 0, 11.184924146779787]
Reward: -1.000000, Currnt Bid: 11.184924
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[36.08090805]
Explore action: 36.080908
Action taken: 36.080908
===============Feedback to random agent round===============
Currnt Bid: 36.080908
=================Random Agent Turn=================
Action taken: 53.786230
===============Feedback to learned agent round===============
Observation:
[0, array([36.08090805]), array([53.78623018])]
Reward: -1.000000, Currnt Bid: 53.786230
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[21.87427869]
Explore action: 21.874279
Action taken: 21.874279
===============Feedback to random agent round===============
Currnt Bid: 53.786230
=================Random Agent Turn=================
Action taken: 55.079254
===============Feedback to learned agent round===============
Observation:
[1, array([36.08090805]), array([53.78623018])]
Reward: -2.000000, Currnt Bid: 53.786230
Is done? True
Episode End
Positive: 123, Negative: 188
EPISODE :- 645
Random Player utility: 179.483276
=================Random Agent Turn=================
Action taken: 90.833629
===============Feedback to learned agent round===============
Observation:
[0, 0, 90.83362897584234]
Reward: -1.000000, Currnt Bid: 90.833629
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.044495
Exploit action: 0.044495
Action taken: 0.044495
===============Feedback to random agent round===============
Currnt Bid: 90.833629
=================Random Agent Turn=================
Action taken: 134.075970
===============Feedback to learned agent round===============
Observation:
[1, 0, 90.83362897584234]
Reward: -2.000000, Currnt Bid: 90.833629
Is done? True
Episode End
Positive: 123, Negative: 188
EPISODE :- 646
Random Player utility: 132.416133
=================Random Agent Turn=================
Action taken: 2.987485
===============Feedback to learned agent round===============
Observation:
[0, 0, 2.987484921633187]
Reward: -1.000000, Currnt Bid: 2.987485
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[32.72847801]
Explore action: 32.728478
Action taken: 32.728478
===============Feedback to random agent round===============
Currnt Bid: 32.728478
=================Random Agent Turn=================
Action taken: 110.313279
===============Feedback to learned agent round===============
Observation:
[0, array([32.72847801]), array([110.31327875])]
Reward: -1.000000, Currnt Bid: 110.313279
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[13.40336782]
Explore action: 13.403368
Action taken: 13.403368
===============Feedback to random agent round===============
Currnt Bid: 110.313279
=================Random Agent Turn=================
Action taken: 121.615399
===============Feedback to learned agent round===============
Observation:
[1, array([32.72847801]), array([110.31327875])]
Reward: -2.000000, Currnt Bid: 110.313279
Is done? True
Episode End
Positive: 123, Negative: 188
EPISODE :- 647
Random Player utility: 177.832865
=================Random Agent Turn=================
Action taken: 71.442636
===============Feedback to learned agent round===============
Observation:
[0, 0, 71.4426361012914]
Reward: -1.000000, Currnt Bid: 71.442636
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[17.81996857]
Explore action: 17.819969
Action taken: 17.819969
===============Feedback to random agent round===============
Currnt Bid: 71.442636
=================Random Agent Turn=================
Action taken: 167.675267
===============Feedback to learned agent round===============
Observation:
[1, 0, 71.4426361012914]
Reward: -2.000000, Currnt Bid: 71.442636
Is done? True
Episode End
Positive: 123, Negative: 188
EPISODE :- 648
Random Player utility: 44.916547
=================Random Agent Turn=================
Action taken: 17.726874
===============Feedback to learned agent round===============
Observation:
[0, 0, 17.726873693126787]
Reward: -1.000000, Currnt Bid: 17.726874
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[23.1354352]
Explore action: 23.135435
Action taken: 23.135435
===============Feedback to random agent round===============
Currnt Bid: 23.135435
=================Random Agent Turn=================
Action taken: 25.286306
===============Feedback to learned agent round===============
Observation:
[0, array([23.1354352]), array([25.28630618])]
Reward: -1.000000, Currnt Bid: 25.286306
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[16.35286442]
Explore action: 16.352864
Action taken: 16.352864
===============Feedback to random agent round===============
Currnt Bid: 25.286306
=================Random Agent Turn=================
Action taken: 40.164647
===============Feedback to learned agent round===============
Observation:
[1, array([23.1354352]), array([25.28630618])]
Reward: -2.000000, Currnt Bid: 25.286306
Is done? True
Episode End
Positive: 123, Negative: 189
EPISODE :- 649
Random Player utility: 133.953714
=================Random Agent Turn=================
Action taken: 28.790766
===============Feedback to learned agent round===============
Observation:
[0, 0, 28.790766223862136]
Reward: -1.000000, Currnt Bid: 28.790766
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[16.70200942]
Explore action: 16.702009
Action taken: 16.702009
===============Feedback to random agent round===============
Currnt Bid: 28.790766
=================Random Agent Turn=================
Action taken: 67.920465
===============Feedback to learned agent round===============
Observation:
[1, 0, 28.790766223862136]
Reward: -2.000000, Currnt Bid: 28.790766
Is done? True
Episode End
Positive: 123, Negative: 189
EPISODE :- 650
Random Player utility: 99.305033
=================Random Agent Turn=================
Action taken: 67.316657
===============Feedback to learned agent round===============
Observation:
[0, 0, 67.31665673438249]
Reward: -1.000000, Currnt Bid: 67.316657
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.040883
Exploit action: 0.040883
Action taken: 0.040883
===============Feedback to random agent round===============
Currnt Bid: 67.316657
=================Random Agent Turn=================
Action taken: 83.336444
===============Feedback to learned agent round===============
Observation:
[1, 0, 67.31665673438249]
Reward: -2.000000, Currnt Bid: 67.316657
Is done? True
Episode End
Positive: 123, Negative: 190
EPISODE :- 651
Random Player utility: 55.345547
=================Random Agent Turn=================
Action taken: 52.815618
===============Feedback to learned agent round===============
Observation:
[0, 0, 52.81561828255612]
Reward: -1.000000, Currnt Bid: 52.815618
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[22.17668202]
Explore action: 22.176682
Action taken: 22.176682
===============Feedback to random agent round===============
Currnt Bid: 52.815618
=================Random Agent Turn=================
Action taken: 52.946900
===============Feedback to learned agent round===============
Observation:
[1, 0, 52.81561828255612]
Reward: -2.000000, Currnt Bid: 52.815618
Is done? True
Episode End
Positive: 123, Negative: 191
EPISODE :- 652
Random Player utility: 16.656334
=================Random Agent Turn=================
Action taken: 1.043793
===============Feedback to learned agent round===============
Observation:
[0, 0, 1.0437927858467386]
Reward: -1.000000, Currnt Bid: 1.043793
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[36.20076233]
Explore action: 36.200762
Action taken: 36.200762
===============Feedback to random agent round===============
Currnt Bid: 36.200762
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([36.20076233]), 1.0437927858467386]
Reward: 63.799238, Currnt Bid: 36.200762
Is done? True
Episode End
Positive: 124, Negative: 191
EPISODE :- 653
Random Player utility: 59.615488
=================Random Agent Turn=================
Action taken: 38.614556
===============Feedback to learned agent round===============
Observation:
[0, 0, 38.614555966152786]
Reward: -1.000000, Currnt Bid: 38.614556
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[39.0309674]
Explore action: 39.030967
Action taken: 39.030967
===============Feedback to random agent round===============
Currnt Bid: 39.030967
=================Random Agent Turn=================
Action taken: 44.067964
===============Feedback to learned agent round===============
Observation:
[0, array([39.0309674]), array([44.06796401])]
Reward: -1.000000, Currnt Bid: 44.067964
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[35.5186463]
Explore action: 35.518646
Action taken: 35.518646
===============Feedback to random agent round===============
Currnt Bid: 44.067964
=================Random Agent Turn=================
Action taken: 45.474171
===============Feedback to learned agent round===============
Observation:
[1, array([39.0309674]), array([44.06796401])]
Reward: -2.000000, Currnt Bid: 44.067964
Is done? True
Episode End
Positive: 124, Negative: 192
EPISODE :- 654
Random Player utility: 167.495354
=================Random Agent Turn=================
Action taken: 95.792515
===============Feedback to learned agent round===============
Observation:
[0, 0, 95.7925150005875]
Reward: -1.000000, Currnt Bid: 95.792515
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[13.09276193]
Explore action: 13.092762
Action taken: 13.092762
===============Feedback to random agent round===============
Currnt Bid: 95.792515
=================Random Agent Turn=================
Action taken: 124.428723
===============Feedback to learned agent round===============
Observation:
[1, 0, 95.7925150005875]
Reward: -2.000000, Currnt Bid: 95.792515
Is done? True
Episode End
Positive: 124, Negative: 192
EPISODE :- 655
Random Player utility: 33.620547
=================Random Agent Turn=================
Action taken: 4.302617
===============Feedback to learned agent round===============
Observation:
[0, 0, 4.302616857852566]
Reward: -1.000000, Currnt Bid: 4.302617
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.037849
Exploit action: 0.037849
Action taken: 0.037849
===============Feedback to random agent round===============
Currnt Bid: 4.302617
=================Random Agent Turn=================
Action taken: 30.969458
===============Feedback to learned agent round===============
Observation:
[1, 0, 4.302616857852566]
Reward: -2.000000, Currnt Bid: 4.302617
Is done? True
Episode End
Positive: 124, Negative: 193
EPISODE :- 656
Random Player utility: 146.145046
=================Random Agent Turn=================
Action taken: 133.084235
===============Feedback to learned agent round===============
Observation:
[0, 0, 133.08423546767224]
Reward: -1.000000, Currnt Bid: 133.084235
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[16.41143506]
Explore action: 16.411435
Action taken: 16.411435
===============Feedback to random agent round===============
Currnt Bid: 133.084235
=================Random Agent Turn=================
Action taken: 136.810773
===============Feedback to learned agent round===============
Observation:
[1, 0, 133.08423546767224]
Reward: -2.000000, Currnt Bid: 133.084235
Is done? True
Episode End
Positive: 124, Negative: 193
EPISODE :- 657
Random Player utility: 53.484048
=================Random Agent Turn=================
Action taken: 36.086189
===============Feedback to learned agent round===============
Observation:
[0, 0, 36.086188999470195]
Reward: -1.000000, Currnt Bid: 36.086189
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[31.18079448]
Explore action: 31.180794
Action taken: 31.180794
===============Feedback to random agent round===============
Currnt Bid: 36.086189
=================Random Agent Turn=================
Action taken: 44.181313
===============Feedback to learned agent round===============
Observation:
[1, 0, 36.086188999470195]
Reward: -2.000000, Currnt Bid: 36.086189
Is done? True
Episode End
Positive: 124, Negative: 194
EPISODE :- 658
Random Player utility: 11.581667
=================Random Agent Turn=================
Action taken: 5.809621
===============Feedback to learned agent round===============
Observation:
[0, 0, 5.809620569416819]
Reward: -1.000000, Currnt Bid: 5.809621
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[47.37529084]
Explore action: 47.375291
Action taken: 47.375291
===============Feedback to random agent round===============
Currnt Bid: 47.375291
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([47.37529084]), 5.809620569416819]
Reward: 52.624709, Currnt Bid: 47.375291
Is done? True
Episode End
Positive: 125, Negative: 194
EPISODE :- 659
Random Player utility: 17.884307
=================Random Agent Turn=================
Action taken: 2.760248
===============Feedback to learned agent round===============
Observation:
[0, 0, 2.7602479257100323]
Reward: -1.000000, Currnt Bid: 2.760248
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[61.33453979]
Explore action: 61.334540
Action taken: 61.334540
===============Feedback to random agent round===============
Currnt Bid: 61.334540
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([61.33453979]), 2.7602479257100323]
Reward: 38.665460, Currnt Bid: 61.334540
Is done? True
Episode End
Positive: 126, Negative: 194
EPISODE :- 660
Random Player utility: 80.695234
=================Random Agent Turn=================
Action taken: 24.728270
===============Feedback to learned agent round===============
Observation:
[0, 0, 24.728269506558266]
Reward: -1.000000, Currnt Bid: 24.728270
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.035292
Exploit action: 0.035292
Action taken: 0.035292
===============Feedback to random agent round===============
Currnt Bid: 24.728270
=================Random Agent Turn=================
Action taken: 41.344816
===============Feedback to learned agent round===============
Observation:
[1, 0, 24.728269506558266]
Reward: -2.000000, Currnt Bid: 24.728270
Is done? True
Episode End
Positive: 126, Negative: 195
EPISODE :- 661
Random Player utility: 82.622828
=================Random Agent Turn=================
Action taken: 7.437232
===============Feedback to learned agent round===============
Observation:
[0, 0, 7.437232471090255]
Reward: -1.000000, Currnt Bid: 7.437232
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[62.5110253]
Explore action: 62.511025
Action taken: 62.511025
===============Feedback to random agent round===============
Currnt Bid: 62.511025
=================Random Agent Turn=================
Action taken: 75.529472
===============Feedback to learned agent round===============
Observation:
[0, array([62.5110253]), array([75.52947165])]
Reward: -1.000000, Currnt Bid: 75.529472
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[57.15419539]
Explore action: 57.154195
Action taken: 57.154195
===============Feedback to random agent round===============
Currnt Bid: 75.529472
=================Random Agent Turn=================
Action taken: 77.659727
===============Feedback to learned agent round===============
Observation:
[1, array([62.5110253]), array([75.52947165])]
Reward: -2.000000, Currnt Bid: 75.529472
Is done? True
Episode End
Positive: 126, Negative: 196
EPISODE :- 662
Random Player utility: 120.898065
=================Random Agent Turn=================
Action taken: 17.191853
===============Feedback to learned agent round===============
Observation:
[0, 0, 17.191852812340645]
Reward: -1.000000, Currnt Bid: 17.191853
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.99047668]
Explore action: 48.990477
Action taken: 48.990477
===============Feedback to random agent round===============
Currnt Bid: 48.990477
=================Random Agent Turn=================
Action taken: 109.863095
===============Feedback to learned agent round===============
Observation:
[0, array([48.99047668]), array([109.86309522])]
Reward: -1.000000, Currnt Bid: 109.863095
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[49.97005108]
Explore action: 49.970051
Action taken: 49.970051
===============Feedback to random agent round===============
Currnt Bid: 109.863095
=================Random Agent Turn=================
Action taken: 117.698866
===============Feedback to learned agent round===============
Observation:
[1, array([48.99047668]), array([109.86309522])]
Reward: -2.000000, Currnt Bid: 109.863095
Is done? True
Episode End
Positive: 126, Negative: 196
EPISODE :- 663
Random Player utility: 17.789695
=================Random Agent Turn=================
Action taken: 17.640374
===============Feedback to learned agent round===============
Observation:
[0, 0, 17.64037396673664]
Reward: -1.000000, Currnt Bid: 17.640374
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[38.95494874]
Explore action: 38.954949
Action taken: 38.954949
===============Feedback to random agent round===============
Currnt Bid: 38.954949
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([38.95494874]), 17.64037396673664]
Reward: 61.045051, Currnt Bid: 38.954949
Is done? True
Episode End
Positive: 127, Negative: 196
EPISODE :- 664
Random Player utility: 118.235563
=================Random Agent Turn=================
Action taken: 31.551505
===============Feedback to learned agent round===============
Observation:
[0, 0, 31.55150486970422]
Reward: -1.000000, Currnt Bid: 31.551505
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[54.21576412]
Explore action: 54.215764
Action taken: 54.215764
===============Feedback to random agent round===============
Currnt Bid: 54.215764
=================Random Agent Turn=================
Action taken: 102.222259
===============Feedback to learned agent round===============
Observation:
[0, array([54.21576412]), array([102.22225857])]
Reward: -1.000000, Currnt Bid: 102.222259
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[58.87147973]
Explore action: 58.871480
Action taken: 58.871480
===============Feedback to random agent round===============
Currnt Bid: 102.222259
=================Random Agent Turn=================
Action taken: 104.203665
===============Feedback to learned agent round===============
Observation:
[1, array([54.21576412]), array([102.22225857])]
Reward: -2.000000, Currnt Bid: 102.222259
Is done? True
Episode End
Positive: 127, Negative: 196
EPISODE :- 665
Random Player utility: 156.785357
=================Random Agent Turn=================
Action taken: 53.838959
===============Feedback to learned agent round===============
Observation:
[0, 0, 53.83895886904519]
Reward: -1.000000, Currnt Bid: 53.838959
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.032246
Exploit action: 0.032246
Action taken: 0.032246
===============Feedback to random agent round===============
Currnt Bid: 53.838959
=================Random Agent Turn=================
Action taken: 84.160047
===============Feedback to learned agent round===============
Observation:
[1, 0, 53.83895886904519]
Reward: -2.000000, Currnt Bid: 53.838959
Is done? True
Episode End
Positive: 127, Negative: 196
EPISODE :- 666
Random Player utility: 131.529124
=================Random Agent Turn=================
Action taken: 69.563638
===============Feedback to learned agent round===============
Observation:
[0, 0, 69.56363817637926]
Reward: -1.000000, Currnt Bid: 69.563638
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[44.17252978]
Explore action: 44.172530
Action taken: 44.172530
===============Feedback to random agent round===============
Currnt Bid: 69.563638
=================Random Agent Turn=================
Action taken: 113.893601
===============Feedback to learned agent round===============
Observation:
[1, 0, 69.56363817637926]
Reward: -2.000000, Currnt Bid: 69.563638
Is done? True
Episode End
Positive: 127, Negative: 196
EPISODE :- 667
Random Player utility: 124.184641
=================Random Agent Turn=================
Action taken: 75.632424
===============Feedback to learned agent round===============
Observation:
[0, 0, 75.63242353930995]
Reward: -1.000000, Currnt Bid: 75.632424
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[55.29632533]
Explore action: 55.296325
Action taken: 55.296325
===============Feedback to random agent round===============
Currnt Bid: 75.632424
=================Random Agent Turn=================
Action taken: 97.933463
===============Feedback to learned agent round===============
Observation:
[1, 0, 75.63242353930995]
Reward: -2.000000, Currnt Bid: 75.632424
Is done? True
Episode End
Positive: 127, Negative: 196
EPISODE :- 668
Random Player utility: 129.110504
=================Random Agent Turn=================
Action taken: 81.404513
===============Feedback to learned agent round===============
Observation:
[0, 0, 81.40451332253465]
Reward: -1.000000, Currnt Bid: 81.404513
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[33.99285395]
Explore action: 33.992854
Action taken: 33.992854
===============Feedback to random agent round===============
Currnt Bid: 81.404513
=================Random Agent Turn=================
Action taken: 83.375946
===============Feedback to learned agent round===============
Observation:
[1, 0, 81.40451332253465]
Reward: -2.000000, Currnt Bid: 81.404513
Is done? True
Episode End
Positive: 127, Negative: 196
EPISODE :- 669
Random Player utility: 75.303229
=================Random Agent Turn=================
Action taken: 45.611165
===============Feedback to learned agent round===============
Observation:
[0, 0, 45.61116514834718]
Reward: -1.000000, Currnt Bid: 45.611165
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[50.2489491]
Explore action: 50.248949
Action taken: 50.248949
===============Feedback to random agent round===============
Currnt Bid: 50.248949
=================Random Agent Turn=================
Action taken: 69.182645
===============Feedback to learned agent round===============
Observation:
[0, array([50.2489491]), array([69.18264499])]
Reward: -1.000000, Currnt Bid: 69.182645
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[42.70556647]
Explore action: 42.705566
Action taken: 42.705566
===============Feedback to random agent round===============
Currnt Bid: 69.182645
=================Random Agent Turn=================
Action taken: 71.003220
===============Feedback to learned agent round===============
Observation:
[1, array([50.2489491]), array([69.18264499])]
Reward: -2.000000, Currnt Bid: 69.182645
Is done? True
Episode End
Positive: 127, Negative: 197
EPISODE :- 670
Random Player utility: 67.613074
=================Random Agent Turn=================
Action taken: 11.375116
===============Feedback to learned agent round===============
Observation:
[0, 0, 11.375116334374937]
Reward: -1.000000, Currnt Bid: 11.375116
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.029880
Exploit action: 0.029880
Action taken: 0.029880
===============Feedback to random agent round===============
Currnt Bid: 11.375116
=================Random Agent Turn=================
Action taken: 46.152332
===============Feedback to learned agent round===============
Observation:
[1, 0, 11.375116334374937]
Reward: -2.000000, Currnt Bid: 11.375116
Is done? True
Episode End
Positive: 127, Negative: 198
EPISODE :- 671
Random Player utility: 93.747069
=================Random Agent Turn=================
Action taken: 38.118792
===============Feedback to learned agent round===============
Observation:
[0, 0, 38.11879156025606]
Reward: -1.000000, Currnt Bid: 38.118792
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.44853537]
Explore action: 48.448535
Action taken: 48.448535
===============Feedback to random agent round===============
Currnt Bid: 48.448535
=================Random Agent Turn=================
Action taken: 51.270253
===============Feedback to learned agent round===============
Observation:
[0, array([48.44853537]), array([51.27025253])]
Reward: -1.000000, Currnt Bid: 51.270253
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[59.05697095]
Explore action: 59.056971
Action taken: 59.056971
===============Feedback to random agent round===============
Currnt Bid: 59.056971
=================Random Agent Turn=================
Action taken: 75.880401
===============Feedback to learned agent round===============
Observation:
[0, array([59.05697095]), array([75.88040145])]
Reward: -1.000000, Currnt Bid: 75.880401
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[40.81776313]
Explore action: 40.817763
Action taken: 40.817763
===============Feedback to random agent round===============
Currnt Bid: 75.880401
=================Random Agent Turn=================
Action taken: 91.014874
===============Feedback to learned agent round===============
Observation:
[1, array([59.05697095]), array([75.88040145])]
Reward: -2.000000, Currnt Bid: 75.880401
Is done? True
Episode End
Positive: 127, Negative: 199
EPISODE :- 672
Random Player utility: 209.591385
=================Random Agent Turn=================
Action taken: 183.728780
===============Feedback to learned agent round===============
Observation:
[0, 0, 183.72877983099255]
Reward: -1.000000, Currnt Bid: 183.728780
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[25.46938095]
Explore action: 25.469381
Action taken: 25.469381
===============Feedback to random agent round===============
Currnt Bid: 183.728780
=================Random Agent Turn=================
Action taken: 192.375005
===============Feedback to learned agent round===============
Observation:
[1, 0, 183.72877983099255]
Reward: -2.000000, Currnt Bid: 183.728780
Is done? True
Episode End
Positive: 127, Negative: 199
EPISODE :- 673
Random Player utility: 169.212753
=================Random Agent Turn=================
Action taken: 77.278615
===============Feedback to learned agent round===============
Observation:
[0, 0, 77.27861548630113]
Reward: -1.000000, Currnt Bid: 77.278615
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[22.70090913]
Explore action: 22.700909
Action taken: 22.700909
===============Feedback to random agent round===============
Currnt Bid: 77.278615
=================Random Agent Turn=================
Action taken: 127.753842
===============Feedback to learned agent round===============
Observation:
[1, 0, 77.27861548630113]
Reward: -2.000000, Currnt Bid: 77.278615
Is done? True
Episode End
Positive: 127, Negative: 199
EPISODE :- 674
Random Player utility: 94.451678
=================Random Agent Turn=================
Action taken: 23.247515
===============Feedback to learned agent round===============
Observation:
[0, 0, 23.247514740612228]
Reward: -1.000000, Currnt Bid: 23.247515
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[18.6948607]
Explore action: 18.694861
Action taken: 18.694861
===============Feedback to random agent round===============
Currnt Bid: 23.247515
=================Random Agent Turn=================
Action taken: 89.051351
===============Feedback to learned agent round===============
Observation:
[1, 0, 23.247514740612228]
Reward: -2.000000, Currnt Bid: 23.247515
Is done? True
Episode End
Positive: 127, Negative: 200
EPISODE :- 675
Random Player utility: 65.811345
=================Random Agent Turn=================
Action taken: 2.707692
===============Feedback to learned agent round===============
Observation:
[0, 0, 2.7076921653331585]
Reward: -1.000000, Currnt Bid: 2.707692
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.027514
Exploit action: 0.027514
Action taken: 0.027514
===============Feedback to random agent round===============
Currnt Bid: 2.707692
=================Random Agent Turn=================
Action taken: 17.943718
===============Feedback to learned agent round===============
Observation:
[1, 0, 2.7076921653331585]
Reward: -2.000000, Currnt Bid: 2.707692
Is done? True
Episode End
Positive: 127, Negative: 201
EPISODE :- 676
Random Player utility: 140.024003
=================Random Agent Turn=================
Action taken: 86.516859
===============Feedback to learned agent round===============
Observation:
[0, 0, 86.5168588408834]
Reward: -1.000000, Currnt Bid: 86.516859
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[30.28333235]
Explore action: 30.283332
Action taken: 30.283332
===============Feedback to random agent round===============
Currnt Bid: 86.516859
=================Random Agent Turn=================
Action taken: 127.512373
===============Feedback to learned agent round===============
Observation:
[1, 0, 86.5168588408834]
Reward: -2.000000, Currnt Bid: 86.516859
Is done? True
Episode End
Positive: 127, Negative: 201
EPISODE :- 677
Random Player utility: 114.127866
=================Random Agent Turn=================
Action taken: 94.980747
===============Feedback to learned agent round===============
Observation:
[0, 0, 94.98074715712981]
Reward: -1.000000, Currnt Bid: 94.980747
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[36.16907266]
Explore action: 36.169073
Action taken: 36.169073
===============Feedback to random agent round===============
Currnt Bid: 94.980747
=================Random Agent Turn=================
Action taken: 113.898252
===============Feedback to learned agent round===============
Observation:
[1, 0, 94.98074715712981]
Reward: -2.000000, Currnt Bid: 94.980747
Is done? True
Episode End
Positive: 127, Negative: 201
EPISODE :- 678
Random Player utility: 151.489427
=================Random Agent Turn=================
Action taken: 38.660075
===============Feedback to learned agent round===============
Observation:
[0, 0, 38.66007527083961]
Reward: -1.000000, Currnt Bid: 38.660075
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[44.88544481]
Explore action: 44.885445
Action taken: 44.885445
===============Feedback to random agent round===============
Currnt Bid: 44.885445
=================Random Agent Turn=================
Action taken: 68.066808
===============Feedback to learned agent round===============
Observation:
[0, array([44.88544481]), array([68.06680784])]
Reward: -1.000000, Currnt Bid: 68.066808
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[50.87214663]
Explore action: 50.872147
Action taken: 50.872147
===============Feedback to random agent round===============
Currnt Bid: 68.066808
=================Random Agent Turn=================
Action taken: 112.120728
===============Feedback to learned agent round===============
Observation:
[1, array([44.88544481]), array([68.06680784])]
Reward: -2.000000, Currnt Bid: 68.066808
Is done? True
Episode End
Positive: 127, Negative: 201
EPISODE :- 679
Random Player utility: 107.231976
=================Random Agent Turn=================
Action taken: 27.976850
===============Feedback to learned agent round===============
Observation:
[0, 0, 27.97684992095847]
Reward: -1.000000, Currnt Bid: 27.976850
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[51.69594806]
Explore action: 51.695948
Action taken: 51.695948
===============Feedback to random agent round===============
Currnt Bid: 51.695948
=================Random Agent Turn=================
Action taken: 90.352545
===============Feedback to learned agent round===============
Observation:
[0, array([51.69594806]), array([90.35254476])]
Reward: -1.000000, Currnt Bid: 90.352545
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[37.17673009]
Explore action: 37.176730
Action taken: 37.176730
===============Feedback to random agent round===============
Currnt Bid: 90.352545
=================Random Agent Turn=================
Action taken: 91.048122
===============Feedback to learned agent round===============
Observation:
[1, array([51.69594806]), array([90.35254476])]
Reward: -2.000000, Currnt Bid: 90.352545
Is done? True
Episode End
Positive: 127, Negative: 201
EPISODE :- 680
Random Player utility: 114.294546
=================Random Agent Turn=================
Action taken: 79.635714
===============Feedback to learned agent round===============
Observation:
[0, 0, 79.63571398125926]
Reward: -1.000000, Currnt Bid: 79.635714
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.025344
Exploit action: 0.025344
Action taken: 0.025344
===============Feedback to random agent round===============
Currnt Bid: 79.635714
=================Random Agent Turn=================
Action taken: 99.849838
===============Feedback to learned agent round===============
Observation:
[1, 0, 79.63571398125926]
Reward: -2.000000, Currnt Bid: 79.635714
Is done? True
Episode End
Positive: 127, Negative: 201
EPISODE :- 681
Random Player utility: 103.681500
=================Random Agent Turn=================
Action taken: 27.326955
===============Feedback to learned agent round===============
Observation:
[0, 0, 27.326955302363906]
Reward: -1.000000, Currnt Bid: 27.326955
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[35.53186127]
Explore action: 35.531861
Action taken: 35.531861
===============Feedback to random agent round===============
Currnt Bid: 35.531861
=================Random Agent Turn=================
Action taken: 93.423754
===============Feedback to learned agent round===============
Observation:
[0, array([35.53186127]), array([93.42375387])]
Reward: -1.000000, Currnt Bid: 93.423754
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[43.04799649]
Explore action: 43.047996
Action taken: 43.047996
===============Feedback to random agent round===============
Currnt Bid: 93.423754
=================Random Agent Turn=================
Action taken: 101.175795
===============Feedback to learned agent round===============
Observation:
[1, array([35.53186127]), array([93.42375387])]
Reward: -2.000000, Currnt Bid: 93.423754
Is done? True
Episode End
Positive: 127, Negative: 201
EPISODE :- 682
Random Player utility: 147.274646
=================Random Agent Turn=================
Action taken: 3.187928
===============Feedback to learned agent round===============
Observation:
[0, 0, 3.187927738700054]
Reward: -1.000000, Currnt Bid: 3.187928
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[43.29479151]
Explore action: 43.294792
Action taken: 43.294792
===============Feedback to random agent round===============
Currnt Bid: 43.294792
=================Random Agent Turn=================
Action taken: 65.403446
===============Feedback to learned agent round===============
Observation:
[0, array([43.29479151]), array([65.4034463])]
Reward: -1.000000, Currnt Bid: 65.403446
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[49.10350743]
Explore action: 49.103507
Action taken: 49.103507
===============Feedback to random agent round===============
Currnt Bid: 65.403446
=================Random Agent Turn=================
Action taken: 111.815293
===============Feedback to learned agent round===============
Observation:
[1, array([43.29479151]), array([65.4034463])]
Reward: -2.000000, Currnt Bid: 65.403446
Is done? True
Episode End
Positive: 127, Negative: 201
EPISODE :- 683
Random Player utility: 114.103173
=================Random Agent Turn=================
Action taken: 105.123844
===============Feedback to learned agent round===============
Observation:
[0, 0, 105.12384372792152]
Reward: -1.000000, Currnt Bid: 105.123844
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[33.02877158]
Explore action: 33.028772
Action taken: 33.028772
===============Feedback to random agent round===============
Currnt Bid: 105.123844
=================Random Agent Turn=================
Action taken: 109.875835
===============Feedback to learned agent round===============
Observation:
[1, 0, 105.12384372792152]
Reward: -2.000000, Currnt Bid: 105.123844
Is done? True
Episode End
Positive: 127, Negative: 201
EPISODE :- 684
Random Player utility: 38.476248
=================Random Agent Turn=================
Action taken: 24.628356
===============Feedback to learned agent round===============
Observation:
[0, 0, 24.628355990476283]
Reward: -1.000000, Currnt Bid: 24.628356
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[40.40039805]
Explore action: 40.400398
Action taken: 40.400398
===============Feedback to random agent round===============
Currnt Bid: 40.400398
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([40.40039805]), 24.628355990476283]
Reward: 59.599602, Currnt Bid: 40.400398
Is done? True
Episode End
Positive: 128, Negative: 201
EPISODE :- 685
Random Player utility: 98.315611
=================Random Agent Turn=================
Action taken: 4.131127
===============Feedback to learned agent round===============
Observation:
[0, 0, 4.131127273835586]
Reward: -1.000000, Currnt Bid: 4.131127
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.023359
Exploit action: 0.023359
Action taken: 0.023359
===============Feedback to random agent round===============
Currnt Bid: 4.131127
=================Random Agent Turn=================
Action taken: 67.697533
===============Feedback to learned agent round===============
Observation:
[1, 0, 4.131127273835586]
Reward: -2.000000, Currnt Bid: 4.131127
Is done? True
Episode End
Positive: 128, Negative: 202
EPISODE :- 686
Random Player utility: 169.132533
=================Random Agent Turn=================
Action taken: 80.591545
===============Feedback to learned agent round===============
Observation:
[0, 0, 80.59154528583585]
Reward: -1.000000, Currnt Bid: 80.591545
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[53.75869017]
Explore action: 53.758690
Action taken: 53.758690
===============Feedback to random agent round===============
Currnt Bid: 80.591545
=================Random Agent Turn=================
Action taken: 168.504786
===============Feedback to learned agent round===============
Observation:
[1, 0, 80.59154528583585]
Reward: -2.000000, Currnt Bid: 80.591545
Is done? True
Episode End
Positive: 128, Negative: 202
EPISODE :- 687
Random Player utility: 109.886843
=================Random Agent Turn=================
Action taken: 78.085986
===============Feedback to learned agent round===============
Observation:
[0, 0, 78.0859855991562]
Reward: -1.000000, Currnt Bid: 78.085986
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.81384889]
Explore action: 48.813849
Action taken: 48.813849
===============Feedback to random agent round===============
Currnt Bid: 78.085986
=================Random Agent Turn=================
Action taken: 80.722556
===============Feedback to learned agent round===============
Observation:
[1, 0, 78.0859855991562]
Reward: -2.000000, Currnt Bid: 78.085986
Is done? True
Episode End
Positive: 128, Negative: 202
EPISODE :- 688
Random Player utility: 144.613119
=================Random Agent Turn=================
Action taken: 61.942984
===============Feedback to learned agent round===============
Observation:
[0, 0, 61.942984264342044]
Reward: -1.000000, Currnt Bid: 61.942984
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[46.87932654]
Explore action: 46.879327
Action taken: 46.879327
===============Feedback to random agent round===============
Currnt Bid: 61.942984
=================Random Agent Turn=================
Action taken: 133.281277
===============Feedback to learned agent round===============
Observation:
[1, 0, 61.942984264342044]
Reward: -2.000000, Currnt Bid: 61.942984
Is done? True
Episode End
Positive: 128, Negative: 202
EPISODE :- 689
Random Player utility: 38.312878
=================Random Agent Turn=================
Action taken: 6.878545
===============Feedback to learned agent round===============
Observation:
[0, 0, 6.878544742322478]
Reward: -1.000000, Currnt Bid: 6.878545
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[60.71025468]
Explore action: 60.710255
Action taken: 60.710255
===============Feedback to random agent round===============
Currnt Bid: 60.710255
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([60.71025468]), 6.878544742322478]
Reward: 39.289745, Currnt Bid: 60.710255
Is done? True
Episode End
Positive: 129, Negative: 202
EPISODE :- 690
Random Player utility: 153.700501
=================Random Agent Turn=================
Action taken: 86.983601
===============Feedback to learned agent round===============
Observation:
[0, 0, 86.98360133375387]
Reward: -1.000000, Currnt Bid: 86.983601
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.021827
Exploit action: 0.021827
Action taken: 0.021827
===============Feedback to random agent round===============
Currnt Bid: 86.983601
=================Random Agent Turn=================
Action taken: 120.627736
===============Feedback to learned agent round===============
Observation:
[1, 0, 86.98360133375387]
Reward: -2.000000, Currnt Bid: 86.983601
Is done? True
Episode End
Positive: 129, Negative: 202
EPISODE :- 691
Random Player utility: 39.736520
=================Random Agent Turn=================
Action taken: 3.419998
===============Feedback to learned agent round===============
Observation:
[0, 0, 3.41999830590793]
Reward: -1.000000, Currnt Bid: 3.419998
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[63.17694412]
Explore action: 63.176944
Action taken: 63.176944
===============Feedback to random agent round===============
Currnt Bid: 63.176944
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([63.17694412]), 3.41999830590793]
Reward: 36.823056, Currnt Bid: 63.176944
Is done? True
Episode End
Positive: 130, Negative: 202
EPISODE :- 692
Random Player utility: 23.855566
=================Random Agent Turn=================
Action taken: 20.022459
===============Feedback to learned agent round===============
Observation:
[0, 0, 20.022458749427127]
Reward: -1.000000, Currnt Bid: 20.022459
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[72.14280167]
Explore action: 72.142802
Action taken: 72.142802
===============Feedback to random agent round===============
Currnt Bid: 72.142802
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([72.14280167]), 20.022458749427127]
Reward: 27.857198, Currnt Bid: 72.142802
Is done? True
Episode End
Positive: 131, Negative: 202
EPISODE :- 693
Random Player utility: 218.453414
=================Random Agent Turn=================
Action taken: 99.176286
===============Feedback to learned agent round===============
Observation:
[0, 0, 99.17628554190604]
Reward: -1.000000, Currnt Bid: 99.176286
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[56.19566292]
Explore action: 56.195663
Action taken: 56.195663
===============Feedback to random agent round===============
Currnt Bid: 99.176286
=================Random Agent Turn=================
Action taken: 204.702301
===============Feedback to learned agent round===============
Observation:
[1, 0, 99.17628554190604]
Reward: -2.000000, Currnt Bid: 99.176286
Is done? True
Episode End
Positive: 131, Negative: 202
EPISODE :- 694
Random Player utility: 91.343825
=================Random Agent Turn=================
Action taken: 28.417307
===============Feedback to learned agent round===============
Observation:
[0, 0, 28.417306811413845]
Reward: -1.000000, Currnt Bid: 28.417307
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[73.02413471]
Explore action: 73.024135
Action taken: 73.024135
===============Feedback to random agent round===============
Currnt Bid: 73.024135
=================Random Agent Turn=================
Action taken: 83.721442
===============Feedback to learned agent round===============
Observation:
[0, array([73.02413471]), array([83.72144233])]
Reward: -1.000000, Currnt Bid: 83.721442
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[64.04895947]
Explore action: 64.048959
Action taken: 64.048959
===============Feedback to random agent round===============
Currnt Bid: 83.721442
=================Random Agent Turn=================
Action taken: 87.157350
===============Feedback to learned agent round===============
Observation:
[1, array([73.02413471]), array([83.72144233])]
Reward: -2.000000, Currnt Bid: 83.721442
Is done? True
Episode End
Positive: 131, Negative: 203
EPISODE :- 695
Random Player utility: 160.809002
=================Random Agent Turn=================
Action taken: 75.204811
===============Feedback to learned agent round===============
Observation:
[0, 0, 75.2048105398276]
Reward: -1.000000, Currnt Bid: 75.204811
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.020272
Exploit action: 0.020272
Action taken: 0.020272
===============Feedback to random agent round===============
Currnt Bid: 75.204811
=================Random Agent Turn=================
Action taken: 160.737515
===============Feedback to learned agent round===============
Observation:
[1, 0, 75.2048105398276]
Reward: -2.000000, Currnt Bid: 75.204811
Is done? True
Episode End
Positive: 131, Negative: 203
EPISODE :- 696
Random Player utility: 113.288548
=================Random Agent Turn=================
Action taken: 55.941238
===============Feedback to learned agent round===============
Observation:
[0, 0, 55.941237570240226]
Reward: -1.000000, Currnt Bid: 55.941238
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[60.56084841]
Explore action: 60.560848
Action taken: 60.560848
===============Feedback to random agent round===============
Currnt Bid: 60.560848
=================Random Agent Turn=================
Action taken: 70.949356
===============Feedback to learned agent round===============
Observation:
[0, array([60.56084841]), array([70.94935551])]
Reward: -1.000000, Currnt Bid: 70.949356
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[69.86091575]
Explore action: 69.860916
Action taken: 69.860916
===============Feedback to random agent round===============
Currnt Bid: 70.949356
=================Random Agent Turn=================
Action taken: 87.595178
===============Feedback to learned agent round===============
Observation:
[1, array([60.56084841]), array([70.94935551])]
Reward: -2.000000, Currnt Bid: 70.949356
Is done? True
Episode End
Positive: 131, Negative: 203
EPISODE :- 697
Random Player utility: 100.791038
=================Random Agent Turn=================
Action taken: 58.015336
===============Feedback to learned agent round===============
Observation:
[0, 0, 58.01533640673622]
Reward: -1.000000, Currnt Bid: 58.015336
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.74656858]
Explore action: 48.746569
Action taken: 48.746569
===============Feedback to random agent round===============
Currnt Bid: 58.015336
=================Random Agent Turn=================
Action taken: 65.961145
===============Feedback to learned agent round===============
Observation:
[1, 0, 58.01533640673622]
Reward: -2.000000, Currnt Bid: 58.015336
Is done? True
Episode End
Positive: 131, Negative: 203
EPISODE :- 698
Random Player utility: 74.943955
=================Random Agent Turn=================
Action taken: 31.072156
===============Feedback to learned agent round===============
Observation:
[0, 0, 31.072155883685596]
Reward: -1.000000, Currnt Bid: 31.072156
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[59.17054754]
Explore action: 59.170548
Action taken: 59.170548
===============Feedback to random agent round===============
Currnt Bid: 59.170548
=================Random Agent Turn=================
Action taken: 73.774164
===============Feedback to learned agent round===============
Observation:
[0, array([59.17054754]), array([73.77416418])]
Reward: -1.000000, Currnt Bid: 73.774164
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[74.32803541]
Explore action: 74.328035
Action taken: 74.328035
===============Feedback to random agent round===============
Currnt Bid: 74.328035
=================Random Agent Turn=================
Action taken: 74.603764
===============Feedback to learned agent round===============
Observation:
[0, array([74.32803541]), array([74.60376438])]
Reward: -1.000000, Currnt Bid: 74.603764
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[75.84614664]
Explore action: 75.846147
Action taken: 75.846147
===============Feedback to random agent round===============
Currnt Bid: 75.846147
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([75.84614664]), array([74.60376438])]
Reward: 24.153853, Currnt Bid: 75.846147
Is done? True
Episode End
Positive: 132, Negative: 203
EPISODE :- 699
Random Player utility: 98.253936
=================Random Agent Turn=================
Action taken: 85.069543
===============Feedback to learned agent round===============
Observation:
[0, 0, 85.06954251232301]
Reward: -1.000000, Currnt Bid: 85.069543
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[69.5362673]
Explore action: 69.536267
Action taken: 69.536267
===============Feedback to random agent round===============
Currnt Bid: 85.069543
=================Random Agent Turn=================
Action taken: 92.071332
===============Feedback to learned agent round===============
Observation:
[1, 0, 85.06954251232301]
Reward: -2.000000, Currnt Bid: 85.069543
Is done? True
Episode End
Positive: 132, Negative: 204
EPISODE :- 700
Random Player utility: 88.745454
=================Random Agent Turn=================
Action taken: 80.836888
===============Feedback to learned agent round===============
Observation:
[0, 0, 80.83688809126775]
Reward: -1.000000, Currnt Bid: 80.836888
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.018579
Exploit action: 0.018579
Action taken: 0.018579
===============Feedback to random agent round===============
Currnt Bid: 80.836888
=================Random Agent Turn=================
Action taken: 82.002121
===============Feedback to learned agent round===============
Observation:
[1, 0, 80.83688809126775]
Reward: -2.000000, Currnt Bid: 80.836888
Is done? True
Episode End
Positive: 132, Negative: 205
Models saved successfully
EPISODE :- 701
Random Player utility: 31.123611
=================Random Agent Turn=================
Action taken: 17.773145
===============Feedback to learned agent round===============
Observation:
[0, 0, 17.773145419227774]
Reward: -1.000000, Currnt Bid: 17.773145
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[64.98808038]
Explore action: 64.988080
Action taken: 64.988080
===============Feedback to random agent round===============
Currnt Bid: 64.988080
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([64.98808038]), 17.773145419227774]
Reward: 35.011920, Currnt Bid: 64.988080
Is done? True
Episode End
Positive: 133, Negative: 205
EPISODE :- 702
Random Player utility: 67.779693
=================Random Agent Turn=================
Action taken: 62.261611
===============Feedback to learned agent round===============
Observation:
[0, 0, 62.261610816246936]
Reward: -1.000000, Currnt Bid: 62.261611
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[75.85978043]
Explore action: 75.859780
Action taken: 75.859780
===============Feedback to random agent round===============
Currnt Bid: 75.859780
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([75.85978043]), 62.261610816246936]
Reward: 24.140220, Currnt Bid: 75.859780
Is done? True
Episode End
Positive: 134, Negative: 205
EPISODE :- 703
Random Player utility: 131.281407
=================Random Agent Turn=================
Action taken: 76.429263
===============Feedback to learned agent round===============
Observation:
[0, 0, 76.42926341878427]
Reward: -1.000000, Currnt Bid: 76.429263
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[69.08616789]
Explore action: 69.086168
Action taken: 69.086168
===============Feedback to random agent round===============
Currnt Bid: 76.429263
=================Random Agent Turn=================
Action taken: 90.684891
===============Feedback to learned agent round===============
Observation:
[1, 0, 76.42926341878427]
Reward: -2.000000, Currnt Bid: 76.429263
Is done? True
Episode End
Positive: 134, Negative: 205
EPISODE :- 704
Random Player utility: 84.886847
=================Random Agent Turn=================
Action taken: 80.793935
===============Feedback to learned agent round===============
Observation:
[0, 0, 80.79393453298795]
Reward: -1.000000, Currnt Bid: 80.793935
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[65.97999975]
Explore action: 65.980000
Action taken: 65.980000
===============Feedback to random agent round===============
Currnt Bid: 80.793935
=================Random Agent Turn=================
Action taken: 82.152444
===============Feedback to learned agent round===============
Observation:
[1, 0, 80.79393453298795]
Reward: -2.000000, Currnt Bid: 80.793935
Is done? True
Episode End
Positive: 134, Negative: 206
EPISODE :- 705
Random Player utility: 98.395161
=================Random Agent Turn=================
Action taken: 5.971906
===============Feedback to learned agent round===============
Observation:
[0, 0, 5.971906094068235]
Reward: -1.000000, Currnt Bid: 5.971906
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.017381
Exploit action: 0.017381
Action taken: 0.017381
===============Feedback to random agent round===============
Currnt Bid: 5.971906
=================Random Agent Turn=================
Action taken: 74.503282
===============Feedback to learned agent round===============
Observation:
[1, 0, 5.971906094068235]
Reward: -2.000000, Currnt Bid: 5.971906
Is done? True
Episode End
Positive: 134, Negative: 207
EPISODE :- 706
Random Player utility: 46.780753
=================Random Agent Turn=================
Action taken: 29.392754
===============Feedback to learned agent round===============
Observation:
[0, 0, 29.392753808359206]
Reward: -1.000000, Currnt Bid: 29.392754
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[60.97188932]
Explore action: 60.971889
Action taken: 60.971889
===============Feedback to random agent round===============
Currnt Bid: 60.971889
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([60.97188932]), 29.392753808359206]
Reward: 39.028111, Currnt Bid: 60.971889
Is done? True
Episode End
Positive: 135, Negative: 207
EPISODE :- 707
Random Player utility: 171.778528
=================Random Agent Turn=================
Action taken: 59.996885
===============Feedback to learned agent round===============
Observation:
[0, 0, 59.99688512745532]
Reward: -1.000000, Currnt Bid: 59.996885
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[54.87861055]
Explore action: 54.878611
Action taken: 54.878611
===============Feedback to random agent round===============
Currnt Bid: 59.996885
=================Random Agent Turn=================
Action taken: 130.287637
===============Feedback to learned agent round===============
Observation:
[1, 0, 59.99688512745532]
Reward: -2.000000, Currnt Bid: 59.996885
Is done? True
Episode End
Positive: 135, Negative: 207
EPISODE :- 708
Random Player utility: 81.202346
=================Random Agent Turn=================
Action taken: 67.064393
===============Feedback to learned agent round===============
Observation:
[0, 0, 67.06439327833411]
Reward: -1.000000, Currnt Bid: 67.064393
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[38.32587809]
Explore action: 38.325878
Action taken: 38.325878
===============Feedback to random agent round===============
Currnt Bid: 67.064393
=================Random Agent Turn=================
Action taken: 77.323541
===============Feedback to learned agent round===============
Observation:
[1, 0, 67.06439327833411]
Reward: -2.000000, Currnt Bid: 67.064393
Is done? True
Episode End
Positive: 135, Negative: 208
EPISODE :- 709
Random Player utility: 168.797181
=================Random Agent Turn=================
Action taken: 148.558398
===============Feedback to learned agent round===============
Observation:
[0, 0, 148.55839763522164]
Reward: -1.000000, Currnt Bid: 148.558398
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[39.70170645]
Explore action: 39.701706
Action taken: 39.701706
===============Feedback to random agent round===============
Currnt Bid: 148.558398
=================Random Agent Turn=================
Action taken: 150.053487
===============Feedback to learned agent round===============
Observation:
[1, 0, 148.55839763522164]
Reward: -2.000000, Currnt Bid: 148.558398
Is done? True
Episode End
Positive: 135, Negative: 208
EPISODE :- 710
Random Player utility: 127.286498
=================Random Agent Turn=================
Action taken: 64.310656
===============Feedback to learned agent round===============
Observation:
[0, 0, 64.31065592512711]
Reward: -1.000000, Currnt Bid: 64.310656
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.016266
Exploit action: 0.016266
Action taken: 0.016266
===============Feedback to random agent round===============
Currnt Bid: 64.310656
=================Random Agent Turn=================
Action taken: 116.666200
===============Feedback to learned agent round===============
Observation:
[1, 0, 64.31065592512711]
Reward: -2.000000, Currnt Bid: 64.310656
Is done? True
Episode End
Positive: 135, Negative: 208
EPISODE :- 711
Random Player utility: 53.321789
=================Random Agent Turn=================
Action taken: 47.608797
===============Feedback to learned agent round===============
Observation:
[0, 0, 47.60879668592867]
Reward: -1.000000, Currnt Bid: 47.608797
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[50.26398103]
Explore action: 50.263981
Action taken: 50.263981
===============Feedback to random agent round===============
Currnt Bid: 50.263981
=================Random Agent Turn=================
Action taken: 52.599932
===============Feedback to learned agent round===============
Observation:
[0, array([50.26398103]), array([52.59993222])]
Reward: -1.000000, Currnt Bid: 52.599932
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[36.67787978]
Explore action: 36.677880
Action taken: 36.677880
===============Feedback to random agent round===============
Currnt Bid: 52.599932
=================Random Agent Turn=================
Action taken: 53.201587
===============Feedback to learned agent round===============
Observation:
[1, array([50.26398103]), array([52.59993222])]
Reward: -2.000000, Currnt Bid: 52.599932
Is done? True
Episode End
Positive: 135, Negative: 209
EPISODE :- 712
Random Player utility: 88.592684
=================Random Agent Turn=================
Action taken: 67.709153
===============Feedback to learned agent round===============
Observation:
[0, 0, 67.70915326234112]
Reward: -1.000000, Currnt Bid: 67.709153
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[27.80948105]
Explore action: 27.809481
Action taken: 27.809481
===============Feedback to random agent round===============
Currnt Bid: 67.709153
=================Random Agent Turn=================
Action taken: 67.950768
===============Feedback to learned agent round===============
Observation:
[1, 0, 67.70915326234112]
Reward: -2.000000, Currnt Bid: 67.709153
Is done? True
Episode End
Positive: 135, Negative: 210
EPISODE :- 713
Random Player utility: 87.561176
=================Random Agent Turn=================
Action taken: 11.832083
===============Feedback to learned agent round===============
Observation:
[0, 0, 11.832082634084433]
Reward: -1.000000, Currnt Bid: 11.832083
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[28.27975793]
Explore action: 28.279758
Action taken: 28.279758
===============Feedback to random agent round===============
Currnt Bid: 28.279758
=================Random Agent Turn=================
Action taken: 63.245225
===============Feedback to learned agent round===============
Observation:
[0, array([28.27975793]), array([63.2452253])]
Reward: -1.000000, Currnt Bid: 63.245225
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[23.18988732]
Explore action: 23.189887
Action taken: 23.189887
===============Feedback to random agent round===============
Currnt Bid: 63.245225
=================Random Agent Turn=================
Action taken: 72.398725
===============Feedback to learned agent round===============
Observation:
[1, array([28.27975793]), array([63.2452253])]
Reward: -2.000000, Currnt Bid: 63.245225
Is done? True
Episode End
Positive: 135, Negative: 211
EPISODE :- 714
Random Player utility: 202.136822
=================Random Agent Turn=================
Action taken: 152.081088
===============Feedback to learned agent round===============
Observation:
[0, 0, 152.08108765387817]
Reward: -1.000000, Currnt Bid: 152.081088
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[20.93005373]
Explore action: 20.930054
Action taken: 20.930054
===============Feedback to random agent round===============
Currnt Bid: 152.081088
=================Random Agent Turn=================
Action taken: 191.248651
===============Feedback to learned agent round===============
Observation:
[1, 0, 152.08108765387817]
Reward: -2.000000, Currnt Bid: 152.081088
Is done? True
Episode End
Positive: 135, Negative: 211
EPISODE :- 715
Random Player utility: 110.281911
=================Random Agent Turn=================
Action taken: 103.624035
===============Feedback to learned agent round===============
Observation:
[0, 0, 103.62403473723091]
Reward: -1.000000, Currnt Bid: 103.624035
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.015032
Exploit action: 0.015032
Action taken: 0.015032
===============Feedback to random agent round===============
Currnt Bid: 103.624035
=================Random Agent Turn=================
Action taken: 106.370915
===============Feedback to learned agent round===============
Observation:
[1, 0, 103.62403473723091]
Reward: -2.000000, Currnt Bid: 103.624035
Is done? True
Episode End
Positive: 135, Negative: 211
EPISODE :- 716
Random Player utility: 116.414146
=================Random Agent Turn=================
Action taken: 115.108413
===============Feedback to learned agent round===============
Observation:
[0, 0, 115.10841278914111]
Reward: -1.000000, Currnt Bid: 115.108413
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[31.86525177]
Explore action: 31.865252
Action taken: 31.865252
===============Feedback to random agent round===============
Currnt Bid: 115.108413
=================Random Agent Turn=================
Action taken: 115.884449
===============Feedback to learned agent round===============
Observation:
[1, 0, 115.10841278914111]
Reward: -2.000000, Currnt Bid: 115.108413
Is done? True
Episode End
Positive: 135, Negative: 211
EPISODE :- 717
Random Player utility: 21.215713
=================Random Agent Turn=================
Action taken: 18.655181
===============Feedback to learned agent round===============
Observation:
[0, 0, 18.655180798679517]
Reward: -1.000000, Currnt Bid: 18.655181
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[46.05433958]
Explore action: 46.054340
Action taken: 46.054340
===============Feedback to random agent round===============
Currnt Bid: 46.054340
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([46.05433958]), 18.655180798679517]
Reward: 53.945660, Currnt Bid: 46.054340
Is done? True
Episode End
Positive: 136, Negative: 211
EPISODE :- 718
Random Player utility: 68.309754
=================Random Agent Turn=================
Action taken: 29.292686
===============Feedback to learned agent round===============
Observation:
[0, 0, 29.292686421224957]
Reward: -1.000000, Currnt Bid: 29.292686
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[34.94055451]
Explore action: 34.940555
Action taken: 34.940555
===============Feedback to random agent round===============
Currnt Bid: 34.940555
=================Random Agent Turn=================
Action taken: 44.201717
===============Feedback to learned agent round===============
Observation:
[0, array([34.94055451]), array([44.20171664])]
Reward: -1.000000, Currnt Bid: 44.201717
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[36.92288146]
Explore action: 36.922881
Action taken: 36.922881
===============Feedback to random agent round===============
Currnt Bid: 44.201717
=================Random Agent Turn=================
Action taken: 55.735717
===============Feedback to learned agent round===============
Observation:
[1, array([34.94055451]), array([44.20171664])]
Reward: -2.000000, Currnt Bid: 44.201717
Is done? True
Episode End
Positive: 136, Negative: 212
EPISODE :- 719
Random Player utility: 117.263844
=================Random Agent Turn=================
Action taken: 69.636171
===============Feedback to learned agent round===============
Observation:
[0, 0, 69.63617140748134]
Reward: -1.000000, Currnt Bid: 69.636171
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[33.84949031]
Explore action: 33.849490
Action taken: 33.849490
===============Feedback to random agent round===============
Currnt Bid: 69.636171
=================Random Agent Turn=================
Action taken: 109.516074
===============Feedback to learned agent round===============
Observation:
[1, 0, 69.63617140748134]
Reward: -2.000000, Currnt Bid: 69.636171
Is done? True
Episode End
Positive: 136, Negative: 212
EPISODE :- 720
Random Player utility: 122.998015
=================Random Agent Turn=================
Action taken: 22.608752
===============Feedback to learned agent round===============
Observation:
[0, 0, 22.6087523697712]
Reward: -1.000000, Currnt Bid: 22.608752
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.013983
Exploit action: 0.013983
Action taken: 0.013983
===============Feedback to random agent round===============
Currnt Bid: 22.608752
=================Random Agent Turn=================
Action taken: 101.967450
===============Feedback to learned agent round===============
Observation:
[1, 0, 22.6087523697712]
Reward: -2.000000, Currnt Bid: 22.608752
Is done? True
Episode End
Positive: 136, Negative: 212
EPISODE :- 721
Random Player utility: 20.876281
=================Random Agent Turn=================
Action taken: 0.731887
===============Feedback to learned agent round===============
Observation:
[0, 0, 0.7318871349132249]
Reward: -1.000000, Currnt Bid: 0.731887
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[27.74897672]
Explore action: 27.748977
Action taken: 27.748977
===============Feedback to random agent round===============
Currnt Bid: 27.748977
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([27.74897672]), 0.7318871349132249]
Reward: 72.251023, Currnt Bid: 27.748977
Is done? True
Episode End
Positive: 137, Negative: 212
EPISODE :- 722
Random Player utility: 89.755314
=================Random Agent Turn=================
Action taken: 57.082432
===============Feedback to learned agent round===============
Observation:
[0, 0, 57.08243231040565]
Reward: -1.000000, Currnt Bid: 57.082432
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[42.37847396]
Explore action: 42.378474
Action taken: 42.378474
===============Feedback to random agent round===============
Currnt Bid: 57.082432
=================Random Agent Turn=================
Action taken: 64.722785
===============Feedback to learned agent round===============
Observation:
[1, 0, 57.08243231040565]
Reward: -2.000000, Currnt Bid: 57.082432
Is done? True
Episode End
Positive: 137, Negative: 213
EPISODE :- 723
Random Player utility: 123.319272
=================Random Agent Turn=================
Action taken: 66.400989
===============Feedback to learned agent round===============
Observation:
[0, 0, 66.40098896009961]
Reward: -1.000000, Currnt Bid: 66.400989
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[46.66687922]
Explore action: 46.666879
Action taken: 46.666879
===============Feedback to random agent round===============
Currnt Bid: 66.400989
=================Random Agent Turn=================
Action taken: 121.660364
===============Feedback to learned agent round===============
Observation:
[1, 0, 66.40098896009961]
Reward: -2.000000, Currnt Bid: 66.400989
Is done? True
Episode End
Positive: 137, Negative: 213
EPISODE :- 724
Random Player utility: 59.114289
=================Random Agent Turn=================
Action taken: 40.076813
===============Feedback to learned agent round===============
Observation:
[0, 0, 40.076813096532526]
Reward: -1.000000, Currnt Bid: 40.076813
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[36.49845792]
Explore action: 36.498458
Action taken: 36.498458
===============Feedback to random agent round===============
Currnt Bid: 40.076813
=================Random Agent Turn=================
Action taken: 54.180759
===============Feedback to learned agent round===============
Observation:
[1, 0, 40.076813096532526]
Reward: -2.000000, Currnt Bid: 40.076813
Is done? True
Episode End
Positive: 137, Negative: 214
EPISODE :- 725
Random Player utility: 80.600382
=================Random Agent Turn=================
Action taken: 39.098528
===============Feedback to learned agent round===============
Observation:
[0, 0, 39.09852766379291]
Reward: -1.000000, Currnt Bid: 39.098528
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.013101
Exploit action: 0.013101
Action taken: 0.013101
===============Feedback to random agent round===============
Currnt Bid: 39.098528
=================Random Agent Turn=================
Action taken: 40.045689
===============Feedback to learned agent round===============
Observation:
[1, 0, 39.09852766379291]
Reward: -2.000000, Currnt Bid: 39.098528
Is done? True
Episode End
Positive: 137, Negative: 215
EPISODE :- 726
Random Player utility: 107.004251
=================Random Agent Turn=================
Action taken: 5.061072
===============Feedback to learned agent round===============
Observation:
[0, 0, 5.061072271550736]
Reward: -1.000000, Currnt Bid: 5.061072
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[20.07647714]
Explore action: 20.076477
Action taken: 20.076477
===============Feedback to random agent round===============
Currnt Bid: 20.076477
=================Random Agent Turn=================
Action taken: 63.704530
===============Feedback to learned agent round===============
Observation:
[0, array([20.07647714]), array([63.70452958])]
Reward: -1.000000, Currnt Bid: 63.704530
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[16.3688813]
Explore action: 16.368881
Action taken: 16.368881
===============Feedback to random agent round===============
Currnt Bid: 63.704530
=================Random Agent Turn=================
Action taken: 72.078874
===============Feedback to learned agent round===============
Observation:
[1, array([20.07647714]), array([63.70452958])]
Reward: -2.000000, Currnt Bid: 63.704530
Is done? True
Episode End
Positive: 137, Negative: 215
EPISODE :- 727
Random Player utility: 224.356226
=================Random Agent Turn=================
Action taken: 102.416178
===============Feedback to learned agent round===============
Observation:
[0, 0, 102.41617771989645]
Reward: -1.000000, Currnt Bid: 102.416178
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[25.7254198]
Explore action: 25.725420
Action taken: 25.725420
===============Feedback to random agent round===============
Currnt Bid: 102.416178
=================Random Agent Turn=================
Action taken: 115.026560
===============Feedback to learned agent round===============
Observation:
[1, 0, 102.41617771989645]
Reward: -2.000000, Currnt Bid: 102.416178
Is done? True
Episode End
Positive: 137, Negative: 215
EPISODE :- 728
Random Player utility: 201.396396
=================Random Agent Turn=================
Action taken: 79.493173
===============Feedback to learned agent round===============
Observation:
[0, 0, 79.49317254580595]
Reward: -1.000000, Currnt Bid: 79.493173
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[35.7751486]
Explore action: 35.775149
Action taken: 35.775149
===============Feedback to random agent round===============
Currnt Bid: 79.493173
=================Random Agent Turn=================
Action taken: 101.916167
===============Feedback to learned agent round===============
Observation:
[1, 0, 79.49317254580595]
Reward: -2.000000, Currnt Bid: 79.493173
Is done? True
Episode End
Positive: 137, Negative: 215
EPISODE :- 729
Random Player utility: 28.495082
=================Random Agent Turn=================
Action taken: 24.123869
===============Feedback to learned agent round===============
Observation:
[0, 0, 24.123868926411188]
Reward: -1.000000, Currnt Bid: 24.123869
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[37.65029656]
Explore action: 37.650297
Action taken: 37.650297
===============Feedback to random agent round===============
Currnt Bid: 37.650297
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([37.65029656]), 24.123868926411188]
Reward: 62.349703, Currnt Bid: 37.650297
Is done? True
Episode End
Positive: 138, Negative: 215
EPISODE :- 730
Random Player utility: 24.299137
=================Random Agent Turn=================
Action taken: 21.399681
===============Feedback to learned agent round===============
Observation:
[0, 0, 21.399680742387236]
Reward: -1.000000, Currnt Bid: 21.399681
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.012201
Exploit action: 0.012201
Action taken: 0.012201
===============Feedback to random agent round===============
Currnt Bid: 21.399681
=================Random Agent Turn=================
Action taken: 23.160136
===============Feedback to learned agent round===============
Observation:
[1, 0, 21.399680742387236]
Reward: -2.000000, Currnt Bid: 21.399681
Is done? True
Episode End
Positive: 138, Negative: 216
EPISODE :- 731
Random Player utility: 149.419546
=================Random Agent Turn=================
Action taken: 13.595754
===============Feedback to learned agent round===============
Observation:
[0, 0, 13.595754214659278]
Reward: -1.000000, Currnt Bid: 13.595754
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[36.92004856]
Explore action: 36.920049
Action taken: 36.920049
===============Feedback to random agent round===============
Currnt Bid: 36.920049
=================Random Agent Turn=================
Action taken: 87.967260
===============Feedback to learned agent round===============
Observation:
[0, array([36.92004856]), array([87.96726004])]
Reward: -1.000000, Currnt Bid: 87.967260
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[41.69271755]
Explore action: 41.692718
Action taken: 41.692718
===============Feedback to random agent round===============
Currnt Bid: 87.967260
=================Random Agent Turn=================
Action taken: 130.035883
===============Feedback to learned agent round===============
Observation:
[1, array([36.92004856]), array([87.96726004])]
Reward: -2.000000, Currnt Bid: 87.967260
Is done? True
Episode End
Positive: 138, Negative: 216
EPISODE :- 732
Random Player utility: 110.105467
=================Random Agent Turn=================
Action taken: 7.160566
===============Feedback to learned agent round===============
Observation:
[0, 0, 7.160565685771005]
Reward: -1.000000, Currnt Bid: 7.160566
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[44.93814686]
Explore action: 44.938147
Action taken: 44.938147
===============Feedback to random agent round===============
Currnt Bid: 44.938147
=================Random Agent Turn=================
Action taken: 52.417824
===============Feedback to learned agent round===============
Observation:
[0, array([44.93814686]), array([52.41782371])]
Reward: -1.000000, Currnt Bid: 52.417824
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[41.45944216]
Explore action: 41.459442
Action taken: 41.459442
===============Feedback to random agent round===============
Currnt Bid: 52.417824
=================Random Agent Turn=================
Action taken: 76.485407
===============Feedback to learned agent round===============
Observation:
[1, array([44.93814686]), array([52.41782371])]
Reward: -2.000000, Currnt Bid: 52.417824
Is done? True
Episode End
Positive: 138, Negative: 216
EPISODE :- 733
Random Player utility: 125.267460
=================Random Agent Turn=================
Action taken: 66.541668
===============Feedback to learned agent round===============
Observation:
[0, 0, 66.54166813499641]
Reward: -1.000000, Currnt Bid: 66.541668
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[45.0724268]
Explore action: 45.072427
Action taken: 45.072427
===============Feedback to random agent round===============
Currnt Bid: 66.541668
=================Random Agent Turn=================
Action taken: 66.980521
===============Feedback to learned agent round===============
Observation:
[1, 0, 66.54166813499641]
Reward: -2.000000, Currnt Bid: 66.541668
Is done? True
Episode End
Positive: 138, Negative: 216
EPISODE :- 734
Random Player utility: 219.952275
=================Random Agent Turn=================
Action taken: 40.802465
===============Feedback to learned agent round===============
Observation:
[0, 0, 40.80246523925197]
Reward: -1.000000, Currnt Bid: 40.802465
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[33.3949528]
Explore action: 33.394953
Action taken: 33.394953
===============Feedback to random agent round===============
Currnt Bid: 40.802465
=================Random Agent Turn=================
Action taken: 164.261785
===============Feedback to learned agent round===============
Observation:
[1, 0, 40.80246523925197]
Reward: -2.000000, Currnt Bid: 40.802465
Is done? True
Episode End
Positive: 138, Negative: 216
EPISODE :- 735
Random Player utility: 82.282762
=================Random Agent Turn=================
Action taken: 16.273396
===============Feedback to learned agent round===============
Observation:
[0, 0, 16.27339620272089]
Reward: -1.000000, Currnt Bid: 16.273396
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.011295
Exploit action: 0.011295
Action taken: 0.011295
===============Feedback to random agent round===============
Currnt Bid: 16.273396
=================Random Agent Turn=================
Action taken: 36.905797
===============Feedback to learned agent round===============
Observation:
[1, 0, 16.27339620272089]
Reward: -2.000000, Currnt Bid: 16.273396
Is done? True
Episode End
Positive: 138, Negative: 217
EPISODE :- 736
Random Player utility: 124.160221
=================Random Agent Turn=================
Action taken: 10.481505
===============Feedback to learned agent round===============
Observation:
[0, 0, 10.481505215080077]
Reward: -1.000000, Currnt Bid: 10.481505
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[30.39095794]
Explore action: 30.390958
Action taken: 30.390958
===============Feedback to random agent round===============
Currnt Bid: 30.390958
=================Random Agent Turn=================
Action taken: 92.240267
===============Feedback to learned agent round===============
Observation:
[0, array([30.39095794]), array([92.24026699])]
Reward: -1.000000, Currnt Bid: 92.240267
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[53.56007987]
Explore action: 53.560080
Action taken: 53.560080
===============Feedback to random agent round===============
Currnt Bid: 92.240267
=================Random Agent Turn=================
Action taken: 93.545369
===============Feedback to learned agent round===============
Observation:
[1, array([30.39095794]), array([92.24026699])]
Reward: -2.000000, Currnt Bid: 92.240267
Is done? True
Episode End
Positive: 138, Negative: 217
EPISODE :- 737
Random Player utility: 173.843885
=================Random Agent Turn=================
Action taken: 75.068155
===============Feedback to learned agent round===============
Observation:
[0, 0, 75.06815527960714]
Reward: -1.000000, Currnt Bid: 75.068155
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[45.69193559]
Explore action: 45.691936
Action taken: 45.691936
===============Feedback to random agent round===============
Currnt Bid: 75.068155
=================Random Agent Turn=================
Action taken: 128.517304
===============Feedback to learned agent round===============
Observation:
[1, 0, 75.06815527960714]
Reward: -2.000000, Currnt Bid: 75.068155
Is done? True
Episode End
Positive: 138, Negative: 217
EPISODE :- 738
Random Player utility: 108.078409
=================Random Agent Turn=================
Action taken: 59.321715
===============Feedback to learned agent round===============
Observation:
[0, 0, 59.32171463619781]
Reward: -1.000000, Currnt Bid: 59.321715
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[57.15164514]
Explore action: 57.151645
Action taken: 57.151645
===============Feedback to random agent round===============
Currnt Bid: 59.321715
=================Random Agent Turn=================
Action taken: 60.299636
===============Feedback to learned agent round===============
Observation:
[1, 0, 59.32171463619781]
Reward: -2.000000, Currnt Bid: 59.321715
Is done? True
Episode End
Positive: 138, Negative: 217
EPISODE :- 739
Random Player utility: 52.335551
=================Random Agent Turn=================
Action taken: 9.005831
===============Feedback to learned agent round===============
Observation:
[0, 0, 9.005831239879178]
Reward: -1.000000, Currnt Bid: 9.005831
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[57.3324955]
Explore action: 57.332496
Action taken: 57.332496
===============Feedback to random agent round===============
Currnt Bid: 57.332496
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([57.3324955]), 9.005831239879178]
Reward: 42.667504, Currnt Bid: 57.332496
Is done? True
Episode End
Positive: 139, Negative: 217
EPISODE :- 740
Random Player utility: 145.071011
=================Random Agent Turn=================
Action taken: 28.813281
===============Feedback to learned agent round===============
Observation:
[0, 0, 28.813281345588827]
Reward: -1.000000, Currnt Bid: 28.813281
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.010526
Exploit action: 0.010526
Action taken: 0.010526
===============Feedback to random agent round===============
Currnt Bid: 28.813281
=================Random Agent Turn=================
Action taken: 96.031307
===============Feedback to learned agent round===============
Observation:
[1, 0, 28.813281345588827]
Reward: -2.000000, Currnt Bid: 28.813281
Is done? True
Episode End
Positive: 139, Negative: 217
EPISODE :- 741
Random Player utility: 88.371702
=================Random Agent Turn=================
Action taken: 81.339017
===============Feedback to learned agent round===============
Observation:
[0, 0, 81.33901700178006]
Reward: -1.000000, Currnt Bid: 81.339017
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[54.41529597]
Explore action: 54.415296
Action taken: 54.415296
===============Feedback to random agent round===============
Currnt Bid: 81.339017
=================Random Agent Turn=================
Action taken: 83.034495
===============Feedback to learned agent round===============
Observation:
[1, 0, 81.33901700178006]
Reward: -2.000000, Currnt Bid: 81.339017
Is done? True
Episode End
Positive: 139, Negative: 218
EPISODE :- 742
Random Player utility: 142.554664
=================Random Agent Turn=================
Action taken: 92.599836
===============Feedback to learned agent round===============
Observation:
[0, 0, 92.59983603212822]
Reward: -1.000000, Currnt Bid: 92.599836
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[57.79738355]
Explore action: 57.797384
Action taken: 57.797384
===============Feedback to random agent round===============
Currnt Bid: 92.599836
=================Random Agent Turn=================
Action taken: 114.325534
===============Feedback to learned agent round===============
Observation:
[1, 0, 92.59983603212822]
Reward: -2.000000, Currnt Bid: 92.599836
Is done? True
Episode End
Positive: 139, Negative: 218
EPISODE :- 743
Random Player utility: 169.007755
=================Random Agent Turn=================
Action taken: 6.538394
===============Feedback to learned agent round===============
Observation:
[0, 0, 6.538393937722253]
Reward: -1.000000, Currnt Bid: 6.538394
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[39.05588247]
Explore action: 39.055882
Action taken: 39.055882
===============Feedback to random agent round===============
Currnt Bid: 39.055882
=================Random Agent Turn=================
Action taken: 117.377715
===============Feedback to learned agent round===============
Observation:
[0, array([39.05588247]), array([117.37771549])]
Reward: -1.000000, Currnt Bid: 117.377715
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[54.24757207]
Explore action: 54.247572
Action taken: 54.247572
===============Feedback to random agent round===============
Currnt Bid: 117.377715
=================Random Agent Turn=================
Action taken: 128.062230
===============Feedback to learned agent round===============
Observation:
[1, array([39.05588247]), array([117.37771549])]
Reward: -2.000000, Currnt Bid: 117.377715
Is done? True
Episode End
Positive: 139, Negative: 218
EPISODE :- 744
Random Player utility: 77.416824
=================Random Agent Turn=================
Action taken: 77.129261
===============Feedback to learned agent round===============
Observation:
[0, 0, 77.1292610168697]
Reward: -1.000000, Currnt Bid: 77.129261
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[51.69913058]
Explore action: 51.699131
Action taken: 51.699131
===============Feedback to random agent round===============
Currnt Bid: 77.129261
=================Random Agent Turn=================
Action taken: 77.238144
===============Feedback to learned agent round===============
Observation:
[1, 0, 77.1292610168697]
Reward: -2.000000, Currnt Bid: 77.129261
Is done? True
Episode End
Positive: 139, Negative: 219
EPISODE :- 745
Random Player utility: 93.858021
=================Random Agent Turn=================
Action taken: 85.246483
===============Feedback to learned agent round===============
Observation:
[0, 0, 85.2464833924236]
Reward: -1.000000, Currnt Bid: 85.246483
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.009817
Exploit action: 0.009817
Action taken: 0.009817
===============Feedback to random agent round===============
Currnt Bid: 85.246483
=================Random Agent Turn=================
Action taken: 93.707764
===============Feedback to learned agent round===============
Observation:
[1, 0, 85.2464833924236]
Reward: -2.000000, Currnt Bid: 85.246483
Is done? True
Episode End
Positive: 139, Negative: 220
EPISODE :- 746
Random Player utility: 126.482555
=================Random Agent Turn=================
Action taken: 44.789227
===============Feedback to learned agent round===============
Observation:
[0, 0, 44.78922679125943]
Reward: -1.000000, Currnt Bid: 44.789227
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[58.24163254]
Explore action: 58.241633
Action taken: 58.241633
===============Feedback to random agent round===============
Currnt Bid: 58.241633
=================Random Agent Turn=================
Action taken: 107.130091
===============Feedback to learned agent round===============
Observation:
[0, array([58.24163254]), array([107.13009062])]
Reward: -1.000000, Currnt Bid: 107.130091
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[69.0611097]
Explore action: 69.061110
Action taken: 69.061110
===============Feedback to random agent round===============
Currnt Bid: 107.130091
=================Random Agent Turn=================
Action taken: 111.752794
===============Feedback to learned agent round===============
Observation:
[1, array([58.24163254]), array([107.13009062])]
Reward: -2.000000, Currnt Bid: 107.130091
Is done? True
Episode End
Positive: 139, Negative: 220
EPISODE :- 747
Random Player utility: 105.862957
=================Random Agent Turn=================
Action taken: 43.775110
===============Feedback to learned agent round===============
Observation:
[0, 0, 43.77511034519219]
Reward: -1.000000, Currnt Bid: 43.775110
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[67.75551283]
Explore action: 67.755513
Action taken: 67.755513
===============Feedback to random agent round===============
Currnt Bid: 67.755513
=================Random Agent Turn=================
Action taken: 104.307073
===============Feedback to learned agent round===============
Observation:
[0, array([67.75551283]), array([104.3070732])]
Reward: -1.000000, Currnt Bid: 104.307073
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[60.75279581]
Explore action: 60.752796
Action taken: 60.752796
===============Feedback to random agent round===============
Currnt Bid: 104.307073
=================Random Agent Turn=================
Action taken: 105.416027
===============Feedback to learned agent round===============
Observation:
[1, array([67.75551283]), array([104.3070732])]
Reward: -2.000000, Currnt Bid: 104.307073
Is done? True
Episode End
Positive: 139, Negative: 220
EPISODE :- 748
Random Player utility: 43.241284
=================Random Agent Turn=================
Action taken: 29.711233
===============Feedback to learned agent round===============
Observation:
[0, 0, 29.71123314876034]
Reward: -1.000000, Currnt Bid: 29.711233
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[57.38659418]
Explore action: 57.386594
Action taken: 57.386594
===============Feedback to random agent round===============
Currnt Bid: 57.386594
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([57.38659418]), 29.71123314876034]
Reward: 42.613406, Currnt Bid: 57.386594
Is done? True
Episode End
Positive: 140, Negative: 220
EPISODE :- 749
Random Player utility: 42.992714
=================Random Agent Turn=================
Action taken: 5.886404
===============Feedback to learned agent round===============
Observation:
[0, 0, 5.886404463699244]
Reward: -1.000000, Currnt Bid: 5.886404
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[59.20187896]
Explore action: 59.201879
Action taken: 59.201879
===============Feedback to random agent round===============
Currnt Bid: 59.201879
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([59.20187896]), 5.886404463699244]
Reward: 40.798121, Currnt Bid: 59.201879
Is done? True
Episode End
Positive: 141, Negative: 220
EPISODE :- 750
Random Player utility: 40.786057
=================Random Agent Turn=================
Action taken: 24.326334
===============Feedback to learned agent round===============
Observation:
[0, 0, 24.326334251155753]
Reward: -1.000000, Currnt Bid: 24.326334
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.009096
Exploit action: 0.009096
Action taken: 0.009096
===============Feedback to random agent round===============
Currnt Bid: 24.326334
=================Random Agent Turn=================
Action taken: 37.443853
===============Feedback to learned agent round===============
Observation:
[1, 0, 24.326334251155753]
Reward: -2.000000, Currnt Bid: 24.326334
Is done? True
Episode End
Positive: 141, Negative: 221
EPISODE :- 751
Random Player utility: 72.023498
=================Random Agent Turn=================
Action taken: 33.236847
===============Feedback to learned agent round===============
Observation:
[0, 0, 33.23684678078314]
Reward: -1.000000, Currnt Bid: 33.236847
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[76.8789663]
Explore action: 76.878966
Action taken: 76.878966
===============Feedback to random agent round===============
Currnt Bid: 76.878966
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([76.8789663]), 33.23684678078314]
Reward: 23.121034, Currnt Bid: 76.878966
Is done? True
Episode End
Positive: 142, Negative: 221
EPISODE :- 752
Random Player utility: 96.382424
=================Random Agent Turn=================
Action taken: 95.942361
===============Feedback to learned agent round===============
Observation:
[0, 0, 95.94236077014456]
Reward: -1.000000, Currnt Bid: 95.942361
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[54.13476911]
Explore action: 54.134769
Action taken: 54.134769
===============Feedback to random agent round===============
Currnt Bid: 95.942361
=================Random Agent Turn=================
Action taken: 95.977214
===============Feedback to learned agent round===============
Observation:
[1, 0, 95.94236077014456]
Reward: -2.000000, Currnt Bid: 95.942361
Is done? True
Episode End
Positive: 142, Negative: 222
EPISODE :- 753
Random Player utility: 82.939240
=================Random Agent Turn=================
Action taken: 63.187677
===============Feedback to learned agent round===============
Observation:
[0, 0, 63.187677299292275]
Reward: -1.000000, Currnt Bid: 63.187677
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[51.30251775]
Explore action: 51.302518
Action taken: 51.302518
===============Feedback to random agent round===============
Currnt Bid: 63.187677
=================Random Agent Turn=================
Action taken: 75.995096
===============Feedback to learned agent round===============
Observation:
[1, 0, 63.187677299292275]
Reward: -2.000000, Currnt Bid: 63.187677
Is done? True
Episode End
Positive: 142, Negative: 223
EPISODE :- 754
Random Player utility: 135.220606
=================Random Agent Turn=================
Action taken: 40.068961
===============Feedback to learned agent round===============
Observation:
[0, 0, 40.06896099465847]
Reward: -1.000000, Currnt Bid: 40.068961
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[46.89554622]
Explore action: 46.895546
Action taken: 46.895546
===============Feedback to random agent round===============
Currnt Bid: 46.895546
=================Random Agent Turn=================
Action taken: 91.774430
===============Feedback to learned agent round===============
Observation:
[0, array([46.89554622]), array([91.77443037])]
Reward: -1.000000, Currnt Bid: 91.774430
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[59.58540895]
Explore action: 59.585409
Action taken: 59.585409
===============Feedback to random agent round===============
Currnt Bid: 91.774430
=================Random Agent Turn=================
Action taken: 104.547476
===============Feedback to learned agent round===============
Observation:
[1, array([46.89554622]), array([91.77443037])]
Reward: -2.000000, Currnt Bid: 91.774430
Is done? True
Episode End
Positive: 142, Negative: 223
EPISODE :- 755
Random Player utility: 63.358700
=================Random Agent Turn=================
Action taken: 42.635706
===============Feedback to learned agent round===============
Observation:
[0, 0, 42.63570590724114]
Reward: -1.000000, Currnt Bid: 42.635706
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.008488
Exploit action: 0.008488
Action taken: 0.008488
===============Feedback to random agent round===============
Currnt Bid: 42.635706
=================Random Agent Turn=================
Action taken: 51.993185
===============Feedback to learned agent round===============
Observation:
[1, 0, 42.63570590724114]
Reward: -2.000000, Currnt Bid: 42.635706
Is done? True
Episode End
Positive: 142, Negative: 224
EPISODE :- 756
Random Player utility: 237.920157
=================Random Agent Turn=================
Action taken: 42.520413
===============Feedback to learned agent round===============
Observation:
[0, 0, 42.520412960176294]
Reward: -1.000000, Currnt Bid: 42.520413
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[35.1082962]
Explore action: 35.108296
Action taken: 35.108296
===============Feedback to random agent round===============
Currnt Bid: 42.520413
=================Random Agent Turn=================
Action taken: 138.450895
===============Feedback to learned agent round===============
Observation:
[1, 0, 42.520412960176294]
Reward: -2.000000, Currnt Bid: 42.520413
Is done? True
Episode End
Positive: 142, Negative: 224
EPISODE :- 757
Random Player utility: 58.203828
=================Random Agent Turn=================
Action taken: 10.169632
===============Feedback to learned agent round===============
Observation:
[0, 0, 10.169631996966716]
Reward: -1.000000, Currnt Bid: 10.169632
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[58.44123339]
Explore action: 58.441233
Action taken: 58.441233
===============Feedback to random agent round===============
Currnt Bid: 58.441233
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([58.44123339]), 10.169631996966716]
Reward: 41.558767, Currnt Bid: 58.441233
Is done? True
Episode End
Positive: 143, Negative: 224
EPISODE :- 758
Random Player utility: 145.687596
=================Random Agent Turn=================
Action taken: 7.875682
===============Feedback to learned agent round===============
Observation:
[0, 0, 7.875682233632547]
Reward: -1.000000, Currnt Bid: 7.875682
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[75.93436877]
Explore action: 75.934369
Action taken: 75.934369
===============Feedback to random agent round===============
Currnt Bid: 75.934369
=================Random Agent Turn=================
Action taken: 106.215273
===============Feedback to learned agent round===============
Observation:
[0, array([75.93436877]), array([106.21527254])]
Reward: -1.000000, Currnt Bid: 106.215273
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[60.42145323]
Explore action: 60.421453
Action taken: 60.421453
===============Feedback to random agent round===============
Currnt Bid: 106.215273
=================Random Agent Turn=================
Action taken: 121.354228
===============Feedback to learned agent round===============
Observation:
[1, array([75.93436877]), array([106.21527254])]
Reward: -2.000000, Currnt Bid: 106.215273
Is done? True
Episode End
Positive: 143, Negative: 224
EPISODE :- 759
Random Player utility: 36.707577
=================Random Agent Turn=================
Action taken: 25.324789
===============Feedback to learned agent round===============
Observation:
[0, 0, 25.32478851026082]
Reward: -1.000000, Currnt Bid: 25.324789
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[49.23722705]
Explore action: 49.237227
Action taken: 49.237227
===============Feedback to random agent round===============
Currnt Bid: 49.237227
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([49.23722705]), 25.32478851026082]
Reward: 50.762773, Currnt Bid: 49.237227
Is done? True
Episode End
Positive: 144, Negative: 224
EPISODE :- 760
Random Player utility: 216.764359
=================Random Agent Turn=================
Action taken: 16.062668
===============Feedback to learned agent round===============
Observation:
[0, 0, 16.062667908249814]
Reward: -1.000000, Currnt Bid: 16.062668
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.007927
Exploit action: 0.007927
Action taken: 0.007927
===============Feedback to random agent round===============
Currnt Bid: 16.062668
=================Random Agent Turn=================
Action taken: 196.622963
===============Feedback to learned agent round===============
Observation:
[1, 0, 16.062667908249814]
Reward: -2.000000, Currnt Bid: 16.062668
Is done? True
Episode End
Positive: 144, Negative: 224
EPISODE :- 761
Random Player utility: 101.329659
=================Random Agent Turn=================
Action taken: 70.782825
===============Feedback to learned agent round===============
Observation:
[0, 0, 70.7828249031404]
Reward: -1.000000, Currnt Bid: 70.782825
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[52.45489783]
Explore action: 52.454898
Action taken: 52.454898
===============Feedback to random agent round===============
Currnt Bid: 70.782825
=================Random Agent Turn=================
Action taken: 98.200122
===============Feedback to learned agent round===============
Observation:
[1, 0, 70.7828249031404]
Reward: -2.000000, Currnt Bid: 70.782825
Is done? True
Episode End
Positive: 144, Negative: 224
EPISODE :- 762
Random Player utility: 141.758353
=================Random Agent Turn=================
Action taken: 39.052423
===============Feedback to learned agent round===============
Observation:
[0, 0, 39.052423094704764]
Reward: -1.000000, Currnt Bid: 39.052423
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[53.22850266]
Explore action: 53.228503
Action taken: 53.228503
===============Feedback to random agent round===============
Currnt Bid: 53.228503
=================Random Agent Turn=================
Action taken: 68.545827
===============Feedback to learned agent round===============
Observation:
[0, array([53.22850266]), array([68.54582703])]
Reward: -1.000000, Currnt Bid: 68.545827
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[52.18615266]
Explore action: 52.186153
Action taken: 52.186153
===============Feedback to random agent round===============
Currnt Bid: 68.545827
=================Random Agent Turn=================
Action taken: 87.528336
===============Feedback to learned agent round===============
Observation:
[1, array([53.22850266]), array([68.54582703])]
Reward: -2.000000, Currnt Bid: 68.545827
Is done? True
Episode End
Positive: 144, Negative: 224
EPISODE :- 763
Random Player utility: 28.870465
=================Random Agent Turn=================
Action taken: 9.989060
===============Feedback to learned agent round===============
Observation:
[0, 0, 9.989059844954241]
Reward: -1.000000, Currnt Bid: 9.989060
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[37.12570563]
Explore action: 37.125706
Action taken: 37.125706
===============Feedback to random agent round===============
Currnt Bid: 37.125706
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([37.12570563]), 9.989059844954241]
Reward: 62.874294, Currnt Bid: 37.125706
Is done? True
Episode End
Positive: 145, Negative: 224
EPISODE :- 764
Random Player utility: 191.875616
=================Random Agent Turn=================
Action taken: 169.928778
===============Feedback to learned agent round===============
Observation:
[0, 0, 169.92877822186477]
Reward: -1.000000, Currnt Bid: 169.928778
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[32.5133626]
Explore action: 32.513363
Action taken: 32.513363
===============Feedback to random agent round===============
Currnt Bid: 169.928778
=================Random Agent Turn=================
Action taken: 191.769485
===============Feedback to learned agent round===============
Observation:
[1, 0, 169.92877822186477]
Reward: -2.000000, Currnt Bid: 169.928778
Is done? True
Episode End
Positive: 145, Negative: 224
EPISODE :- 765
Random Player utility: 45.013260
=================Random Agent Turn=================
Action taken: 24.528563
===============Feedback to learned agent round===============
Observation:
[0, 0, 24.528562713601154]
Reward: -1.000000, Currnt Bid: 24.528563
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.007403
Exploit action: 0.007403
Action taken: 0.007403
===============Feedback to random agent round===============
Currnt Bid: 24.528563
=================Random Agent Turn=================
Action taken: 37.909041
===============Feedback to learned agent round===============
Observation:
[1, 0, 24.528562713601154]
Reward: -2.000000, Currnt Bid: 24.528563
Is done? True
Episode End
Positive: 145, Negative: 225
EPISODE :- 766
Random Player utility: 97.966114
=================Random Agent Turn=================
Action taken: 18.329254
===============Feedback to learned agent round===============
Observation:
[0, 0, 18.329253936715126]
Reward: -1.000000, Currnt Bid: 18.329254
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[8.98153928]
Explore action: 8.981539
Action taken: 8.981539
===============Feedback to random agent round===============
Currnt Bid: 18.329254
=================Random Agent Turn=================
Action taken: 95.326067
===============Feedback to learned agent round===============
Observation:
[1, 0, 18.329253936715126]
Reward: -2.000000, Currnt Bid: 18.329254
Is done? True
Episode End
Positive: 145, Negative: 226
EPISODE :- 767
Random Player utility: 120.366067
=================Random Agent Turn=================
Action taken: 55.994489
===============Feedback to learned agent round===============
Observation:
[0, 0, 55.99448938613198]
Reward: -1.000000, Currnt Bid: 55.994489
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[28.58434957]
Explore action: 28.584350
Action taken: 28.584350
===============Feedback to random agent round===============
Currnt Bid: 55.994489
=================Random Agent Turn=================
Action taken: 84.957470
===============Feedback to learned agent round===============
Observation:
[1, 0, 55.99448938613198]
Reward: -2.000000, Currnt Bid: 55.994489
Is done? True
Episode End
Positive: 145, Negative: 226
EPISODE :- 768
Random Player utility: 88.571674
=================Random Agent Turn=================
Action taken: 56.543383
===============Feedback to learned agent round===============
Observation:
[0, 0, 56.54338295709257]
Reward: -1.000000, Currnt Bid: 56.543383
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[27.75202762]
Explore action: 27.752028
Action taken: 27.752028
===============Feedback to random agent round===============
Currnt Bid: 56.543383
=================Random Agent Turn=================
Action taken: 79.052271
===============Feedback to learned agent round===============
Observation:
[1, 0, 56.54338295709257]
Reward: -2.000000, Currnt Bid: 56.543383
Is done? True
Episode End
Positive: 145, Negative: 227
EPISODE :- 769
Random Player utility: 172.035230
=================Random Agent Turn=================
Action taken: 122.986281
===============Feedback to learned agent round===============
Observation:
[0, 0, 122.98628088799613]
Reward: -1.000000, Currnt Bid: 122.986281
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[21.43521134]
Explore action: 21.435211
Action taken: 21.435211
===============Feedback to random agent round===============
Currnt Bid: 122.986281
=================Random Agent Turn=================
Action taken: 126.088312
===============Feedback to learned agent round===============
Observation:
[1, 0, 122.98628088799613]
Reward: -2.000000, Currnt Bid: 122.986281
Is done? True
Episode End
Positive: 145, Negative: 227
EPISODE :- 770
Random Player utility: 90.679309
=================Random Agent Turn=================
Action taken: 75.561285
===============Feedback to learned agent round===============
Observation:
[0, 0, 75.56128495621483]
Reward: -1.000000, Currnt Bid: 75.561285
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.006962
Exploit action: 0.006962
Action taken: 0.006962
===============Feedback to random agent round===============
Currnt Bid: 75.561285
=================Random Agent Turn=================
Action taken: 89.210669
===============Feedback to learned agent round===============
Observation:
[1, 0, 75.56128495621483]
Reward: -2.000000, Currnt Bid: 75.561285
Is done? True
Episode End
Positive: 145, Negative: 228
EPISODE :- 771
Random Player utility: 117.994634
=================Random Agent Turn=================
Action taken: 56.244278
===============Feedback to learned agent round===============
Observation:
[0, 0, 56.244277950052904]
Reward: -1.000000, Currnt Bid: 56.244278
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[27.38221118]
Explore action: 27.382211
Action taken: 27.382211
===============Feedback to random agent round===============
Currnt Bid: 56.244278
=================Random Agent Turn=================
Action taken: 112.530180
===============Feedback to learned agent round===============
Observation:
[1, 0, 56.244277950052904]
Reward: -2.000000, Currnt Bid: 56.244278
Is done? True
Episode End
Positive: 145, Negative: 228
EPISODE :- 772
Random Player utility: 68.659401
=================Random Agent Turn=================
Action taken: 48.446201
===============Feedback to learned agent round===============
Observation:
[0, 0, 48.44620099442877]
Reward: -1.000000, Currnt Bid: 48.446201
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[34.887498]
Explore action: 34.887498
Action taken: 34.887498
===============Feedback to random agent round===============
Currnt Bid: 48.446201
=================Random Agent Turn=================
Action taken: 62.859891
===============Feedback to learned agent round===============
Observation:
[1, 0, 48.44620099442877]
Reward: -2.000000, Currnt Bid: 48.446201
Is done? True
Episode End
Positive: 145, Negative: 229
EPISODE :- 773
Random Player utility: 29.811395
=================Random Agent Turn=================
Action taken: 18.617126
===============Feedback to learned agent round===============
Observation:
[0, 0, 18.61712572541345]
Reward: -1.000000, Currnt Bid: 18.617126
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[16.86025019]
Explore action: 16.860250
Action taken: 16.860250
===============Feedback to random agent round===============
Currnt Bid: 18.617126
=================Random Agent Turn=================
Action taken: 20.206735
===============Feedback to learned agent round===============
Observation:
[1, 0, 18.61712572541345]
Reward: -2.000000, Currnt Bid: 18.617126
Is done? True
Episode End
Positive: 145, Negative: 230
EPISODE :- 774
Random Player utility: 204.870484
=================Random Agent Turn=================
Action taken: 115.858169
===============Feedback to learned agent round===============
Observation:
[0, 0, 115.85816903044243]
Reward: -1.000000, Currnt Bid: 115.858169
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[6.7117736]
Explore action: 6.711774
Action taken: 6.711774
===============Feedback to random agent round===============
Currnt Bid: 115.858169
=================Random Agent Turn=================
Action taken: 171.912400
===============Feedback to learned agent round===============
Observation:
[1, 0, 115.85816903044243]
Reward: -2.000000, Currnt Bid: 115.858169
Is done? True
Episode End
Positive: 145, Negative: 230
EPISODE :- 775
Random Player utility: 89.242271
=================Random Agent Turn=================
Action taken: 75.125773
===============Feedback to learned agent round===============
Observation:
[0, 0, 75.12577251593615]
Reward: -1.000000, Currnt Bid: 75.125773
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.006545
Exploit action: 0.006545
Action taken: 0.006545
===============Feedback to random agent round===============
Currnt Bid: 75.125773
=================Random Agent Turn=================
Action taken: 85.073165
===============Feedback to learned agent round===============
Observation:
[1, 0, 75.12577251593615]
Reward: -2.000000, Currnt Bid: 75.125773
Is done? True
Episode End
Positive: 145, Negative: 231
EPISODE :- 776
Random Player utility: 75.356677
=================Random Agent Turn=================
Action taken: 37.229119
===============Feedback to learned agent round===============
Observation:
[0, 0, 37.22911896602248]
Reward: -1.000000, Currnt Bid: 37.229119
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[19.43588878]
Explore action: 19.435889
Action taken: 19.435889
===============Feedback to random agent round===============
Currnt Bid: 37.229119
=================Random Agent Turn=================
Action taken: 45.086695
===============Feedback to learned agent round===============
Observation:
[1, 0, 37.22911896602248]
Reward: -2.000000, Currnt Bid: 37.229119
Is done? True
Episode End
Positive: 145, Negative: 232
EPISODE :- 777
Random Player utility: 15.936454
=================Random Agent Turn=================
Action taken: 9.380664
===============Feedback to learned agent round===============
Observation:
[0, 0, 9.380663782220251]
Reward: -1.000000, Currnt Bid: 9.380664
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[30.26324163]
Explore action: 30.263242
Action taken: 30.263242
===============Feedback to random agent round===============
Currnt Bid: 30.263242
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([30.26324163]), 9.380663782220251]
Reward: 69.736758, Currnt Bid: 30.263242
Is done? True
Episode End
Positive: 146, Negative: 232
EPISODE :- 778
Random Player utility: 107.012081
=================Random Agent Turn=================
Action taken: 88.547884
===============Feedback to learned agent round===============
Observation:
[0, 0, 88.54788438337152]
Reward: -1.000000, Currnt Bid: 88.547884
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[36.70102384]
Explore action: 36.701024
Action taken: 36.701024
===============Feedback to random agent round===============
Currnt Bid: 88.547884
=================Random Agent Turn=================
Action taken: 106.707580
===============Feedback to learned agent round===============
Observation:
[1, 0, 88.54788438337152]
Reward: -2.000000, Currnt Bid: 88.547884
Is done? True
Episode End
Positive: 146, Negative: 232
EPISODE :- 779
Random Player utility: 83.029800
=================Random Agent Turn=================
Action taken: 73.677678
===============Feedback to learned agent round===============
Observation:
[0, 0, 73.67767809991136]
Reward: -1.000000, Currnt Bid: 73.677678
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[40.49564078]
Explore action: 40.495641
Action taken: 40.495641
===============Feedback to random agent round===============
Currnt Bid: 73.677678
=================Random Agent Turn=================
Action taken: 73.970265
===============Feedback to learned agent round===============
Observation:
[1, 0, 73.67767809991136]
Reward: -2.000000, Currnt Bid: 73.677678
Is done? True
Episode End
Positive: 146, Negative: 233
EPISODE :- 780
Random Player utility: 102.680061
=================Random Agent Turn=================
Action taken: 43.124330
===============Feedback to learned agent round===============
Observation:
[0, 0, 43.124329573961674]
Reward: -1.000000, Currnt Bid: 43.124330
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.006157
Exploit action: 0.006157
Action taken: 0.006157
===============Feedback to random agent round===============
Currnt Bid: 43.124330
=================Random Agent Turn=================
Action taken: 101.103843
===============Feedback to learned agent round===============
Observation:
[1, 0, 43.124329573961674]
Reward: -2.000000, Currnt Bid: 43.124330
Is done? True
Episode End
Positive: 146, Negative: 233
EPISODE :- 781
Random Player utility: 51.155271
=================Random Agent Turn=================
Action taken: 49.329544
===============Feedback to learned agent round===============
Observation:
[0, 0, 49.32954385496863]
Reward: -1.000000, Currnt Bid: 49.329544
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[32.93947556]
Explore action: 32.939476
Action taken: 32.939476
===============Feedback to random agent round===============
Currnt Bid: 49.329544
=================Random Agent Turn=================
Action taken: 49.576454
===============Feedback to learned agent round===============
Observation:
[1, 0, 49.32954385496863]
Reward: -2.000000, Currnt Bid: 49.329544
Is done? True
Episode End
Positive: 146, Negative: 234
EPISODE :- 782
Random Player utility: 147.872630
=================Random Agent Turn=================
Action taken: 107.315691
===============Feedback to learned agent round===============
Observation:
[0, 0, 107.31569090152705]
Reward: -1.000000, Currnt Bid: 107.315691
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[55.56195465]
Explore action: 55.561955
Action taken: 55.561955
===============Feedback to random agent round===============
Currnt Bid: 107.315691
=================Random Agent Turn=================
Action taken: 117.560887
===============Feedback to learned agent round===============
Observation:
[1, 0, 107.31569090152705]
Reward: -2.000000, Currnt Bid: 107.315691
Is done? True
Episode End
Positive: 146, Negative: 234
EPISODE :- 783
Random Player utility: 113.329083
=================Random Agent Turn=================
Action taken: 49.655887
===============Feedback to learned agent round===============
Observation:
[0, 0, 49.65588713954021]
Reward: -1.000000, Currnt Bid: 49.655887
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[54.39862958]
Explore action: 54.398630
Action taken: 54.398630
===============Feedback to random agent round===============
Currnt Bid: 54.398630
=================Random Agent Turn=================
Action taken: 55.613894
===============Feedback to learned agent round===============
Observation:
[0, array([54.39862958]), array([55.61389356])]
Reward: -1.000000, Currnt Bid: 55.613894
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[46.08409945]
Explore action: 46.084099
Action taken: 46.084099
===============Feedback to random agent round===============
Currnt Bid: 55.613894
=================Random Agent Turn=================
Action taken: 105.801924
===============Feedback to learned agent round===============
Observation:
[1, array([54.39862958]), array([55.61389356])]
Reward: -2.000000, Currnt Bid: 55.613894
Is done? True
Episode End
Positive: 146, Negative: 234
EPISODE :- 784
Random Player utility: 272.197981
=================Random Agent Turn=================
Action taken: 167.973014
===============Feedback to learned agent round===============
Observation:
[0, 0, 167.97301388964175]
Reward: -1.000000, Currnt Bid: 167.973014
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[45.16701673]
Explore action: 45.167017
Action taken: 45.167017
===============Feedback to random agent round===============
Currnt Bid: 167.973014
=================Random Agent Turn=================
Action taken: 239.799549
===============Feedback to learned agent round===============
Observation:
[1, 0, 167.97301388964175]
Reward: -2.000000, Currnt Bid: 167.973014
Is done? True
Episode End
Positive: 146, Negative: 234
EPISODE :- 785
Random Player utility: 187.251979
=================Random Agent Turn=================
Action taken: 38.472825
===============Feedback to learned agent round===============
Observation:
[0, 0, 38.4728248414713]
Reward: -1.000000, Currnt Bid: 38.472825
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.005764
Exploit action: 0.005764
Action taken: 0.005764
===============Feedback to random agent round===============
Currnt Bid: 38.472825
=================Random Agent Turn=================
Action taken: 155.490624
===============Feedback to learned agent round===============
Observation:
[1, 0, 38.4728248414713]
Reward: -2.000000, Currnt Bid: 38.472825
Is done? True
Episode End
Positive: 146, Negative: 234
EPISODE :- 786
Random Player utility: 77.226940
=================Random Agent Turn=================
Action taken: 25.805546
===============Feedback to learned agent round===============
Observation:
[0, 0, 25.805546141676395]
Reward: -1.000000, Currnt Bid: 25.805546
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[56.23649992]
Explore action: 56.236500
Action taken: 56.236500
===============Feedback to random agent round===============
Currnt Bid: 56.236500
=================Random Agent Turn=================
Action taken: 64.737106
===============Feedback to learned agent round===============
Observation:
[0, array([56.23649992]), array([64.73710636])]
Reward: -1.000000, Currnt Bid: 64.737106
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[44.66521499]
Explore action: 44.665215
Action taken: 44.665215
===============Feedback to random agent round===============
Currnt Bid: 64.737106
=================Random Agent Turn=================
Action taken: 66.933217
===============Feedback to learned agent round===============
Observation:
[1, array([56.23649992]), array([64.73710636])]
Reward: -2.000000, Currnt Bid: 64.737106
Is done? True
Episode End
Positive: 146, Negative: 235
EPISODE :- 787
Random Player utility: 133.492698
=================Random Agent Turn=================
Action taken: 37.588143
===============Feedback to learned agent round===============
Observation:
[0, 0, 37.5881425443223]
Reward: -1.000000, Currnt Bid: 37.588143
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[49.34022354]
Explore action: 49.340224
Action taken: 49.340224
===============Feedback to random agent round===============
Currnt Bid: 49.340224
=================Random Agent Turn=================
Action taken: 127.956116
===============Feedback to learned agent round===============
Observation:
[0, array([49.34022354]), array([127.9561156])]
Reward: -1.000000, Currnt Bid: 127.956116
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[38.68157888]
Explore action: 38.681579
Action taken: 38.681579
===============Feedback to random agent round===============
Currnt Bid: 127.956116
=================Random Agent Turn=================
Action taken: 128.900322
===============Feedback to learned agent round===============
Observation:
[1, array([49.34022354]), array([127.9561156])]
Reward: -2.000000, Currnt Bid: 127.956116
Is done? True
Episode End
Positive: 146, Negative: 235
EPISODE :- 788
Random Player utility: 115.945433
=================Random Agent Turn=================
Action taken: 14.536224
===============Feedback to learned agent round===============
Observation:
[0, 0, 14.536224044035103]
Reward: -1.000000, Currnt Bid: 14.536224
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[38.32046697]
Explore action: 38.320467
Action taken: 38.320467
===============Feedback to random agent round===============
Currnt Bid: 38.320467
=================Random Agent Turn=================
Action taken: 54.021792
===============Feedback to learned agent round===============
Observation:
[0, array([38.32046697]), array([54.02179183])]
Reward: -1.000000, Currnt Bid: 54.021792
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[43.65933923]
Explore action: 43.659339
Action taken: 43.659339
===============Feedback to random agent round===============
Currnt Bid: 54.021792
=================Random Agent Turn=================
Action taken: 101.227658
===============Feedback to learned agent round===============
Observation:
[1, array([38.32046697]), array([54.02179183])]
Reward: -2.000000, Currnt Bid: 54.021792
Is done? True
Episode End
Positive: 146, Negative: 235
EPISODE :- 789
Random Player utility: 148.813692
=================Random Agent Turn=================
Action taken: 137.372428
===============Feedback to learned agent round===============
Observation:
[0, 0, 137.37242754708595]
Reward: -1.000000, Currnt Bid: 137.372428
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[44.48956322]
Explore action: 44.489563
Action taken: 44.489563
===============Feedback to random agent round===============
Currnt Bid: 137.372428
=================Random Agent Turn=================
Action taken: 148.588459
===============Feedback to learned agent round===============
Observation:
[1, 0, 137.37242754708595]
Reward: -2.000000, Currnt Bid: 137.372428
Is done? True
Episode End
Positive: 146, Negative: 235
EPISODE :- 790
Random Player utility: 107.141535
=================Random Agent Turn=================
Action taken: 98.111111
===============Feedback to learned agent round===============
Observation:
[0, 0, 98.111110790474]
Reward: -1.000000, Currnt Bid: 98.111111
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.005329
Exploit action: 0.005329
Action taken: 0.005329
===============Feedback to random agent round===============
Currnt Bid: 98.111111
=================Random Agent Turn=================
Action taken: 103.080892
===============Feedback to learned agent round===============
Observation:
[1, 0, 98.111110790474]
Reward: -2.000000, Currnt Bid: 98.111111
Is done? True
Episode End
Positive: 146, Negative: 235
EPISODE :- 791
Random Player utility: 82.118364
=================Random Agent Turn=================
Action taken: 34.196406
===============Feedback to learned agent round===============
Observation:
[0, 0, 34.196405514762134]
Reward: -1.000000, Currnt Bid: 34.196406
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.39317518]
Explore action: 48.393175
Action taken: 48.393175
===============Feedback to random agent round===============
Currnt Bid: 48.393175
=================Random Agent Turn=================
Action taken: 63.989378
===============Feedback to learned agent round===============
Observation:
[0, array([48.39317518]), array([63.98937808])]
Reward: -1.000000, Currnt Bid: 63.989378
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[39.00937607]
Explore action: 39.009376
Action taken: 39.009376
===============Feedback to random agent round===============
Currnt Bid: 63.989378
=================Random Agent Turn=================
Action taken: 80.691110
===============Feedback to learned agent round===============
Observation:
[1, array([48.39317518]), array([63.98937808])]
Reward: -2.000000, Currnt Bid: 63.989378
Is done? True
Episode End
Positive: 146, Negative: 236
EPISODE :- 792
Random Player utility: 43.700195
=================Random Agent Turn=================
Action taken: 17.312961
===============Feedback to learned agent round===============
Observation:
[0, 0, 17.312960716933148]
Reward: -1.000000, Currnt Bid: 17.312961
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[36.37565136]
Explore action: 36.375651
Action taken: 36.375651
===============Feedback to random agent round===============
Currnt Bid: 36.375651
=================Random Agent Turn=================
Action taken: 39.400975
===============Feedback to learned agent round===============
Observation:
[0, array([36.37565136]), array([39.40097482])]
Reward: -1.000000, Currnt Bid: 39.400975
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[49.00730893]
Explore action: 49.007309
Action taken: 49.007309
===============Feedback to random agent round===============
Currnt Bid: 49.007309
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([49.00730893]), array([39.40097482])]
Reward: 50.992691, Currnt Bid: 49.007309
Is done? True
Episode End
Positive: 147, Negative: 236
EPISODE :- 793
Random Player utility: 115.060735
=================Random Agent Turn=================
Action taken: 7.150789
===============Feedback to learned agent round===============
Observation:
[0, 0, 7.150789491744779]
Reward: -1.000000, Currnt Bid: 7.150789
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[47.08209735]
Explore action: 47.082097
Action taken: 47.082097
===============Feedback to random agent round===============
Currnt Bid: 47.082097
=================Random Agent Turn=================
Action taken: 110.217977
===============Feedback to learned agent round===============
Observation:
[0, array([47.08209735]), array([110.21797713])]
Reward: -1.000000, Currnt Bid: 110.217977
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[23.20917837]
Explore action: 23.209178
Action taken: 23.209178
===============Feedback to random agent round===============
Currnt Bid: 110.217977
=================Random Agent Turn=================
Action taken: 112.726127
===============Feedback to learned agent round===============
Observation:
[1, array([47.08209735]), array([110.21797713])]
Reward: -2.000000, Currnt Bid: 110.217977
Is done? True
Episode End
Positive: 147, Negative: 236
EPISODE :- 794
Random Player utility: 55.444052
=================Random Agent Turn=================
Action taken: 12.667652
===============Feedback to learned agent round===============
Observation:
[0, 0, 12.66765233422729]
Reward: -1.000000, Currnt Bid: 12.667652
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[22.58387252]
Explore action: 22.583873
Action taken: 22.583873
===============Feedback to random agent round===============
Currnt Bid: 22.583873
=================Random Agent Turn=================
Action taken: 49.785601
===============Feedback to learned agent round===============
Observation:
[0, array([22.58387252]), array([49.78560076])]
Reward: -1.000000, Currnt Bid: 49.785601
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[19.07245982]
Explore action: 19.072460
Action taken: 19.072460
===============Feedback to random agent round===============
Currnt Bid: 49.785601
=================Random Agent Turn=================
Action taken: 52.311421
===============Feedback to learned agent round===============
Observation:
[1, array([22.58387252]), array([49.78560076])]
Reward: -2.000000, Currnt Bid: 49.785601
Is done? True
Episode End
Positive: 147, Negative: 237
EPISODE :- 795
Random Player utility: 35.778241
=================Random Agent Turn=================
Action taken: 11.343142
===============Feedback to learned agent round===============
Observation:
[0, 0, 11.343142138486668]
Reward: -1.000000, Currnt Bid: 11.343142
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.004900
Exploit action: 0.004900
Action taken: 0.004900
===============Feedback to random agent round===============
Currnt Bid: 11.343142
=================Random Agent Turn=================
Action taken: 23.890136
===============Feedback to learned agent round===============
Observation:
[1, 0, 11.343142138486668]
Reward: -2.000000, Currnt Bid: 11.343142
Is done? True
Episode End
Positive: 147, Negative: 238
EPISODE :- 796
Random Player utility: 17.855146
=================Random Agent Turn=================
Action taken: 8.538659
===============Feedback to learned agent round===============
Observation:
[0, 0, 8.538658802255553]
Reward: -1.000000, Currnt Bid: 8.538659
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[22.88905498]
Explore action: 22.889055
Action taken: 22.889055
===============Feedback to random agent round===============
Currnt Bid: 22.889055
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([22.88905498]), 8.538658802255553]
Reward: 77.110945, Currnt Bid: 22.889055
Is done? True
Episode End
Positive: 148, Negative: 238
EPISODE :- 797
Random Player utility: 69.537073
=================Random Agent Turn=================
Action taken: 66.909432
===============Feedback to learned agent round===============
Observation:
[0, 0, 66.90943151373615]
Reward: -1.000000, Currnt Bid: 66.909432
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[25.86699283]
Explore action: 25.866993
Action taken: 25.866993
===============Feedback to random agent round===============
Currnt Bid: 66.909432
=================Random Agent Turn=================
Action taken: 68.614086
===============Feedback to learned agent round===============
Observation:
[1, 0, 66.90943151373615]
Reward: -2.000000, Currnt Bid: 66.909432
Is done? True
Episode End
Positive: 148, Negative: 239
EPISODE :- 798
Random Player utility: 87.761620
=================Random Agent Turn=================
Action taken: 11.148485
===============Feedback to learned agent round===============
Observation:
[0, 0, 11.148485131321463]
Reward: -1.000000, Currnt Bid: 11.148485
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[29.03131426]
Explore action: 29.031314
Action taken: 29.031314
===============Feedback to random agent round===============
Currnt Bid: 29.031314
=================Random Agent Turn=================
Action taken: 55.597700
===============Feedback to learned agent round===============
Observation:
[0, array([29.03131426]), array([55.59769997])]
Reward: -1.000000, Currnt Bid: 55.597700
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[7.98640482]
Explore action: 7.986405
Action taken: 7.986405
===============Feedback to random agent round===============
Currnt Bid: 55.597700
=================Random Agent Turn=================
Action taken: 80.190714
===============Feedback to learned agent round===============
Observation:
[1, array([29.03131426]), array([55.59769997])]
Reward: -2.000000, Currnt Bid: 55.597700
Is done? True
Episode End
Positive: 148, Negative: 240
EPISODE :- 799
Random Player utility: 177.967317
=================Random Agent Turn=================
Action taken: 52.852640
===============Feedback to learned agent round===============
Observation:
[0, 0, 52.85263971711764]
Reward: -1.000000, Currnt Bid: 52.852640
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[12.10626393]
Explore action: 12.106264
Action taken: 12.106264
===============Feedback to random agent round===============
Currnt Bid: 52.852640
=================Random Agent Turn=================
Action taken: 127.555212
===============Feedback to learned agent round===============
Observation:
[1, 0, 52.85263971711764]
Reward: -2.000000, Currnt Bid: 52.852640
Is done? True
Episode End
Positive: 148, Negative: 240
EPISODE :- 800
Random Player utility: 151.350870
=================Random Agent Turn=================
Action taken: 40.808209
===============Feedback to learned agent round===============
Observation:
[0, 0, 40.808208944203614]
Reward: -1.000000, Currnt Bid: 40.808209
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.004590
Exploit action: 0.004590
Action taken: 0.004590
===============Feedback to random agent round===============
Currnt Bid: 40.808209
=================Random Agent Turn=================
Action taken: 148.310190
===============Feedback to learned agent round===============
Observation:
[1, 0, 40.808208944203614]
Reward: -2.000000, Currnt Bid: 40.808209
Is done? True
Episode End
Positive: 148, Negative: 240
Models saved successfully
EPISODE :- 801
Random Player utility: 156.425533
=================Random Agent Turn=================
Action taken: 67.308918
===============Feedback to learned agent round===============
Observation:
[0, 0, 67.30891828462694]
Reward: -1.000000, Currnt Bid: 67.308918
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[14.3173375]
Explore action: 14.317337
Action taken: 14.317337
===============Feedback to random agent round===============
Currnt Bid: 67.308918
=================Random Agent Turn=================
Action taken: 107.558471
===============Feedback to learned agent round===============
Observation:
[1, 0, 67.30891828462694]
Reward: -2.000000, Currnt Bid: 67.308918
Is done? True
Episode End
Positive: 148, Negative: 240
EPISODE :- 802
Random Player utility: 56.525173
=================Random Agent Turn=================
Action taken: 53.016146
===============Feedback to learned agent round===============
Observation:
[0, 0, 53.01614579381574]
Reward: -1.000000, Currnt Bid: 53.016146
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[11.12416015]
Explore action: 11.124160
Action taken: 11.124160
===============Feedback to random agent round===============
Currnt Bid: 53.016146
=================Random Agent Turn=================
Action taken: 53.929634
===============Feedback to learned agent round===============
Observation:
[1, 0, 53.01614579381574]
Reward: -2.000000, Currnt Bid: 53.016146
Is done? True
Episode End
Positive: 148, Negative: 241
EPISODE :- 803
Random Player utility: 115.956153
=================Random Agent Turn=================
Action taken: 14.727116
===============Feedback to learned agent round===============
Observation:
[0, 0, 14.72711630357738]
Reward: -1.000000, Currnt Bid: 14.727116
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[27.46741853]
Explore action: 27.467419
Action taken: 27.467419
===============Feedback to random agent round===============
Currnt Bid: 27.467419
=================Random Agent Turn=================
Action taken: 77.165761
===============Feedback to learned agent round===============
Observation:
[0, array([27.46741853]), array([77.16576091])]
Reward: -1.000000, Currnt Bid: 77.165761
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[23.79042389]
Explore action: 23.790424
Action taken: 23.790424
===============Feedback to random agent round===============
Currnt Bid: 77.165761
=================Random Agent Turn=================
Action taken: 96.415544
===============Feedback to learned agent round===============
Observation:
[1, array([27.46741853]), array([77.16576091])]
Reward: -2.000000, Currnt Bid: 77.165761
Is done? True
Episode End
Positive: 148, Negative: 241
EPISODE :- 804
Random Player utility: 171.822330
=================Random Agent Turn=================
Action taken: 122.642725
===============Feedback to learned agent round===============
Observation:
[0, 0, 122.64272488338571]
Reward: -1.000000, Currnt Bid: 122.642725
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[23.67193243]
Explore action: 23.671932
Action taken: 23.671932
===============Feedback to random agent round===============
Currnt Bid: 122.642725
=================Random Agent Turn=================
Action taken: 138.578273
===============Feedback to learned agent round===============
Observation:
[1, 0, 122.64272488338571]
Reward: -2.000000, Currnt Bid: 122.642725
Is done? True
Episode End
Positive: 148, Negative: 241
EPISODE :- 805
Random Player utility: 266.664628
=================Random Agent Turn=================
Action taken: 29.399110
===============Feedback to learned agent round===============
Observation:
[0, 0, 29.399110458125573]
Reward: -1.000000, Currnt Bid: 29.399110
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.004303
Exploit action: 0.004303
Action taken: 0.004303
===============Feedback to random agent round===============
Currnt Bid: 29.399110
=================Random Agent Turn=================
Action taken: 214.488051
===============Feedback to learned agent round===============
Observation:
[1, 0, 29.399110458125573]
Reward: -2.000000, Currnt Bid: 29.399110
Is done? True
Episode End
Positive: 148, Negative: 241
EPISODE :- 806
Random Player utility: 145.687743
=================Random Agent Turn=================
Action taken: 37.362521
===============Feedback to learned agent round===============
Observation:
[0, 0, 37.36252125356783]
Reward: -1.000000, Currnt Bid: 37.362521
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[28.28607918]
Explore action: 28.286079
Action taken: 28.286079
===============Feedback to random agent round===============
Currnt Bid: 37.362521
=================Random Agent Turn=================
Action taken: 123.906315
===============Feedback to learned agent round===============
Observation:
[1, 0, 37.36252125356783]
Reward: -2.000000, Currnt Bid: 37.362521
Is done? True
Episode End
Positive: 148, Negative: 241
EPISODE :- 807
Random Player utility: 56.282106
=================Random Agent Turn=================
Action taken: 4.897627
===============Feedback to learned agent round===============
Observation:
[0, 0, 4.8976265459105495]
Reward: -1.000000, Currnt Bid: 4.897627
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[30.77361159]
Explore action: 30.773612
Action taken: 30.773612
===============Feedback to random agent round===============
Currnt Bid: 30.773612
=================Random Agent Turn=================
Action taken: 47.554194
===============Feedback to learned agent round===============
Observation:
[0, array([30.77361159]), array([47.55419399])]
Reward: -1.000000, Currnt Bid: 47.554194
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[29.32837701]
Explore action: 29.328377
Action taken: 29.328377
===============Feedback to random agent round===============
Currnt Bid: 47.554194
=================Random Agent Turn=================
Action taken: 49.586356
===============Feedback to learned agent round===============
Observation:
[1, array([30.77361159]), array([47.55419399])]
Reward: -2.000000, Currnt Bid: 47.554194
Is done? True
Episode End
Positive: 148, Negative: 242
EPISODE :- 808
Random Player utility: 45.139301
=================Random Agent Turn=================
Action taken: 26.046536
===============Feedback to learned agent round===============
Observation:
[0, 0, 26.046536146237397]
Reward: -1.000000, Currnt Bid: 26.046536
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[37.37477324]
Explore action: 37.374773
Action taken: 37.374773
===============Feedback to random agent round===============
Currnt Bid: 37.374773
=================Random Agent Turn=================
Action taken: 43.399072
===============Feedback to learned agent round===============
Observation:
[0, array([37.37477324]), array([43.39907194])]
Reward: -1.000000, Currnt Bid: 43.399072
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[53.74313744]
Explore action: 53.743137
Action taken: 53.743137
===============Feedback to random agent round===============
Currnt Bid: 53.743137
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([53.74313744]), array([43.39907194])]
Reward: 46.256863, Currnt Bid: 53.743137
Is done? True
Episode End
Positive: 149, Negative: 242
EPISODE :- 809
Random Player utility: 84.226743
=================Random Agent Turn=================
Action taken: 71.149573
===============Feedback to learned agent round===============
Observation:
[0, 0, 71.14957289017741]
Reward: -1.000000, Currnt Bid: 71.149573
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[57.06983061]
Explore action: 57.069831
Action taken: 57.069831
===============Feedback to random agent round===============
Currnt Bid: 71.149573
=================Random Agent Turn=================
Action taken: 72.054183
===============Feedback to learned agent round===============
Observation:
[1, 0, 71.14957289017741]
Reward: -2.000000, Currnt Bid: 71.149573
Is done? True
Episode End
Positive: 149, Negative: 243
EPISODE :- 810
Random Player utility: 152.644423
=================Random Agent Turn=================
Action taken: 52.743432
===============Feedback to learned agent round===============
Observation:
[0, 0, 52.74343222748405]
Reward: -1.000000, Currnt Bid: 52.743432
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.004011
Exploit action: 0.004011
Action taken: 0.004011
===============Feedback to random agent round===============
Currnt Bid: 52.743432
=================Random Agent Turn=================
Action taken: 136.940446
===============Feedback to learned agent round===============
Observation:
[1, 0, 52.74343222748405]
Reward: -2.000000, Currnt Bid: 52.743432
Is done? True
Episode End
Positive: 149, Negative: 243
EPISODE :- 811
Random Player utility: 138.673298
=================Random Agent Turn=================
Action taken: 30.715121
===============Feedback to learned agent round===============
Observation:
[0, 0, 30.715121264251287]
Reward: -1.000000, Currnt Bid: 30.715121
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[53.6806431]
Explore action: 53.680643
Action taken: 53.680643
===============Feedback to random agent round===============
Currnt Bid: 53.680643
=================Random Agent Turn=================
Action taken: 62.254545
===============Feedback to learned agent round===============
Observation:
[0, array([53.6806431]), array([62.25454526])]
Reward: -1.000000, Currnt Bid: 62.254545
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[51.234143]
Explore action: 51.234143
Action taken: 51.234143
===============Feedback to random agent round===============
Currnt Bid: 62.254545
=================Random Agent Turn=================
Action taken: 96.497874
===============Feedback to learned agent round===============
Observation:
[1, array([53.6806431]), array([62.25454526])]
Reward: -2.000000, Currnt Bid: 62.254545
Is done? True
Episode End
Positive: 149, Negative: 243
EPISODE :- 812
Random Player utility: 44.348111
=================Random Agent Turn=================
Action taken: 44.056510
===============Feedback to learned agent round===============
Observation:
[0, 0, 44.0565095434991]
Reward: -1.000000, Currnt Bid: 44.056510
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[54.7487611]
Explore action: 54.748761
Action taken: 54.748761
===============Feedback to random agent round===============
Currnt Bid: 54.748761
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([54.7487611]), 44.0565095434991]
Reward: 45.251239, Currnt Bid: 54.748761
Is done? True
Episode End
Positive: 150, Negative: 243
EPISODE :- 813
Random Player utility: 50.220941
=================Random Agent Turn=================
Action taken: 36.691017
===============Feedback to learned agent round===============
Observation:
[0, 0, 36.69101688762397]
Reward: -1.000000, Currnt Bid: 36.691017
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[45.96471329]
Explore action: 45.964713
Action taken: 45.964713
===============Feedback to random agent round===============
Currnt Bid: 45.964713
=================Random Agent Turn=================
Action taken: 48.817590
===============Feedback to learned agent round===============
Observation:
[0, array([45.96471329]), array([48.81759049])]
Reward: -1.000000, Currnt Bid: 48.817590
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[50.63684203]
Explore action: 50.636842
Action taken: 50.636842
===============Feedback to random agent round===============
Currnt Bid: 50.636842
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([50.63684203]), array([48.81759049])]
Reward: 49.363158, Currnt Bid: 50.636842
Is done? True
Episode End
Positive: 151, Negative: 243
EPISODE :- 814
Random Player utility: 249.786637
=================Random Agent Turn=================
Action taken: 56.373736
===============Feedback to learned agent round===============
Observation:
[0, 0, 56.37373571584302]
Reward: -1.000000, Currnt Bid: 56.373736
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[56.79200853]
Explore action: 56.792009
Action taken: 56.792009
===============Feedback to random agent round===============
Currnt Bid: 56.792009
=================Random Agent Turn=================
Action taken: 131.596504
===============Feedback to learned agent round===============
Observation:
[0, array([56.79200853]), array([131.59650361])]
Reward: -1.000000, Currnt Bid: 131.596504
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[44.10090402]
Explore action: 44.100904
Action taken: 44.100904
===============Feedback to random agent round===============
Currnt Bid: 131.596504
=================Random Agent Turn=================
Action taken: 135.277031
===============Feedback to learned agent round===============
Observation:
[1, array([56.79200853]), array([131.59650361])]
Reward: -2.000000, Currnt Bid: 131.596504
Is done? True
Episode End
Positive: 151, Negative: 243
EPISODE :- 815
Random Player utility: 125.187189
=================Random Agent Turn=================
Action taken: 80.970271
===============Feedback to learned agent round===============
Observation:
[0, 0, 80.97027130548999]
Reward: -1.000000, Currnt Bid: 80.970271
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.003719
Exploit action: 0.003719
Action taken: 0.003719
===============Feedback to random agent round===============
Currnt Bid: 80.970271
=================Random Agent Turn=================
Action taken: 118.653927
===============Feedback to learned agent round===============
Observation:
[1, 0, 80.97027130548999]
Reward: -2.000000, Currnt Bid: 80.970271
Is done? True
Episode End
Positive: 151, Negative: 243
EPISODE :- 816
Random Player utility: 73.005358
=================Random Agent Turn=================
Action taken: 26.145325
===============Feedback to learned agent round===============
Observation:
[0, 0, 26.1453245943707]
Reward: -1.000000, Currnt Bid: 26.145325
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[40.30837679]
Explore action: 40.308377
Action taken: 40.308377
===============Feedback to random agent round===============
Currnt Bid: 40.308377
=================Random Agent Turn=================
Action taken: 71.547237
===============Feedback to learned agent round===============
Observation:
[0, array([40.30837679]), array([71.5472375])]
Reward: -1.000000, Currnt Bid: 71.547237
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[50.25822405]
Explore action: 50.258224
Action taken: 50.258224
===============Feedback to random agent round===============
Currnt Bid: 71.547237
=================Random Agent Turn=================
Action taken: 71.740320
===============Feedback to learned agent round===============
Observation:
[1, array([40.30837679]), array([71.5472375])]
Reward: -2.000000, Currnt Bid: 71.547237
Is done? True
Episode End
Positive: 151, Negative: 244
EPISODE :- 817
Random Player utility: 46.210659
=================Random Agent Turn=================
Action taken: 40.481912
===============Feedback to learned agent round===============
Observation:
[0, 0, 40.481911766984915]
Reward: -1.000000, Currnt Bid: 40.481912
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.97686612]
Explore action: 48.976866
Action taken: 48.976866
===============Feedback to random agent round===============
Currnt Bid: 48.976866
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([48.97686612]), 40.481911766984915]
Reward: 51.023134, Currnt Bid: 48.976866
Is done? True
Episode End
Positive: 152, Negative: 244
EPISODE :- 818
Random Player utility: 70.446677
=================Random Agent Turn=================
Action taken: 43.376196
===============Feedback to learned agent round===============
Observation:
[0, 0, 43.37619571330888]
Reward: -1.000000, Currnt Bid: 43.376196
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[45.07878655]
Explore action: 45.078787
Action taken: 45.078787
===============Feedback to random agent round===============
Currnt Bid: 45.078787
=================Random Agent Turn=================
Action taken: 52.344579
===============Feedback to learned agent round===============
Observation:
[0, array([45.07878655]), array([52.3445785])]
Reward: -1.000000, Currnt Bid: 52.344579
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[47.59446006]
Explore action: 47.594460
Action taken: 47.594460
===============Feedback to random agent round===============
Currnt Bid: 52.344579
=================Random Agent Turn=================
Action taken: 60.964578
===============Feedback to learned agent round===============
Observation:
[1, array([45.07878655]), array([52.3445785])]
Reward: -2.000000, Currnt Bid: 52.344579
Is done? True
Episode End
Positive: 152, Negative: 245
EPISODE :- 819
Random Player utility: 18.691534
=================Random Agent Turn=================
Action taken: 8.838175
===============Feedback to learned agent round===============
Observation:
[0, 0, 8.838175441081823]
Reward: -1.000000, Currnt Bid: 8.838175
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[43.67595525]
Explore action: 43.675955
Action taken: 43.675955
===============Feedback to random agent round===============
Currnt Bid: 43.675955
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([43.67595525]), 8.838175441081823]
Reward: 56.324045, Currnt Bid: 43.675955
Is done? True
Episode End
Positive: 153, Negative: 245
EPISODE :- 820
Random Player utility: 91.105446
=================Random Agent Turn=================
Action taken: 3.169529
===============Feedback to learned agent round===============
Observation:
[0, 0, 3.1695289143267837]
Reward: -1.000000, Currnt Bid: 3.169529
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.003475
Exploit action: 0.003475
Action taken: 0.003475
===============Feedback to random agent round===============
Currnt Bid: 3.169529
=================Random Agent Turn=================
Action taken: 25.337186
===============Feedback to learned agent round===============
Observation:
[1, 0, 3.1695289143267837]
Reward: -2.000000, Currnt Bid: 3.169529
Is done? True
Episode End
Positive: 153, Negative: 246
EPISODE :- 821
Random Player utility: 148.691274
=================Random Agent Turn=================
Action taken: 34.083604
===============Feedback to learned agent round===============
Observation:
[0, 0, 34.08360411461439]
Reward: -1.000000, Currnt Bid: 34.083604
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[31.6315195]
Explore action: 31.631519
Action taken: 31.631519
===============Feedback to random agent round===============
Currnt Bid: 34.083604
=================Random Agent Turn=================
Action taken: 39.358422
===============Feedback to learned agent round===============
Observation:
[1, 0, 34.08360411461439]
Reward: -2.000000, Currnt Bid: 34.083604
Is done? True
Episode End
Positive: 153, Negative: 246
EPISODE :- 822
Random Player utility: 31.752123
=================Random Agent Turn=================
Action taken: 6.355924
===============Feedback to learned agent round===============
Observation:
[0, 0, 6.355924207722341]
Reward: -1.000000, Currnt Bid: 6.355924
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[29.07152861]
Explore action: 29.071529
Action taken: 29.071529
===============Feedback to random agent round===============
Currnt Bid: 29.071529
=================Random Agent Turn=================
Action taken: 29.163059
===============Feedback to learned agent round===============
Observation:
[0, array([29.07152861]), array([29.16305888])]
Reward: -1.000000, Currnt Bid: 29.163059
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[41.08183826]
Explore action: 41.081838
Action taken: 41.081838
===============Feedback to random agent round===============
Currnt Bid: 41.081838
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([41.08183826]), array([29.16305888])]
Reward: 58.918162, Currnt Bid: 41.081838
Is done? True
Episode End
Positive: 154, Negative: 246
EPISODE :- 823
Random Player utility: 80.948071
=================Random Agent Turn=================
Action taken: 40.501983
===============Feedback to learned agent round===============
Observation:
[0, 0, 40.501982722864575]
Reward: -1.000000, Currnt Bid: 40.501983
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[46.58212691]
Explore action: 46.582127
Action taken: 46.582127
===============Feedback to random agent round===============
Currnt Bid: 46.582127
=================Random Agent Turn=================
Action taken: 72.551804
===============Feedback to learned agent round===============
Observation:
[0, array([46.58212691]), array([72.55180366])]
Reward: -1.000000, Currnt Bid: 72.551804
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[36.44603429]
Explore action: 36.446034
Action taken: 36.446034
===============Feedback to random agent round===============
Currnt Bid: 72.551804
=================Random Agent Turn=================
Action taken: 76.377394
===============Feedback to learned agent round===============
Observation:
[1, array([46.58212691]), array([72.55180366])]
Reward: -2.000000, Currnt Bid: 72.551804
Is done? True
Episode End
Positive: 154, Negative: 247
EPISODE :- 824
Random Player utility: 93.923233
=================Random Agent Turn=================
Action taken: 44.297134
===============Feedback to learned agent round===============
Observation:
[0, 0, 44.297134263253405]
Reward: -1.000000, Currnt Bid: 44.297134
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[36.54945729]
Explore action: 36.549457
Action taken: 36.549457
===============Feedback to random agent round===============
Currnt Bid: 44.297134
=================Random Agent Turn=================
Action taken: 87.775925
===============Feedback to learned agent round===============
Observation:
[1, 0, 44.297134263253405]
Reward: -2.000000, Currnt Bid: 44.297134
Is done? True
Episode End
Positive: 154, Negative: 248
EPISODE :- 825
Random Player utility: 184.035463
=================Random Agent Turn=================
Action taken: 67.741913
===============Feedback to learned agent round===============
Observation:
[0, 0, 67.74191299747662]
Reward: -1.000000, Currnt Bid: 67.741913
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.003242
Exploit action: 0.003242
Action taken: 0.003242
===============Feedback to random agent round===============
Currnt Bid: 67.741913
=================Random Agent Turn=================
Action taken: 178.183254
===============Feedback to learned agent round===============
Observation:
[1, 0, 67.74191299747662]
Reward: -2.000000, Currnt Bid: 67.741913
Is done? True
Episode End
Positive: 154, Negative: 248
EPISODE :- 826
Random Player utility: 67.149890
=================Random Agent Turn=================
Action taken: 61.444312
===============Feedback to learned agent round===============
Observation:
[0, 0, 61.444311857015386]
Reward: -1.000000, Currnt Bid: 61.444312
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[40.45982478]
Explore action: 40.459825
Action taken: 40.459825
===============Feedback to random agent round===============
Currnt Bid: 61.444312
=================Random Agent Turn=================
Action taken: 63.318433
===============Feedback to learned agent round===============
Observation:
[1, 0, 61.444311857015386]
Reward: -2.000000, Currnt Bid: 61.444312
Is done? True
Episode End
Positive: 154, Negative: 249
EPISODE :- 827
Random Player utility: 48.317000
=================Random Agent Turn=================
Action taken: 20.512255
===============Feedback to learned agent round===============
Observation:
[0, 0, 20.512255017238797]
Reward: -1.000000, Currnt Bid: 20.512255
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.33259397]
Explore action: 48.332594
Action taken: 48.332594
===============Feedback to random agent round===============
Currnt Bid: 48.332594
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([48.33259397]), 20.512255017238797]
Reward: 51.667406, Currnt Bid: 48.332594
Is done? True
Episode End
Positive: 155, Negative: 249
EPISODE :- 828
Random Player utility: 233.113882
=================Random Agent Turn=================
Action taken: 93.068795
===============Feedback to learned agent round===============
Observation:
[0, 0, 93.06879488540537]
Reward: -1.000000, Currnt Bid: 93.068795
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[45.77586192]
Explore action: 45.775862
Action taken: 45.775862
===============Feedback to random agent round===============
Currnt Bid: 93.068795
=================Random Agent Turn=================
Action taken: 147.487777
===============Feedback to learned agent round===============
Observation:
[1, 0, 93.06879488540537]
Reward: -2.000000, Currnt Bid: 93.068795
Is done? True
Episode End
Positive: 155, Negative: 249
EPISODE :- 829
Random Player utility: 155.820004
=================Random Agent Turn=================
Action taken: 112.336844
===============Feedback to learned agent round===============
Observation:
[0, 0, 112.33684446607606]
Reward: -1.000000, Currnt Bid: 112.336844
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.37569304]
Explore action: 48.375693
Action taken: 48.375693
===============Feedback to random agent round===============
Currnt Bid: 112.336844
=================Random Agent Turn=================
Action taken: 119.915905
===============Feedback to learned agent round===============
Observation:
[1, 0, 112.33684446607606]
Reward: -2.000000, Currnt Bid: 112.336844
Is done? True
Episode End
Positive: 155, Negative: 249
EPISODE :- 830
Random Player utility: 70.960563
=================Random Agent Turn=================
Action taken: 68.599888
===============Feedback to learned agent round===============
Observation:
[0, 0, 68.59988837618845]
Reward: -1.000000, Currnt Bid: 68.599888
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.003064
Exploit action: 0.003064
Action taken: 0.003064
===============Feedback to random agent round===============
Currnt Bid: 68.599888
=================Random Agent Turn=================
Action taken: 70.024898
===============Feedback to learned agent round===============
Observation:
[1, 0, 68.59988837618845]
Reward: -2.000000, Currnt Bid: 68.599888
Is done? True
Episode End
Positive: 155, Negative: 250
EPISODE :- 831
Random Player utility: 104.532320
=================Random Agent Turn=================
Action taken: 82.643872
===============Feedback to learned agent round===============
Observation:
[0, 0, 82.6438715010406]
Reward: -1.000000, Currnt Bid: 82.643872
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[66.91052708]
Explore action: 66.910527
Action taken: 66.910527
===============Feedback to random agent round===============
Currnt Bid: 82.643872
=================Random Agent Turn=================
Action taken: 95.306549
===============Feedback to learned agent round===============
Observation:
[1, 0, 82.6438715010406]
Reward: -2.000000, Currnt Bid: 82.643872
Is done? True
Episode End
Positive: 155, Negative: 250
EPISODE :- 832
Random Player utility: 112.704194
=================Random Agent Turn=================
Action taken: 34.050599
===============Feedback to learned agent round===============
Observation:
[0, 0, 34.05059882897275]
Reward: -1.000000, Currnt Bid: 34.050599
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[65.23623598]
Explore action: 65.236236
Action taken: 65.236236
===============Feedback to random agent round===============
Currnt Bid: 65.236236
=================Random Agent Turn=================
Action taken: 96.453086
===============Feedback to learned agent round===============
Observation:
[0, array([65.23623598]), array([96.45308572])]
Reward: -1.000000, Currnt Bid: 96.453086
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[59.48101884]
Explore action: 59.481019
Action taken: 59.481019
===============Feedback to random agent round===============
Currnt Bid: 96.453086
=================Random Agent Turn=================
Action taken: 102.931731
===============Feedback to learned agent round===============
Observation:
[1, array([65.23623598]), array([96.45308572])]
Reward: -2.000000, Currnt Bid: 96.453086
Is done? True
Episode End
Positive: 155, Negative: 250
EPISODE :- 833
Random Player utility: 174.159825
=================Random Agent Turn=================
Action taken: 5.631139
===============Feedback to learned agent round===============
Observation:
[0, 0, 5.631139315505391]
Reward: -1.000000, Currnt Bid: 5.631139
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[59.14854846]
Explore action: 59.148548
Action taken: 59.148548
===============Feedback to random agent round===============
Currnt Bid: 59.148548
=================Random Agent Turn=================
Action taken: 59.447462
===============Feedback to learned agent round===============
Observation:
[0, array([59.14854846]), array([59.44746172])]
Reward: -1.000000, Currnt Bid: 59.447462
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[72.96884794]
Explore action: 72.968848
Action taken: 72.968848
===============Feedback to random agent round===============
Currnt Bid: 72.968848
=================Random Agent Turn=================
Action taken: 86.553404
===============Feedback to learned agent round===============
Observation:
[0, array([72.96884794]), array([86.55340425])]
Reward: -1.000000, Currnt Bid: 86.553404
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[78.72156697]
Explore action: 78.721567
Action taken: 78.721567
===============Feedback to random agent round===============
Currnt Bid: 86.553404
=================Random Agent Turn=================
Action taken: 152.478688
===============Feedback to learned agent round===============
Observation:
[1, array([72.96884794]), array([86.55340425])]
Reward: -2.000000, Currnt Bid: 86.553404
Is done? True
Episode End
Positive: 155, Negative: 250
EPISODE :- 834
Random Player utility: 92.255744
=================Random Agent Turn=================
Action taken: 21.929598
===============Feedback to learned agent round===============
Observation:
[0, 0, 21.929597863587833]
Reward: -1.000000, Currnt Bid: 21.929598
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[54.20797218]
Explore action: 54.207972
Action taken: 54.207972
===============Feedback to random agent round===============
Currnt Bid: 54.207972
=================Random Agent Turn=================
Action taken: 65.369293
===============Feedback to learned agent round===============
Observation:
[0, array([54.20797218]), array([65.36929287])]
Reward: -1.000000, Currnt Bid: 65.369293
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[62.87818141]
Explore action: 62.878181
Action taken: 62.878181
===============Feedback to random agent round===============
Currnt Bid: 65.369293
=================Random Agent Turn=================
Action taken: 83.585513
===============Feedback to learned agent round===============
Observation:
[1, array([54.20797218]), array([65.36929287])]
Reward: -2.000000, Currnt Bid: 65.369293
Is done? True
Episode End
Positive: 155, Negative: 251
EPISODE :- 835
Random Player utility: 128.874180
=================Random Agent Turn=================
Action taken: 108.605458
===============Feedback to learned agent round===============
Observation:
[0, 0, 108.60545812055972]
Reward: -1.000000, Currnt Bid: 108.605458
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.002831
Exploit action: 0.002831
Action taken: 0.002831
===============Feedback to random agent round===============
Currnt Bid: 108.605458
=================Random Agent Turn=================
Action taken: 115.331538
===============Feedback to learned agent round===============
Observation:
[1, 0, 108.60545812055972]
Reward: -2.000000, Currnt Bid: 108.605458
Is done? True
Episode End
Positive: 155, Negative: 251
EPISODE :- 836
Random Player utility: 96.841651
=================Random Agent Turn=================
Action taken: 59.746541
===============Feedback to learned agent round===============
Observation:
[0, 0, 59.74654133748316]
Reward: -1.000000, Currnt Bid: 59.746541
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[38.81921511]
Explore action: 38.819215
Action taken: 38.819215
===============Feedback to random agent round===============
Currnt Bid: 59.746541
=================Random Agent Turn=================
Action taken: 64.444181
===============Feedback to learned agent round===============
Observation:
[1, 0, 59.74654133748316]
Reward: -2.000000, Currnt Bid: 59.746541
Is done? True
Episode End
Positive: 155, Negative: 252
EPISODE :- 837
Random Player utility: 76.312938
=================Random Agent Turn=================
Action taken: 61.924256
===============Feedback to learned agent round===============
Observation:
[0, 0, 61.924255928551645]
Reward: -1.000000, Currnt Bid: 61.924256
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[46.22174936]
Explore action: 46.221749
Action taken: 46.221749
===============Feedback to random agent round===============
Currnt Bid: 61.924256
=================Random Agent Turn=================
Action taken: 68.170930
===============Feedback to learned agent round===============
Observation:
[1, 0, 61.924255928551645]
Reward: -2.000000, Currnt Bid: 61.924256
Is done? True
Episode End
Positive: 155, Negative: 253
EPISODE :- 838
Random Player utility: 86.945621
=================Random Agent Turn=================
Action taken: 28.049677
===============Feedback to learned agent round===============
Observation:
[0, 0, 28.04967747748225]
Reward: -1.000000, Currnt Bid: 28.049677
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[59.03551023]
Explore action: 59.035510
Action taken: 59.035510
===============Feedback to random agent round===============
Currnt Bid: 59.035510
=================Random Agent Turn=================
Action taken: 78.655993
===============Feedback to learned agent round===============
Observation:
[0, array([59.03551023]), array([78.65599318])]
Reward: -1.000000, Currnt Bid: 78.655993
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[38.69608518]
Explore action: 38.696085
Action taken: 38.696085
===============Feedback to random agent round===============
Currnt Bid: 78.655993
=================Random Agent Turn=================
Action taken: 85.859941
===============Feedback to learned agent round===============
Observation:
[1, array([59.03551023]), array([78.65599318])]
Reward: -2.000000, Currnt Bid: 78.655993
Is done? True
Episode End
Positive: 155, Negative: 254
EPISODE :- 839
Random Player utility: 129.321050
=================Random Agent Turn=================
Action taken: 66.055510
===============Feedback to learned agent round===============
Observation:
[0, 0, 66.05550967960353]
Reward: -1.000000, Currnt Bid: 66.055510
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[38.3186156]
Explore action: 38.318616
Action taken: 38.318616
===============Feedback to random agent round===============
Currnt Bid: 66.055510
=================Random Agent Turn=================
Action taken: 107.617098
===============Feedback to learned agent round===============
Observation:
[1, 0, 66.05550967960353]
Reward: -2.000000, Currnt Bid: 66.055510
Is done? True
Episode End
Positive: 155, Negative: 254
EPISODE :- 840
Random Player utility: 111.341617
=================Random Agent Turn=================
Action taken: 97.428947
===============Feedback to learned agent round===============
Observation:
[0, 0, 97.42894703852899]
Reward: -1.000000, Currnt Bid: 97.428947
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.002664
Exploit action: 0.002664
Action taken: 0.002664
===============Feedback to random agent round===============
Currnt Bid: 97.428947
=================Random Agent Turn=================
Action taken: 103.978976
===============Feedback to learned agent round===============
Observation:
[1, 0, 97.42894703852899]
Reward: -2.000000, Currnt Bid: 97.428947
Is done? True
Episode End
Positive: 155, Negative: 254
EPISODE :- 841
Random Player utility: 119.318349
=================Random Agent Turn=================
Action taken: 36.056680
===============Feedback to learned agent round===============
Observation:
[0, 0, 36.05668030289377]
Reward: -1.000000, Currnt Bid: 36.056680
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[42.01271686]
Explore action: 42.012717
Action taken: 42.012717
===============Feedback to random agent round===============
Currnt Bid: 42.012717
=================Random Agent Turn=================
Action taken: 117.134542
===============Feedback to learned agent round===============
Observation:
[0, array([42.01271686]), array([117.13454218])]
Reward: -1.000000, Currnt Bid: 117.134542
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[36.66706291]
Explore action: 36.667063
Action taken: 36.667063
===============Feedback to random agent round===============
Currnt Bid: 117.134542
=================Random Agent Turn=================
Action taken: 118.946758
===============Feedback to learned agent round===============
Observation:
[1, array([42.01271686]), array([117.13454218])]
Reward: -2.000000, Currnt Bid: 117.134542
Is done? True
Episode End
Positive: 155, Negative: 254
EPISODE :- 842
Random Player utility: 110.232420
=================Random Agent Turn=================
Action taken: 6.176567
===============Feedback to learned agent round===============
Observation:
[0, 0, 6.176567037112861]
Reward: -1.000000, Currnt Bid: 6.176567
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.0121361]
Explore action: 48.012136
Action taken: 48.012136
===============Feedback to random agent round===============
Currnt Bid: 48.012136
=================Random Agent Turn=================
Action taken: 88.305767
===============Feedback to learned agent round===============
Observation:
[0, array([48.0121361]), array([88.30576658])]
Reward: -1.000000, Currnt Bid: 88.305767
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[39.60696982]
Explore action: 39.606970
Action taken: 39.606970
===============Feedback to random agent round===============
Currnt Bid: 88.305767
=================Random Agent Turn=================
Action taken: 101.090552
===============Feedback to learned agent round===============
Observation:
[1, array([48.0121361]), array([88.30576658])]
Reward: -2.000000, Currnt Bid: 88.305767
Is done? True
Episode End
Positive: 155, Negative: 254
EPISODE :- 843
Random Player utility: 80.022239
=================Random Agent Turn=================
Action taken: 9.447648
===============Feedback to learned agent round===============
Observation:
[0, 0, 9.447648223882519]
Reward: -1.000000, Currnt Bid: 9.447648
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[28.57655384]
Explore action: 28.576554
Action taken: 28.576554
===============Feedback to random agent round===============
Currnt Bid: 28.576554
=================Random Agent Turn=================
Action taken: 33.524979
===============Feedback to learned agent round===============
Observation:
[0, array([28.57655384]), array([33.52497903])]
Reward: -1.000000, Currnt Bid: 33.524979
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[28.06823069]
Explore action: 28.068231
Action taken: 28.068231
===============Feedback to random agent round===============
Currnt Bid: 33.524979
=================Random Agent Turn=================
Action taken: 65.648454
===============Feedback to learned agent round===============
Observation:
[1, array([28.57655384]), array([33.52497903])]
Reward: -2.000000, Currnt Bid: 33.524979
Is done? True
Episode End
Positive: 155, Negative: 255
EPISODE :- 844
Random Player utility: 77.552240
=================Random Agent Turn=================
Action taken: 32.875940
===============Feedback to learned agent round===============
Observation:
[0, 0, 32.875940367095126]
Reward: -1.000000, Currnt Bid: 32.875940
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[40.45855294]
Explore action: 40.458553
Action taken: 40.458553
===============Feedback to random agent round===============
Currnt Bid: 40.458553
=================Random Agent Turn=================
Action taken: 68.068503
===============Feedback to learned agent round===============
Observation:
[0, array([40.45855294]), array([68.06850307])]
Reward: -1.000000, Currnt Bid: 68.068503
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[40.32883264]
Explore action: 40.328833
Action taken: 40.328833
===============Feedback to random agent round===============
Currnt Bid: 68.068503
=================Random Agent Turn=================
Action taken: 73.993795
===============Feedback to learned agent round===============
Observation:
[1, array([40.45855294]), array([68.06850307])]
Reward: -2.000000, Currnt Bid: 68.068503
Is done? True
Episode End
Positive: 155, Negative: 256
EPISODE :- 845
Random Player utility: 51.064958
=================Random Agent Turn=================
Action taken: 25.293326
===============Feedback to learned agent round===============
Observation:
[0, 0, 25.29332584509661]
Reward: -1.000000, Currnt Bid: 25.293326
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.002468
Exploit action: 0.002468
Action taken: 0.002468
===============Feedback to random agent round===============
Currnt Bid: 25.293326
=================Random Agent Turn=================
Action taken: 38.157884
===============Feedback to learned agent round===============
Observation:
[1, 0, 25.29332584509661]
Reward: -2.000000, Currnt Bid: 25.293326
Is done? True
Episode End
Positive: 155, Negative: 257
EPISODE :- 846
Random Player utility: 30.532474
=================Random Agent Turn=================
Action taken: 25.621469
===============Feedback to learned agent round===============
Observation:
[0, 0, 25.62146924538011]
Reward: -1.000000, Currnt Bid: 25.621469
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[49.87393775]
Explore action: 49.873938
Action taken: 49.873938
===============Feedback to random agent round===============
Currnt Bid: 49.873938
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([49.87393775]), 25.62146924538011]
Reward: 50.126062, Currnt Bid: 49.873938
Is done? True
Episode End
Positive: 156, Negative: 257
EPISODE :- 847
Random Player utility: 71.767337
=================Random Agent Turn=================
Action taken: 48.314212
===============Feedback to learned agent round===============
Observation:
[0, 0, 48.314212139331865]
Reward: -1.000000, Currnt Bid: 48.314212
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[66.53060291]
Explore action: 66.530603
Action taken: 66.530603
===============Feedback to random agent round===============
Currnt Bid: 66.530603
=================Random Agent Turn=================
Action taken: 69.694970
===============Feedback to learned agent round===============
Observation:
[0, array([66.53060291]), array([69.69496976])]
Reward: -1.000000, Currnt Bid: 69.694970
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[66.7673851]
Explore action: 66.767385
Action taken: 66.767385
===============Feedback to random agent round===============
Currnt Bid: 69.694970
=================Random Agent Turn=================
Action taken: 70.838908
===============Feedback to learned agent round===============
Observation:
[1, array([66.53060291]), array([69.69496976])]
Reward: -2.000000, Currnt Bid: 69.694970
Is done? True
Episode End
Positive: 156, Negative: 258
EPISODE :- 848
Random Player utility: 231.690454
=================Random Agent Turn=================
Action taken: 52.428820
===============Feedback to learned agent round===============
Observation:
[0, 0, 52.42881951379739]
Reward: -1.000000, Currnt Bid: 52.428820
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[63.36147073]
Explore action: 63.361471
Action taken: 63.361471
===============Feedback to random agent round===============
Currnt Bid: 63.361471
=================Random Agent Turn=================
Action taken: 161.672551
===============Feedback to learned agent round===============
Observation:
[0, array([63.36147073]), array([161.67255069])]
Reward: -1.000000, Currnt Bid: 161.672551
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[46.11479082]
Explore action: 46.114791
Action taken: 46.114791
===============Feedback to random agent round===============
Currnt Bid: 161.672551
=================Random Agent Turn=================
Action taken: 178.213295
===============Feedback to learned agent round===============
Observation:
[1, array([63.36147073]), array([161.67255069])]
Reward: -2.000000, Currnt Bid: 161.672551
Is done? True
Episode End
Positive: 156, Negative: 258
EPISODE :- 849
Random Player utility: 60.135335
=================Random Agent Turn=================
Action taken: 58.450730
===============Feedback to learned agent round===============
Observation:
[0, 0, 58.450729842534116]
Reward: -1.000000, Currnt Bid: 58.450730
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[41.18267212]
Explore action: 41.182672
Action taken: 41.182672
===============Feedback to random agent round===============
Currnt Bid: 58.450730
=================Random Agent Turn=================
Action taken: 60.062036
===============Feedback to learned agent round===============
Observation:
[1, 0, 58.450729842534116]
Reward: -2.000000, Currnt Bid: 58.450730
Is done? True
Episode End
Positive: 156, Negative: 259
EPISODE :- 850
Random Player utility: 132.987988
=================Random Agent Turn=================
Action taken: 109.774703
===============Feedback to learned agent round===============
Observation:
[0, 0, 109.77470302320869]
Reward: -1.000000, Currnt Bid: 109.774703
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.002307
Exploit action: 0.002307
Action taken: 0.002307
===============Feedback to random agent round===============
Currnt Bid: 109.774703
=================Random Agent Turn=================
Action taken: 122.380338
===============Feedback to learned agent round===============
Observation:
[1, 0, 109.77470302320869]
Reward: -2.000000, Currnt Bid: 109.774703
Is done? True
Episode End
Positive: 156, Negative: 259
EPISODE :- 851
Random Player utility: 181.134620
=================Random Agent Turn=================
Action taken: 108.768121
===============Feedback to learned agent round===============
Observation:
[0, 0, 108.76812125864792]
Reward: -1.000000, Currnt Bid: 108.768121
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[25.55009049]
Explore action: 25.550090
Action taken: 25.550090
===============Feedback to random agent round===============
Currnt Bid: 108.768121
=================Random Agent Turn=================
Action taken: 114.375254
===============Feedback to learned agent round===============
Observation:
[1, 0, 108.76812125864792]
Reward: -2.000000, Currnt Bid: 108.768121
Is done? True
Episode End
Positive: 156, Negative: 259
EPISODE :- 852
Random Player utility: 73.768718
=================Random Agent Turn=================
Action taken: 15.202201
===============Feedback to learned agent round===============
Observation:
[0, 0, 15.202201440482874]
Reward: -1.000000, Currnt Bid: 15.202201
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[32.75653975]
Explore action: 32.756540
Action taken: 32.756540
===============Feedback to random agent round===============
Currnt Bid: 32.756540
=================Random Agent Turn=================
Action taken: 59.777748
===============Feedback to learned agent round===============
Observation:
[0, array([32.75653975]), array([59.77774835])]
Reward: -1.000000, Currnt Bid: 59.777748
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[19.4338624]
Explore action: 19.433862
Action taken: 19.433862
===============Feedback to random agent round===============
Currnt Bid: 59.777748
=================Random Agent Turn=================
Action taken: 63.240737
===============Feedback to learned agent round===============
Observation:
[1, array([32.75653975]), array([59.77774835])]
Reward: -2.000000, Currnt Bid: 59.777748
Is done? True
Episode End
Positive: 156, Negative: 260
EPISODE :- 853
Random Player utility: 122.777641
=================Random Agent Turn=================
Action taken: 9.609051
===============Feedback to learned agent round===============
Observation:
[0, 0, 9.60905087853072]
Reward: -1.000000, Currnt Bid: 9.609051
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[12.08785387]
Explore action: 12.087854
Action taken: 12.087854
===============Feedback to random agent round===============
Currnt Bid: 12.087854
=================Random Agent Turn=================
Action taken: 28.903198
===============Feedback to learned agent round===============
Observation:
[0, array([12.08785387]), array([28.90319811])]
Reward: -1.000000, Currnt Bid: 28.903198
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[22.88012821]
Explore action: 22.880128
Action taken: 22.880128
===============Feedback to random agent round===============
Currnt Bid: 28.903198
=================Random Agent Turn=================
Action taken: 33.641606
===============Feedback to learned agent round===============
Observation:
[1, array([12.08785387]), array([28.90319811])]
Reward: -2.000000, Currnt Bid: 28.903198
Is done? True
Episode End
Positive: 156, Negative: 260
EPISODE :- 854
Random Player utility: 118.602738
=================Random Agent Turn=================
Action taken: 111.296910
===============Feedback to learned agent round===============
Observation:
[0, 0, 111.29690952292125]
Reward: -1.000000, Currnt Bid: 111.296910
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[28.12397489]
Explore action: 28.123975
Action taken: 28.123975
===============Feedback to random agent round===============
Currnt Bid: 111.296910
=================Random Agent Turn=================
Action taken: 112.125845
===============Feedback to learned agent round===============
Observation:
[1, 0, 111.29690952292125]
Reward: -2.000000, Currnt Bid: 111.296910
Is done? True
Episode End
Positive: 156, Negative: 260
EPISODE :- 855
Random Player utility: 42.433304
=================Random Agent Turn=================
Action taken: 17.346972
===============Feedback to learned agent round===============
Observation:
[0, 0, 17.346972057448134]
Reward: -1.000000, Currnt Bid: 17.346972
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.002164
Exploit action: 0.002164
Action taken: 0.002164
===============Feedback to random agent round===============
Currnt Bid: 17.346972
=================Random Agent Turn=================
Action taken: 32.657789
===============Feedback to learned agent round===============
Observation:
[1, 0, 17.346972057448134]
Reward: -2.000000, Currnt Bid: 17.346972
Is done? True
Episode End
Positive: 156, Negative: 261
EPISODE :- 856
Random Player utility: 101.467417
=================Random Agent Turn=================
Action taken: 3.532681
===============Feedback to learned agent round===============
Observation:
[0, 0, 3.5326813823871617]
Reward: -1.000000, Currnt Bid: 3.532681
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[52.22871476]
Explore action: 52.228715
Action taken: 52.228715
===============Feedback to random agent round===============
Currnt Bid: 52.228715
=================Random Agent Turn=================
Action taken: 82.276229
===============Feedback to learned agent round===============
Observation:
[0, array([52.22871476]), array([82.27622883])]
Reward: -1.000000, Currnt Bid: 82.276229
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[57.00545002]
Explore action: 57.005450
Action taken: 57.005450
===============Feedback to random agent round===============
Currnt Bid: 82.276229
=================Random Agent Turn=================
Action taken: 98.453231
===============Feedback to learned agent round===============
Observation:
[1, array([52.22871476]), array([82.27622883])]
Reward: -2.000000, Currnt Bid: 82.276229
Is done? True
Episode End
Positive: 156, Negative: 261
EPISODE :- 857
Random Player utility: 104.802422
=================Random Agent Turn=================
Action taken: 2.174045
===============Feedback to learned agent round===============
Observation:
[0, 0, 2.1740447849124243]
Reward: -1.000000, Currnt Bid: 2.174045
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[56.24028636]
Explore action: 56.240286
Action taken: 56.240286
===============Feedback to random agent round===============
Currnt Bid: 56.240286
=================Random Agent Turn=================
Action taken: 86.607615
===============Feedback to learned agent round===============
Observation:
[0, array([56.24028636]), array([86.60761483])]
Reward: -1.000000, Currnt Bid: 86.607615
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[54.52416521]
Explore action: 54.524165
Action taken: 54.524165
===============Feedback to random agent round===============
Currnt Bid: 86.607615
=================Random Agent Turn=================
Action taken: 102.562368
===============Feedback to learned agent round===============
Observation:
[1, array([56.24028636]), array([86.60761483])]
Reward: -2.000000, Currnt Bid: 86.607615
Is done? True
Episode End
Positive: 156, Negative: 261
EPISODE :- 858
Random Player utility: 120.783746
=================Random Agent Turn=================
Action taken: 79.990421
===============Feedback to learned agent round===============
Observation:
[0, 0, 79.99042099775765]
Reward: -1.000000, Currnt Bid: 79.990421
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[55.84579834]
Explore action: 55.845798
Action taken: 55.845798
===============Feedback to random agent round===============
Currnt Bid: 79.990421
=================Random Agent Turn=================
Action taken: 99.462533
===============Feedback to learned agent round===============
Observation:
[1, 0, 79.99042099775765]
Reward: -2.000000, Currnt Bid: 79.990421
Is done? True
Episode End
Positive: 156, Negative: 261
EPISODE :- 859
Random Player utility: 213.824844
=================Random Agent Turn=================
Action taken: 168.735930
===============Feedback to learned agent round===============
Observation:
[0, 0, 168.73592965930885]
Reward: -1.000000, Currnt Bid: 168.735930
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[55.49738981]
Explore action: 55.497390
Action taken: 55.497390
===============Feedback to random agent round===============
Currnt Bid: 168.735930
=================Random Agent Turn=================
Action taken: 185.688234
===============Feedback to learned agent round===============
Observation:
[1, 0, 168.73592965930885]
Reward: -2.000000, Currnt Bid: 168.735930
Is done? True
Episode End
Positive: 156, Negative: 261
EPISODE :- 860
Random Player utility: 21.431064
=================Random Agent Turn=================
Action taken: 2.467337
===============Feedback to learned agent round===============
Observation:
[0, 0, 2.4673371175290115]
Reward: -1.000000, Currnt Bid: 2.467337
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.002027
Exploit action: 0.002027
Action taken: 0.002027
===============Feedback to random agent round===============
Currnt Bid: 2.467337
=================Random Agent Turn=================
Action taken: 20.348836
===============Feedback to learned agent round===============
Observation:
[1, 0, 2.4673371175290115]
Reward: -2.000000, Currnt Bid: 2.467337
Is done? True
Episode End
Positive: 156, Negative: 262
EPISODE :- 861
Random Player utility: 204.254058
=================Random Agent Turn=================
Action taken: 76.492261
===============Feedback to learned agent round===============
Observation:
[0, 0, 76.49226098273024]
Reward: -1.000000, Currnt Bid: 76.492261
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[49.55994247]
Explore action: 49.559942
Action taken: 49.559942
===============Feedback to random agent round===============
Currnt Bid: 76.492261
=================Random Agent Turn=================
Action taken: 164.340736
===============Feedback to learned agent round===============
Observation:
[1, 0, 76.49226098273024]
Reward: -2.000000, Currnt Bid: 76.492261
Is done? True
Episode End
Positive: 156, Negative: 262
EPISODE :- 862
Random Player utility: 35.635801
=================Random Agent Turn=================
Action taken: 30.311639
===============Feedback to learned agent round===============
Observation:
[0, 0, 30.311639029588086]
Reward: -1.000000, Currnt Bid: 30.311639
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[54.52610554]
Explore action: 54.526106
Action taken: 54.526106
===============Feedback to random agent round===============
Currnt Bid: 54.526106
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([54.52610554]), 30.311639029588086]
Reward: 45.473894, Currnt Bid: 54.526106
Is done? True
Episode End
Positive: 157, Negative: 262
EPISODE :- 863
Random Player utility: 38.625894
=================Random Agent Turn=================
Action taken: 20.216614
===============Feedback to learned agent round===============
Observation:
[0, 0, 20.216614283382675]
Reward: -1.000000, Currnt Bid: 20.216614
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[40.39535946]
Explore action: 40.395359
Action taken: 40.395359
===============Feedback to random agent round===============
Currnt Bid: 40.395359
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([40.39535946]), 20.216614283382675]
Reward: 59.604641, Currnt Bid: 40.395359
Is done? True
Episode End
Positive: 158, Negative: 262
EPISODE :- 864
Random Player utility: 221.794854
=================Random Agent Turn=================
Action taken: 27.951298
===============Feedback to learned agent round===============
Observation:
[0, 0, 27.951297564535654]
Reward: -1.000000, Currnt Bid: 27.951298
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[40.56893063]
Explore action: 40.568931
Action taken: 40.568931
===============Feedback to random agent round===============
Currnt Bid: 40.568931
=================Random Agent Turn=================
Action taken: 155.694418
===============Feedback to learned agent round===============
Observation:
[0, array([40.56893063]), array([155.69441809])]
Reward: -1.000000, Currnt Bid: 155.694418
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[31.91414499]
Explore action: 31.914145
Action taken: 31.914145
===============Feedback to random agent round===============
Currnt Bid: 155.694418
=================Random Agent Turn=================
Action taken: 191.590195
===============Feedback to learned agent round===============
Observation:
[1, array([40.56893063]), array([155.69441809])]
Reward: -2.000000, Currnt Bid: 155.694418
Is done? True
Episode End
Positive: 158, Negative: 262
EPISODE :- 865
Random Player utility: 122.941899
=================Random Agent Turn=================
Action taken: 88.220714
===============Feedback to learned agent round===============
Observation:
[0, 0, 88.22071426531696]
Reward: -1.000000, Currnt Bid: 88.220714
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.001907
Exploit action: 0.001907
Action taken: 0.001907
===============Feedback to random agent round===============
Currnt Bid: 88.220714
=================Random Agent Turn=================
Action taken: 110.122770
===============Feedback to learned agent round===============
Observation:
[1, 0, 88.22071426531696]
Reward: -2.000000, Currnt Bid: 88.220714
Is done? True
Episode End
Positive: 158, Negative: 262
EPISODE :- 866
Random Player utility: 117.205659
=================Random Agent Turn=================
Action taken: 50.546653
===============Feedback to learned agent round===============
Observation:
[0, 0, 50.54665349803615]
Reward: -1.000000, Currnt Bid: 50.546653
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[28.17877411]
Explore action: 28.178774
Action taken: 28.178774
===============Feedback to random agent round===============
Currnt Bid: 50.546653
=================Random Agent Turn=================
Action taken: 77.534063
===============Feedback to learned agent round===============
Observation:
[1, 0, 50.54665349803615]
Reward: -2.000000, Currnt Bid: 50.546653
Is done? True
Episode End
Positive: 158, Negative: 262
EPISODE :- 867
Random Player utility: 8.994919
=================Random Agent Turn=================
Action taken: 5.245337
===============Feedback to learned agent round===============
Observation:
[0, 0, 5.245337168311242]
Reward: -1.000000, Currnt Bid: 5.245337
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[41.86733136]
Explore action: 41.867331
Action taken: 41.867331
===============Feedback to random agent round===============
Currnt Bid: 41.867331
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([41.86733136]), 5.245337168311242]
Reward: 58.132669, Currnt Bid: 41.867331
Is done? True
Episode End
Positive: 159, Negative: 262
EPISODE :- 868
Random Player utility: 86.154308
=================Random Agent Turn=================
Action taken: 76.838734
===============Feedback to learned agent round===============
Observation:
[0, 0, 76.8387341128912]
Reward: -1.000000, Currnt Bid: 76.838734
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[57.79595243]
Explore action: 57.795952
Action taken: 57.795952
===============Feedback to random agent round===============
Currnt Bid: 76.838734
=================Random Agent Turn=================
Action taken: 79.233418
===============Feedback to learned agent round===============
Observation:
[1, 0, 76.8387341128912]
Reward: -2.000000, Currnt Bid: 76.838734
Is done? True
Episode End
Positive: 159, Negative: 263
EPISODE :- 869
Random Player utility: 97.715343
=================Random Agent Turn=================
Action taken: 75.036457
===============Feedback to learned agent round===============
Observation:
[0, 0, 75.03645733771764]
Reward: -1.000000, Currnt Bid: 75.036457
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[45.62199975]
Explore action: 45.622000
Action taken: 45.622000
===============Feedback to random agent round===============
Currnt Bid: 75.036457
=================Random Agent Turn=================
Action taken: 82.639800
===============Feedback to learned agent round===============
Observation:
[1, 0, 75.03645733771764]
Reward: -2.000000, Currnt Bid: 75.036457
Is done? True
Episode End
Positive: 159, Negative: 264
EPISODE :- 870
Random Player utility: 92.184633
=================Random Agent Turn=================
Action taken: 20.398381
===============Feedback to learned agent round===============
Observation:
[0, 0, 20.398381242361044]
Reward: -1.000000, Currnt Bid: 20.398381
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.001812
Exploit action: 0.001812
Action taken: 0.001812
===============Feedback to random agent round===============
Currnt Bid: 20.398381
=================Random Agent Turn=================
Action taken: 21.056633
===============Feedback to learned agent round===============
Observation:
[1, 0, 20.398381242361044]
Reward: -2.000000, Currnt Bid: 20.398381
Is done? True
Episode End
Positive: 159, Negative: 265
EPISODE :- 871
Random Player utility: 2.734541
=================Random Agent Turn=================
Action taken: 2.506369
===============Feedback to learned agent round===============
Observation:
[0, 0, 2.5063687658910236]
Reward: -1.000000, Currnt Bid: 2.506369
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[38.37407578]
Explore action: 38.374076
Action taken: 38.374076
===============Feedback to random agent round===============
Currnt Bid: 38.374076
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([38.37407578]), 2.5063687658910236]
Reward: 61.625924, Currnt Bid: 38.374076
Is done? True
Episode End
Positive: 160, Negative: 265
EPISODE :- 872
Random Player utility: 32.036435
=================Random Agent Turn=================
Action taken: 20.183791
===============Feedback to learned agent round===============
Observation:
[0, 0, 20.183791400717865]
Reward: -1.000000, Currnt Bid: 20.183791
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[54.89809961]
Explore action: 54.898100
Action taken: 54.898100
===============Feedback to random agent round===============
Currnt Bid: 54.898100
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([54.89809961]), 20.183791400717865]
Reward: 45.101900, Currnt Bid: 54.898100
Is done? True
Episode End
Positive: 161, Negative: 265
EPISODE :- 873
Random Player utility: 96.177772
=================Random Agent Turn=================
Action taken: 64.061045
===============Feedback to learned agent round===============
Observation:
[0, 0, 64.06104549028956]
Reward: -1.000000, Currnt Bid: 64.061045
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.25229556]
Explore action: 48.252296
Action taken: 48.252296
===============Feedback to random agent round===============
Currnt Bid: 64.061045
=================Random Agent Turn=================
Action taken: 74.965143
===============Feedback to learned agent round===============
Observation:
[1, 0, 64.06104549028956]
Reward: -2.000000, Currnt Bid: 64.061045
Is done? True
Episode End
Positive: 161, Negative: 266
EPISODE :- 874
Random Player utility: 80.224990
=================Random Agent Turn=================
Action taken: 52.236181
===============Feedback to learned agent round===============
Observation:
[0, 0, 52.23618114785241]
Reward: -1.000000, Currnt Bid: 52.236181
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[43.53339672]
Explore action: 43.533397
Action taken: 43.533397
===============Feedback to random agent round===============
Currnt Bid: 52.236181
=================Random Agent Turn=================
Action taken: 78.266785
===============Feedback to learned agent round===============
Observation:
[1, 0, 52.23618114785241]
Reward: -2.000000, Currnt Bid: 52.236181
Is done? True
Episode End
Positive: 161, Negative: 267
EPISODE :- 875
Random Player utility: 55.485378
=================Random Agent Turn=================
Action taken: 28.543651
===============Feedback to learned agent round===============
Observation:
[0, 0, 28.543651145856035]
Reward: -1.000000, Currnt Bid: 28.543651
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.001717
Exploit action: 0.001717
Action taken: 0.001717
===============Feedback to random agent round===============
Currnt Bid: 28.543651
=================Random Agent Turn=================
Action taken: 43.269732
===============Feedback to learned agent round===============
Observation:
[1, 0, 28.543651145856035]
Reward: -2.000000, Currnt Bid: 28.543651
Is done? True
Episode End
Positive: 161, Negative: 268
EPISODE :- 876
Random Player utility: 129.351225
=================Random Agent Turn=================
Action taken: 3.746194
===============Feedback to learned agent round===============
Observation:
[0, 0, 3.74619424496619]
Reward: -1.000000, Currnt Bid: 3.746194
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.50139189]
Explore action: 48.501392
Action taken: 48.501392
===============Feedback to random agent round===============
Currnt Bid: 48.501392
=================Random Agent Turn=================
Action taken: 105.588428
===============Feedback to learned agent round===============
Observation:
[0, array([48.50139189]), array([105.5884279])]
Reward: -1.000000, Currnt Bid: 105.588428
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[61.10032959]
Explore action: 61.100330
Action taken: 61.100330
===============Feedback to random agent round===============
Currnt Bid: 105.588428
=================Random Agent Turn=================
Action taken: 111.265007
===============Feedback to learned agent round===============
Observation:
[1, array([48.50139189]), array([105.5884279])]
Reward: -2.000000, Currnt Bid: 105.588428
Is done? True
Episode End
Positive: 161, Negative: 268
EPISODE :- 877
Random Player utility: 155.436508
=================Random Agent Turn=================
Action taken: 38.255626
===============Feedback to learned agent round===============
Observation:
[0, 0, 38.25562574779314]
Reward: -1.000000, Currnt Bid: 38.255626
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[67.69403596]
Explore action: 67.694036
Action taken: 67.694036
===============Feedback to random agent round===============
Currnt Bid: 67.694036
=================Random Agent Turn=================
Action taken: 146.773733
===============Feedback to learned agent round===============
Observation:
[0, array([67.69403596]), array([146.77373268])]
Reward: -1.000000, Currnt Bid: 146.773733
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[75.24263888]
Explore action: 75.242639
Action taken: 75.242639
===============Feedback to random agent round===============
Currnt Bid: 146.773733
=================Random Agent Turn=================
Action taken: 153.776527
===============Feedback to learned agent round===============
Observation:
[1, array([67.69403596]), array([146.77373268])]
Reward: -2.000000, Currnt Bid: 146.773733
Is done? True
Episode End
Positive: 161, Negative: 268
EPISODE :- 878
Random Player utility: 83.638384
=================Random Agent Turn=================
Action taken: 73.328019
===============Feedback to learned agent round===============
Observation:
[0, 0, 73.3280189373822]
Reward: -1.000000, Currnt Bid: 73.328019
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[66.59960692]
Explore action: 66.599607
Action taken: 66.599607
===============Feedback to random agent round===============
Currnt Bid: 73.328019
=================Random Agent Turn=================
Action taken: 80.815794
===============Feedback to learned agent round===============
Observation:
[1, 0, 73.3280189373822]
Reward: -2.000000, Currnt Bid: 73.328019
Is done? True
Episode End
Positive: 161, Negative: 269
EPISODE :- 879
Random Player utility: 185.784469
=================Random Agent Turn=================
Action taken: 125.111332
===============Feedback to learned agent round===============
Observation:
[0, 0, 125.11133169924292]
Reward: -1.000000, Currnt Bid: 125.111332
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[59.32790943]
Explore action: 59.327909
Action taken: 59.327909
===============Feedback to random agent round===============
Currnt Bid: 125.111332
=================Random Agent Turn=================
Action taken: 158.328652
===============Feedback to learned agent round===============
Observation:
[1, 0, 125.11133169924292]
Reward: -2.000000, Currnt Bid: 125.111332
Is done? True
Episode End
Positive: 161, Negative: 269
EPISODE :- 880
Random Player utility: 107.120774
=================Random Agent Turn=================
Action taken: 3.830885
===============Feedback to learned agent round===============
Observation:
[0, 0, 3.8308854463638435]
Reward: -1.000000, Currnt Bid: 3.830885
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.001615
Exploit action: 0.001615
Action taken: 0.001615
===============Feedback to random agent round===============
Currnt Bid: 3.830885
=================Random Agent Turn=================
Action taken: 72.279570
===============Feedback to learned agent round===============
Observation:
[1, 0, 3.8308854463638435]
Reward: -2.000000, Currnt Bid: 3.830885
Is done? True
Episode End
Positive: 161, Negative: 269
EPISODE :- 881
Random Player utility: 28.029804
=================Random Agent Turn=================
Action taken: 2.867639
===============Feedback to learned agent round===============
Observation:
[0, 0, 2.867639148636281]
Reward: -1.000000, Currnt Bid: 2.867639
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[55.69033726]
Explore action: 55.690337
Action taken: 55.690337
===============Feedback to random agent round===============
Currnt Bid: 55.690337
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([55.69033726]), 2.867639148636281]
Reward: 44.309663, Currnt Bid: 55.690337
Is done? True
Episode End
Positive: 162, Negative: 269
EPISODE :- 882
Random Player utility: 14.073404
=================Random Agent Turn=================
Action taken: 7.709908
===============Feedback to learned agent round===============
Observation:
[0, 0, 7.709907569830722]
Reward: -1.000000, Currnt Bid: 7.709908
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[52.99097569]
Explore action: 52.990976
Action taken: 52.990976
===============Feedback to random agent round===============
Currnt Bid: 52.990976
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([52.99097569]), 7.709907569830722]
Reward: 47.009024, Currnt Bid: 52.990976
Is done? True
Episode End
Positive: 163, Negative: 269
EPISODE :- 883
Random Player utility: 42.759859
=================Random Agent Turn=================
Action taken: 15.343376
===============Feedback to learned agent round===============
Observation:
[0, 0, 15.343376021822083]
Reward: -1.000000, Currnt Bid: 15.343376
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[49.46103074]
Explore action: 49.461031
Action taken: 49.461031
===============Feedback to random agent round===============
Currnt Bid: 49.461031
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([49.46103074]), 15.343376021822083]
Reward: 50.538969, Currnt Bid: 49.461031
Is done? True
Episode End
Positive: 164, Negative: 269
EPISODE :- 884
Random Player utility: 165.553781
=================Random Agent Turn=================
Action taken: 148.008462
===============Feedback to learned agent round===============
Observation:
[0, 0, 148.00846152221524]
Reward: -1.000000, Currnt Bid: 148.008462
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[34.38551057]
Explore action: 34.385511
Action taken: 34.385511
===============Feedback to random agent round===============
Currnt Bid: 148.008462
=================Random Agent Turn=================
Action taken: 151.847165
===============Feedback to learned agent round===============
Observation:
[1, 0, 148.00846152221524]
Reward: -2.000000, Currnt Bid: 148.008462
Is done? True
Episode End
Positive: 164, Negative: 269
EPISODE :- 885
Random Player utility: 147.965219
=================Random Agent Turn=================
Action taken: 43.001391
===============Feedback to learned agent round===============
Observation:
[0, 0, 43.001390873347134]
Reward: -1.000000, Currnt Bid: 43.001391
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.001532
Exploit action: 0.001532
Action taken: 0.001532
===============Feedback to random agent round===============
Currnt Bid: 43.001391
=================Random Agent Turn=================
Action taken: 77.495665
===============Feedback to learned agent round===============
Observation:
[1, 0, 43.001390873347134]
Reward: -2.000000, Currnt Bid: 43.001391
Is done? True
Episode End
Positive: 164, Negative: 269
EPISODE :- 886
Random Player utility: 68.458338
=================Random Agent Turn=================
Action taken: 65.464980
===============Feedback to learned agent round===============
Observation:
[0, 0, 65.46498021961361]
Reward: -1.000000, Currnt Bid: 65.464980
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[34.55397262]
Explore action: 34.553973
Action taken: 34.553973
===============Feedback to random agent round===============
Currnt Bid: 65.464980
=================Random Agent Turn=================
Action taken: 67.726023
===============Feedback to learned agent round===============
Observation:
[1, 0, 65.46498021961361]
Reward: -2.000000, Currnt Bid: 65.464980
Is done? True
Episode End
Positive: 164, Negative: 270
EPISODE :- 887
Random Player utility: 80.667401
=================Random Agent Turn=================
Action taken: 72.998947
===============Feedback to learned agent round===============
Observation:
[0, 0, 72.9989470196914]
Reward: -1.000000, Currnt Bid: 72.998947
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[49.15408272]
Explore action: 49.154083
Action taken: 49.154083
===============Feedback to random agent round===============
Currnt Bid: 72.998947
=================Random Agent Turn=================
Action taken: 78.743017
===============Feedback to learned agent round===============
Observation:
[1, 0, 72.9989470196914]
Reward: -2.000000, Currnt Bid: 72.998947
Is done? True
Episode End
Positive: 164, Negative: 271
EPISODE :- 888
Random Player utility: 115.494666
=================Random Agent Turn=================
Action taken: 66.417545
===============Feedback to learned agent round===============
Observation:
[0, 0, 66.4175452910113]
Reward: -1.000000, Currnt Bid: 66.417545
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[54.10809651]
Explore action: 54.108097
Action taken: 54.108097
===============Feedback to random agent round===============
Currnt Bid: 66.417545
=================Random Agent Turn=================
Action taken: 90.194111
===============Feedback to learned agent round===============
Observation:
[1, 0, 66.4175452910113]
Reward: -2.000000, Currnt Bid: 66.417545
Is done? True
Episode End
Positive: 164, Negative: 271
EPISODE :- 889
Random Player utility: 93.178095
=================Random Agent Turn=================
Action taken: 48.972850
===============Feedback to learned agent round===============
Observation:
[0, 0, 48.9728495629311]
Reward: -1.000000, Currnt Bid: 48.972850
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[46.84370764]
Explore action: 46.843708
Action taken: 46.843708
===============Feedback to random agent round===============
Currnt Bid: 48.972850
=================Random Agent Turn=================
Action taken: 77.694936
===============Feedback to learned agent round===============
Observation:
[1, 0, 48.9728495629311]
Reward: -2.000000, Currnt Bid: 48.972850
Is done? True
Episode End
Positive: 164, Negative: 272
EPISODE :- 890
Random Player utility: 60.672959
=================Random Agent Turn=================
Action taken: 35.764224
===============Feedback to learned agent round===============
Observation:
[0, 0, 35.76422429913236]
Reward: -1.000000, Currnt Bid: 35.764224
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.001454
Exploit action: 0.001454
Action taken: 0.001454
===============Feedback to random agent round===============
Currnt Bid: 35.764224
=================Random Agent Turn=================
Action taken: 49.865165
===============Feedback to learned agent round===============
Observation:
[1, 0, 35.76422429913236]
Reward: -2.000000, Currnt Bid: 35.764224
Is done? True
Episode End
Positive: 164, Negative: 273
EPISODE :- 891
Random Player utility: 143.235829
=================Random Agent Turn=================
Action taken: 111.959860
===============Feedback to learned agent round===============
Observation:
[0, 0, 111.95986035190454]
Reward: -1.000000, Currnt Bid: 111.959860
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[50.35578332]
Explore action: 50.355783
Action taken: 50.355783
===============Feedback to random agent round===============
Currnt Bid: 111.959860
=================Random Agent Turn=================
Action taken: 129.050845
===============Feedback to learned agent round===============
Observation:
[1, 0, 111.95986035190454]
Reward: -2.000000, Currnt Bid: 111.959860
Is done? True
Episode End
Positive: 164, Negative: 273
EPISODE :- 892
Random Player utility: 135.281341
=================Random Agent Turn=================
Action taken: 127.448188
===============Feedback to learned agent round===============
Observation:
[0, 0, 127.44818841541638]
Reward: -1.000000, Currnt Bid: 127.448188
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[58.74285896]
Explore action: 58.742859
Action taken: 58.742859
===============Feedback to random agent round===============
Currnt Bid: 127.448188
=================Random Agent Turn=================
Action taken: 135.276913
===============Feedback to learned agent round===============
Observation:
[1, 0, 127.44818841541638]
Reward: -2.000000, Currnt Bid: 127.448188
Is done? True
Episode End
Positive: 164, Negative: 273
EPISODE :- 893
Random Player utility: 78.304767
=================Random Agent Turn=================
Action taken: 22.794657
===============Feedback to learned agent round===============
Observation:
[0, 0, 22.79465663764189]
Reward: -1.000000, Currnt Bid: 22.794657
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[68.96738925]
Explore action: 68.967389
Action taken: 68.967389
===============Feedback to random agent round===============
Currnt Bid: 68.967389
=================Random Agent Turn=================
Action taken: 71.790743
===============Feedback to learned agent round===============
Observation:
[0, array([68.96738925]), array([71.79074268])]
Reward: -1.000000, Currnt Bid: 71.790743
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[62.98719177]
Explore action: 62.987192
Action taken: 62.987192
===============Feedback to random agent round===============
Currnt Bid: 71.790743
=================Random Agent Turn=================
Action taken: 74.849152
===============Feedback to learned agent round===============
Observation:
[1, array([68.96738925]), array([71.79074268])]
Reward: -2.000000, Currnt Bid: 71.790743
Is done? True
Episode End
Positive: 164, Negative: 274
EPISODE :- 894
Random Player utility: 60.554858
=================Random Agent Turn=================
Action taken: 49.692082
===============Feedback to learned agent round===============
Observation:
[0, 0, 49.69208197277078]
Reward: -1.000000, Currnt Bid: 49.692082
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[53.87536589]
Explore action: 53.875366
Action taken: 53.875366
===============Feedback to random agent round===============
Currnt Bid: 53.875366
=================Random Agent Turn=================
Action taken: 59.804261
===============Feedback to learned agent round===============
Observation:
[0, array([53.87536589]), array([59.80426115])]
Reward: -1.000000, Currnt Bid: 59.804261
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[47.92447388]
Explore action: 47.924474
Action taken: 47.924474
===============Feedback to random agent round===============
Currnt Bid: 59.804261
=================Random Agent Turn=================
Action taken: 60.395090
===============Feedback to learned agent round===============
Observation:
[1, array([53.87536589]), array([59.80426115])]
Reward: -2.000000, Currnt Bid: 59.804261
Is done? True
Episode End
Positive: 164, Negative: 275
EPISODE :- 895
Random Player utility: 180.758309
=================Random Agent Turn=================
Action taken: 63.742054
===============Feedback to learned agent round===============
Observation:
[0, 0, 63.74205396752197]
Reward: -1.000000, Currnt Bid: 63.742054
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.001365
Exploit action: 0.001365
Action taken: 0.001365
===============Feedback to random agent round===============
Currnt Bid: 63.742054
=================Random Agent Turn=================
Action taken: 177.573332
===============Feedback to learned agent round===============
Observation:
[1, 0, 63.74205396752197]
Reward: -2.000000, Currnt Bid: 63.742054
Is done? True
Episode End
Positive: 164, Negative: 275
EPISODE :- 896
Random Player utility: 255.904127
=================Random Agent Turn=================
Action taken: 48.997432
===============Feedback to learned agent round===============
Observation:
[0, 0, 48.99743168059112]
Reward: -1.000000, Currnt Bid: 48.997432
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[49.9159027]
Explore action: 49.915903
Action taken: 49.915903
===============Feedback to random agent round===============
Currnt Bid: 49.915903
=================Random Agent Turn=================
Action taken: 93.608769
===============Feedback to learned agent round===============
Observation:
[0, array([49.9159027]), array([93.60876908])]
Reward: -1.000000, Currnt Bid: 93.608769
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[45.90845853]
Explore action: 45.908459
Action taken: 45.908459
===============Feedback to random agent round===============
Currnt Bid: 93.608769
=================Random Agent Turn=================
Action taken: 114.770386
===============Feedback to learned agent round===============
Observation:
[1, array([49.9159027]), array([93.60876908])]
Reward: -2.000000, Currnt Bid: 93.608769
Is done? True
Episode End
Positive: 164, Negative: 275
EPISODE :- 897
Random Player utility: 37.830596
=================Random Agent Turn=================
Action taken: 26.768097
===============Feedback to learned agent round===============
Observation:
[0, 0, 26.768096637314677]
Reward: -1.000000, Currnt Bid: 26.768097
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[53.47981225]
Explore action: 53.479812
Action taken: 53.479812
===============Feedback to random agent round===============
Currnt Bid: 53.479812
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([53.47981225]), 26.768096637314677]
Reward: 46.520188, Currnt Bid: 53.479812
Is done? True
Episode End
Positive: 165, Negative: 275
EPISODE :- 898
Random Player utility: 59.638185
=================Random Agent Turn=================
Action taken: 40.969735
===============Feedback to learned agent round===============
Observation:
[0, 0, 40.969735285402216]
Reward: -1.000000, Currnt Bid: 40.969735
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[53.43154382]
Explore action: 53.431544
Action taken: 53.431544
===============Feedback to random agent round===============
Currnt Bid: 53.431544
=================Random Agent Turn=================
Action taken: 57.885929
===============Feedback to learned agent round===============
Observation:
[0, array([53.43154382]), array([57.88592858])]
Reward: -1.000000, Currnt Bid: 57.885929
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[54.83441781]
Explore action: 54.834418
Action taken: 54.834418
===============Feedback to random agent round===============
Currnt Bid: 57.885929
=================Random Agent Turn=================
Action taken: 58.362115
===============Feedback to learned agent round===============
Observation:
[1, array([53.43154382]), array([57.88592858])]
Reward: -2.000000, Currnt Bid: 57.885929
Is done? True
Episode End
Positive: 165, Negative: 276
EPISODE :- 899
Random Player utility: 120.487831
=================Random Agent Turn=================
Action taken: 91.263220
===============Feedback to learned agent round===============
Observation:
[0, 0, 91.26322003594683]
Reward: -1.000000, Currnt Bid: 91.263220
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[66.6215347]
Explore action: 66.621535
Action taken: 66.621535
===============Feedback to random agent round===============
Currnt Bid: 91.263220
=================Random Agent Turn=================
Action taken: 114.912808
===============Feedback to learned agent round===============
Observation:
[1, 0, 91.26322003594683]
Reward: -2.000000, Currnt Bid: 91.263220
Is done? True
Episode End
Positive: 165, Negative: 276
EPISODE :- 900
Random Player utility: 218.047192
=================Random Agent Turn=================
Action taken: 52.200286
===============Feedback to learned agent round===============
Observation:
[0, 0, 52.20028559606417]
Reward: -1.000000, Currnt Bid: 52.200286
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.001287
Exploit action: 0.001287
Action taken: 0.001287
===============Feedback to random agent round===============
Currnt Bid: 52.200286
=================Random Agent Turn=================
Action taken: 74.650973
===============Feedback to learned agent round===============
Observation:
[1, 0, 52.20028559606417]
Reward: -2.000000, Currnt Bid: 52.200286
Is done? True
Episode End
Positive: 165, Negative: 276
Models saved successfully
EPISODE :- 901
Random Player utility: 49.798614
=================Random Agent Turn=================
Action taken: 48.574569
===============Feedback to learned agent round===============
Observation:
[0, 0, 48.57456894434733]
Reward: -1.000000, Currnt Bid: 48.574569
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[76.73034827]
Explore action: 76.730348
Action taken: 76.730348
===============Feedback to random agent round===============
Currnt Bid: 76.730348
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([76.73034827]), 48.57456894434733]
Reward: 23.269652, Currnt Bid: 76.730348
Is done? True
Episode End
Positive: 166, Negative: 276
EPISODE :- 902
Random Player utility: 174.989978
=================Random Agent Turn=================
Action taken: 84.442708
===============Feedback to learned agent round===============
Observation:
[0, 0, 84.442708396186]
Reward: -1.000000, Currnt Bid: 84.442708
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[81.85766222]
Explore action: 81.857662
Action taken: 81.857662
===============Feedback to random agent round===============
Currnt Bid: 84.442708
=================Random Agent Turn=================
Action taken: 99.183159
===============Feedback to learned agent round===============
Observation:
[1, 0, 84.442708396186]
Reward: -2.000000, Currnt Bid: 84.442708
Is done? True
Episode End
Positive: 166, Negative: 276
EPISODE :- 903
Random Player utility: 93.660929
=================Random Agent Turn=================
Action taken: 23.446414
===============Feedback to learned agent round===============
Observation:
[0, 0, 23.446413891558315]
Reward: -1.000000, Currnt Bid: 23.446414
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[66.98441178]
Explore action: 66.984412
Action taken: 66.984412
===============Feedback to random agent round===============
Currnt Bid: 66.984412
=================Random Agent Turn=================
Action taken: 74.356049
===============Feedback to learned agent round===============
Observation:
[0, array([66.98441178]), array([74.35604946])]
Reward: -1.000000, Currnt Bid: 74.356049
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[78.72019232]
Explore action: 78.720192
Action taken: 78.720192
===============Feedback to random agent round===============
Currnt Bid: 78.720192
=================Random Agent Turn=================
Action taken: 79.545156
===============Feedback to learned agent round===============
Observation:
[0, array([78.72019232]), array([79.54515554])]
Reward: -1.000000, Currnt Bid: 79.545156
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[62.11792622]
Explore action: 62.117926
Action taken: 62.117926
===============Feedback to random agent round===============
Currnt Bid: 79.545156
=================Random Agent Turn=================
Action taken: 85.242824
===============Feedback to learned agent round===============
Observation:
[1, array([78.72019232]), array([79.54515554])]
Reward: -2.000000, Currnt Bid: 79.545156
Is done? True
Episode End
Positive: 166, Negative: 277
EPISODE :- 904
Random Player utility: 104.129505
=================Random Agent Turn=================
Action taken: 2.741325
===============Feedback to learned agent round===============
Observation:
[0, 0, 2.7413253045962676]
Reward: -1.000000, Currnt Bid: 2.741325
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[63.43639437]
Explore action: 63.436394
Action taken: 63.436394
===============Feedback to random agent round===============
Currnt Bid: 63.436394
=================Random Agent Turn=================
Action taken: 99.860505
===============Feedback to learned agent round===============
Observation:
[0, array([63.43639437]), array([99.86050514])]
Reward: -1.000000, Currnt Bid: 99.860505
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[71.13759129]
Explore action: 71.137591
Action taken: 71.137591
===============Feedback to random agent round===============
Currnt Bid: 99.860505
=================Random Agent Turn=================
Action taken: 101.503775
===============Feedback to learned agent round===============
Observation:
[1, array([63.43639437]), array([99.86050514])]
Reward: -2.000000, Currnt Bid: 99.860505
Is done? True
Episode End
Positive: 166, Negative: 277
EPISODE :- 905
Random Player utility: 83.522944
=================Random Agent Turn=================
Action taken: 69.253461
===============Feedback to learned agent round===============
Observation:
[0, 0, 69.25346135744904]
Reward: -1.000000, Currnt Bid: 69.253461
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.001204
Exploit action: 0.001204
Action taken: 0.001204
===============Feedback to random agent round===============
Currnt Bid: 69.253461
=================Random Agent Turn=================
Action taken: 73.667311
===============Feedback to learned agent round===============
Observation:
[1, 0, 69.25346135744904]
Reward: -2.000000, Currnt Bid: 69.253461
Is done? True
Episode End
Positive: 166, Negative: 278
EPISODE :- 906
Random Player utility: 125.887089
=================Random Agent Turn=================
Action taken: 122.394796
===============Feedback to learned agent round===============
Observation:
[0, 0, 122.39479618300614]
Reward: -1.000000, Currnt Bid: 122.394796
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[66.23874187]
Explore action: 66.238742
Action taken: 66.238742
===============Feedback to random agent round===============
Currnt Bid: 122.394796
=================Random Agent Turn=================
Action taken: 124.786181
===============Feedback to learned agent round===============
Observation:
[1, 0, 122.39479618300614]
Reward: -2.000000, Currnt Bid: 122.394796
Is done? True
Episode End
Positive: 166, Negative: 278
EPISODE :- 907
Random Player utility: 126.117535
=================Random Agent Turn=================
Action taken: 86.833201
===============Feedback to learned agent round===============
Observation:
[0, 0, 86.83320075499209]
Reward: -1.000000, Currnt Bid: 86.833201
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[60.38007776]
Explore action: 60.380078
Action taken: 60.380078
===============Feedback to random agent round===============
Currnt Bid: 86.833201
=================Random Agent Turn=================
Action taken: 123.111669
===============Feedback to learned agent round===============
Observation:
[1, 0, 86.83320075499209]
Reward: -2.000000, Currnt Bid: 86.833201
Is done? True
Episode End
Positive: 166, Negative: 278
EPISODE :- 908
Random Player utility: 36.634951
=================Random Agent Turn=================
Action taken: 20.716094
===============Feedback to learned agent round===============
Observation:
[0, 0, 20.71609362152884]
Reward: -1.000000, Currnt Bid: 20.716094
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[68.83383929]
Explore action: 68.833839
Action taken: 68.833839
===============Feedback to random agent round===============
Currnt Bid: 68.833839
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([68.83383929]), 20.71609362152884]
Reward: 31.166161, Currnt Bid: 68.833839
Is done? True
Episode End
Positive: 167, Negative: 278
EPISODE :- 909
Random Player utility: 15.967586
=================Random Agent Turn=================
Action taken: 7.015257
===============Feedback to learned agent round===============
Observation:
[0, 0, 7.01525709010589]
Reward: -1.000000, Currnt Bid: 7.015257
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[70.171906]
Explore action: 70.171906
Action taken: 70.171906
===============Feedback to random agent round===============
Currnt Bid: 70.171906
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([70.171906]), 7.01525709010589]
Reward: 29.828094, Currnt Bid: 70.171906
Is done? True
Episode End
Positive: 168, Negative: 278
EPISODE :- 910
Random Player utility: 168.068573
=================Random Agent Turn=================
Action taken: 49.965828
===============Feedback to learned agent round===============
Observation:
[0, 0, 49.96582813624303]
Reward: -1.000000, Currnt Bid: 49.965828
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.001144
Exploit action: 0.001144
Action taken: 0.001144
===============Feedback to random agent round===============
Currnt Bid: 49.965828
=================Random Agent Turn=================
Action taken: 98.937362
===============Feedback to learned agent round===============
Observation:
[1, 0, 49.96582813624303]
Reward: -2.000000, Currnt Bid: 49.965828
Is done? True
Episode End
Positive: 168, Negative: 278
EPISODE :- 911
Random Player utility: 86.367675
=================Random Agent Turn=================
Action taken: 74.401559
===============Feedback to learned agent round===============
Observation:
[0, 0, 74.40155864056801]
Reward: -1.000000, Currnt Bid: 74.401559
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[70.97545907]
Explore action: 70.975459
Action taken: 70.975459
===============Feedback to random agent round===============
Currnt Bid: 74.401559
=================Random Agent Turn=================
Action taken: 86.069360
===============Feedback to learned agent round===============
Observation:
[1, 0, 74.40155864056801]
Reward: -2.000000, Currnt Bid: 74.401559
Is done? True
Episode End
Positive: 168, Negative: 279
EPISODE :- 912
Random Player utility: 41.888193
=================Random Agent Turn=================
Action taken: 41.521712
===============Feedback to learned agent round===============
Observation:
[0, 0, 41.52171204452814]
Reward: -1.000000, Currnt Bid: 41.521712
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.93598055]
Explore action: 48.935981
Action taken: 48.935981
===============Feedback to random agent round===============
Currnt Bid: 48.935981
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([48.93598055]), 41.52171204452814]
Reward: 51.064019, Currnt Bid: 48.935981
Is done? True
Episode End
Positive: 169, Negative: 279
EPISODE :- 913
Random Player utility: 15.389525
=================Random Agent Turn=================
Action taken: 9.197326
===============Feedback to learned agent round===============
Observation:
[0, 0, 9.197325738523901]
Reward: -1.000000, Currnt Bid: 9.197326
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[49.82929931]
Explore action: 49.829299
Action taken: 49.829299
===============Feedback to random agent round===============
Currnt Bid: 49.829299
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([49.82929931]), 9.197325738523901]
Reward: 50.170701, Currnt Bid: 49.829299
Is done? True
Episode End
Positive: 170, Negative: 279
EPISODE :- 914
Random Player utility: 90.202856
=================Random Agent Turn=================
Action taken: 65.716562
===============Feedback to learned agent round===============
Observation:
[0, 0, 65.7165620092959]
Reward: -1.000000, Currnt Bid: 65.716562
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[39.29429542]
Explore action: 39.294295
Action taken: 39.294295
===============Feedback to random agent round===============
Currnt Bid: 65.716562
=================Random Agent Turn=================
Action taken: 84.587236
===============Feedback to learned agent round===============
Observation:
[1, 0, 65.7165620092959]
Reward: -2.000000, Currnt Bid: 65.716562
Is done? True
Episode End
Positive: 170, Negative: 280
EPISODE :- 915
Random Player utility: 85.286774
=================Random Agent Turn=================
Action taken: 78.303588
===============Feedback to learned agent round===============
Observation:
[0, 0, 78.303587674943]
Reward: -1.000000, Currnt Bid: 78.303588
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.001091
Exploit action: 0.001091
Action taken: 0.001091
===============Feedback to random agent round===============
Currnt Bid: 78.303588
=================Random Agent Turn=================
Action taken: 81.388991
===============Feedback to learned agent round===============
Observation:
[1, 0, 78.303587674943]
Reward: -2.000000, Currnt Bid: 78.303588
Is done? True
Episode End
Positive: 170, Negative: 281
EPISODE :- 916
Random Player utility: 59.934312
=================Random Agent Turn=================
Action taken: 51.885952
===============Feedback to learned agent round===============
Observation:
[0, 0, 51.88595216947161]
Reward: -1.000000, Currnt Bid: 51.885952
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[44.90299014]
Explore action: 44.902990
Action taken: 44.902990
===============Feedback to random agent round===============
Currnt Bid: 51.885952
=================Random Agent Turn=================
Action taken: 54.270973
===============Feedback to learned agent round===============
Observation:
[1, 0, 51.88595216947161]
Reward: -2.000000, Currnt Bid: 51.885952
Is done? True
Episode End
Positive: 170, Negative: 282
EPISODE :- 917
Random Player utility: 115.613491
=================Random Agent Turn=================
Action taken: 54.414360
===============Feedback to learned agent round===============
Observation:
[0, 0, 54.414360137071974]
Reward: -1.000000, Currnt Bid: 54.414360
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[39.60489968]
Explore action: 39.604900
Action taken: 39.604900
===============Feedback to random agent round===============
Currnt Bid: 54.414360
=================Random Agent Turn=================
Action taken: 78.574099
===============Feedback to learned agent round===============
Observation:
[1, 0, 54.414360137071974]
Reward: -2.000000, Currnt Bid: 54.414360
Is done? True
Episode End
Positive: 170, Negative: 282
EPISODE :- 918
Random Player utility: 18.428653
=================Random Agent Turn=================
Action taken: 1.285559
===============Feedback to learned agent round===============
Observation:
[0, 0, 1.2855590673456052]
Reward: -1.000000, Currnt Bid: 1.285559
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.4457858]
Explore action: 48.445786
Action taken: 48.445786
===============Feedback to random agent round===============
Currnt Bid: 48.445786
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([48.4457858]), 1.2855590673456052]
Reward: 51.554214, Currnt Bid: 48.445786
Is done? True
Episode End
Positive: 171, Negative: 282
EPISODE :- 919
Random Player utility: 136.242355
=================Random Agent Turn=================
Action taken: 6.054843
===============Feedback to learned agent round===============
Observation:
[0, 0, 6.054843011072376]
Reward: -1.000000, Currnt Bid: 6.054843
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[50.55087463]
Explore action: 50.550875
Action taken: 50.550875
===============Feedback to random agent round===============
Currnt Bid: 50.550875
=================Random Agent Turn=================
Action taken: 96.989004
===============Feedback to learned agent round===============
Observation:
[0, array([50.55087463]), array([96.9890041])]
Reward: -1.000000, Currnt Bid: 96.989004
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[60.00505504]
Explore action: 60.005055
Action taken: 60.005055
===============Feedback to random agent round===============
Currnt Bid: 96.989004
=================Random Agent Turn=================
Action taken: 124.039503
===============Feedback to learned agent round===============
Observation:
[1, array([50.55087463]), array([96.9890041])]
Reward: -2.000000, Currnt Bid: 96.989004
Is done? True
Episode End
Positive: 171, Negative: 282
EPISODE :- 920
Random Player utility: 64.386338
=================Random Agent Turn=================
Action taken: 51.140218
===============Feedback to learned agent round===============
Observation:
[0, 0, 51.140217578738515]
Reward: -1.000000, Currnt Bid: 51.140218
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.001031
Exploit action: 0.001031
Action taken: 0.001031
===============Feedback to random agent round===============
Currnt Bid: 51.140218
=================Random Agent Turn=================
Action taken: 55.422568
===============Feedback to learned agent round===============
Observation:
[1, 0, 51.140217578738515]
Reward: -2.000000, Currnt Bid: 51.140218
Is done? True
Episode End
Positive: 171, Negative: 283
EPISODE :- 921
Random Player utility: 71.600589
=================Random Agent Turn=================
Action taken: 17.968894
===============Feedback to learned agent round===============
Observation:
[0, 0, 17.968894447635844]
Reward: -1.000000, Currnt Bid: 17.968894
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[68.91325669]
Explore action: 68.913257
Action taken: 68.913257
===============Feedback to random agent round===============
Currnt Bid: 68.913257
=================Random Agent Turn=================
Action taken: 70.109623
===============Feedback to learned agent round===============
Observation:
[0, array([68.91325669]), array([70.10962289])]
Reward: -1.000000, Currnt Bid: 70.109623
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[56.40062411]
Explore action: 56.400624
Action taken: 56.400624
===============Feedback to random agent round===============
Currnt Bid: 70.109623
=================Random Agent Turn=================
Action taken: 71.019472
===============Feedback to learned agent round===============
Observation:
[1, array([68.91325669]), array([70.10962289])]
Reward: -2.000000, Currnt Bid: 70.109623
Is done? True
Episode End
Positive: 171, Negative: 284
EPISODE :- 922
Random Player utility: 108.176465
=================Random Agent Turn=================
Action taken: 105.465998
===============Feedback to learned agent round===============
Observation:
[0, 0, 105.46599819710502]
Reward: -1.000000, Currnt Bid: 105.465998
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[51.98238368]
Explore action: 51.982384
Action taken: 51.982384
===============Feedback to random agent round===============
Currnt Bid: 105.465998
=================Random Agent Turn=================
Action taken: 107.829413
===============Feedback to learned agent round===============
Observation:
[1, 0, 105.46599819710502]
Reward: -2.000000, Currnt Bid: 105.465998
Is done? True
Episode End
Positive: 171, Negative: 284
EPISODE :- 923
Random Player utility: 124.213292
=================Random Agent Turn=================
Action taken: 60.590981
===============Feedback to learned agent round===============
Observation:
[0, 0, 60.59098109032668]
Reward: -1.000000, Currnt Bid: 60.590981
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[41.03147434]
Explore action: 41.031474
Action taken: 41.031474
===============Feedback to random agent round===============
Currnt Bid: 60.590981
=================Random Agent Turn=================
Action taken: 69.303153
===============Feedback to learned agent round===============
Observation:
[1, 0, 60.59098109032668]
Reward: -2.000000, Currnt Bid: 60.590981
Is done? True
Episode End
Positive: 171, Negative: 284
EPISODE :- 924
Random Player utility: 252.826781
=================Random Agent Turn=================
Action taken: 242.627198
===============Feedback to learned agent round===============
Observation:
[0, 0, 242.6271979961597]
Reward: -1.000000, Currnt Bid: 242.627198
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[49.23207772]
Explore action: 49.232078
Action taken: 49.232078
===============Feedback to random agent round===============
Currnt Bid: 242.627198
=================Random Agent Turn=================
Action taken: 243.700250
===============Feedback to learned agent round===============
Observation:
[1, 0, 242.6271979961597]
Reward: -2.000000, Currnt Bid: 242.627198
Is done? True
Episode End
Positive: 171, Negative: 284
EPISODE :- 925
Random Player utility: 140.305215
=================Random Agent Turn=================
Action taken: 8.631739
===============Feedback to learned agent round===============
Observation:
[0, 0, 8.631738914026167]
Reward: -1.000000, Currnt Bid: 8.631739
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.000978
Exploit action: 0.000978
Action taken: 0.000978
===============Feedback to random agent round===============
Currnt Bid: 8.631739
=================Random Agent Turn=================
Action taken: 135.737276
===============Feedback to learned agent round===============
Observation:
[1, 0, 8.631738914026167]
Reward: -2.000000, Currnt Bid: 8.631739
Is done? True
Episode End
Positive: 171, Negative: 284
EPISODE :- 926
Random Player utility: 126.872653
=================Random Agent Turn=================
Action taken: 35.826667
===============Feedback to learned agent round===============
Observation:
[0, 0, 35.82666660149957]
Reward: -1.000000, Currnt Bid: 35.826667
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[43.64546533]
Explore action: 43.645465
Action taken: 43.645465
===============Feedback to random agent round===============
Currnt Bid: 43.645465
=================Random Agent Turn=================
Action taken: 78.343659
===============Feedback to learned agent round===============
Observation:
[0, array([43.64546533]), array([78.34365901])]
Reward: -1.000000, Currnt Bid: 78.343659
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[49.88167044]
Explore action: 49.881670
Action taken: 49.881670
===============Feedback to random agent round===============
Currnt Bid: 78.343659
=================Random Agent Turn=================
Action taken: 117.127391
===============Feedback to learned agent round===============
Observation:
[1, array([43.64546533]), array([78.34365901])]
Reward: -2.000000, Currnt Bid: 78.343659
Is done? True
Episode End
Positive: 171, Negative: 284
EPISODE :- 927
Random Player utility: 123.392196
=================Random Agent Turn=================
Action taken: 50.852515
===============Feedback to learned agent round===============
Observation:
[0, 0, 50.85251516832678]
Reward: -1.000000, Currnt Bid: 50.852515
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[34.78680784]
Explore action: 34.786808
Action taken: 34.786808
===============Feedback to random agent round===============
Currnt Bid: 50.852515
=================Random Agent Turn=================
Action taken: 80.602067
===============Feedback to learned agent round===============
Observation:
[1, 0, 50.85251516832678]
Reward: -2.000000, Currnt Bid: 50.852515
Is done? True
Episode End
Positive: 171, Negative: 284
EPISODE :- 928
Random Player utility: 46.254711
=================Random Agent Turn=================
Action taken: 5.753644
===============Feedback to learned agent round===============
Observation:
[0, 0, 5.753643889833244]
Reward: -1.000000, Currnt Bid: 5.753644
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[40.00917718]
Explore action: 40.009177
Action taken: 40.009177
===============Feedback to random agent round===============
Currnt Bid: 40.009177
=================Random Agent Turn=================
Action taken: 41.447915
===============Feedback to learned agent round===============
Observation:
[0, array([40.00917718]), array([41.44791471])]
Reward: -1.000000, Currnt Bid: 41.447915
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[42.62238498]
Explore action: 42.622385
Action taken: 42.622385
===============Feedback to random agent round===============
Currnt Bid: 42.622385
=================Random Agent Turn=================
Action taken: 46.221332
===============Feedback to learned agent round===============
Observation:
[0, array([42.62238498]), array([46.22133193])]
Reward: -1.000000, Currnt Bid: 46.221332
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[58.84182439]
Explore action: 58.841824
Action taken: 58.841824
===============Feedback to random agent round===============
Currnt Bid: 58.841824
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([58.84182439]), array([46.22133193])]
Reward: 41.158176, Currnt Bid: 58.841824
Is done? True
Episode End
Positive: 172, Negative: 284
EPISODE :- 929
Random Player utility: 72.988061
=================Random Agent Turn=================
Action taken: 4.867816
===============Feedback to learned agent round===============
Observation:
[0, 0, 4.8678160368663494]
Reward: -1.000000, Currnt Bid: 4.867816
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[66.63347533]
Explore action: 66.633475
Action taken: 66.633475
===============Feedback to random agent round===============
Currnt Bid: 66.633475
=================Random Agent Turn=================
Action taken: 67.077432
===============Feedback to learned agent round===============
Observation:
[0, array([66.63347533]), array([67.07743196])]
Reward: -1.000000, Currnt Bid: 67.077432
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[56.73270735]
Explore action: 56.732707
Action taken: 56.732707
===============Feedback to random agent round===============
Currnt Bid: 67.077432
=================Random Agent Turn=================
Action taken: 69.096186
===============Feedback to learned agent round===============
Observation:
[1, array([66.63347533]), array([67.07743196])]
Reward: -2.000000, Currnt Bid: 67.077432
Is done? True
Episode End
Positive: 172, Negative: 285
EPISODE :- 930
Random Player utility: 46.844863
=================Random Agent Turn=================
Action taken: 13.786231
===============Feedback to learned agent round===============
Observation:
[0, 0, 13.786230731689205]
Reward: -1.000000, Currnt Bid: 13.786231
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.000912
Exploit action: 0.000912
Action taken: 0.000912
===============Feedback to random agent round===============
Currnt Bid: 13.786231
=================Random Agent Turn=================
Action taken: 27.557636
===============Feedback to learned agent round===============
Observation:
[1, 0, 13.786230731689205]
Reward: -2.000000, Currnt Bid: 13.786231
Is done? True
Episode End
Positive: 172, Negative: 286
EPISODE :- 931
Random Player utility: 131.842498
=================Random Agent Turn=================
Action taken: 53.974063
===============Feedback to learned agent round===============
Observation:
[0, 0, 53.974063453926625]
Reward: -1.000000, Currnt Bid: 53.974063
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[42.18162348]
Explore action: 42.181623
Action taken: 42.181623
===============Feedback to random agent round===============
Currnt Bid: 53.974063
=================Random Agent Turn=================
Action taken: 57.960009
===============Feedback to learned agent round===============
Observation:
[1, 0, 53.974063453926625]
Reward: -2.000000, Currnt Bid: 53.974063
Is done? True
Episode End
Positive: 172, Negative: 286
EPISODE :- 932
Random Player utility: 166.554799
=================Random Agent Turn=================
Action taken: 6.570237
===============Feedback to learned agent round===============
Observation:
[0, 0, 6.570237297449332]
Reward: -1.000000, Currnt Bid: 6.570237
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[39.88741261]
Explore action: 39.887413
Action taken: 39.887413
===============Feedback to random agent round===============
Currnt Bid: 39.887413
=================Random Agent Turn=================
Action taken: 146.232516
===============Feedback to learned agent round===============
Observation:
[0, array([39.88741261]), array([146.2325158])]
Reward: -1.000000, Currnt Bid: 146.232516
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[58.36588175]
Explore action: 58.365882
Action taken: 58.365882
===============Feedback to random agent round===============
Currnt Bid: 146.232516
=================Random Agent Turn=================
Action taken: 162.946812
===============Feedback to learned agent round===============
Observation:
[1, array([39.88741261]), array([146.2325158])]
Reward: -2.000000, Currnt Bid: 146.232516
Is done? True
Episode End
Positive: 172, Negative: 286
EPISODE :- 933
Random Player utility: 86.329370
=================Random Agent Turn=================
Action taken: 59.087503
===============Feedback to learned agent round===============
Observation:
[0, 0, 59.08750328785973]
Reward: -1.000000, Currnt Bid: 59.087503
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[71.59743871]
Explore action: 71.597439
Action taken: 71.597439
===============Feedback to random agent round===============
Currnt Bid: 71.597439
=================Random Agent Turn=================
Action taken: 81.012995
===============Feedback to learned agent round===============
Observation:
[0, array([71.59743871]), array([81.01299488])]
Reward: -1.000000, Currnt Bid: 81.012995
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[67.34184279]
Explore action: 67.341843
Action taken: 67.341843
===============Feedback to random agent round===============
Currnt Bid: 81.012995
=================Random Agent Turn=================
Action taken: 82.995349
===============Feedback to learned agent round===============
Observation:
[1, array([71.59743871]), array([81.01299488])]
Reward: -2.000000, Currnt Bid: 81.012995
Is done? True
Episode End
Positive: 172, Negative: 287
EPISODE :- 934
Random Player utility: 34.223032
=================Random Agent Turn=================
Action taken: 17.931445
===============Feedback to learned agent round===============
Observation:
[0, 0, 17.93144512632337]
Reward: -1.000000, Currnt Bid: 17.931445
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[45.51356324]
Explore action: 45.513563
Action taken: 45.513563
===============Feedback to random agent round===============
Currnt Bid: 45.513563
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([45.51356324]), 17.93144512632337]
Reward: 54.486437, Currnt Bid: 45.513563
Is done? True
Episode End
Positive: 173, Negative: 287
EPISODE :- 935
Random Player utility: 132.724695
=================Random Agent Turn=================
Action taken: 20.895905
===============Feedback to learned agent round===============
Observation:
[0, 0, 20.89590506794461]
Reward: -1.000000, Currnt Bid: 20.895905
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.000864
Exploit action: 0.000864
Action taken: 0.000864
===============Feedback to random agent round===============
Currnt Bid: 20.895905
=================Random Agent Turn=================
Action taken: 131.083672
===============Feedback to learned agent round===============
Observation:
[1, 0, 20.89590506794461]
Reward: -2.000000, Currnt Bid: 20.895905
Is done? True
Episode End
Positive: 173, Negative: 287
EPISODE :- 936
Random Player utility: 68.113232
=================Random Agent Turn=================
Action taken: 20.968738
===============Feedback to learned agent round===============
Observation:
[0, 0, 20.96873841888276]
Reward: -1.000000, Currnt Bid: 20.968738
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[33.68640912]
Explore action: 33.686409
Action taken: 33.686409
===============Feedback to random agent round===============
Currnt Bid: 33.686409
=================Random Agent Turn=================
Action taken: 57.031649
===============Feedback to learned agent round===============
Observation:
[0, array([33.68640912]), array([57.03164855])]
Reward: -1.000000, Currnt Bid: 57.031649
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[28.15715113]
Explore action: 28.157151
Action taken: 28.157151
===============Feedback to random agent round===============
Currnt Bid: 57.031649
=================Random Agent Turn=================
Action taken: 58.624174
===============Feedback to learned agent round===============
Observation:
[1, array([33.68640912]), array([57.03164855])]
Reward: -2.000000, Currnt Bid: 57.031649
Is done? True
Episode End
Positive: 173, Negative: 288
EPISODE :- 937
Random Player utility: 86.530103
=================Random Agent Turn=================
Action taken: 74.033513
===============Feedback to learned agent round===============
Observation:
[0, 0, 74.0335126705961]
Reward: -1.000000, Currnt Bid: 74.033513
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[33.10733842]
Explore action: 33.107338
Action taken: 33.107338
===============Feedback to random agent round===============
Currnt Bid: 74.033513
=================Random Agent Turn=================
Action taken: 79.790766
===============Feedback to learned agent round===============
Observation:
[1, 0, 74.0335126705961]
Reward: -2.000000, Currnt Bid: 74.033513
Is done? True
Episode End
Positive: 173, Negative: 289
EPISODE :- 938
Random Player utility: 197.850517
=================Random Agent Turn=================
Action taken: 49.028698
===============Feedback to learned agent round===============
Observation:
[0, 0, 49.02869756906661]
Reward: -1.000000, Currnt Bid: 49.028698
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[19.66355278]
Explore action: 19.663553
Action taken: 19.663553
===============Feedback to random agent round===============
Currnt Bid: 49.028698
=================Random Agent Turn=================
Action taken: 109.140777
===============Feedback to learned agent round===============
Observation:
[1, 0, 49.02869756906661]
Reward: -2.000000, Currnt Bid: 49.028698
Is done? True
Episode End
Positive: 173, Negative: 289
EPISODE :- 939
Random Player utility: 108.075692
=================Random Agent Turn=================
Action taken: 66.577805
===============Feedback to learned agent round===============
Observation:
[0, 0, 66.57780504951272]
Reward: -1.000000, Currnt Bid: 66.577805
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[25.61639309]
Explore action: 25.616393
Action taken: 25.616393
===============Feedback to random agent round===============
Currnt Bid: 66.577805
=================Random Agent Turn=================
Action taken: 93.700106
===============Feedback to learned agent round===============
Observation:
[1, 0, 66.57780504951272]
Reward: -2.000000, Currnt Bid: 66.577805
Is done? True
Episode End
Positive: 173, Negative: 289
EPISODE :- 940
Random Player utility: 58.689379
=================Random Agent Turn=================
Action taken: 13.297421
===============Feedback to learned agent round===============
Observation:
[0, 0, 13.297421388361457]
Reward: -1.000000, Currnt Bid: 13.297421
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.000817
Exploit action: 0.000817
Action taken: 0.000817
===============Feedback to random agent round===============
Currnt Bid: 13.297421
=================Random Agent Turn=================
Action taken: 44.789294
===============Feedback to learned agent round===============
Observation:
[1, 0, 13.297421388361457]
Reward: -2.000000, Currnt Bid: 13.297421
Is done? True
Episode End
Positive: 173, Negative: 290
EPISODE :- 941
Random Player utility: 35.128832
=================Random Agent Turn=================
Action taken: 15.179165
===============Feedback to learned agent round===============
Observation:
[0, 0, 15.17916459937463]
Reward: -1.000000, Currnt Bid: 15.179165
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[32.23518611]
Explore action: 32.235186
Action taken: 32.235186
===============Feedback to random agent round===============
Currnt Bid: 32.235186
=================Random Agent Turn=================
Action taken: 33.724510
===============Feedback to learned agent round===============
Observation:
[0, array([32.23518611]), array([33.72450986])]
Reward: -1.000000, Currnt Bid: 33.724510
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[35.29106431]
Explore action: 35.291064
Action taken: 35.291064
===============Feedback to random agent round===============
Currnt Bid: 35.291064
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([35.29106431]), array([33.72450986])]
Reward: 64.708936, Currnt Bid: 35.291064
Is done? True
Episode End
Positive: 174, Negative: 290
EPISODE :- 942
Random Player utility: 127.684675
=================Random Agent Turn=================
Action taken: 121.013029
===============Feedback to learned agent round===============
Observation:
[0, 0, 121.01302850198198]
Reward: -1.000000, Currnt Bid: 121.013029
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.09137723]
Explore action: 48.091377
Action taken: 48.091377
===============Feedback to random agent round===============
Currnt Bid: 121.013029
=================Random Agent Turn=================
Action taken: 126.992476
===============Feedback to learned agent round===============
Observation:
[1, 0, 121.01302850198198]
Reward: -2.000000, Currnt Bid: 121.013029
Is done? True
Episode End
Positive: 174, Negative: 290
EPISODE :- 943
Random Player utility: 25.389600
=================Random Agent Turn=================
Action taken: 20.862239
===============Feedback to learned agent round===============
Observation:
[0, 0, 20.862239190255284]
Reward: -1.000000, Currnt Bid: 20.862239
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[50.91321073]
Explore action: 50.913211
Action taken: 50.913211
===============Feedback to random agent round===============
Currnt Bid: 50.913211
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([50.91321073]), 20.862239190255284]
Reward: 49.086789, Currnt Bid: 50.913211
Is done? True
Episode End
Positive: 175, Negative: 290
EPISODE :- 944
Random Player utility: 190.730873
=================Random Agent Turn=================
Action taken: 9.146082
===============Feedback to learned agent round===============
Observation:
[0, 0, 9.14608169352371]
Reward: -1.000000, Currnt Bid: 9.146082
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[63.30015874]
Explore action: 63.300159
Action taken: 63.300159
===============Feedback to random agent round===============
Currnt Bid: 63.300159
=================Random Agent Turn=================
Action taken: 171.401840
===============Feedback to learned agent round===============
Observation:
[0, array([63.30015874]), array([171.40183969])]
Reward: -1.000000, Currnt Bid: 171.401840
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[77.79646418]
Explore action: 77.796464
Action taken: 77.796464
===============Feedback to random agent round===============
Currnt Bid: 171.401840
=================Random Agent Turn=================
Action taken: 184.362660
===============Feedback to learned agent round===============
Observation:
[1, array([63.30015874]), array([171.40183969])]
Reward: -2.000000, Currnt Bid: 171.401840
Is done? True
Episode End
Positive: 175, Negative: 290
EPISODE :- 945
Random Player utility: 111.954734
=================Random Agent Turn=================
Action taken: 26.561716
===============Feedback to learned agent round===============
Observation:
[0, 0, 26.56171555926668]
Reward: -1.000000, Currnt Bid: 26.561716
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.000775
Exploit action: 0.000775
Action taken: 0.000775
===============Feedback to random agent round===============
Currnt Bid: 26.561716
=================Random Agent Turn=================
Action taken: 49.616882
===============Feedback to learned agent round===============
Observation:
[1, 0, 26.56171555926668]
Reward: -2.000000, Currnt Bid: 26.561716
Is done? True
Episode End
Positive: 175, Negative: 290
EPISODE :- 946
Random Player utility: 102.843728
=================Random Agent Turn=================
Action taken: 32.024177
===============Feedback to learned agent round===============
Observation:
[0, 0, 32.02417714055002]
Reward: -1.000000, Currnt Bid: 32.024177
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[65.49297499]
Explore action: 65.492975
Action taken: 65.492975
===============Feedback to random agent round===============
Currnt Bid: 65.492975
=================Random Agent Turn=================
Action taken: 83.157853
===============Feedback to learned agent round===============
Observation:
[0, array([65.49297499]), array([83.15785302])]
Reward: -1.000000, Currnt Bid: 83.157853
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[39.91179927]
Explore action: 39.911799
Action taken: 39.911799
===============Feedback to random agent round===============
Currnt Bid: 83.157853
=================Random Agent Turn=================
Action taken: 87.955407
===============Feedback to learned agent round===============
Observation:
[1, array([65.49297499]), array([83.15785302])]
Reward: -2.000000, Currnt Bid: 83.157853
Is done? True
Episode End
Positive: 175, Negative: 290
EPISODE :- 947
Random Player utility: 51.183321
=================Random Agent Turn=================
Action taken: 1.677481
===============Feedback to learned agent round===============
Observation:
[0, 0, 1.677481047304203]
Reward: -1.000000, Currnt Bid: 1.677481
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[38.5097751]
Explore action: 38.509775
Action taken: 38.509775
===============Feedback to random agent round===============
Currnt Bid: 38.509775
=================Random Agent Turn=================
Action taken: 46.326292
===============Feedback to learned agent round===============
Observation:
[0, array([38.5097751]), array([46.32629203])]
Reward: -1.000000, Currnt Bid: 46.326292
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[31.36709908]
Explore action: 31.367099
Action taken: 31.367099
===============Feedback to random agent round===============
Currnt Bid: 46.326292
=================Random Agent Turn=================
Action taken: 47.275152
===============Feedback to learned agent round===============
Observation:
[1, array([38.5097751]), array([46.32629203])]
Reward: -2.000000, Currnt Bid: 46.326292
Is done? True
Episode End
Positive: 175, Negative: 291
EPISODE :- 948
Random Player utility: 105.979503
=================Random Agent Turn=================
Action taken: 102.063280
===============Feedback to learned agent round===============
Observation:
[0, 0, 102.06327993106176]
Reward: -1.000000, Currnt Bid: 102.063280
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[45.61898066]
Explore action: 45.618981
Action taken: 45.618981
===============Feedback to random agent round===============
Currnt Bid: 102.063280
=================Random Agent Turn=================
Action taken: 103.010482
===============Feedback to learned agent round===============
Observation:
[1, 0, 102.06327993106176]
Reward: -2.000000, Currnt Bid: 102.063280
Is done? True
Episode End
Positive: 175, Negative: 291
EPISODE :- 949
Random Player utility: 20.927605
=================Random Agent Turn=================
Action taken: 16.431024
===============Feedback to learned agent round===============
Observation:
[0, 0, 16.43102397983972]
Reward: -1.000000, Currnt Bid: 16.431024
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[28.79735189]
Explore action: 28.797352
Action taken: 28.797352
===============Feedback to random agent round===============
Currnt Bid: 28.797352
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([28.79735189]), 16.43102397983972]
Reward: 71.202648, Currnt Bid: 28.797352
Is done? True
Episode End
Positive: 176, Negative: 291
EPISODE :- 950
Random Player utility: 70.991349
=================Random Agent Turn=================
Action taken: 46.753707
===============Feedback to learned agent round===============
Observation:
[0, 0, 46.753706848651674]
Reward: -1.000000, Currnt Bid: 46.753707
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.000733
Exploit action: 0.000733
Action taken: 0.000733
===============Feedback to random agent round===============
Currnt Bid: 46.753707
=================Random Agent Turn=================
Action taken: 52.381485
===============Feedback to learned agent round===============
Observation:
[1, 0, 46.753706848651674]
Reward: -2.000000, Currnt Bid: 46.753707
Is done? True
Episode End
Positive: 176, Negative: 292
EPISODE :- 951
Random Player utility: 4.156100
=================Random Agent Turn=================
Action taken: 2.035867
===============Feedback to learned agent round===============
Observation:
[0, 0, 2.035867167972753]
Reward: -1.000000, Currnt Bid: 2.035867
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[32.27780413]
Explore action: 32.277804
Action taken: 32.277804
===============Feedback to random agent round===============
Currnt Bid: 32.277804
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([32.27780413]), 2.035867167972753]
Reward: 67.722196, Currnt Bid: 32.277804
Is done? True
Episode End
Positive: 177, Negative: 292
EPISODE :- 952
Random Player utility: 87.881798
=================Random Agent Turn=================
Action taken: 22.259568
===============Feedback to learned agent round===============
Observation:
[0, 0, 22.259567742325515]
Reward: -1.000000, Currnt Bid: 22.259568
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[36.56223656]
Explore action: 36.562237
Action taken: 36.562237
===============Feedback to random agent round===============
Currnt Bid: 36.562237
=================Random Agent Turn=================
Action taken: 50.835935
===============Feedback to learned agent round===============
Observation:
[0, array([36.56223656]), array([50.83593452])]
Reward: -1.000000, Currnt Bid: 50.835935
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[39.01253547]
Explore action: 39.012535
Action taken: 39.012535
===============Feedback to random agent round===============
Currnt Bid: 50.835935
=================Random Agent Turn=================
Action taken: 54.794176
===============Feedback to learned agent round===============
Observation:
[1, array([36.56223656]), array([50.83593452])]
Reward: -2.000000, Currnt Bid: 50.835935
Is done? True
Episode End
Positive: 177, Negative: 293
EPISODE :- 953
Random Player utility: 101.605932
=================Random Agent Turn=================
Action taken: 33.786420
===============Feedback to learned agent round===============
Observation:
[0, 0, 33.78641993130556]
Reward: -1.000000, Currnt Bid: 33.786420
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[34.12781065]
Explore action: 34.127811
Action taken: 34.127811
===============Feedback to random agent round===============
Currnt Bid: 34.127811
=================Random Agent Turn=================
Action taken: 63.974897
===============Feedback to learned agent round===============
Observation:
[0, array([34.12781065]), array([63.97489744])]
Reward: -1.000000, Currnt Bid: 63.974897
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[38.35735036]
Explore action: 38.357350
Action taken: 38.357350
===============Feedback to random agent round===============
Currnt Bid: 63.974897
=================Random Agent Turn=================
Action taken: 74.336094
===============Feedback to learned agent round===============
Observation:
[1, array([34.12781065]), array([63.97489744])]
Reward: -2.000000, Currnt Bid: 63.974897
Is done? True
Episode End
Positive: 177, Negative: 293
EPISODE :- 954
Random Player utility: 125.361451
=================Random Agent Turn=================
Action taken: 49.968205
===============Feedback to learned agent round===============
Observation:
[0, 0, 49.96820484488953]
Reward: -1.000000, Currnt Bid: 49.968205
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[32.29696237]
Explore action: 32.296962
Action taken: 32.296962
===============Feedback to random agent round===============
Currnt Bid: 49.968205
=================Random Agent Turn=================
Action taken: 73.537255
===============Feedback to learned agent round===============
Observation:
[1, 0, 49.96820484488953]
Reward: -2.000000, Currnt Bid: 49.968205
Is done? True
Episode End
Positive: 177, Negative: 293
EPISODE :- 955
Random Player utility: 43.032794
=================Random Agent Turn=================
Action taken: 17.952139
===============Feedback to learned agent round===============
Observation:
[0, 0, 17.952138990171285]
Reward: -1.000000, Currnt Bid: 17.952139
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.000691
Exploit action: 0.000691
Action taken: 0.000691
===============Feedback to random agent round===============
Currnt Bid: 17.952139
=================Random Agent Turn=================
Action taken: 28.059763
===============Feedback to learned agent round===============
Observation:
[1, 0, 17.952138990171285]
Reward: -2.000000, Currnt Bid: 17.952139
Is done? True
Episode End
Positive: 177, Negative: 294
EPISODE :- 956
Random Player utility: 43.924070
=================Random Agent Turn=================
Action taken: 9.430461
===============Feedback to learned agent round===============
Observation:
[0, 0, 9.430460962796404]
Reward: -1.000000, Currnt Bid: 9.430461
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[17.15990833]
Explore action: 17.159908
Action taken: 17.159908
===============Feedback to random agent round===============
Currnt Bid: 17.159908
=================Random Agent Turn=================
Action taken: 24.386209
===============Feedback to learned agent round===============
Observation:
[0, array([17.15990833]), array([24.38620893])]
Reward: -1.000000, Currnt Bid: 24.386209
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[20.00763782]
Explore action: 20.007638
Action taken: 20.007638
===============Feedback to random agent round===============
Currnt Bid: 24.386209
=================Random Agent Turn=================
Action taken: 42.911717
===============Feedback to learned agent round===============
Observation:
[1, array([17.15990833]), array([24.38620893])]
Reward: -2.000000, Currnt Bid: 24.386209
Is done? True
Episode End
Positive: 177, Negative: 295
EPISODE :- 957
Random Player utility: 82.748420
=================Random Agent Turn=================
Action taken: 82.480505
===============Feedback to learned agent round===============
Observation:
[0, 0, 82.4805052288289]
Reward: -1.000000, Currnt Bid: 82.480505
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[19.52204221]
Explore action: 19.522042
Action taken: 19.522042
===============Feedback to random agent round===============
Currnt Bid: 82.480505
=================Random Agent Turn=================
Action taken: 82.701051
===============Feedback to learned agent round===============
Observation:
[1, 0, 82.4805052288289]
Reward: -2.000000, Currnt Bid: 82.480505
Is done? True
Episode End
Positive: 177, Negative: 296
EPISODE :- 958
Random Player utility: 122.258084
=================Random Agent Turn=================
Action taken: 95.965079
===============Feedback to learned agent round===============
Observation:
[0, 0, 95.9650790003388]
Reward: -1.000000, Currnt Bid: 95.965079
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[37.0567859]
Explore action: 37.056786
Action taken: 37.056786
===============Feedback to random agent round===============
Currnt Bid: 95.965079
=================Random Agent Turn=================
Action taken: 105.946753
===============Feedback to learned agent round===============
Observation:
[1, 0, 95.9650790003388]
Reward: -2.000000, Currnt Bid: 95.965079
Is done? True
Episode End
Positive: 177, Negative: 296
EPISODE :- 959
Random Player utility: 43.881058
=================Random Agent Turn=================
Action taken: 7.389470
===============Feedback to learned agent round===============
Observation:
[0, 0, 7.389469802708348]
Reward: -1.000000, Currnt Bid: 7.389470
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[39.1704428]
Explore action: 39.170443
Action taken: 39.170443
===============Feedback to random agent round===============
Currnt Bid: 39.170443
=================Random Agent Turn=================
Action taken: 41.363969
===============Feedback to learned agent round===============
Observation:
[0, array([39.1704428]), array([41.36396933])]
Reward: -1.000000, Currnt Bid: 41.363969
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[44.33744489]
Explore action: 44.337445
Action taken: 44.337445
===============Feedback to random agent round===============
Currnt Bid: 44.337445
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([44.33744489]), array([41.36396933])]
Reward: 55.662555, Currnt Bid: 44.337445
Is done? True
Episode End
Positive: 178, Negative: 296
EPISODE :- 960
Random Player utility: 193.974124
=================Random Agent Turn=================
Action taken: 105.855125
===============Feedback to learned agent round===============
Observation:
[0, 0, 105.855124902657]
Reward: -1.000000, Currnt Bid: 105.855125
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.000656
Exploit action: 0.000656
Action taken: 0.000656
===============Feedback to random agent round===============
Currnt Bid: 105.855125
=================Random Agent Turn=================
Action taken: 138.009131
===============Feedback to learned agent round===============
Observation:
[1, 0, 105.855124902657]
Reward: -2.000000, Currnt Bid: 105.855125
Is done? True
Episode End
Positive: 178, Negative: 296
EPISODE :- 961
Random Player utility: 103.677190
=================Random Agent Turn=================
Action taken: 46.278734
===============Feedback to learned agent round===============
Observation:
[0, 0, 46.27873437373299]
Reward: -1.000000, Currnt Bid: 46.278734
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[42.84984272]
Explore action: 42.849843
Action taken: 42.849843
===============Feedback to random agent round===============
Currnt Bid: 46.278734
=================Random Agent Turn=================
Action taken: 75.240245
===============Feedback to learned agent round===============
Observation:
[1, 0, 46.27873437373299]
Reward: -2.000000, Currnt Bid: 46.278734
Is done? True
Episode End
Positive: 178, Negative: 296
EPISODE :- 962
Random Player utility: 53.913299
=================Random Agent Turn=================
Action taken: 40.990710
===============Feedback to learned agent round===============
Observation:
[0, 0, 40.99070976440506]
Reward: -1.000000, Currnt Bid: 40.990710
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.48471866]
Explore action: 48.484719
Action taken: 48.484719
===============Feedback to random agent round===============
Currnt Bid: 48.484719
=================Random Agent Turn=================
Action taken: 52.220838
===============Feedback to learned agent round===============
Observation:
[0, array([48.48471866]), array([52.22083845])]
Reward: -1.000000, Currnt Bid: 52.220838
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[55.91152484]
Explore action: 55.911525
Action taken: 55.911525
===============Feedback to random agent round===============
Currnt Bid: 55.911525
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([55.91152484]), array([52.22083845])]
Reward: 44.088475, Currnt Bid: 55.911525
Is done? True
Episode End
Positive: 179, Negative: 296
EPISODE :- 963
Random Player utility: 236.129064
=================Random Agent Turn=================
Action taken: 80.736423
===============Feedback to learned agent round===============
Observation:
[0, 0, 80.73642286023261]
Reward: -1.000000, Currnt Bid: 80.736423
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[54.40860519]
Explore action: 54.408605
Action taken: 54.408605
===============Feedback to random agent round===============
Currnt Bid: 80.736423
=================Random Agent Turn=================
Action taken: 154.358648
===============Feedback to learned agent round===============
Observation:
[1, 0, 80.73642286023261]
Reward: -2.000000, Currnt Bid: 80.736423
Is done? True
Episode End
Positive: 179, Negative: 296
EPISODE :- 964
Random Player utility: 88.932068
=================Random Agent Turn=================
Action taken: 2.794207
===============Feedback to learned agent round===============
Observation:
[0, 0, 2.7942071431567097]
Reward: -1.000000, Currnt Bid: 2.794207
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[49.056089]
Explore action: 49.056089
Action taken: 49.056089
===============Feedback to random agent round===============
Currnt Bid: 49.056089
=================Random Agent Turn=================
Action taken: 79.088761
===============Feedback to learned agent round===============
Observation:
[0, array([49.056089]), array([79.08876114])]
Reward: -1.000000, Currnt Bid: 79.088761
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[40.29867752]
Explore action: 40.298678
Action taken: 40.298678
===============Feedback to random agent round===============
Currnt Bid: 79.088761
=================Random Agent Turn=================
Action taken: 83.997534
===============Feedback to learned agent round===============
Observation:
[1, array([49.056089]), array([79.08876114])]
Reward: -2.000000, Currnt Bid: 79.088761
Is done? True
Episode End
Positive: 179, Negative: 297
EPISODE :- 965
Random Player utility: 171.909798
=================Random Agent Turn=================
Action taken: 3.520383
===============Feedback to learned agent round===============
Observation:
[0, 0, 3.5203831641052292]
Reward: -1.000000, Currnt Bid: 3.520383
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.000620
Exploit action: 0.000620
Action taken: 0.000620
===============Feedback to random agent round===============
Currnt Bid: 3.520383
=================Random Agent Turn=================
Action taken: 60.762438
===============Feedback to learned agent round===============
Observation:
[1, 0, 3.5203831641052292]
Reward: -2.000000, Currnt Bid: 3.520383
Is done? True
Episode End
Positive: 179, Negative: 297
EPISODE :- 966
Random Player utility: 171.664124
=================Random Agent Turn=================
Action taken: 107.931859
===============Feedback to learned agent round===============
Observation:
[0, 0, 107.93185874782186]
Reward: -1.000000, Currnt Bid: 107.931859
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[32.98326854]
Explore action: 32.983269
Action taken: 32.983269
===============Feedback to random agent round===============
Currnt Bid: 107.931859
=================Random Agent Turn=================
Action taken: 111.723841
===============Feedback to learned agent round===============
Observation:
[1, 0, 107.93185874782186]
Reward: -2.000000, Currnt Bid: 107.931859
Is done? True
Episode End
Positive: 179, Negative: 297
EPISODE :- 967
Random Player utility: 13.054096
=================Random Agent Turn=================
Action taken: 3.010020
===============Feedback to learned agent round===============
Observation:
[0, 0, 3.010020055457403]
Reward: -1.000000, Currnt Bid: 3.010020
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[36.22514305]
Explore action: 36.225143
Action taken: 36.225143
===============Feedback to random agent round===============
Currnt Bid: 36.225143
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([36.22514305]), 3.010020055457403]
Reward: 63.774857, Currnt Bid: 36.225143
Is done? True
Episode End
Positive: 180, Negative: 297
EPISODE :- 968
Random Player utility: 102.618928
=================Random Agent Turn=================
Action taken: 2.797491
===============Feedback to learned agent round===============
Observation:
[0, 0, 2.7974908587048843]
Reward: -1.000000, Currnt Bid: 2.797491
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[52.86352952]
Explore action: 52.863530
Action taken: 52.863530
===============Feedback to random agent round===============
Currnt Bid: 52.863530
=================Random Agent Turn=================
Action taken: 97.855829
===============Feedback to learned agent round===============
Observation:
[0, array([52.86352952]), array([97.85582879])]
Reward: -1.000000, Currnt Bid: 97.855829
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[42.54840735]
Explore action: 42.548407
Action taken: 42.548407
===============Feedback to random agent round===============
Currnt Bid: 97.855829
=================Random Agent Turn=================
Action taken: 98.541952
===============Feedback to learned agent round===============
Observation:
[1, array([52.86352952]), array([97.85582879])]
Reward: -2.000000, Currnt Bid: 97.855829
Is done? True
Episode End
Positive: 180, Negative: 297
EPISODE :- 969
Random Player utility: 0.726415
=================Random Agent Turn=================
Action taken: 0.284978
===============Feedback to learned agent round===============
Observation:
[0, 0, 0.2849780545280518]
Reward: -1.000000, Currnt Bid: 0.284978
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[28.8563116]
Explore action: 28.856312
Action taken: 28.856312
===============Feedback to random agent round===============
Currnt Bid: 28.856312
=================Random Agent Turn=================
Action taken: 0.000000
===============Feedback to learned agent round===============
Observation:
[1, array([28.8563116]), 0.2849780545280518]
Reward: 71.143688, Currnt Bid: 28.856312
Is done? True
Episode End
Positive: 181, Negative: 297
EPISODE :- 970
Random Player utility: 79.510483
=================Random Agent Turn=================
Action taken: 78.818141
===============Feedback to learned agent round===============
Observation:
[0, 0, 78.81814069693768]
Reward: -1.000000, Currnt Bid: 78.818141
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.000590
Exploit action: 0.000590
Action taken: 0.000590
===============Feedback to random agent round===============
Currnt Bid: 78.818141
=================Random Agent Turn=================
Action taken: 79.134505
===============Feedback to learned agent round===============
Observation:
[1, 0, 78.81814069693768]
Reward: -2.000000, Currnt Bid: 78.818141
Is done? True
Episode End
Positive: 181, Negative: 298
EPISODE :- 971
Random Player utility: 152.607989
=================Random Agent Turn=================
Action taken: 129.121434
===============Feedback to learned agent round===============
Observation:
[0, 0, 129.12143431635354]
Reward: -1.000000, Currnt Bid: 129.121434
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[30.52213019]
Explore action: 30.522130
Action taken: 30.522130
===============Feedback to random agent round===============
Currnt Bid: 129.121434
=================Random Agent Turn=================
Action taken: 152.096824
===============Feedback to learned agent round===============
Observation:
[1, 0, 129.12143431635354]
Reward: -2.000000, Currnt Bid: 129.121434
Is done? True
Episode End
Positive: 181, Negative: 298
EPISODE :- 972
Random Player utility: 33.258700
=================Random Agent Turn=================
Action taken: 18.332162
===============Feedback to learned agent round===============
Observation:
[0, 0, 18.332161671820437]
Reward: -1.000000, Currnt Bid: 18.332162
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[29.69602489]
Explore action: 29.696025
Action taken: 29.696025
===============Feedback to random agent round===============
Currnt Bid: 29.696025
=================Random Agent Turn=================
Action taken: 31.833597
===============Feedback to learned agent round===============
Observation:
[0, array([29.69602489]), array([31.83359722])]
Reward: -1.000000, Currnt Bid: 31.833597
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[16.85312767]
Explore action: 16.853128
Action taken: 16.853128
===============Feedback to random agent round===============
Currnt Bid: 31.833597
=================Random Agent Turn=================
Action taken: 32.695899
===============Feedback to learned agent round===============
Observation:
[1, array([29.69602489]), array([31.83359722])]
Reward: -2.000000, Currnt Bid: 31.833597
Is done? True
Episode End
Positive: 181, Negative: 299
EPISODE :- 973
Random Player utility: 80.111739
=================Random Agent Turn=================
Action taken: 16.256447
===============Feedback to learned agent round===============
Observation:
[0, 0, 16.25644743841439]
Reward: -1.000000, Currnt Bid: 16.256447
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[24.73083886]
Explore action: 24.730839
Action taken: 24.730839
===============Feedback to random agent round===============
Currnt Bid: 24.730839
=================Random Agent Turn=================
Action taken: 57.133208
===============Feedback to learned agent round===============
Observation:
[0, array([24.73083886]), array([57.13320793])]
Reward: -1.000000, Currnt Bid: 57.133208
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[32.585922]
Explore action: 32.585922
Action taken: 32.585922
===============Feedback to random agent round===============
Currnt Bid: 57.133208
=================Random Agent Turn=================
Action taken: 60.289012
===============Feedback to learned agent round===============
Observation:
[1, array([24.73083886]), array([57.13320793])]
Reward: -2.000000, Currnt Bid: 57.133208
Is done? True
Episode End
Positive: 181, Negative: 300
EPISODE :- 974
Random Player utility: 218.207149
=================Random Agent Turn=================
Action taken: 169.377757
===============Feedback to learned agent round===============
Observation:
[0, 0, 169.37775657199333]
Reward: -1.000000, Currnt Bid: 169.377757
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[32.06134058]
Explore action: 32.061341
Action taken: 32.061341
===============Feedback to random agent round===============
Currnt Bid: 169.377757
=================Random Agent Turn=================
Action taken: 172.524285
===============Feedback to learned agent round===============
Observation:
[1, 0, 169.37775657199333]
Reward: -2.000000, Currnt Bid: 169.377757
Is done? True
Episode End
Positive: 181, Negative: 300
EPISODE :- 975
Random Player utility: 72.550724
=================Random Agent Turn=================
Action taken: 11.019587
===============Feedback to learned agent round===============
Observation:
[0, 0, 11.019587470244645]
Reward: -1.000000, Currnt Bid: 11.019587
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.000560
Exploit action: 0.000560
Action taken: 0.000560
===============Feedback to random agent round===============
Currnt Bid: 11.019587
=================Random Agent Turn=================
Action taken: 31.239329
===============Feedback to learned agent round===============
Observation:
[1, 0, 11.019587470244645]
Reward: -2.000000, Currnt Bid: 11.019587
Is done? True
Episode End
Positive: 181, Negative: 301
EPISODE :- 976
Random Player utility: 114.084912
=================Random Agent Turn=================
Action taken: 61.258423
===============Feedback to learned agent round===============
Observation:
[0, 0, 61.258422861514894]
Reward: -1.000000, Currnt Bid: 61.258423
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[10.61330787]
Explore action: 10.613308
Action taken: 10.613308
===============Feedback to random agent round===============
Currnt Bid: 61.258423
=================Random Agent Turn=================
Action taken: 91.546088
===============Feedback to learned agent round===============
Observation:
[1, 0, 61.258422861514894]
Reward: -2.000000, Currnt Bid: 61.258423
Is done? True
Episode End
Positive: 181, Negative: 301
EPISODE :- 977
Random Player utility: 96.585831
=================Random Agent Turn=================
Action taken: 85.014974
===============Feedback to learned agent round===============
Observation:
[0, 0, 85.0149740539569]
Reward: -1.000000, Currnt Bid: 85.014974
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[17.11384516]
Explore action: 17.113845
Action taken: 17.113845
===============Feedback to random agent round===============
Currnt Bid: 85.014974
=================Random Agent Turn=================
Action taken: 87.413339
===============Feedback to learned agent round===============
Observation:
[1, 0, 85.0149740539569]
Reward: -2.000000, Currnt Bid: 85.014974
Is done? True
Episode End
Positive: 181, Negative: 302
EPISODE :- 978
Random Player utility: 60.643415
=================Random Agent Turn=================
Action taken: 23.436716
===============Feedback to learned agent round===============
Observation:
[0, 0, 23.43671636339688]
Reward: -1.000000, Currnt Bid: 23.436716
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[27.55174077]
Explore action: 27.551741
Action taken: 27.551741
===============Feedback to random agent round===============
Currnt Bid: 27.551741
=================Random Agent Turn=================
Action taken: 56.243157
===============Feedback to learned agent round===============
Observation:
[0, array([27.55174077]), array([56.24315658])]
Reward: -1.000000, Currnt Bid: 56.243157
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[23.33824781]
Explore action: 23.338248
Action taken: 23.338248
===============Feedback to random agent round===============
Currnt Bid: 56.243157
=================Random Agent Turn=================
Action taken: 59.011527
===============Feedback to learned agent round===============
Observation:
[1, array([27.55174077]), array([56.24315658])]
Reward: -2.000000, Currnt Bid: 56.243157
Is done? True
Episode End
Positive: 181, Negative: 303
EPISODE :- 979
Random Player utility: 26.669423
=================Random Agent Turn=================
Action taken: 17.836556
===============Feedback to learned agent round===============
Observation:
[0, 0, 17.836556101016352]
Reward: -1.000000, Currnt Bid: 17.836556
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[10.3601538]
Explore action: 10.360154
Action taken: 10.360154
===============Feedback to random agent round===============
Currnt Bid: 17.836556
=================Random Agent Turn=================
Action taken: 26.418544
===============Feedback to learned agent round===============
Observation:
[1, 0, 17.836556101016352]
Reward: -2.000000, Currnt Bid: 17.836556
Is done? True
Episode End
Positive: 181, Negative: 304
EPISODE :- 980
Random Player utility: 54.081549
=================Random Agent Turn=================
Action taken: 28.922097
===============Feedback to learned agent round===============
Observation:
[0, 0, 28.9220969750519]
Reward: -1.000000, Currnt Bid: 28.922097
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.000530
Exploit action: 0.000530
Action taken: 0.000530
===============Feedback to random agent round===============
Currnt Bid: 28.922097
=================Random Agent Turn=================
Action taken: 44.882928
===============Feedback to learned agent round===============
Observation:
[1, 0, 28.9220969750519]
Reward: -2.000000, Currnt Bid: 28.922097
Is done? True
Episode End
Positive: 181, Negative: 305
EPISODE :- 981
Random Player utility: 121.913599
=================Random Agent Turn=================
Action taken: 33.378794
===============Feedback to learned agent round===============
Observation:
[0, 0, 33.3787941880901]
Reward: -1.000000, Currnt Bid: 33.378794
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[18.76551305]
Explore action: 18.765513
Action taken: 18.765513
===============Feedback to random agent round===============
Currnt Bid: 33.378794
=================Random Agent Turn=================
Action taken: 61.414583
===============Feedback to learned agent round===============
Observation:
[1, 0, 33.3787941880901]
Reward: -2.000000, Currnt Bid: 33.378794
Is done? True
Episode End
Positive: 181, Negative: 305
EPISODE :- 982
Random Player utility: 104.331128
=================Random Agent Turn=================
Action taken: 34.018284
===============Feedback to learned agent round===============
Observation:
[0, 0, 34.018284076976826]
Reward: -1.000000, Currnt Bid: 34.018284
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[18.97345856]
Explore action: 18.973459
Action taken: 18.973459
===============Feedback to random agent round===============
Currnt Bid: 34.018284
=================Random Agent Turn=================
Action taken: 95.324325
===============Feedback to learned agent round===============
Observation:
[1, 0, 34.018284076976826]
Reward: -2.000000, Currnt Bid: 34.018284
Is done? True
Episode End
Positive: 181, Negative: 305
EPISODE :- 983
Random Player utility: 122.362398
=================Random Agent Turn=================
Action taken: 10.525321
===============Feedback to learned agent round===============
Observation:
[0, 0, 10.525320900697276]
Reward: -1.000000, Currnt Bid: 10.525321
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[27.94851145]
Explore action: 27.948511
Action taken: 27.948511
===============Feedback to random agent round===============
Currnt Bid: 27.948511
=================Random Agent Turn=================
Action taken: 53.577090
===============Feedback to learned agent round===============
Observation:
[0, array([27.94851145]), array([53.57709003])]
Reward: -1.000000, Currnt Bid: 53.577090
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[51.61121882]
Explore action: 51.611219
Action taken: 51.611219
===============Feedback to random agent round===============
Currnt Bid: 53.577090
=================Random Agent Turn=================
Action taken: 105.655106
===============Feedback to learned agent round===============
Observation:
[1, array([27.94851145]), array([53.57709003])]
Reward: -2.000000, Currnt Bid: 53.577090
Is done? True
Episode End
Positive: 181, Negative: 305
EPISODE :- 984
Random Player utility: 144.913453
=================Random Agent Turn=================
Action taken: 87.840530
===============Feedback to learned agent round===============
Observation:
[0, 0, 87.84053042484702]
Reward: -1.000000, Currnt Bid: 87.840530
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[36.38384909]
Explore action: 36.383849
Action taken: 36.383849
===============Feedback to random agent round===============
Currnt Bid: 87.840530
=================Random Agent Turn=================
Action taken: 138.228008
===============Feedback to learned agent round===============
Observation:
[1, 0, 87.84053042484702]
Reward: -2.000000, Currnt Bid: 87.840530
Is done? True
Episode End
Positive: 181, Negative: 305
EPISODE :- 985
Random Player utility: 92.537698
=================Random Agent Turn=================
Action taken: 70.076269
===============Feedback to learned agent round===============
Observation:
[0, 0, 70.0762691939552]
Reward: -1.000000, Currnt Bid: 70.076269
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.000507
Exploit action: 0.000507
Action taken: 0.000507
===============Feedback to random agent round===============
Currnt Bid: 70.076269
=================Random Agent Turn=================
Action taken: 91.913561
===============Feedback to learned agent round===============
Observation:
[1, 0, 70.0762691939552]
Reward: -2.000000, Currnt Bid: 70.076269
Is done? True
Episode End
Positive: 181, Negative: 306
EPISODE :- 986
Random Player utility: 97.877022
=================Random Agent Turn=================
Action taken: 63.763049
===============Feedback to learned agent round===============
Observation:
[0, 0, 63.76304870380059]
Reward: -1.000000, Currnt Bid: 63.763049
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[18.0809533]
Explore action: 18.080953
Action taken: 18.080953
===============Feedback to random agent round===============
Currnt Bid: 63.763049
=================Random Agent Turn=================
Action taken: 72.756182
===============Feedback to learned agent round===============
Observation:
[1, 0, 63.76304870380059]
Reward: -2.000000, Currnt Bid: 63.763049
Is done? True
Episode End
Positive: 181, Negative: 307
EPISODE :- 987
Random Player utility: 116.458453
=================Random Agent Turn=================
Action taken: 85.259370
===============Feedback to learned agent round===============
Observation:
[0, 0, 85.25936981010443]
Reward: -1.000000, Currnt Bid: 85.259370
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[19.09696064]
Explore action: 19.096961
Action taken: 19.096961
===============Feedback to random agent round===============
Currnt Bid: 85.259370
=================Random Agent Turn=================
Action taken: 100.598943
===============Feedback to learned agent round===============
Observation:
[1, 0, 85.25936981010443]
Reward: -2.000000, Currnt Bid: 85.259370
Is done? True
Episode End
Positive: 181, Negative: 307
EPISODE :- 988
Random Player utility: 137.656791
=================Random Agent Turn=================
Action taken: 45.009967
===============Feedback to learned agent round===============
Observation:
[0, 0, 45.00996706478233]
Reward: -1.000000, Currnt Bid: 45.009967
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[7.98712656]
Explore action: 7.987127
Action taken: 7.987127
===============Feedback to random agent round===============
Currnt Bid: 45.009967
=================Random Agent Turn=================
Action taken: 124.088931
===============Feedback to learned agent round===============
Observation:
[1, 0, 45.00996706478233]
Reward: -2.000000, Currnt Bid: 45.009967
Is done? True
Episode End
Positive: 181, Negative: 307
EPISODE :- 989
Random Player utility: 48.256240
=================Random Agent Turn=================
Action taken: 29.147928
===============Feedback to learned agent round===============
Observation:
[0, 0, 29.147927626472075]
Reward: -1.000000, Currnt Bid: 29.147928
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[-12.39220058]
Explore action: -12.392201
Action taken: -12.392201
===============Feedback to random agent round===============
Currnt Bid: 29.147928
=================Random Agent Turn=================
Action taken: 32.741029
===============Feedback to learned agent round===============
Observation:
[1, 0, 29.147927626472075]
Reward: -2.000000, Currnt Bid: 29.147928
Is done? True
Episode End
Positive: 181, Negative: 308
EPISODE :- 990
Random Player utility: 177.381515
=================Random Agent Turn=================
Action taken: 3.015128
===============Feedback to learned agent round===============
Observation:
[0, 0, 3.015127797629385]
Reward: -1.000000, Currnt Bid: 3.015128
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.000483
Exploit action: 0.000483
Action taken: 0.000483
===============Feedback to random agent round===============
Currnt Bid: 3.015128
=================Random Agent Turn=================
Action taken: 57.914163
===============Feedback to learned agent round===============
Observation:
[1, 0, 3.015127797629385]
Reward: -2.000000, Currnt Bid: 3.015128
Is done? True
Episode End
Positive: 181, Negative: 308
EPISODE :- 991
Random Player utility: 153.403624
=================Random Agent Turn=================
Action taken: 33.678039
===============Feedback to learned agent round===============
Observation:
[0, 0, 33.67803853259352]
Reward: -1.000000, Currnt Bid: 33.678039
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[14.26118115]
Explore action: 14.261181
Action taken: 14.261181
===============Feedback to random agent round===============
Currnt Bid: 33.678039
=================Random Agent Turn=================
Action taken: 112.923497
===============Feedback to learned agent round===============
Observation:
[1, 0, 33.67803853259352]
Reward: -2.000000, Currnt Bid: 33.678039
Is done? True
Episode End
Positive: 181, Negative: 308
EPISODE :- 992
Random Player utility: 46.538369
=================Random Agent Turn=================
Action taken: 30.918630
===============Feedback to learned agent round===============
Observation:
[0, 0, 30.918630149310257]
Reward: -1.000000, Currnt Bid: 30.918630
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[9.86057326]
Explore action: 9.860573
Action taken: 9.860573
===============Feedback to random agent round===============
Currnt Bid: 30.918630
=================Random Agent Turn=================
Action taken: 44.591991
===============Feedback to learned agent round===============
Observation:
[1, 0, 30.918630149310257]
Reward: -2.000000, Currnt Bid: 30.918630
Is done? True
Episode End
Positive: 181, Negative: 309
EPISODE :- 993
Random Player utility: 108.747918
=================Random Agent Turn=================
Action taken: 98.467388
===============Feedback to learned agent round===============
Observation:
[0, 0, 98.46738819836763]
Reward: -1.000000, Currnt Bid: 98.467388
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[27.65095563]
Explore action: 27.650956
Action taken: 27.650956
===============Feedback to random agent round===============
Currnt Bid: 98.467388
=================Random Agent Turn=================
Action taken: 104.656386
===============Feedback to learned agent round===============
Observation:
[1, 0, 98.46738819836763]
Reward: -2.000000, Currnt Bid: 98.467388
Is done? True
Episode End
Positive: 181, Negative: 309
EPISODE :- 994
Random Player utility: 74.354061
=================Random Agent Turn=================
Action taken: 49.171262
===============Feedback to learned agent round===============
Observation:
[0, 0, 49.171262388534885]
Reward: -1.000000, Currnt Bid: 49.171262
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[31.31137516]
Explore action: 31.311375
Action taken: 31.311375
===============Feedback to random agent round===============
Currnt Bid: 49.171262
=================Random Agent Turn=================
Action taken: 53.819276
===============Feedback to learned agent round===============
Observation:
[1, 0, 49.171262388534885]
Reward: -2.000000, Currnt Bid: 49.171262
Is done? True
Episode End
Positive: 181, Negative: 310
EPISODE :- 995
Random Player utility: 45.777064
=================Random Agent Turn=================
Action taken: 4.748330
===============Feedback to learned agent round===============
Observation:
[0, 0, 4.748329683933411]
Reward: -1.000000, Currnt Bid: 4.748330
Is done? False
=================Learned Agent Turn=================
Forwarded Action: 0.000465
Exploit action: 0.000465
Action taken: 0.000465
===============Feedback to random agent round===============
Currnt Bid: 4.748330
=================Random Agent Turn=================
Action taken: 41.122617
===============Feedback to learned agent round===============
Observation:
[1, 0, 4.748329683933411]
Reward: -2.000000, Currnt Bid: 4.748330
Is done? True
Episode End
Positive: 181, Negative: 311
EPISODE :- 996
Random Player utility: 95.032799
=================Random Agent Turn=================
Action taken: 37.502089
===============Feedback to learned agent round===============
Observation:
[0, 0, 37.50208853032874]
Reward: -1.000000, Currnt Bid: 37.502089
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[35.79398635]
Explore action: 35.793986
Action taken: 35.793986
===============Feedback to random agent round===============
Currnt Bid: 37.502089
=================Random Agent Turn=================
Action taken: 78.662254
===============Feedback to learned agent round===============
Observation:
[1, 0, 37.50208853032874]
Reward: -2.000000, Currnt Bid: 37.502089
Is done? True
Episode End
Positive: 181, Negative: 312
EPISODE :- 997
Random Player utility: 108.255194
=================Random Agent Turn=================
Action taken: 12.713481
===============Feedback to learned agent round===============
Observation:
[0, 0, 12.713480611275106]
Reward: -1.000000, Currnt Bid: 12.713481
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[48.85054617]
Explore action: 48.850546
Action taken: 48.850546
===============Feedback to random agent round===============
Currnt Bid: 48.850546
=================Random Agent Turn=================
Action taken: 107.791202
===============Feedback to learned agent round===============
Observation:
[0, array([48.85054617]), array([107.79120238])]
Reward: -1.000000, Currnt Bid: 107.791202
Is done? False
=================Learned Agent Turn=================
Before exploration
tensor([0.])
After exploration
[65.08834591]
Explore action: 65.088346
Action taken: 65.088346
===============Feedback to random agent round===============
Currnt Bid: 107.791202
=================Random Agent Turn=================